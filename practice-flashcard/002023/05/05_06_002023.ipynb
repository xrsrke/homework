{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92a1e823-1df9-4d70-8910-2e150850340e",
   "metadata": {},
   "source": [
    "### Sci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74a686e-bf85-473c-9e89-e4684bc09729",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4da4b3e-5f35-46c3-90fb-da35e49d24fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnparallellinear, rowparallellinear, gelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2d386e-235d-4a0e-a00c-dadf99f40e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f252f82-9f1a-4eb3-a153-4c08b9ec33fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_column_parallelism(inputs, weights):\n",
    "    n_cols = weight.shape[-1]\n",
    "    \n",
    "    w1, w2 = weights[:, :n_cols//2], weights[:, n_cols//2:]\n",
    "    \n",
    "    out1 = inputs @ w1\n",
    "    out2 = inputs @ w2\n",
    "    \n",
    "    return torch.cat([out1, out2], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c19d173-bfbe-4388-8f82-862e8e6924eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def forward(self, x, labels):\n",
    "        preds = self.net(x)\n",
    "        loss = loss_func(preds, labels)\n",
    "        return preds, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a13e0b-cd6b-40e0-b493-3728f9ad0934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_memory(model):\n",
    "    total_memory = 0\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        total_memory = param.storage.size() *  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d4b505-04f0-49ec-a93c-0cc1041a3ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: scale the loss\n",
    "step 2: compute the gradient with respect to the scaled loss\n",
    "step 3: unscale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9ad40e-18ce-43b3-8d04-0addce7557b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_forward_pass_using_data_parallelism(\n",
    "    model, input, device_ids, output_id\n",
    "):\n",
    "    inputs = nn.parallel.scatter(input, device_ids)\n",
    "    models = nn.parallel.replicate(model, device_ids)\n",
    "    \n",
    "    logit = nn.parallel.parallel_apply(models, inputs)\n",
    "    logits = nn.parallel.gather(logits, output_id)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28efc765-9ec6-428c-90f3-5d512f6d3b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RowParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        self.input_size = input_size\n",
    "        self.output_size_per_patrition = output_size // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_patrition,\n",
    "            self.input_size\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_patrition\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3548b50a-430c-4d2b-a3ef-cd0493550302",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter, broadcast, gather, reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9046a2c-9a53-4f4f-b97d-86c090488fd2",
   "metadata": {},
   "source": [
    "### ML Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96306c38-16cb-4de9-a840-08855670f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "@resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5758617c-c730-424f-a0d6-0e60acf58218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2306b53-f454-420b-a577-3306f0c5bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, Integer, String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc1ee05-7e27-4e3d-bbb5-0c1305aee37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class User(Base):\n",
    "    __tablename__ = \"users\"\n",
    "    \n",
    "    id = Column(\"id\", Integer, primary_key=True)\n",
    "    username = Column(\"username\", String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b499df-862c-4955-acd4-369fc40f6d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5d6c4f-8ea9-4c10-a283-f3795a145fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['echo', 'hello world'], returncode=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"echo\", \"hello world\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb19481e-bc1f-49f1-a916-6386e30d4ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, String, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602b2c3d-058e-4935-a395-5db0a88ba115",
   "metadata": {},
   "outputs": [],
   "source": [
    "class User(Base):\n",
    "    __tablename__ = \"users\"\n",
    "    \n",
    "    id = Column(\"id\", Integer, primary_key=True)\n",
    "    username = Column(\"username\", Strin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee39a6-a5e7-41cd-ac5f-03fd22baaf83",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6b6826-d036-4eaf-9265-71f201aff27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee0c1d3-40c5-44e0-a48d-8cfe4939b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RowParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        self.input_size_per_patrition = input_size // world_size\n",
    "        self.output_size = output_size\n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.input_size_per_patrition,\n",
    "            self.output_size\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.empty(\n",
    "            self.input_size_per_patrition\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        world_size = torch.distributed.get_world_size\n",
    "        \n",
    "        last_dim_size = input.shape[-1]\n",
    "        dim_per_patrition = last_dim_size // world_size\n",
    "        input_chunks = torch.chunk(input, dim_per_patrition, dim=-1)\n",
    "        \n",
    "        input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082826b5-ff09-43f2-bc51-cc414e18b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class f(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e8f15a-b542-4f99-9373-35926085d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "class g(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        inputs = [torch.empty_like(input) for _ in range(world_size)]\n",
    "        torch.distributed.all_gather(inputs, input)\n",
    "        inputs = torch.cat(inputs, dim=-1)\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, input):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ad7b74-17c8-4ba5-b06b-80b72357b8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size, world_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size_per_patrition = output_size // world_size\n",
    "        self.world_size = world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_patrition,\n",
    "            self.input_size\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_patrition\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_parallel = f.apply(input)\n",
    "        \n",
    "        output_parallel = F.linear(input, self.weight, self.bias)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e3fb14-a139-41f0-ae15-c389d8f9ab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_row_parallelism(inputs, weights):\n",
    "    n_cols = weights.shape[-1]\n",
    "    \n",
    "    x1, x2 = inputs[:, :n_cols//2], x[:, n_cols//2:]\n",
    "    w1, w2 = weights[:n_cols//2, :], weights[n_cols//2:, :]\n",
    "    \n",
    "    out1 = x1 @ w1\n",
    "    out2 = x2 @ w2\n",
    "    \n",
    "    return out1 + out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c4e531-8208-4589-a0cd-fdbf3dbee238",
   "metadata": {},
   "outputs": [],
   "source": [
    "message passing, p2p, collective communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24da983c-111d-4d44-8fa7-71649bcb2be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "source code > compiler > os > hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e579a2f-0bd4-496f-bb05-3c382d2b5ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RowParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        self.input_size_per_patrition = input_size // world_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.output_size,\n",
    "            self.input_size_per_patrition,\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.empty(\n",
    "            self.input_size_per_patrition\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        rank = torch.distributed.get_rank()\n",
    "        \n",
    "        last_dim_size = input.shape[-1]\n",
    "        n_chunks = last_dim_size // world_size\n",
    "        input_chunks = torch.chunk(input, n_chunks, dim=-1)\n",
    "        \n",
    "        input_parallel = input_chunks[rank]\n",
    "        output_paralell = F.linear(input_parallel, self.weight, self.bias)\n",
    "        \n",
    "        torch.distributed.all_reduce(output_parallel)\n",
    "        \n",
    "        return output_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1270761-d77e-4a2d-88ad-a1e01c799dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class f(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c646011f-a76e-45f0-876a-2cf3eb6d91e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class g(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        inputs = [torch.empty_like(input) for _ in range(world_size)]\n",
    "        torch.distributed.all_gather(inputs, input)\n",
    "        inputs = torch.cat(inputs, dim=-1)\n",
    "        return inputs\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        last_dim_size = grad_output.shape[-1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c2818f-f553-4c02-bd83-4a453f7b2f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size, world_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size_per_patrition = output_size // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_patrition,\n",
    "            self.input_size\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_patrition\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_parallel = f.apply(input)\n",
    "        output_parallel = F.linear(input_parallel, self.weight, self.bias)\n",
    "        output = g.apply(output_parallel)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4926c504-0b9e-44f9-81fe-3713dadea977",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread\n",
    "process\n",
    "vectorization\n",
    "stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c64b379-8e32-4c80-a342-fd7c6edea8e0",
   "metadata": {},
   "source": [
    "### AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347382d7-fe0d-479f-b580-cc15901a2eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f79f20a-76f7-4e3a-9584-85322c02607c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorForLanguageModeling(tokenizer, mlm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baeb960-217b-4749-8dac-307cbdf56127",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune.callback import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f70ae0-d132-4377-96c7-0c94b3fde068",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintResultCallback(Callback):\n",
    "    def on_trial_result(self, iteration, trails, trail, result, **info):\n",
    "        print(result[\"score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4511578-c5f2-474e-b391-5e822b43387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune.run(\n",
    "    objective,\n",
    "    config=search_space,\n",
    "    callbacks=[PrintResultCallback()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9509274c-37e1-4c72-a8f0-66e44e8ad5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31bce9f-cd1e-4a3b-af9d-9ff6961f9506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_communication(name, rank, world_size):\n",
    "    rpc.init_rpc(name, rank, world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b58b385-4a20-4b70-9e80-8b71d79532fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfea3477-ed7a-4994-84e5-109f2c0f2efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = repeat(x, \"h w -> h w n\", n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfff6ef-b35d-4789-a6ff-abc0bd46cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a69eb81-5d6c-46a2-9f18-47f589dd876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params:\n",
    "                if p.requires_grad:\n",
    "                    p -= p.grad * self.lr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
