{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f72c800-ebef-4a63-baac-bd2e44c58068",
   "metadata": {},
   "source": [
    "### ML Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d8357b-a6ae-4bc7-bfa0-112862a9f5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a4f408-f8bc-4692-8b81-469deda7126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f27f95-e37a-4b89-862d-3889e8aff04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df4f34a-d38f-4606-a0b9-0a630cfbb186",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache()\n",
    "def expensive_function():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2861957-e2a7-4291-82c7-7b4812bf3799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506819cd-69a3-48a3-899f-e99c262e142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.report import Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb12a8-0b3d-4f79-87aa-82ff86f7c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.metric_preset import DataDriftPreset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c041664e-89f2-41ad-8a14-9d115e0d6fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = Report(metrics=[\n",
    "    DataDriftPreset()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1036061-6899-4618-8755-7684951feffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.run(\n",
    "    reference_data=reference,\n",
    "    current_data=current\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb086b7a-95ee-4d52-b385-43e22406d34c",
   "metadata": {},
   "source": [
    "### AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d004053-265c-40c3-a62c-5657057ec9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee5969d-a006-4922-bf1b-690438b10b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = torch.roll(x, shifts=1, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d13a20-e441-4a01-94e7-a40ac126bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490fb813-ed0a-40ec-a42d-3704affc2d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b573829a-56f1-44ab-8749-63ad88241eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72195c32-67a1-4449-80ca-e774db5b0ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = torch.distributed.broadcast(x, src=0, async_op=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d69dc52-4ce5-47fa-9bfe-41dcb39b198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3e7376-51e9-4c81-aa09-3f8ddedd27f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributed.broadcast(x, src=0, async_op=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc70daca-aea8-4438-9f3a-3b95cc53db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7adb4d-4838-4aef-9bf4-b7df694ea267",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515d5dfb-5616-4404-8273-c60828dd1cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bf5c70-2ebe-409f-8306-3d729dada100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(attention_pattern, target_pattern):\n",
    "    score = attention_pattern * target_pattern\n",
    "    return score.sum() / attention_pattern.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e634402d-47fc-4aad-ba21-0d04be1b2f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9614561f-a1e7-492f-9572-ee2f4325b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b0222b-aab4-4487-b76e-35937c7f5dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = torch.zeros(n_layers, n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecb08e7-8393-4e70-b819-39e4cb096ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(n_layers):\n",
    "    hook_name = f\"block.{layer_idx}.attn.hook_pattern\"\n",
    "    layer_attention_pattern = cache[hook_name]\n",
    "    for head_idx in range(n_heads):\n",
    "        attention_pattern = layer_attention_pattern[batch_idx, head_idx, :, :]\n",
    "        score = compute_score(attention_pattern, target_pattern)\n",
    "        scores[layer_idx, head_idx] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee54cb8-4a38-48af-bd00-d1fe2d5cc1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gym import Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0515c5a-7e59-4cb4-8108-4752229e4ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: parameter partrition\n",
    "step 2: move to ranks\n",
    "step 3: move to device\n",
    "step 4: init local optimizer\n",
    "step 5: step\n",
    "step 6: broadcast\n",
    "step 7: sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722398a4-e828-434b-83d1-a62c13d1989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_model_parallel_size = 2\n",
    "pipeline_model_parallel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35280bb1-b2e3-457d-aa40-4cf871f6b60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline_model_parallel_groups = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effec696-d3d3-4fde-99e8-028e2c65cbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2]\n",
      "[1, 3]\n",
      "[4, 6]\n",
      "[5, 7]\n",
      "[8, 10]\n",
      "[9, 11]\n",
      "[12, 14]\n",
      "[13, 15]\n"
     ]
    }
   ],
   "source": [
    "for i in range(pipeline_model_parallel_size):\n",
    "    start_rank = i*num_pipeline_model_parallel_groups\n",
    "    end_rank = (i+1)*num_pipeline_model_parallel_groups\n",
    "    \n",
    "    for j in range(tensor_model_parallel_size):\n",
    "        ranks = list(range(\n",
    "            start_rank+j,\n",
    "            end_rank,\n",
    "            tensor_model_parallel_size\n",
    "        ))\n",
    "        \n",
    "        print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6dd66-dd94-41f5-a03e-0c9fe4edaa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cross_entropy(logits, targets):\n",
    "    log_probs = F.log_probs(logits, dim=-1)\n",
    "    return -log_probs[torch.arange(targets.shape[-1]), targets].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0899a0-47e1-4a67-b055-fc0756c26d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d525b3ac-1994-49fb-a466-4329f8d631d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: partrition\n",
    "step 2: rank\n",
    "step 3: device\n",
    "step 4: local optimizer\n",
    "step 5: step\n",
    "step 6: broadcast\n",
    "step 7: sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2484a68-0776-438f-ab16-6a566a96f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc332384-68cc-465c-8bd3-9179023c389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv(Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.action_space = Discrete(3)\n",
    "        self.observation_space = Box(\n",
    "            low=np.array([0]),\n",
    "            high=np.array([100])\n",
    "        )\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.state += action - 1\n",
    "        self.shower_lenth -= 1\n",
    "        \n",
    "        reward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d010a9-3ca3-4de1-a52c-2b3692e2f6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ecae92-bfb5-4fc2-8e6b-30e681362e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interference = einsum(\n",
    "    W,\n",
    "    W,\n",
    "    \"b f1 d, b f2 d -> b f1 f2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0c885d-d8f8-42a0-8ef5-72e00550069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2502dc-3359-49b0-9e56-cb74a7fa76dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_head):\n",
    "        super().__init__()\n",
    "        self.d_head = d_head\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        k = k.tranpose(3, 2)\n",
    "        qk = torch.matmul(q, k)\n",
    "        scores = qk / math.sqrt(self.d_head)\n",
    "        \n",
    "        if mask != None:\n",
    "            scores.mask_fill(mask==0, 1e-9)\n",
    "        \n",
    "        attention_weights = F.softmax(scores)\n",
    "        output = torch.matmul(attention_weights, v)\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce163ca-7057-43f1-8c1a-dd5368e4a287",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for param in self.params:\n",
    "                if param.requires_grad:\n",
    "                    param.data -= param.grad * self.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab87ff7-dd84-42be-a79b-df7185e93a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, mom, eps):\n",
    "        super().__init__()\n",
    "        self.mom = mom\n",
    "        self.eps = eps\n",
    "        self.adds = nn.Parameter(torch.zeros(1))\n",
    "        self.mults = nn.Parameter(torch.ones(1))\n",
    "        self.mean = nn.Parameter(torch.zeros(1))\n",
    "        self.var = nn.Parameter(torch.ones(1))\n",
    "    \n",
    "    def update_stats(self, x):\n",
    "        mean, var = x.mean(dim=-1), x.var(dim=-1)\n",
    "        \n",
    "        self.mean.lerp_(mean, self.mom)\n",
    "        self.var.lerp_(var, self.mom)\n",
    "        \n",
    "        return mean, var\n",
    "    \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            mean, var = self.update_stats(x)\n",
    "        \n",
    "        x = (x-mean)/(var+self.eps).sqrt()\n",
    "        x = self.adds + self.mults*x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f83fb8-744d-4888-acea-23ad48110e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.spaces import Discrete, Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a961c21d-34e2-49e2-a815-3c922f23be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv(Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.action_space = Discrete(3)\n",
    "        self.observation_space = Box(\n",
    "            low=np.array([0]),\n",
    "            high=np.array([100])\n",
    "        )\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.temperature -= action\n",
    "        self.shower_length -= 1\n",
    "        reward = 1 if 37 <= self.temperature <= 39 else 0\n",
    "        done = True if self.shower_length == 0 else False\n",
    "        info = {}\n",
    "        \n",
    "        return self.temperature, reward, done, info\n",
    "    \n",
    "    def reset(self):\n",
    "        self.temperature = 20\n",
    "        self.shower_length = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401585b6-b6d1-4f33-93ae-e612f48b3a47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
