{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c455d47-6152-4b0b-897e-7b35122bdec6",
   "metadata": {},
   "source": [
    "### Sci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5d1ce9-0947-4a6c-8aa1-b44ec194b000",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6172f561-28de-4fa1-ba8a-c49f6fe85600",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread\n",
    "process\n",
    "vectorization\n",
    "streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f2027e-521c-46bb-a176-33dd90a7a407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27de1d6c-383e-453f-9cff-c5bfb28c12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RowParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        self.input_size_per_patrition = input_size // world_size\n",
    "        self.output_size = output_size\n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.output_size,\n",
    "            self.input_size_per_patrition\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.empty(\n",
    "            self.output_size\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        n_chunks = input.shape[-1] / rank\n",
    "        input_chunks = torch.chunk(input, n_chunks)\n",
    "        input_parallel = input_chunks[rank]\n",
    "        \n",
    "        output_parallel = F.linear(input_parallel, self.weight, self.bias)\n",
    "        \n",
    "        torch.distributed.all_reduce(output_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2131dae0-8833-4030-a4ce-9c160ef34234",
   "metadata": {},
   "outputs": [],
   "source": [
    "message passing, collective communication, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79f16f6-0c3c-462e-97a9-144707cc4a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "source code > compiler > operating system > hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87275006-2818-4563-9ab2-36cadb049bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: scale the loss\n",
    "step 2: compute the gradient with respect to the scale loss\n",
    "step 3: accumu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79178ef-03cd-4749-9628-81b89d8756b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabParallelEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        self.num_embeddings_per_patrition = num_embeddings // world_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.vocab_start_idx, self.vocab_end_idx = self.get_vocab_range(\n",
    "            num_embeddings, world_size\n",
    "        )\n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.num_embeddings_per_patrition,\n",
    "            self.embedding_dim\n",
    "        ))\n",
    "    \n",
    "    def get_vocab_range(self, num_embeddings, world_size):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        num_embeddings_per_patrition = num_embeddings // world_size\n",
    "        start_idx = rank * num_embeddings_per_patrition\n",
    "        end_idx = start_idx + num_embeddings_per_patrition\n",
    "        return start_idx, end_idx\n",
    "\n",
    "    def forward(self, input):\n",
    "        mask = (input < self.vocab_start_idx) | (input >= self.vocab_end_idx)\n",
    "        input.sub_(self.vocab_start_idx)\n",
    "        input[mask] = 0.\n",
    "        \n",
    "        output_parallel = F.embedding(input, self.weight)\n",
    "        mask_idxs = torch.where(mask == True)[1]\n",
    "        output_parallel[mask_idxs, :] = 0.\n",
    "        \n",
    "        torch.distributed.all_reduce(output_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe200c3-8eff-4848-884f-baaa12bcf0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: determine the size of the patrition\n",
    "step 2: compute the correspond\n",
    "step 3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d360a23-a04c-436e-98ee-ead805d4e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.distributed.get_rank() == 69:\n",
    "    torch.distributed.isend(x, dst=42)\n",
    "elif torch.distributed.get_rank() == 42:\n",
    "    torch.distributed.ircv(x, src=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80e5c3e-217b-4440-b607-02a4e184e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter, broadcast, reduce, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ac9af-f00d-44ab-adf7-b4f2a57d9786",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce, gather, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f19c05e-31ce-40b6-97e5-d062ee7316da",
   "metadata": {},
   "source": [
    "### ML Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7119f22b-42e2-4473-b9e3-4a85815ebc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b20ba3-b723-40b6-b5b2-97bb4ffdf7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache\n",
    "def expensive_func():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a56d31-9764-4002-9023-75cc4b08f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "__repr__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54c2f98-929b-44fb-a36f-e9f840afe078",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.where(x > 1, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eba804-7ef2-4d21-a6ca-e7bfb296b2a6",
   "metadata": {},
   "source": [
    "### AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b9f33d-cb47-4063-9d06-62f76ef8c563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d814fa92-8940-4c25-b031-263dbd68e2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30562524-8ae1-4a81-a035-c0986458e3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.schedulers import HyperBandScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3bc582-a89f-4176-a3ba-603c5fb0bb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = HyperBandScheduler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535da575-6459-460d-830b-822125795884",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune.report(\n",
    "    objective,\n",
    "    config=search_space,\n",
    "    scheduler=scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fa2904-87ac-49dc-a97f-8e8ae3b04de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagonal = x.diagonal(dim1=-2, dim2=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081d7caa-391a-4089-a4f1-1b82483c8af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcd75a1-7bda-45c3-99ae-28b0f0e5191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU],\n",
    "    schedule=torch.profiler.schedule(**schedular_params)\n",
    ") as prof:\n",
    "    for idx in range(8):\n",
    "        model(inputs)\n",
    "        prof.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f8d40-d8ca-4b83-bb16-fd2d9d5b61c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU]\n",
    ") as prof:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07480628-7f12-4c17-9403-bdf61172bb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f47265-e5d7-4fa5-8e01-afd66a8c00d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f999c03f-5312-43f4-9a84-4d2deeecac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit)\n",
    "def demo():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbcc416-8867-4976-ba9b-43e4c522dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e94bfc-88a5-4436-bd2b-389433c8a4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_communication():\n",
    "    rpc.init_rpc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2542368d-afbc-44d4-b6be-360683c7f108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(act, hook):\n",
    "    act[:, :, 4, :] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128624c9-66fd-4505-b7e2-b865f61dd85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run_with_hooks(\n",
    "    tokens,\n",
    "    hook_fwd=[(hook_name, func)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bd5101-3251-4602-996e-5954203a8b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_directions[:, tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c3c5b9-77bc-40ff-bd87-2ec27a9ad63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7802ecb4-6a79-4487-b102-14a32c1ff082",
   "metadata": {},
   "outputs": [],
   "source": [
    "interference = einsum(\n",
    "    W, W,\n",
    "    \"instances feature_1 dim, instances feature_2 dim -> instances feature_1 feature_2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a817a0a2-23f8-4080-a950-7027baaafc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3b79e0-3635-4327-9f25-4c85ab0f869a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interference[torch.arange(n_features), torch.arange(n_features)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1056d8c0-7d02-44a1-8ac7-990e6d68aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "polysemanticity = interference.pow(2).sum().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71709150-91d4-49a4-af41-56f71aff5f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_layer(act, prob):\n",
    "    assert 0 <= prob <= 1\n",
    "    \n",
    "    if prob == 1:\n",
    "        return torch.zeros_like(act)\n",
    "\n",
    "    mask = (torch.randn_like(act) > prob).float()\n",
    "    return (mask*act) / (1-prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
