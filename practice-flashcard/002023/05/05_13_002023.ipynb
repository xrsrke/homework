{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa5ff12b-daa2-4d8c-85de-2745c1f2dbff",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd6e1eb-7b14-4019-a26c-4aeb9ee1fedb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f21b92-c59b-4941-a55a-c19c0b23ef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589b5779-2438-40b2-b3e3-13f4f1482b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast, gather, reduce, scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b6b5ce-741c-448d-ade7-84cf4c5513bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation, gradient, optimizer states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164aa5af-4a94-41b4-b33c-f71351b81aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor paralleism, and pipeline parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc30e880-9c7c-45ad-9ee3-1f9517de4e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "threaded\n",
    "process\n",
    "vectorization\n",
    "stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf14b5d1-4dc5-476e-acf8-70a748f34eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class f(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        torch.distributed.all_reduce(grad_output)\n",
    "        return grad_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b60f55e-6fb9-4431-8823-14d931ef3bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class g(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        inputs = [torch.empty_like(input) for _ in range(world_size)]\n",
    "        torch.distributed.all_gather(inputs, input)\n",
    "        inputs = torch.cat(inputs, dim=-1)\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        dim_size = input.shape[-1]\n",
    "        chunk_dim_size = dim_size // world_size\n",
    "        grad_split = torch.split(grad_output, chunk_dim_size, dim=-1)\n",
    "        return grad_split[rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b9f66-23d8-4991-90d5-0089aa8f6821",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size, world_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output_size_per_patrition = output_size // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_patrition,\n",
    "            self.input_size\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_patrition\n",
    "        ))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        input_parallel = f.apply(x)\n",
    "        output_parallel = F.linear(input_parallel, self.weight, self.bias)\n",
    "        outputs = g.apply(output_parallel)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00b1455-b81e-435d-8249-27ef294bed87",
   "metadata": {},
   "outputs": [],
   "source": [
    "- clock cycle 1: F_{1, 1}\n",
    "- clock cycle 2: F_{1, 2}, F_{2, 1}\n",
    "- clock cycle 3: F_{1, 3}, F_{2, 2}, F_{3, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bf3ef9-51be-4f51-a7fd-8d5b9d996468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_forward_pass_using_data_parallelism(\n",
    "    model, inout, device_ids, output_id\n",
    "):\n",
    "    models = nn.parallel.replicate(model)\n",
    "    inputs = nn.parallel.scatter(input)\n",
    "    \n",
    "    logit = nn.parallel.parallel_apply(models, inputs)\n",
    "    \n",
    "    logits = nn.parallel.gather(logit)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a996b859-8503-466a-b4fd-a1ff6ef4aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro-batch n, micro-batch n-1,...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47736917-76b0-40c3-807d-6ef014c849d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: weight fp16, fp32\n",
    "step 2: compute the loss in fp16\n",
    "step 3: scale the loss\n",
    "step 4: compute the gradient in fp16 with respect to the scaled loss\n",
    "step 5: unscale the gradient\n",
    "step 6: cast the gradient to fp32\n",
    "step 7: update parameters using fp32 of the gradient and fp32 of the weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd5ce4-d4d2-4a0b-acd6-83a9ab24443a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_memory(model):\n",
    "    total_memory = 0\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        total_memory += param.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a8877a-e42b-4b65-b268-b2bc79da98a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = torch.distributed.get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    torch.distributed.broadcast(x, src=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9493c854-2d99-44ca-ae43-28d7aa4533dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ranks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd52c25d-0f68-440d-90cb-acdb77623922",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tensor_model_parallel_groups = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6348a908-d0bd-49d0-a6b8-db91a05149ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_model_parallel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4413b8ab-0ab2-40f7-b999-b0cbf9edac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = torch.distributed.get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e38112-6db7-4265-a7f2-c6c0e53dc3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_tensor_model_parallel_groups):\n",
    "    ranks = range(\n",
    "        i*tensor_model_parallel_size,\n",
    "        i*tensor_model_parallel_size+1\n",
    "    )\n",
    "    \n",
    "    list_ranks.append(ranks)\n",
    "    \n",
    "    if rank in ranks:\n",
    "        group = torch.distributed.new_group(ranks=ranks)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268d1d9f-0ed6-4b66-a77d-6ee382926406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[range(0, 1),\n",
       " range(2, 3),\n",
       " range(4, 5),\n",
       " range(6, 7),\n",
       " range(8, 9),\n",
       " range(10, 11),\n",
       " range(12, 13),\n",
       " range(14, 15)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645a7b8e-e289-48f4-809a-2e55a45fb390",
   "metadata": {},
   "outputs": [],
   "source": [
    "- task of patrition j must be on the j-th device\n",
    "- F_{m, n} must be completed before F_{m+1, n}\n",
    "- B_{m, n} must be completed before B_{m-1, n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e57378-c5c5-4d0f-a40a-0784136c3f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "- clock cycle 1: b_{m, n}\n",
    "- clock cycle 2: b_{m, n-1}, b_{m-1, n}\n",
    "- clock cycle 3: b_{m, n-2}, b_{m-2, n-1}, b_{m-2, n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4761b58d-3109-4e19-aab3-18bfadaf614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: record\n",
    "step 2: split\n",
    "step 3: move to "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0219d747-4a60-4653-b243-de51e47f3e9e",
   "metadata": {},
   "source": [
    "### ML Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41f447c-6ff8-4fdf-accb-cb292097c019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b919ffe7-9641-4f40-9340-e9ab2abce11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['echo', 'hello world'], returncode=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"echo\", \"hello world\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0cb105-55a9-4425-a986-9de00b38e962",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue = x[[1, 3], [0, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3311f193-baaa-4d8d-ac39-ecf9cfc202ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect.deployments import Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3aeb5a-c5fb-4a6f-9477-2e1e8fdf6b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_dev = Deployment.build_from_flow(\n",
    "    training,\n",
    "    name=\"model_training-dev\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a93df8-3bdd-40cb-a0a7-47df95c92eac",
   "metadata": {},
   "source": [
    "### Sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f78ac-38e1-4481-9dd3-1c7a95eddfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "e > optic nerve >  visual cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934d481f-b63d-4eea-88b2-dceadfb9e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron 1 > axon > synapse > dendrite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f01ac5e-ee53-4486-b49b-5ee87dcded72",
   "metadata": {},
   "source": [
    "### AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac28a2f1-4ad7-496c-bac1-03cc5fea1967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b7aaae-1436-4d2c-a5e6-0a798d048430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baabec3-8e1d-41de-a9c3-1a4b5690bc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOptimizer(Optimizer):\n",
    "    def __init__(self, params):\n",
    "        defaults = dict()\n",
    "        super.__init__(self, params, defaults)\n",
    "    \n",
    "    def step(self):\n",
    "        for param in self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab9f87c-9ab3-4a0a-9373-b568531029fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e22e3d-3eaa-45df-9b06-442d5b2b69f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = DataCollatorForLanguageModeling(tokenizer, mlm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1c04ee-d757-4352-b86c-6f777546cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = collator([tokenized_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93c0f1c-44eb-406a-b5e1-364e63d34b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d5a9d2-ed37-455d-8083-4b5a9b07825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(param):\n",
    "    x, y = param[\"x\"], param[\"y\"]\n",
    "    score = objective(x, y)\n",
    "    tune.report(score=score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e846673-48e5-4b59-8a59-2b94189c35d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tune.run(\n",
    "    target,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9d67b1-478f-4b0b-8ef1-daecf67bdb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOptimizer(Optimizer):\n",
    "    def __init__(self, params):\n",
    "        defaults = dict()\n",
    "        super().__init__(params, defaults)\n",
    "    \n",
    "    def step(self):\n",
    "        for group in self.param_groups:\n",
    "            for p in group:\n",
    "                if param.requires_grad is not True:\n",
    "                    continue\n",
    "\n",
    "                p.data = p.data * 6.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9559839-c235-4c32-a439-ceac8595329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3321450-e202-48b4-92a3-6aa3b1ef5455",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpc.remote(\"worker_1\", create_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c6b228-90ba-4655-bfa7-63b81276f46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83faef25-23c7-4a9d-8d73-545cefd14bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, block in enumerate(model.blocks):\n",
    "    if i >= 6:\n",
    "        for param in block.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eb4811-36f2-4e9b-bf7f-9a577667146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.transformer.ln_final.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f94665-3597-4632-aca4-24807399faab",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.lm_head.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a5adda-51fd-440d-b8ca-0baf459473e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8fccff-bfc7-45ce-9637-3bab4c5b11cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01982c0-fd38-4ae9-b9fe-235f0a0baf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_logits = logit[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12edcd98-2f13-4def-aa00-7b6acf952883",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_log_prob = F.log_softmax(last_token_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ee3387-1135-4110-bbca-779d1c941546",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_token = tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb7ed1a-2850-4f76-a99c-a5a25d3d555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_log_probs = -torch.gather(last_token_log_prob, dim=-1, index=target_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff3b2bd-2aff-4e31-81a8-b0b94df924b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3a9a4c-0b94-4659-83a8-4873202b6054",
   "metadata": {},
   "outputs": [],
   "source": [
    "interference[torch.arange(5), torch.arange(5)] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7cfcaf-ed55-454b-bb49-79c186cf17fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "interference.pow(2).sum(dim=-1).sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e81ebb-0bc2-4584-aaa6-bc106c3157d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        device_0 = torch.device(\"cuda:0\")\n",
    "        device_1 = torch.device(\"cuda:1\")\n",
    "        \n",
    "        self.net1 = nn.Sequential(\n",
    "            nn.Linear(69, 420),\n",
    "            nn.ReLU()\n",
    "        ).to(device_0)\n",
    "        \n",
    "        self.net_2 = nn.Sequential(\n",
    "            nn.Linear(420, 69)\n",
    "        ).to(device_1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.net1(x)\n",
    "        next_device = next(self.net2.parameters()).device\n",
    "        \n",
    "        x.to(next_device)\n",
    "        \n",
    "        x = self.net2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50660d54-d74d-450d-bd2f-aaad0febd0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = cache[\"hook_embed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce484a0-b2ed-43c6-8ed6-b05d698db8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_embeddings = cache[\"hook_pos_embed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33db07e9-6b28-4ef8-b17d-9cdeafc10863",
   "metadata": {},
   "outputs": [],
   "source": [
    "components = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b717fc2-6e77-4b58-804b-d782d9479d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "components.append(text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d036cb-64ee-4501-b1f0-e8b512ef9cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "components.append(positional_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0064f7ba-027d-400b-9045-73c52cf57b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019abc97-5e68-422b-b021-9593593cbb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(4):\n",
    "    attn_name = get_act_name(\"attn_out\", layer)\n",
    "    mlp_name = get_act_name(\"mlp_out\", layer)\n",
    "    components.append(cache[attn_name])\n",
    "    components.append(cache[mlp_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2c8be6-12a7-4681-95f3-19db671ec880",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        for p in self.params:\n",
    "            if p.requires_grad:\n",
    "                p.data.add_(-self.lr, p.grad.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15707ef4-9c8f-4796-990b-f0db6ea57eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "interference[torch.arange(5), torch.arange(5)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75b9260-b90f-4f4f-ac9d-9ee37fbf4ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = interference.pow(2).sum(dim=-1).sqrt()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
