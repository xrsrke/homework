{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "886c2178-bd33-48d3-a0ce-304ac817a50c",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df2fc8f-d19e-4fba-9330-ebf18a9699a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d62f682-f14b-4b00-bfdd-2cb6f0b881bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_grad_enabled(input):\n",
    "    return torch.is_grad_enabled() and input.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52207669-2647-46a0-b32d-9305d0aedb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _broadcast(input):\n",
    "    return input.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8d65b0-1d71-4788-a221-385051a602d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reduce(input):\n",
    "    world_size = torch.distributed.get_world_size()\n",
    "    \n",
    "    if world_size == 1:\n",
    "        return input\n",
    "    \n",
    "    torch.distributed.all_reduce(input)\n",
    "    \n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892f553d-3bfe-44e3-b207-761024bc69d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Broadcast(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return _broadcast(input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return _reduce(grad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ff2c86-5279-445e-b0c2-1300aaf7b6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_with_forward_and_backward(inputs):\n",
    "    if is_grad_enabled(inputs):\n",
    "        outputs = Broadcast.apply(inputs)\n",
    "    else:\n",
    "        outputs = _broadcast(inputs)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94385b0-06a6-4bf0-bdbd-6e844d724ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = torch.distributed.get_world_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe68904-269c-46ce-9669-e453c6360a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_params = sorted(param_list, key=lambda x: x.numel(), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aa488e-5d05-4fb7-9454-f296f84d0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "numel_per_rank = [0 for _ in range(world_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958e33b4-acac-431f-b4dd-1032337f78d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_per_rank = [[] for _ in range(world_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc881b9-58f9-408c-971b-1e1861693e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in sorted_params:\n",
    "    next_device = numel_per_rank.index(min(numel_per_rank))\n",
    "    \n",
    "    param_per_rank[next_device].append(param)\n",
    "    numel_per_rank[next_device] += param.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f48300-e36a-445a-9041-464e35233134",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: send\n",
    "step 2: sender continues their execution\n",
    "step 3: recever stops\n",
    "step 4: if, then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fc2938-b646-424f-ad37-c3a02bfbfaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabParallelEmbedding(nn.Module):\n",
    "    def __init__(self, num_embedding, embedding_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        self.num_embedding = num_embedding\n",
    "        self.embedding_dim_per_partrition = embedding_dim // world_size\n",
    "        self.embedding = nn.Embedding(\n",
    "            num_embedding,\n",
    "            embedding_dim=self.embedding_dim_per_partrition\n",
    "        )\n",
    "        self.vocab_start_idx, self.vocab_end_idx = self.get_vocab_range(\n",
    "            self.embedding_dim_per_partrition\n",
    "        )\n",
    "    \n",
    "    def get_vocab_range(self, embedding_dim_per_partrition):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        start_idx = rank*embedding_dim_per_partrition\n",
    "        end_idx = start_idx+embedding_dim_per_partrition\n",
    "        return start_idx, end_idx\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        mask = (self.vocab_start_idx < tokens) | (tokens >= self.vocab_end_idx)\n",
    "        tokens = tokens - self.vocab_start_idx\n",
    "        tokens[mask] = 0.\n",
    "        \n",
    "        embeddings = self.embedding(tokens)\n",
    "        mask_idxs = torch.where(mask == 0)[1]\n",
    "        embedding[mask_idxs] = 0.\n",
    "        \n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0104d7c-3030-4a4e-80ae-ba7de2ab0848",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: replicate the model\n",
    "step 2: micro-batch\n",
    "step 3: grad\n",
    "step 4: average all the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc76906f-f2a4-46a9-b7d1-c9d66572efe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "register > cached sram > main memory dram > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692ac179-8181-43b0-9125-f59973a34fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: partrition the params\n",
    "step 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a09658-ba57-4077-9d34-cc560c6a4502",
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient, params, optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db68c38f-8c84-4c95-ba37-2509af5be64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9381be-b03e-4343-91ee-befc2c4eb0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPU:\n",
    "    def __init__(self, master_addr, master_port, backend):\n",
    "        if not torch.distributed.is_initialized():\n",
    "            rank = os.getenv(\"RANK\")\n",
    "            world_size = os.getenv(\"WORLD_SIZE\")\n",
    "            os.environ[\"MASTER_ADDR\"] = master_addr\n",
    "            os.environ[\"MASTER_PORT\"] = master_port\n",
    "            \n",
    "            device_count = torch.cuda.device_count()\n",
    "            \n",
    "            if device_count > 0:\n",
    "                device = rank % device_count\n",
    "                torch.cuda.set_device(device)\n",
    "            \n",
    "            torch.distributed.init_process_group(\n",
    "                rank=rank,\n",
    "                world_size=world_size,\n",
    "                backend=backend\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559c0586-77e1-4870-b568-f07bd8e6b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelMLP(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.dense_h_to_4h = ColumnParallelLinear(\n",
    "            input_size=hidden_size,\n",
    "            output_size=hidden_size*4\n",
    "        )\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dense_4h_to_h = RowParallelLinear(\n",
    "            input_size=hidden_size*4,\n",
    "            output_size=hidden_size\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        intermediate_activations = self.dense_h_to_4h(x)\n",
    "        intermediate_activations = self.gelu(intermediate_activations)\n",
    "        outputs = self.dense_4h_to_h(intermediate_activations)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e03ff6-bbf1-4063-a66e-e2edad95e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc185e-1a8c-4ee3-a8ba-b7d50268499d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachedDataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.data = data\n",
    "        self.cache_index = {}\n",
    "    \n",
    "    def prefetch(self, idxs):\n",
    "        if all([x in self.cache_index for x in idxs]):\n",
    "            return\n",
    "        \n",
    "        if not self.data:\n",
    "            self.data = torch.load(self.filename)\n",
    "        \n",
    "        total_numbers = sum([self.data[x].numel() for x in idxs])\n",
    "        \n",
    "        self.cache = torch.randn(total_numbers, dtype=self.data.dtype)\n",
    "        \n",
    "        offset = 0\n",
    "        for i in idxs:\n",
    "            n_numbers = self.data[i].numel()\n",
    "            self.cache[offset:offset+n_numbers]\n",
    "            self.cache_index[i] = offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0b6199-82bd-47e8-8736-5bd34ea6a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_tensor_model_parallel_groups):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195104eb-d597-40b7-a509-c204ba46bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: load data to main memory\n",
    "step 2: the size\n",
    "step 3: reserve\n",
    "step 4: load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db859c9-8544-4978-98ce-093e0893818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared memory, file system, message passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf9b87f-8a7d-464f-a796-5d06434ad3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: partrition\n",
    "step 2: move\n",
    "step 3: init local optimizer\n",
    "step 4: sync locla optimizer\n",
    "step 5: move local params to a bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075b6ff9-5fb4-489a-82ed-38e7b524fa69",
   "metadata": {},
   "source": [
    "### ML Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12adf3d-d69f-43f8-85d2-d0ad781381fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "key, value, timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017274ee-04b2-4790-b7cf-8ab4678a03c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdff956d-2f2d-49a6-99d6-ff1de85a80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = threading.Thread(target=print_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef6eea3-9f00-4b5e-8fbf-82a449e1e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f07b1a-e5fd-4235-89e5-981abb6f5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aae8f9a-5ace-4c52-8bfa-20b0f3da7d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = cast(List[int], numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b3da9-06f3-4b48-b601-696e7a15ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: create a network\n",
    "step 2: attach the network\n",
    "step 3:receive ip\n",
    "step 4: communicate through the IPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce4cd9-f29b-490c-b2f7-1a2e5b167ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a56f93c-6edf-4df8-9dd2-0ebc570988d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def first_context():\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c475a3fa-7188-43f4-bd70-2e3c5966ebe1",
   "metadata": {},
   "source": [
    "### Ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41c404e-95f4-4004-9d18-d22d0354b004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f96b02-3401-4fba-a6f4-d8c63c488281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    return {\n",
    "        \"sentence1\": tokenizer(x[\"tokenizer\"])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780995ce-39a2-439e-9bbf-7b6ff6071f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = small_dataset.map(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79f64aa-6e84-4e89-8393-170fe7b3a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_func(x):\n",
    "    return x[\"sentence1\"].startswith(\"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9abcc12-fe61-4031-ab66-55205d87e5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset.filter(filter_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396aef27-5270-4127-b24b-6c9a5dced0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributed.broadcast(x, src=0, async_op=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9915869d-6499-48c5-9cbf-9a4d676fcf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    for param in param_group[\"param\"]:\n",
    "        print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73c6ecf-1446-4bde-ba99-447295677104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_func(activations, hook):\n",
    "    activations[:, :, 4, :] = 0.\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddcfa5d-eb16-44a4-84b7-594c5a9e214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run_with_hooks(\n",
    "    tokens,\n",
    "    fwd_hooks=[(hook_name, patch_func)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ee84ed-1b75-4175-acf0-a160a692efc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabParallelEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim_per_partrition = embedding_dim // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.num_embeddings,\n",
    "            self.embedding_dim_per_partrition\n",
    "        ))\n",
    "        self.vocab_start_idx, self.vocab_end_idx = self.get_vocab_range(\n",
    "            self.embedding_dim_per_partrition\n",
    "        )\n",
    "        \n",
    "    def get_vocab_range(self, embedding_dim_per_partrition):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        start_idx = rank*embedding_dim_per_partrition\n",
    "        end_idx = start_idx+embedding_dim_per_partrition\n",
    "        return start_idx, end_idx\n",
    "\n",
    "    def forward(self, tokens):\n",
    "        mask = (self.vocab_start_idx < tokens) | (tokens >= self.vocab_end_idx)\n",
    "        mask_tokens = tokens - self.vocab_start_idx\n",
    "        masked_tokens[mask] = 0.\n",
    "        \n",
    "        embeddings = F.embedding(masked_tokens, self.weight)\n",
    "        mask_idxs = torch.where(mask == 0)[1]\n",
    "        embeddings[mask_idxs] = 0.\n",
    "        \n",
    "        torch.distributed.all_reduce(embeddings)\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405edf27-9826-499a-96cd-fca135343bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b238a2-7649-4cbe-b9fa-76c29c426aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = rearrange(\n",
    "    images,\n",
    "    \"b c (p_h n_h) (p_w n_w) -> b (n_h n_w) (p_h p_w c)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d783ff-2172-4821-8a97-fef8f62bccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d628849-43d3-4633-b7cc-80cdcc0abfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf56bbee-a054-420d-b9e2-2488481e3e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = F.softmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd180d46-986a-4aa5-a2bf-576850e4dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_probs = probs[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f14c2-b56c-4dec-a275-c4b6112be17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b898a6a-8b45-44c6-b35d-ac581da45052",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_log_probs = -last_tokens_probs[target].log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cfd5a7-9b77-416a-a87b-2b8aacb53921",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_tokens = model.to_tokens(repeated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556869ef-8a8b-4b82-93b4-c110830878d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "induction_heads = [(6, 9), (4, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e0cc0-e3df-44d7-ae67-8c67f75b62d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_patterns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a829b95-aaac-4492-9b95-ce074ed4d4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e59d2da-e7b5-4822-9a53-68a5b0309207",
   "metadata": {},
   "outputs": [],
   "source": [
    "for head_idx, layer_idx in induction_heads:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6034a3ed-3854-4e63-803a-3305d969faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = model.embed(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b1eebf-b333-45a7-8991-6a6eb21982d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_embeddings = model.pos_embed(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b457a0d3-b57b-4ddb-8d2d-9d0f98523b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = text_embeddings + positional_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072ed9af-782c-4352-8bd4-8343b9defe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b31bd29-f8af-470d-aacd-3708d0dd5880",
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in model.blocks:\n",
    "    residual = block(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eab0d4-2752-44fd-a6e9-526a8f2e02de",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = model.ln_final(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fc43a9-c8a3-4bf5-8368-6a5ecf02b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.unembed(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a8c0b7-309b-48d9-8794-6ed588ada1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = torch.distributed.broadcast(x, src=0, async_op=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f4e73b-0fed-4567-ab05-86e3e7fa493b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb21ab0a-71d0-4f18-9806-58bd96b67d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc99e36c-554f-4677-929b-b1f63e1b5b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interference[torch.arange(n_features), torch.arange(n_features)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3034baf3-3ce9-4cbc-bbf0-db0606bf5a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "polysemanticity = interference.pow(2).sum(dim=-1).sqrt() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d9d426-619c-402a-817c-8991a3fd755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[\"hook_embed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9493bc02-9449-45b9-acb1-ff6581ccd9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[\"hook_pos_embd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a522ab4d-ff01-41c9-a2ec-2b89f3fc2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear, residual connection, layernorm, multi, mask-multi,"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
