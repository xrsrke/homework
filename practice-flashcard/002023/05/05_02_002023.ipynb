{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d8aa225-c939-493e-a41b-803c189b9830",
   "metadata": {},
   "source": [
    "### Sci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0fa97b-6c74-4d0e-951b-1f921c2b17d2",
   "metadata": {},
   "source": [
    "### ML Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1933ea8d-8399-4724-a372-b9a43bc8772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ceb43b-e4ca-4aeb-bcf6-aafea24351c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dbbaac-72bf-47ff-b037-c594f36dc9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@task\n",
    "def hello():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa9e78e-8ae3-4104-9087-fd6a6422d4e9",
   "metadata": {},
   "source": [
    "SELECT users.name, likes.like FROM users LEFT JOIN likes ON users.id == likes.user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48761d3-8a75-4faf-a64b-ca4d16efa866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d0121b-c494-44ad-8d30-02573c00e905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['echo', 'hello world'], returncode=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"echo\", \"hello world\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffba80cc-dcf2-4c3f-8184-1bd59cf2d663",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa7a70-c3db-4d95-93b0-9dde7f17da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "gather, broadcast, reduce, scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec098a-bf9c-434f-9bb9-29029e3bbefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a40ce27-2f3b-4d46-a2e8-a20eb30be51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnLinearParallel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_patritions):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size_per_patrition = output_size // num_patritions\n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_patrition,\n",
    "            self.input_size\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.empty(torch.output_size_per_patrition))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output_patrition = F.linear(x, self.weight, self.bias)\n",
    "        \n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        outputs = [torch.empty_like(output_patrition) for _ in world_size]\n",
    "        torch.distributed.all_gather(outputs, output_patrition)\n",
    "        \n",
    "        output = torch.cat(outputs, dim=-1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4784353-1887-4de7-985e-011469f68e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_memory(model):\n",
    "    total = 0\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        total += param.storage.size() * param.elements()\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced8bb6d-52bc-453e-ae5e-9b0f977da97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69071ca0-2fec-4133-a064-7f91f4622d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [0, 1, 3, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7c31b8-0acf-4f6b-a8a0-1aaa4af8a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = torch.distributed.get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7639bd31-3a9e-46ca-9fca-a807f19867a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fb22b7-ebb4-4288-bf53-987f17627a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rank in ranks:\n",
    "    group = torch.distributed.new_group(ranks=ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afa845b-ea3d-46c6-9176-a2b0fa7bcdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rank == 0:\n",
    "    torch.distributed.broadcast(x, src=0, group=groupb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096e55a0-818d-40c4-aaa4-3e678c5a4535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_forward_pass_using_data_parallelism(\n",
    "    model, input, device_ids, output_id\n",
    "):\n",
    "    inputs = nn.parallel.broadcast(input, device_ids=device_ids)\n",
    "    models = nn.parallel.replicate(model, device_ids)\n",
    "    \n",
    "    logit = nn.parallel.parallel_apply(models, inputs)\n",
    "    \n",
    "    logits = nn.parallel.gather(logit, output_id)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945026ab-ae09-40c6-9cee-20da1cd22a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f82710-4c76-498c-afe4-cb4ab528cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_model(model, balances, devices):\n",
    "    patrition_idx = 0\n",
    "    layers = OrderedDict()\n",
    "    patritions = []\n",
    "    \n",
    "    for i, layer in enumerate(model):\n",
    "        layers[i] = layer\n",
    "        if len(layers) == balances[patrition_idx]:\n",
    "            device = devices[patrition_idx]\n",
    "            patrition = nn.ModuleList(layers)\n",
    "            patrition.to(device)\n",
    "            \n",
    "            patritions.append(patrition)\n",
    "            layers.clear()\n",
    "        \n",
    "    return patritions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3456d823-729c-4a67-9999-c25f93e885fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: fp16, fp32 copy of the weight\n",
    "step 2: do forward and backward pass in fp16\n",
    "step 3: cast the gradient from fp16 to fp32\n",
    "step 4: update "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3b3721-a382-4490-9e84-9682c90aa65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu memory in forward pass, optimizer buffers, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4873b795-92e7-4ce8-baac-6ddac74fe9c8",
   "metadata": {},
   "source": [
    "step 1: scale the loss value \n",
    "step 2: compute the gradient with respect to the scaled loss\n",
    "step 3: unscale the gradient\n",
    "step 4: update model's parameters with respect to the unscaled gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0298f245-a5d5-4e19-a645-9b295d679f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "address, port, rank, world_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47629dc4-67ab-42f1-a08b-64f5662fb563",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: create 4 processes\n",
    "step 2: set env\n",
    "step 3: ini distributed communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96b96d-0d5a-4f8e-a874-ab97e110a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b7d33e-35f8-4de2-90b3-02c0e73f61e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_forward_pass_using_data_parallelism(\n",
    "    model, input, device_ids, output_id\n",
    "):\n",
    "    inputs = nn.parallel.scatter(input, device_ids)\n",
    "    models = nn.parallel.replicate(model, device_ids)\n",
    "    \n",
    "    logit = nn.parallel.parallel_apply(models, inputs)\n",
    "    \n",
    "    logits = nn.parallel.gather(logit, output_id)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c4b5de-0e65-46c4-9ef6-273ebffe47f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "message passing, p2p, collective communicatin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb326348-836e-419c-8848-dd8795d6903f",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: scale the loss\n",
    "step 2: compute the gradient with respect to the scaled loss\n",
    "step 3: unscale the gradient\n",
    "step 4: update model's parameters with respect to the unscaled gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5394294-c5c0-4bff-bb93-ff81494c4e1e",
   "metadata": {},
   "source": [
    "### AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38860a39-5305-4886-91ef-7d73f145434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b3ae6-5365-42b7-9858-26361ee57408",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_xs = xs.at[2].set(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bd3e1b-2801-4981-a5ff-eb112ffaba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e7eb9d-1a48-404d-acd8-6852df6914d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mhm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d25f8a-d8dc-4da0-a2a4-c5044ec9c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90449e7-01b1-4451-8bce-7a308df8f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "interference[torch.arange(n_features), torch.arange(n_features)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a263efb-01bd-494d-b7bc-98a1cc290981",
   "metadata": {},
   "outputs": [],
   "source": [
    "polysemanticity = interference.pow(2).sum(dim=-1).sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544f7895-1243-4e41-afc7-4355405ce4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c85ded0-9282-4619-a261-f2a3103b35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mhm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aba18a-dd37-471e-907d-9f3cb3826bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = data_collator([tokenized_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ac1f5-c537-4289-bc39-afc12dadd27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef55e89d-0096-4cee-9d34-2dcdcb497530",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = reduce(images, \"b c h w -> b h w\", reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eb42dc-1282-4ded-9413-759d576961b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = W[:, :, 0]\n",
    "ys = W[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baebaff-569d-4926-86ed-07ebce4e871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "representation, dynamics, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a38a5e-e95e-4097-b587-e40d2c614895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clipped_surrogate_objective(\n",
    "    ratio, advantage_estimate, epsilon\n",
    "):\n",
    "    clipped_ratio = torch.clamp(ratio, 1-epsilon, 1+epsilon)\n",
    "    target = ratio * advantage_estimate\n",
    "    clipped_target = clipped_ratio * advantage_estimate\n",
    "    return torch.min(target, clipped_target).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edee28d2-51db-4f3c-9883-20401e25bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2121e6c0-6c91-47a0-a203-28b61e520ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['echo', 'hello world'], returncode=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"echo\", \"hello world\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd967e2-8709-43ff-8f5c-e7b5e2b0e3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0098ffe0-75b5-46e4-ac2f-095f3a6dd478",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params, lr):\n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        for p in self.params:\n",
    "            if p.requires_grad:\n",
    "                p -= p.grad * self.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527fbb1f-76ef-4374-9539-53a3eb3e11ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_idx = torch.where(dsets.train[0][1], 1.)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd0561b-c3d4-4e70-ac01-f6e1676e9a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = vocab[label_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec230de9-c8de-4e30-b2b7-5bb0cb5874a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params:\n",
    "                if p.requires_grad:\n",
    "                    p -= p.grad * self.lr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
