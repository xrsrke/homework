{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93c68171-e874-4434-8c85-01574c039206",
   "metadata": {},
   "source": [
    "### ML Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf232a0-17b2-4155-9e06-82a7edfbf252",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: create a nat gateway\n",
    "step 2: create a route table\n",
    "step 3: direct traffic in the route table to the nat gateway\n",
    "step 4: attach the route table to the vpc\n",
    "step 5: attach the nat to the vpc\n",
    "step 6: create"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ff9d6-5698-4404-9dd7-cd45f3de381f",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e616a-f073-4b6d-a772-380dfb95caff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3447928b-1186-4f29-9808-80e108acc3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "micro-batch 1, micro-batch 2,... micro-batch n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c5b2b8-6ba7-42ba-b8e5-cec92d6adcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: parameter partrition\n",
    "step 2: assign the partrition to ranks\n",
    "step 3: device\n",
    "step 4: local optimizer\n",
    "step 5: sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45ff17b-fe24-44c8-80c1-7d25f01abc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabParallelEmbedding(nn.Module):\n",
    "    def __init__(self, num_embedding, embedding_dim):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        self.num_embedding = num_embedding\n",
    "        self.embedding_dim_per_partrition = embedding_dim // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.embedding_dim_per_partrition,\n",
    "            self.num_embedding\n",
    "        ))\n",
    "        \n",
    "        self.vocab_start_idx, self.vocab_end_idx = self.get_vocab_range(\n",
    "            embedding_dim_per_partrition\n",
    "        )\n",
    "    \n",
    "    def get_vocab_range(self, embedding_dim_per_partrition):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        start_idx = rank*embedding_dim_per_partrition\n",
    "        end_idx = start_idx+embedding_dim_per_partrition\n",
    "        return start_idx, end_idx\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        mask = (tokens < self.vocab_start_idx) | (tokens >= self.vocab_end_idx)\n",
    "        tokens = tokens - self.vocab_start_idx\n",
    "        tokens[mask] = 0.\n",
    "        \n",
    "        embeddings = F.embedding(tokens, weight=self.weight)\n",
    "        mask_idxs = torch.where(mask == 0)[1]\n",
    "        embeddings[mask_idxs] = 0.\n",
    "        \n",
    "        torch.distributed.all_reduce(embeddings)\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec87efe6-a913-4910-a36b-e08160f426f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnLinearParallel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, world_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size_per_partrition = output_size // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_partrition,\n",
    "            self.input_size\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_partrition\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output_parallel = F.linear(input, self.weight, self.bias)\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        outputs = [torch.empty_like(output_parallel) for _ in range(world_size)]\n",
    "        torch.distributed.all_gather(outputs, output_parallel)\n",
    "        outputs = torch.cat(outputs, dim=-1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9dd3a7-55c3-4488-b9d1-cf3ef64d299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_tensor(x):\n",
    "    world_size = torch.distributed.get_world_size()\n",
    "    xs = [torch.empty_like(x) for _ in range(world_size)]\n",
    "    torch.distributed.all_gather(xs, x)\n",
    "    xs = torch.cat(xs, dim=-1)\n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19012788-16ae-492b-b4be-a4b60678a254",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: determine the location of checkpoints\n",
    "step 2: forward, save the checkpoint\n",
    "step 3: delete\n",
    "step 4: compute the grad\n",
    "step 5: recompute the forward from the clostest checkpoint\n",
    "step 6: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff9cabd-adf6-4d04-9e53-258b84205bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward computing, recompute, gradientb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4fdd4a-fba5-4c00-9c30-8b5d253d71f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def forward(self, x, labels):\n",
    "        outputs = self.net(x)\n",
    "        losses = loss_func(outputs, labels)\n",
    "        return outputs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d517701-d624-4a6c-a5d1-0486c937358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, losses = model(x, labels)\n",
    "loss = losses.mean()\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aa99cf-4b9c-4dfd-9db2-cee23d8df537",
   "metadata": {},
   "outputs": [],
   "source": [
    "os boot\n",
    "user\n",
    "process spawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7134c3-4770-4ba9-b1bb-0233f10d898b",
   "metadata": {},
   "outputs": [],
   "source": [
    "register > cache (sram) > main memory (dram) >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07503cd8-2847-4c49-94e4-e775b1df8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37247519-fe1c-432d-a713-970e02b456b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target(rank, world_size, config):\n",
    "    torch.distributed.init_process_group(\n",
    "        **config,\n",
    "        rank=rank,\n",
    "        world_size=world_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523154a8-8468-47e9-b792-979017f99722",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 4\n",
    "\n",
    "for rank in range(world_size):\n",
    "    process = Process(target=target, args=(rank, world_size, config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb8702b-831b-445c-96c0-791dc3b41de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2178f25a-f650-4f8e-a618-07a8fb81ed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(world_size):\n",
    "    process = Process(target=say_hello)\n",
    "    process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74058ccf-81c5-4b61-be36-d27722642125",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_to_gpu = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78855778-7358-446d-97c3-4a8147f2ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rank in range(world_size):\n",
    "    device = rank % num_gpus\n",
    "    process_to_gpu.append(device )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51fc1bb-cc46-4fa7-8914-ccc1bda3c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: partrition\n",
    "step 2: move\n",
    "step 3: init local\n",
    "step 4: sync lococal and global\n",
    "step 5: move local params to a bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fc9fc1-7c9c-4c0a-bb84-bf0ca7574e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rank in range(world_size):\n",
    "    p = Process(target=say_hello, args=(rank,))\n",
    "    p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d6b605-509d-4e6e-b4d9-a0189ee6ca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_model_parallel_size = 2\n",
    "num_tensor_model_parallel_groups = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50aaa35-ebb6-469b-aca9-862acc13ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ranks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74b9235-ac69-486b-a44b-b5245d07e1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[2, 3]\n",
      "[4, 5]\n",
      "[6, 7]\n",
      "[8, 9]\n",
      "[10, 11]\n",
      "[12, 13]\n",
      "[14, 15]\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_tensor_model_parallel_groups):\n",
    "    ranks = list(range(\n",
    "        i*tensor_model_parallel_size,\n",
    "        (i+1)*tensor_model_parallel_size\n",
    "    ))\n",
    "    print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49808ef-b25f-4044-b031-a8d4fca48b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 16\n",
    "tensor_model_parallel_size = 2\n",
    "pipeline_model_parallel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2793dfd-1cc9-4ab1-acb0-87671bc05b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline_model_parallel_groups = world_size // pipeline_model_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e949fece-ebb8-41bc-bc75-34edc71c1da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline_model_parallel_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e434f-f0b8-4ea2-9d9d-21f91c19344b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_parallel_groups = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d128d8af-6cb7-4c0d-92a2-e9b6863ef442",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_pipeline_model_parallel_groups):\n",
    "    start_rank = i*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cfab95-2935-4b06-8fdb-69a1a6218563",
   "metadata": {},
   "outputs": [],
   "source": [
    "register > cache sram > main memory dram > hard disk > backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba0b99-dd7b-48a0-b659-e05d7e2d7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "- clock cycle 1: F_{1, 1}\n",
    "- clock cycle 2: F_{1, 2}, F_{2, 1}\n",
    "- clock cycle 3: F_{1, 3}, F_{2, 2}, F_{3, 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b17377f-dada-4e8a-8333-c0dd661f3723",
   "metadata": {},
   "outputs": [],
   "source": [
    "new > ready > running > blocked > finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1efa7d-8c8f-489b-95cb-a1943baecd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "different consecutive stages\n",
    "in the same replicas model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fee035b-1861-4d2b-aa67-3fb79b890314",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_group\n",
    "world_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9156951b-0276-4fad-a667-7b626f7b81f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor model parallel, pipeline model parallel, data parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83de832d-d83c-494a-9a58-165064834f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "4 process\n",
    "init\n",
    "comminicate through the ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b220d-b69e-4be0-8b5f-c8f50cb058d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2]\n",
      "[1, 3]\n",
      "[4, 6]\n",
      "[5, 7]\n",
      "[8, 10]\n",
      "[9, 11]\n",
      "[12, 14]\n",
      "[13, 15]\n"
     ]
    }
   ],
   "source": [
    "for i in range(pipeline_model_parallel_size):\n",
    "    start_rank = i*num_pipeline_model_parallel_groups\n",
    "    end_rank = (i+1)*num_pipeline_model_parallel_groups\n",
    "    \n",
    "    for j in range(tensor_model_parallel_size):\n",
    "        ranks = list(range(\n",
    "            start_rank+j,\n",
    "            end_rank,\n",
    "            tensor_model_parallel_size\n",
    "        ))\n",
    "        \n",
    "        print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89428083-7f74-47f3-9932-bbc977425be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "same portion\n",
    "different replicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7211eceb-4da0-4f7d-b392-90ddc92d85fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: local env\n",
    "step 2: init\n",
    "step3: cuda\n",
    "setp 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263864b7-6a36-4002-a08d-934702a8a19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank, world_size, master_addr, master_port"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319a67a1-1071-496c-842d-be1b9513f228",
   "metadata": {},
   "source": [
    "### ML Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbd5569-89aa-40c1-9cd4-76bf483ee8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: attach internet gateway to vpc\n",
    "step 2: create a route table\n",
    "step 3: direct traffic to the internet gateway\n",
    "step 4: create a subnet\n",
    "step 5: attach the route table to the subnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6acc5f3-19b7-4c5c-a39b-6faf9ba163cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nat\n",
    "subvpc\n",
    "route\n",
    "traffic\n",
    "attach route to subvpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5897ea-b5c6-4e13-862c-156a6f2e5b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "download\n",
    "in-memory using apache arrow\n",
    "extract schema\n",
    "modify schema if needed\n",
    "create a data catalog from the schema using aws glue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f356af23-2b38-45bf-ba65-5b2e9b204b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import FlowSpec, step, project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0805800-5c3c-4f77-9d03-12d4f813eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "@project(name=\"project_69\")\n",
    "class TrainFlow(FlowSpec):\n",
    "    @step\n",
    "    def start(self):\n",
    "        self.next(self.train)\n",
    "    \n",
    "    @step\n",
    "    def train(self):\n",
    "        train()\n",
    "        self.next(self.end)\n",
    "    \n",
    "    @step\n",
    "    def end(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a3d9ea-e961-4fab-97e9-70dd41fc143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f010c65-9205-40ea-a667-78192310942f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['echo', 'hello world'], returncode=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subprocess.run([\"echo\", \"hello world\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a84b8a5-9ffe-466d-bae5-daa0d5487cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23824bde-e99b-451b-84f4-1e68667b5688",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = reduce(lambda x, y: x+y, numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a897d4-0fbe-4fe8-b11a-088e58d3ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac2978e-99cf-494b-a8a0-c1a6456094cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\n",
    "    \"input, output\",\n",
    "    [(2, 1), (2, 4)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdece6dd-527c-4b20-b0f7-a6a24bbe4ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a7a0c2-d4e5-4b52-8fae-544d41c59363",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = cast(List[int], numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a011675-ff51-4d51-9304-edce640661e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outer_func():\n",
    "    x = \"hello\"\n",
    "    def inner_func():\n",
    "        nonlocal x\n",
    "        x = \"shivon\"\n",
    "    \n",
    "    inner_func()\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa889a-3e91-407e-9ec4-44a4916eed6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shivon\n"
     ]
    }
   ],
   "source": [
    "outer_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6c0e75-3d1b-4a9c-b41c-b1eff0f792ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: num\n",
    "step 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1947ba-9e43-49e5-aa33-f4c676992d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: create a network\n",
    "step 2: attach the network\n",
    "step 3: receive the ips\n",
    "step 4: communicate through the ips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc216d2-1aaf-4ce8-a2ec-498ae173c757",
   "metadata": {},
   "outputs": [],
   "source": [
    "value, key, timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a090fd3c-d5bf-410f-95ba-31b33f81f536",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d493f1-80a3-49bd-b926-8697a1002afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2abc5f2-1aca-4fd5-85ad-9bb173609e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelMLP(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.dense_h_to_4h = ColumnParallelLinear(\n",
    "            input_size=hidden_size,\n",
    "            ouput_size=hidden_size*4\n",
    "        )\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dense_4h_to_h = RowParallelLinear(\n",
    "            input_size=hidden_size*4,\n",
    "            output_size=hidden_size\n",
    "        )\n",
    "    \n",
    "    def forward(self, input):\n",
    "        intermediate_output = self.dense_h_to_4h(input)\n",
    "        intermediate_output = self.gelu(intermediate_output)\n",
    "        output = self.dense_4h_to_h(intermediate_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3198ba0e-2987-4f31-ac61-acce2d536196",
   "metadata": {},
   "outputs": [],
   "source": [
    "in the same replicas model\n",
    "different partrition of the same layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe31348-7447-4967-b3cd-4980b189f4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_grad_enabled(x):\n",
    "    return torch.is_grad_enabled() and x.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf1bd8f-96be-4e7c-b54f-38f56c25a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _broadcast(x):\n",
    "    return x.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0720bd5f-1ac3-40c7-9a71-035689ac1f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reduce(x):\n",
    "    world_size = torch.distributed.get_world_size(group=parallel_group)\n",
    "    torch.distributed.all_reduce(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c47fd-4977-44b5-8c46-b356fe96a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Broadcast(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return _broadcast(input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return _reduce(grad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58624d13-67e9-4a8c-9b0a-0e77b6f9fc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_with_forward_and_backward(inputs):\n",
    "    if is_grad_enabled(inputs):\n",
    "        outputs = Broadcast.apply(inputs)\n",
    "    else:\n",
    "        outputs = _broadcast(inputs)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a618cd-9715-4c5a-b744-06bf835178df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabParallelEmbedding(nn.Module):\n",
    "    def __init__(self, num_embedding, embedding_dim):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        self.num_embedding = num_embedding\n",
    "        self.embedding_dim_per_partrition = embedding_dim // world_size\n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.embedding_dim_per_partrition\n",
    "        ))\n",
    "        \n",
    "        self.vocab_start_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5ce0db-98e2-4ca4-aeea-3ef2be573d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: load to disk\n",
    "step 2: ids\n",
    "step 3: memory size\n",
    "step 4: reserve\n",
    "step 5: load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037ea2c5-64dc-4788-ae62-7a16b383ab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = interference.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd8d6f2-68ef-424b-bbe2-71034c9c6781",
   "metadata": {},
   "outputs": [],
   "source": [
    "polysemanticity[\n",
    "    torch.arange(n_features),\n",
    "    torch.arange(n_features)\n",
    "] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f883e0-4e57-4eba-bbe7-db8ea3b514d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "polysemanticity = polysemanticity.pow(2).sum(dim=-1).sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576e9072-45f3-46b7-8dc3-a04723a07048",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31cdaa7-1b61-4946-bd1e-d95a06f5dc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0290e6c-bd57-4f76-a9ca-70b5826c7f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pattern = torch.zeros(seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed51385-9ed6-445d-b98d-3dde896fd34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pattern[torch.arange(seq_len), torch.arange(seq_len)-1] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061b0872-c429-4e4e-b502-d173b95d569f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd773be-1499-4f67-82cf-ae7ef0a8593b",
   "metadata": {},
   "outputs": [],
   "source": [
    "consis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb54a1-5aba-4622-a77e-5c8ef33ab202",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_tokens = model.to_tokens(repeated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f07caa6-333a-4144-bdcd-9b725a538c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model(repeated_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd171895-1d52-4475-a2b7-b1ee57eab00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "induction_heads = [(6, 9), (4, 2)]\n",
    "attention_patterns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a49e8-7ea1-400a-a8a9-e0413ba2cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a27a59a-a204-4497-962e-95c9a449009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for head_idx, layer_idx in induction_heads:\n",
    "    act_name = utils.get_act_name(\"attn\", layer_idx)\n",
    "    layer_attention_pattern = cache[act_name]\n",
    "    head_attention_pattern = layer_attention_pattern[:, head_idx]\n",
    "    attention_patterns.append(head_attention_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5ad151-0e24-4585-95d8-a427cdfd019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: create two prompts\n",
    "step 2: record activation\n",
    "step 3: patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60359639-bc27-4997-b7a7-7dd6ddf78159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694e2290-4158-4ec7-a930-0d4727b3d9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "induction_score = reduce(\n",
    "    induction_stripe,\n",
    "    \"heads n_weights -> heads\",\n",
    "    reduction=\"mean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72f2c0b-9db3-420b-be1d-f53a1b467f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_weights.diagonal(\n",
    "    dim1=-2,\n",
    "    dim2=-1,\n",
    "    offset=1-seq_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ef1618-c285-4a77-8f73-19c047250698",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = model.to_tokens(clean_prompt)\n",
    "corrupted_tokens = model.to_tokens(corrupted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f5aa32-394c-4106-a856-2af86d05163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_token = model.to_single_token(\" John\")\n",
    "incorrect_token = model.to_single_token(\" Mary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7457c94b-94af-4bfb-8cb0-1a099554b12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = clean_tokens.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c162078-c612-4179-ba6c-84e716ce11bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_activations = model.run_with_cache(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8214b355-41f9-40d2-98b0-1f90ca7af000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_component(\n",
    "    corrupted_activations,\n",
    "    hook,\n",
    "    position,\n",
    "    clean_activations\n",
    "):\n",
    "    corrupted_activations[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb74e11a-337c-4668-bec1-9f3f0be3cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf23d91-27e8-477c-bc37-c32141538e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ca4b31-b368-4adf-a4d3-a0b94f431225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logit_diff(logits, correct_token, incorrect_token):\n",
    "    last_token_logits = logits[:, -1, :]\n",
    "    correct_logit = last_token_logits[:, correct_token]\n",
    "    incorrect_logit = last_token_logits[:, incorrect_token]\n",
    "    return correct_logit - incorrect_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363ddf38-c9b1-4bd0-8167-72a0ade67687",
   "metadata": {},
   "outputs": [],
   "source": [
    "patched_residual_stream_diff = torch.zeros(n_layers, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ca4d15-60ff-4131-bed5-0779454d6a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(n_layers):\n",
    "    for position in range(seq_len):\n",
    "        hook_name = utils.get_act_name(\"resid_pre\", layer_idx)\n",
    "        hook_func = partial(\n",
    "            patch_component,\n",
    "            position=position,\n",
    "            clean_activations=clean_activations\n",
    "        )\n",
    "        \n",
    "        patched_logits = model.run_with_hooks(\n",
    "            corrupted_tokens,\n",
    "            fwd_hooks=[(hook_name, hook_func)]\n",
    "        )\n",
    "        logit_diff = compute_logit_diff(patched_logits, correct_token, incorrect_token)\n",
    "        patched_residual_stream_diff[layer_idx, position] = logit_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582d9dba-e577-4481-a58e-4ba75d230fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: create a clean prompt and corrupted prompt\n",
    "step 2: record the activations of the clean prompt\n",
    "step 3: run the model again with the corrupted prompt\n",
    "step 4: patch\n",
    "step 5: logit diff\n",
    "step 6: identify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1c0799-d04b-411a-a6dc-e9ecf84e8552",
   "metadata": {},
   "source": [
    "### AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e51514-8af9-4787-a6c9-b6e71fc1a6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25c9e3a-2bd0-46b2-8113-6572ec26c077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e307d75-2fd1-4d2d-9777-e68be240b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer,\n",
    "    mlm=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b437640f-714d-4024-ade2-974f4a029c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a77595-2251-4231-8db6-a882064ea490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bee544-ced8-4aa6-a853-4e8262ff6c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jax.jit, static_argnames=[\"n\"])\n",
    "def demo():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64367acf-d386-4159-a670-a37e46a1c338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7670a95e-7711-40e3-abb6-33b035c6ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def fast_retrieve(x):\n",
    "    return retrieve(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9860a3c6-858b-455b-87fc-488cf239b05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [fast_retrieve.remote(x) for x in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e5fd2b-277d-4bbb-95fc-13898fdd2b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c1386d-90ae-4957-af2f-ed8c31dd2a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b46e34-f485-4ecf-aba7-c5a7f63ffb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4718e982-64c4-4f38-9f58-4a830d1f588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d84f4-3cc4-449a-a7f5-2d9d80029d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune.schedulers import HyperBandScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c912beae-aa16-487e-9b67-9db23c66b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = HyperBandScheduler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431d8a3a-7af8-4adb-b2ad-fcf392b64f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune.run(\n",
    "    objective,\n",
    "    config=search_space,\n",
    "    scheduler=scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f1fb46-79a1-4b73-a414-858e487ad077",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_state = torch.tensor([0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5867aba3-4770-4d14-bc72-c737cf5ee614",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_state.T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde727b2-581a-4dde-9f43-a857de87047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import tree_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159f0431-9c02-4a07-92e5-5cd09a76545f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_map(square, xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442478f7-27ae-42c4-b772-2e774559eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = torch.cuda.Stream(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc6aa7-cd6c-4d8f-a07b-4ec1ba64232f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.device(device):\n",
    "    torch.cuda.stream(stream):\n",
    "        mean = xs.mean(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5e0758-a327-452e-a7f5-13f4f9608be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153b0666-92c1-458d-a94b-54cbffefe553",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv(Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.action_space = Discrete(3)\n",
    "        self.observation_space = Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e11af59-2c48-4365-9dc1-43fc0b06ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditioned, stimulus-evoke, motor, population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eff1c42-3492-42fa-ae7c-3fefb8391962",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd77b6d-28b6-40b2-a364-c17ee2662300",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_logits = logits[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18aa82c5-e0e7-448a-8cdb-eb1062db4e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_logits[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6302fdc-84f2-47a7-b6f5-6e680edafc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cross_entropy(logits, targets):\n",
    "    log_probs = F.log_probs(logits, dim=-1)\n",
    "    return -log_probs[torch.arange(targets), targets].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e6bdd6-ced8-46f7-bdbf-d59c7eda6da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42c9775-ab8c-410e-b3f5-542ddbbd664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.vector.SyncVectorEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a5ee5b-f18a-4d5b-8a05-492eca7e427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_score(image_embedding, text_embedding):\n",
    "    image_norm = image_embedding.norm(dim=-1)\n",
    "    image_embedding = image_embedding / image_norm\n",
    "    \n",
    "    text_norm = text_embedding.norm(dim=-1)\n",
    "    text_embedding = text_embedding / text_norm\n",
    "    \n",
    "    similarities = image_embedding @ text_embedding.T\n",
    "    probs = F.probs(similarities, dim=-1)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a4c813-3ce3-41b7-a492-f576736885eb",
   "metadata": {},
   "source": [
    "Step 1: Add the file to DVC.\n",
    "\n",
    "Step 2: Update the `.gitignore` file to ignore the original file `x.txt`. Because we only want Git to track the DVC file (which is a small metadata file), not the original large data file.\n",
    "\n",
    "Step 3: Commit the changes to Git.\n",
    "\n",
    "Step 4: Push the dvc metadata file to remote storage\n",
    "\n",
    "Step 5: Push the changes to Git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f75503b-fede-43ca-bf95-2474a1bb3f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1b9585-e0d4-4489-878b-871d2d9072e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec300e21-af73-4471-a2c5-a4cb89bcc0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = Report(metrics=[\n",
    "    DataDriftPreset()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0be9c8-64c2-43a0-9f6e-3c37913f9040",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.run(reference=reference, current=current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e9b88f-4fea-4128-b2f5-2cc4d2523514",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: add the file to dvc\n",
    "step 2: add git\n",
    "step 3: git ignore\n",
    "step 4: dvc push\n",
    "step 5: git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd19876b-79cc-4b60-b9ce-38a283e5076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: q&a prompt\n",
    "step 2: yes and no\n",
    "step 3: hidden states to probs\n",
    "step 4: normalize\n",
    "step 5: linear probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8e45e6-2ed1-4151-97d3-6795353f6597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77af74d-b46d-4628-8482-29d8af060b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cross_entropy(logits, targets):\n",
    "    log_probs = F.log_probs(logits, dim=-1)\n",
    "    return -log_probs[torch.arange(len(targets)), targets].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643bde22-9bc9-4d6c-b698-89fdd8c275f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "components = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12495ba-2c83-4330-852a-2404b27d86d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = cache[\"hook_embed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b84aeb0-32ba-42b1-8ff6-81ae5ab177c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_embeddings = cache[\"hook_pos_embed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c8251-4af1-49be-8793-f73264eb05eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "components.append(text_embeddings)\n",
    "components.append(positional_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678ac31f-cc79-4d7e-a042-eb323fa3f9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(4):\n",
    "    attn_name = get_act_name(\"attn_out\", layer_idx)\n",
    "    mlp_name = get_act_name(\"mlp_out\", layer_idx)\n",
    "    components.append(attn_name)\n",
    "    components.append(mlp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f748c9-2df5-449d-b61d-4ee4921dcf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "discounted_returns = get_discounted_return(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62b0b11-c157-4a77-b9fa-65a2e25d3064",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c305e0-7c81-4138-8295-59efc3dd327e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for discounted_return, prob in zip(discounted_return, selected_action_probs):\n",
    "    total_loss += -discounted_return*prob.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c90d5e-feb1-44dc-b448-40a9fc610aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, n_heads)\n",
    "        self.norm_1 = ResidualLayerNorm(d_model, dropout)\n",
    "        self.feedforward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm_2 = ResidualLayerNorm(d_model, dropout)\n",
    "    \n",
    "    def forward(self, embeddings):\n",
    "        attn_output, attn_pattern = self.mha(embeddings)\n",
    "        norm_1 = self.norm_1(attn_output, embeddings)\n",
    "        feedforward = self.feedforward(norm_1)\n",
    "        norm_2 = self.norm_2(feedforward, norm_1)\n",
    "        return norm_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d828ded-06bc-4ac6-90f4-87702f8f89b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        for param in self.params:\n",
    "            if param.requires_grad:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194736ba-2463-489c-9fac-a9346f0d2198",
   "metadata": {},
   "outputs": [],
   "source": [
    "5, 27, 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8719dc9d-11f4-442e-871c-fff0710814a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: qa\n",
    "step 2: yes no\n",
    "step 3: hidden states\n",
    "step 4: normalize\n",
    "step 5: probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc17a36-f0de-408a-a67f-8da2930392cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for param in self.params:\n",
    "                if param.requires_grad:\n",
    "                    param -= param.grad * self.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502c22d3-c331-4a84-a1d6-8e3f0b135ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
