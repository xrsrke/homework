{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "592022ed-629d-4600-95d1-5127846e0024",
   "metadata": {},
   "source": [
    "### SCi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23849f2e-ffac-4ca4-af79-7e0e5bb45fe7",
   "metadata": {},
   "source": [
    "### ML Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed2731-d3a1-42cc-9582-2bc8dae734e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4ddded-cf36-41e6-9480-a103ee4be58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.groupby(\"title\")[\"rating\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77413e38-6774-4e9a-8f21-ad24f23e9f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f14a419-2402-4c4d-bf15-e044925a54fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = Thread(target=print_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e1a404-a67f-4030-9bde-c657b764453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea70dc14-b5e8-48b3-890c-f41ae866c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c38e4a-6688-4b47-9cb9-a5db220eabe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def second_context():\n",
    "    print(\"entering\")\n",
    "    \n",
    "    yield \"hello, world\"\n",
    "    \n",
    "    print(\"exit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccd4659-da9c-4c01-a727-5ad9e084a24e",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cee4c3-16af-4d65-85ee-7a8977ec577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer states, param, forwrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cf3b5a-b21d-4610-8c5e-4f20157c5250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af9297f-39c0-4d2d-8a71-5ab6fe5ad916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_communication(rank, world_size, config):\n",
    "    torch.distributed.init_process_group(*config, rank=rank, world_size=world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675c80f1-eb21-4636-b8fc-c0263514172c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rank in range(world_size):\n",
    "    p = Process(target=init_communication, args=(rank, world_size, config))\n",
    "    p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedd6004-8661-474c-91bd-b5d30d6bcfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rank in range(world_size):\n",
    "    p = Process(target=say_hello, args=(rank, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5307fb9e-5c10-4851-a89b-30da8e57ad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabParallelEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        self.num_embedding_per_patrition = num_embeddings // world_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.num_embedding_per_patrition,\n",
    "            self.embedding_dim\n",
    "        ))\n",
    "        \n",
    "        self.vocab_start_idx, self.vocab_end_idx = self.get_range(\n",
    "            rank,\n",
    "            world_size\n",
    "        )\n",
    "    \n",
    "    def get_range(self):\n",
    "        return \n",
    "    \n",
    "    def forward(self, input):\n",
    "        \n",
    "        mask = (input < vocab_start_idx) | (input >= vocab_end_idx)\n",
    "        input[mask] = 0\n",
    "        \n",
    "        output_parallel = F.embedding(input, self.weight)\n",
    "        mask_idx = torch.where(mask == True)[1]\n",
    "        output_parallel[:, mask_idx, :] 0.\n",
    "        \n",
    "        torch.distributed.all_reduce(output_paralle )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2f6a08-d1b4-42a7-a137-16d21d4ca80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5475af61-b1a2-4390-94d7-2268eafa075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0798bd6-8f79-4615-a323-d3f03c77684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0204ae55-38d3-43b7-8421-e18213002a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_weights(x):\n",
    "    n_cols = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7133d4-3154-4adb-885d-ae05ae55d4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabParallelEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        self.num_embedding_per_patrition = world_size // num_embeddings\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.vocab_start_idx, self.end_vocab_idx = self.get_vocab_range(num_embeddings, embedding_dim)\n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.num_embedding_per_patrition,\n",
    "            self.embedding_dim\n",
    "        ))\n",
    "    \n",
    "    def get_vocab_range(self, rank, num_embedding_per_patrition\n",
    "        start_idx = rank * num_embedding_per_patrition\n",
    "        end_idx = start_idx + num_embedding_per_patrition\n",
    "        return start_idx, end_idx\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mask = (x < self.vocab_start_idx) | (x >= self.vocab_end_idx)\n",
    "        x.sub_(self.vocab_start_idx)\n",
    "        x[mask] = 0.\n",
    "        output_paralell = F.embedding(x, self.weight)\n",
    "        mask_idxs = torch.where(mask == True)[1]\n",
    "        output_parallel[mask_idxs] = 0.\n",
    "        \n",
    "        torch.distributed.all_reduce(output_paralle)\n",
    "                        \n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5932e92a-3632-4aed-ae20-6e2000ae01e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.init.kaiming_normal_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35729a0-7901-4baa-86e8-338634fc47e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1.data.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2350a5b0-b615-450d-bee5-569159ec44b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5c010e-ff6a-448c-b4aa-c33d4d93d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b45a7f6-4dd3-4b70-b0dd-60ec9fb66fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(x):\n",
    "    return tokenizer(x[\"sentence1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e96b0-969d-41b2-8717-76c3d38a4180",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = small_dataset.map(tokenize_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a012b-5be1-45dd-829d-ed9200b5a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = torch.cuda.Stream(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd47d27-2609-459d-9cd9-6952b05e2046",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.stream(stream):\n",
    "    mean = xs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b8f6b0-3b79-4843-8ba2-2b10020b160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb0a765-9f41-4fa1-9161-2bdbaa25137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU]\n",
    ") as prof:\n",
    "    hardcore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563eb545-1283-4e2d-a6c2-aeb8fbf32f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521df9b9-8ede-428f-9bba-087f4ea95c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(params):\n",
    "    x, y = params[\"x\"], params[\"y\"]\n",
    "    score = objective(x, y)\n",
    "    tune.report(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0c0e8f-7e18-4e73-b769-01037db7cad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tune.run(\n",
    "    func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24b7a15-e343-4eeb-bc24-291b16b03433",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.ppo import PPOConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d69a462-42dd-4a3b-bc16-d1b13a606408",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.device(device):\n",
    "    total = x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac83c1-25bf-4501-90e1-9a68795ccd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e422f581-1364-463f-be50-fb55f3163445",
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU],\n",
    "    schedule=schedule()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf38ce0-87a4-4b54-a954-9ad6d7511db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.schedulers import Hyb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5273cd67-9d79-4500-b02d-9355644f03e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02001b88-0e82-414c-832f-59087bedb494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_communication(name, rank, world_size):\n",
    "    rpc.init_rpc(\"worker_1\", rank=rank, world_size=world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda07d43-37ad-4b4b-956e-94e15a91c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_func(act, hook):\n",
    "    print(act.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd0f88e-e1ac-4d85-9a27-356a84a2e366",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run_with_hooks(tokens, hook_fwd=[(hook_name, hook_func)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9025fea3-005c-4b78-b10e-20e1e8e679aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(x):\n",
    "    return x[\"sentence1\"].startswith(\"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a489ac6d-9928-452e-97c9-44fa5719fcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = small_dataset.filter(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a4a6a4-5439-485c-89d0-93e3de48e016",
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU],\n",
    "    schedule=torch.profiler.schedule(**schedular_params)\n",
    "):\n",
    "    for idx in range(8):\n",
    "        model(inputs)\n",
    "        profiler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0911a76d-7096-4303-b585-08435b643633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994010fd-7d0f-47e4-b682-716fa0b1f442",
   "metadata": {},
   "outputs": [],
   "source": [
    "interference = einsum(\n",
    "    W, W,\n",
    "    \"instances feature_1 dim, instances feature_2 dim -> instances\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1526e18-8890-4cf0-98fc-a6386fabcafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.schedulers import HyperBandScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b8dca5-b301-4156-a9ea-fdbc559ca576",
   "metadata": {},
   "outputs": [],
   "source": [
    " step 1: tokenize the prompt\n",
    "    step 2: pre\n",
    "    step 3: exec\n",
    "    step 4: tokenize the observation\n",
    "    step 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1a3b4a-8f6a-4453-84bf-835d2c0f6ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U[tokens, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c416e7-2cc6-45cc-a0fd-7f37ce0a2846",
   "metadata": {},
   "outputs": [],
   "source": [
    "interference = einsum(\n",
    "    W, W,\n",
    "    \"instances feature_1 dim, instances feature_2 dim -> instances feature_1 feature_2\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
