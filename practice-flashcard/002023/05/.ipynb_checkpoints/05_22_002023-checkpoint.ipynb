{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9877c173-3263-4058-bb5d-2a015d2bf83d",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab701069-8186-443c-a445-ff15c1cba2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fc7922-b20c-4e53-95fd-3c653f3ba278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738baf7a-5140-4b77-8e43-3fa84fd6f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPU:\n",
    "    def __init__(self, master_addr, master_port, backend):\n",
    "        if not torch.distributed.is_initialized():\n",
    "            self.initialize_distributed(master_addr, master_port, backend)\n",
    "    \n",
    "    def process_to_device(self, rank):\n",
    "        device_count = torch.cuda.device_count()\n",
    "        \n",
    "        if device_count > 0:\n",
    "            device = rank % device_count\n",
    "            torch.cuda.set_device(device)\n",
    "    \n",
    "    def initialize_distributed(self, master_addr, master_port, backend):\n",
    "        if not torch.distributed.is_initialized():\n",
    "            rank = int(os.getenv[\"RANK\"])\n",
    "            world_size = int(os.getenv[\"WORLD_SIZE\"])\n",
    "            os.environ[\"MASTER_ADDR\"] = master_addr\n",
    "            os.environ[\"MASTER_PORT\"] = master_port\n",
    "            \n",
    "            self.process_to_device(rank)\n",
    "            \n",
    "            torch.distributed.new_process_group(\n",
    "                rank=rank,\n",
    "                world_size=world_size,\n",
    "                backend=backend\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f466931-8637-433f-8d07-3f5805fe1817",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size, world_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size_per_partrition = output_size // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_partrition,\n",
    "            self.input_size\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_partrition\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output_partrition = F.linear(input, self.weight, self.bias)\n",
    "        \n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        outputs = [torch.empty_like(output_partrition) for _ in range(world_size)]\n",
    "        torch.distributed.all_gather(outputs, output_partrition)\n",
    "        outputs = torch.cat(outputs, dim=-1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79b4e4c-7f24-4615-b05b-a6a514e85551",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: replicate the model\n",
    "step 2: divide mini-batch into micro-batches\n",
    "step 3: forward pass\n",
    "step 4: average the gradient\n",
    "step 5: update gradient to all devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535a627e-1d36-48fa-bbcc-cb9e1eaac0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor parallelism, pipeline parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1956180b-9af4-48e7-ba09-f2470e1f42ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_memory(model):\n",
    "    total_memory = 0\n",
    "    \n",
    "    for param model.parameters():\n",
    "        total_size += param.numel() * param.element_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2639af6a-cc82-4c46-88f4-655aff42420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file system, shared memory, message passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d0950d-5976-4cc5-ad10-07f9866d0094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _broadcast(input):\n",
    "    return input.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b88358d-fa3e-4b1c-b23b-1a2fcdaa83f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reduce(grad_output):\n",
    "    world_size = torch.distributed.get_world_size(group=process_group)\n",
    "    \n",
    "    if world_size == 1:\n",
    "        return grad_output\n",
    "\n",
    "    torch.distributed.all_reduce(grad_output)\n",
    "    return grad_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a929a2-d8ef-4df4-80b2-cc46460f9064",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Broadcast(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return _broadcast(input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return _reduce(grad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7c729a-a7de-460d-807e-f5819011af40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_with_forward_and_backward(inputs):\n",
    "    if is_grad_enable(inputs):\n",
    "        outputs = Broadcast.apply(inputs)\n",
    "    else:\n",
    "        outputs = _broadcast(inputs)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39263811-c7c3-4d2a-8e94-bffc6b2dc124",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540bf68f-1075-422b-9244-2bdd122720e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachedDataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.cache_index = []\n",
    "        self.data = None\n",
    "    \n",
    "    def prefetch(self, idxs):\n",
    "        if all([i in self.cache_index for i in idxs]):\n",
    "            return\n",
    "    \n",
    "        if not self.data:\n",
    "            self.data = torch.load(self.filename)\n",
    "        \n",
    "        total_elements = sum([x.numel() for x in self.data])\n",
    "        self.cache = torch.empty(total_elements, dtype=self.data.dtype)\n",
    "        self.cache_index.clear()\n",
    "        \n",
    "        offset = 0\n",
    "        \n",
    "        for i in idxs:\n",
    "            n_elements = self.data[i].numel()\n",
    "            self.cache[offset:offset+n_elements] = self.data[i]\n",
    "            self.cache_index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30748d4e-a283-414f-aa1a-743d5c2273ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b17aa5-64ed-492c-8715-f03fa59787f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_model_parallel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7c2e91-8386-4437-acbb-77be754ae888",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model_parallel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f7856e-54e0-40fe-bd49-15bcde8d3248",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline_model_parallel_groups = world_size // pipeline_model_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb08dd0-8c67-43d4-ac89-73c76a7687ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline_model_parallel_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef8243e-1ff3-47f9-b127-ea1c73b14cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2]\n",
      "[1, 3]\n",
      "[4, 6]\n",
      "[5, 7]\n",
      "[8, 10]\n",
      "[9, 11]\n",
      "[12, 14]\n",
      "[13, 15]\n"
     ]
    }
   ],
   "source": [
    "for i in range(pipeline_model_parallel_size):\n",
    "    start_rank = i*num_pipeline_model_parallel_groups\n",
    "    end_rank = (i+1)*num_pipeline_model_parallel_groups\n",
    "    \n",
    "    for j in range(tensor_model_parallel_size):\n",
    "        ranks = list(range(\n",
    "            start_rank+j,\n",
    "            end_rank,\n",
    "            tensor_model_parallel_size\n",
    "        ))\n",
    "        \n",
    "        print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e79658-2b8c-4b6b-b592-995a3f2978e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast, scatter, reduce, gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd52da0-cbb4-41f4-bba6-508332318568",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size, world_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size_per_partrition = output_size // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_partrition,\n",
    "            self.input_size\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_partrition\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output_parallel = F.linear(input, self.weight, self.bias)\n",
    "        \n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        outputs = [torch.empty_like(output_parallel) for _ in range(world_size)]\n",
    "        torch.distributed.all_gather(outputs, output_parallel)\n",
    "        outputs = torch.cat(outputs, dim=-1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376b42cd-8f4d-4bda-b02b-33145b7c7a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_column_parallelism(inputs, weights):\n",
    "    dim_size = weights.shape[-1]\n",
    "    \n",
    "    w1, w2 = weights[:, :dim_size//2], weights[:, dim_size//2:]\n",
    "    \n",
    "    out1 = torch.matmul(inputs, w1)\n",
    "    out2 = torch.matmul(inputs, w2)\n",
    "    out = torch.cat([out1, out2], dim=-1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d574e6c2-7e5f-42c9-abda-16ee578a97bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: load training data\n",
    "step 2: list items\n",
    "step 3: total size\n",
    "step 4: memory continuous\n",
    "step 5: load item to that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303c841f-b4ee-4de1-9c5d-a839e78f90bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: patrition the parmaeter\n",
    "step 2: move to rank\n",
    "step 3: move to device\n",
    "step 4: init local optimizer\n",
    "step 5: do local step\n",
    "step 6: broadcast\n",
    "step 7: update all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a62ae0-4f07-4bc9-87ad-af41da73e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fee418-7d7a-4cee-8411-14301d24f899",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.randn(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b511da7c-c256-4ad4-87c3-67603c94f748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_row_parallelism(inputs, weights):\n",
    "    x1, x2 = torch.chunk(inputs, chunks=2, dim=-1)\n",
    "    w1, w2 = torch.chunk(weights, chunks=2, dim=0)\n",
    "    \n",
    "    out1 = x1 @ w1\n",
    "    out2 = x2 @ w2\n",
    "    \n",
    "    return out1 + out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9708838-922f-4755-b2c1-31c70ba7e47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8840,  0.0045],\n",
       "        [ 2.1557,  0.1922]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_row_parallelism(inputs, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093df742-0064-4aa3-81ad-9832f66dd588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.8840,  0.0045],\n",
       "        [ 2.1557,  0.1922]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs @ weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6aabdb-68b0-4c5e-8cda-f8a745b1fd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "send sync, recv sync\n",
    "send sync, recev async\n",
    "send async, recev sync\n",
    "send async, recev async"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e163f5-7406-48fd-8653-70e4ebe30ca8",
   "metadata": {},
   "source": [
    "### ML Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5446e0f-ebc5-482e-9408-9cebb894ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import FlowSpec, conda, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb85240d-9b25-4bd9-a276-6d32045fb35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingFlow(FlowSpec):\n",
    "    @step\n",
    "    def start(self):\n",
    "        self.next(self.train)\n",
    "    \n",
    "    @conda(python=\"3.11.0\", libraries={\"pytorch\": \"2.0.0\"})\n",
    "    @step\n",
    "    def train(self):\n",
    "        train()\n",
    "        self.next(self.end)\n",
    "    \n",
    "    @step\n",
    "    def end(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388656a0-0075-4b38-a09a-50b88e002287",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker start 31b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e0f1e-5686-473b-93fb-6fe9971467de",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker network create mongo-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48710e21-e158-4507-ba64-e2ac7856458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7f724a-69dc-4265-901f-a6fb0a52b542",
   "metadata": {},
   "outputs": [],
   "source": [
    "class User(BaseModel):\n",
    "    user_id: int\n",
    "    username: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50afa3be-4e67-4a2b-855d-e2643756062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01462329-f966-483c-b2de-f11472c26ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with S3() as s3:\n",
    "    res = s3.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66616a3c-ac78-4c9f-a204-047c4da8197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abee5a8-bc98-40ed-b5e1-dc0f0d6cae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = partial(lambda x, y: x + y, numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8d4dbf-74d0-47b6-b57e-9202e0ffec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker log monitor_app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8ad845-ca34-459e-b3ff-0d635b9ef93c",
   "metadata": {},
   "source": [
    "### AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c78e125-8a5d-4a50-8af7-41c778ee7068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb738b76-7f1f-4f2a-be59-450416b5b938",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_groups in optimizer.param_groups:\n",
    "    for param in param_groups[\"params\"]:\n",
    "        print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4e22b3-c86c-495b-9cc0-676eb5775f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.amax(6, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e82d48-ece9-4247-9e78-a968535284f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = torch.cuda.Stream(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5edacd3-f546-4159-85d1-0f20876d40ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.device(device):\n",
    "    with torch.cuda.stream(stream):\n",
    "        mean = xs.mean(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615bcd2f-3808-4911-9a46-37427b4bac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77855935-74c2-4eea-87b6-34b8c4b5a409",
   "metadata": {},
   "outputs": [],
   "source": [
    "features are represented directions\n",
    "features are linear representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0037b70-d7b4-4cae-9d35-9c8c46a65e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102d86e4-8e51-479e-8b12-1953a044394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: choose a component C\n",
    "step 2: two prompts x1 and x2\n",
    "step 3: record activations of C in x1\n",
    "step 4: activation patching \n",
    "step 5: compare the difference in the output logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961d87dd-ccff-459b-9ea8-73ef62058798",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[\"embed.hook_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cd8af2-c3e9-49de-ba32-38b826694b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = model.to_tokens(clean_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f9c0ed-2bf7-4e0b-84bc-fcb85b1c5550",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_tokens = model.to_tokens(corrupted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac426a5-16b3-4955-913a-3c86d858940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_token = model.to_single_token(\" John\")\n",
    "incorrect_token = model.to_single_token(\" Mary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84951e9-eca8-40fd-96e5-987c2598c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_activations = model(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7bf6f0-979b-4156-b208-b5f84890a3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = clean_tokens.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378ad83e-2164-45c2-9b61-253df744eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018b40f1-6a8c-4546-945f-dcb475ef5176",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15673b2e-cabf-4959-9393-4d33c9fda489",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98b3405-8a6b-4dd0-8211-cf8c3f0374f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_component(corrupted_activations, hook, position, clean_activations):\n",
    "    corrupted_activations[batch_idx, position, :] = clean_activations[hook.name][batch_idx, position, :]\n",
    "    return clean_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e96d8f-dc94-447f-9b1c-6940910dbcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logit_diff(logits, correct_token, incorrect_token):\n",
    "    last_token_logit = logits[:, -1, :]\n",
    "    correct_logit = last_token_logit[:, correct_token]\n",
    "    incorrect_logit = last_token_logit[:, incorrect_token]\n",
    "    return correct_logit - incorrect_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d41496a-9527-4f2c-82ec-6d63e32c507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.zeros(n_layers, n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d67709-e3f4-47ce-9fb9-1b34545c90ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(n_layers):\n",
    "    for position in range(n_tokens):\n",
    "        hook_name = get_act_name(\"resid_pre\", layer_idx)\n",
    "        hook_func = partial(patch_component, position=position, clean_activations=clean_activations)\n",
    "        \n",
    "        corrupted_logits = model.run_with_hooks(\n",
    "            corrupted_tokens,\n",
    "            fwd_hooks=[(hook_name, hook_func)],\n",
    "            return_type=\"logits\"\n",
    "        )\n",
    "        logit_diff = compute_logit_diff(corrupted_logits, correct_token, incorrect_token)\n",
    "        data[layer_idx][position] = logit_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e74332-51e0-476c-a3a1-6a2ce9069aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f14c73a-fb79-443e-95a3-79c05912be60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550dcdb-b91f-4fc3-aa6b-3618a9c90863",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = repeat(x, \"h w -> h w new_axis\", n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b6022-2364-4270-9f9a-78ed5fe95877",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_tokens = model.to_tokens(repeated_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71219e7b-647b-40c0-8b34-460651b2d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_logits = model(repeated_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa789b29-fe70-4c5f-888b-1e2d28038962",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = F.softmax(repeated_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa22b2b7-0638-4079-bbcf-1b35bac8f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_probs = probs[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeece9ed-b14a-477f-b01b-cd52dc1262e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = repeated_tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39a2110-9440-4f72-be6a-30138331fd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_log_probs = -last_probs[target].log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a9a1ba-732a-4537-986e-e2ae15caaf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_scores(image_embedding, text_embedding):\n",
    "    image_norm = image_embedding.norm(dim=-1)\n",
    "    image_embedding = image_embedding / image_norm\n",
    "    \n",
    "    text_norm = text_embedding.norm(dim=-1)\n",
    "    text_embedding = text_embedding / text_norm\n",
    "    \n",
    "    similarities = image_embedding @ text_embedding.T\n",
    "    probs = F.softmax(similarities, dim=-1)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea195c-5e3c-4f02-ae7d-803a737e9c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, n_heads)\n",
    "        self.norm_1 = ResidualLayerNorm(d_model, dropout)\n",
    "        self.feed_forward = PositionFeedForward(d_model, d_ff, dropout)\n",
    "        self.norm_2 = ResidualLayerNorm(d_model, dropout)\n",
    "    \n",
    "    def forward(self, embeddings):\n",
    "        attn_output, attn_weights = self.mha(embeddings)\n",
    "        norm_1 = self.norm_1(attn_output, embeddings)\n",
    "        feed_forward = self.feed_forward(norm_1)\n",
    "        norm_2 = self.norm_2(feed_forward, norm_1)\n",
    "        return norm_2, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b657b8d-b6ea-4a5f-9c45-839694f71f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6069b3-8877-40dd-a8d7-50aed2ba82df",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = repeat(x, \"h w -> h w n\", n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade8aaac-7123-4001-a01c-1003460768ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026e9084-7771-4864-93a4-75e83ebcbcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for discount_return, prob in zip():\n",
    "    total_loss += discount_return * -prob.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e677b84-4631-4381-92cf-b0036e54f167",
   "metadata": {},
   "outputs": [],
   "source": [
    "isend"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
