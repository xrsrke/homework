{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41d97317-4e1a-44af-8cf3-77ab9fc7d5b1",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369ae974-119f-4e29-abb4-bb00138e38dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff05dd0-fcc7-4738-adf6-f51461950928",
   "metadata": {},
   "outputs": [],
   "source": [
    "class f(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        torch.distributed.all_reduce(grad_output)\n",
    "        return grad_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b09f58-cb4b-4edb-803a-314641b8c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class g(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        inputs = [torch.empty_like(input) for _ in range(world_size)]\n",
    "        torch.distributed.all_gather(inputs, input)\n",
    "        inputs = torch.cat(inputs, dim=-1)\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        last_dim_size = grad_output.shape[-1]\n",
    "        chunk_size = last_dim_size // world_size\n",
    "        grad_chunks = torch.split(grad_output, chunk_size, dim=-1)\n",
    "        return grad_chunks[rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93b0f58-65fd-4318-9bf0-6bdb2b850e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output_size_per_patrition = output_size // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_patrition,\n",
    "            self.input_size\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_patrition\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_parallel = f.apply(input)\n",
    "        output_parallel = F.linear(input_parallel, self.weight, self.bias)\n",
    "        outputs = g.apply(output_parallel)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156bca64-3924-4842-9564-b9888523a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba13257-ca1e-4d22-a2cd-1f724d2f7a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_model(model, balances, devices):\n",
    "    patrition_idx = 0\n",
    "    layers = Orde\n",
    "    patritions = []\n",
    "    \n",
    "    for i, layer in enumerate(model):\n",
    "        layers.append(i, layer)\n",
    "        \n",
    "        if len(layer) == balances[patrition_idx]:\n",
    "            patrition = nn.Sequential(*layers)\n",
    "            patrition.to(devices[patrition_idx])\n",
    "            patritions.append(patrition)\n",
    "            layers.clear()\n",
    "    \n",
    "    return patritions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79f2696-bcc2-47a5-b641-fcf97f21a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p2p, message passing, collective communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9008dfa5-639e-4998-bb1e-246f49a16199",
   "metadata": {},
   "outputs": [],
   "source": [
    "gather, reduce, scatter, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b14bb22-9d80-46ff-8e90-2cd4339c473c",
   "metadata": {},
   "source": [
    "### Sci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56eca52-3a89-490c-93c5-b0949660d7c8",
   "metadata": {},
   "source": [
    "### ML Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82089723-ae3f-40a4-a4b4-ffa5c8aad616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect import flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6b29d1-8e21-4be7-bc11-b69b09802987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import FlowSpec, step, Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff39c62-87aa-4df6-81d7-a3dbbe6aa3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training(FlowSpec):\n",
    "    secret = Parameter(\"secret\")\n",
    "    \n",
    "    @step\n",
    "    def start(self):\n",
    "        self.next(self.train)\n",
    "    \n",
    "    @step\n",
    "    def train(self):\n",
    "        self.secret = 69\n",
    "        print(f\"secret {self.secret}\")\n",
    "        self.next(self.end)\n",
    "    \n",
    "    @step\n",
    "    def end(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a569455-3d0b-4aa6-83d9-e8823df04e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a292c7-3a24-49de-b123-032e4b393b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "Flow(\"CountFlow\").latest_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebdce6c-8f63-4529-8196-dbd2d34f6cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect.deployments import Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe75dc5-59d0-472f-938c-b1f0b829b455",
   "metadata": {},
   "outputs": [],
   "source": [
    "Deployment.build_from_flow(\n",
    "    flow=run_workflowb\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b976e61-88ee-4e58-bd10-9fb837cb600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f00e2a9-c995-4080-ac14-99d154af20a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training(FlowSpec):\n",
    "    @step\n",
    "    def start(self):\n",
    "        self.next(self.train)\n",
    "    \n",
    "    @step\n",
    "    def train(self):\n",
    "        train()\n",
    "        self.next(self.end)\n",
    "    \n",
    "    @step\n",
    "    def end(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57b3e0e-7f44-4fa1-95cc-ff3e3d4f3357",
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM x x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a831f4-c6c6-4a2c-af4a-90f74f25479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d75ce-a687-43ae-af93-cafa23946f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "lock = threading.Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e547211d-7dec-42aa-9603-f26ef9120f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target():\n",
    "    with lock:\n",
    "        increment_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77965ed-b02e-4839-87b4-6fe10adaddf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    thread = threading.Thread(target=target)\n",
    "    thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35310c91-a26a-492e-9238-e9eb8ba41b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d609612-eecf-486a-976a-7228625046de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prefect.deployments import Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5444d250-5c1a-4425-b8a8-696e1aa58649",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_dev = Deployment.build_from_flow(\n",
    "    flow=training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb8a9c-88a1-494e-a7f4-7ca9e2e3da9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6328559e-4118-417a-b708-a55c001d466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, block in enumerate(model.transformer.h):\n",
    "    if i >= 6:\n",
    "        for param in block.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e04677-0e7f-4342-8b5b-96c38cb8ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.ln_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797c2612-4db7-49c5-8b3e-f2e681895c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452a31c4-8bf7-45e5-8309-c973aadb3abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenzier.add_special_tokens(SPECIAL_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54283a5a-99b7-4901-9728-b3c106f316b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resize_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c8e318-3cc9-4e33-9ed6-214486bda9ef",
   "metadata": {},
   "source": [
    "### AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb29804-6d23-450a-9bcd-43798af41df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5fcb82-d75b-408f-9856-4281c566705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6235fbf3-539b-4677-bd50-fedd26b190d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenClassifier(nn.Module):\n",
    "    def __init__(self, checkpoint, n_labels, dropout):\n",
    "        self.model = AutoModel.from_pretrained(checkpoint)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(768, n_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        last_hidden_state = output.last_hidden_state\n",
    "        output = self.dropout(last_hidden_state)\n",
    "        output = self.classifier(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695bc0c3-1e00-4607-9347-593ae788290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_head = activations[1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6cc84e-48ee-4aa7-b722-688760f298fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0f335e-45ab-44fa-a065-1527807d3f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    outputs.append(cache[f\"blocks.{i}.attn.hook_result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43eeddc-a8e9-4ac9-8949-79e32bd30751",
   "metadata": {},
   "outputs": [],
   "source": [
    "WA[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013c2e14-15fe-4ac5-b63b-e23e4089a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86e0789-8d3d-4c1a-bb61-8a5c9c3bd169",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae10e11-51c2-4320-ac09-2ed5faf40256",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_token = tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4837f148-afb0-4e1c-9f74-9743dc82ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = F.log_probs(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4af498-2139-45ad-aecf-eba33abcf856",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_logits = log_probs[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d26bc-a588-4be3-a2c1-287db9d0688f",
   "metadata": {},
   "outputs": [],
   "source": [
    "targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3137f93-7989-42e9-8e22-70352761595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7cd79d-20c4-4046-9ecb-71997f56b1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_logits = logits[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8ca35d-53cb-414f-ad55-d139524567bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tokens = tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32742d2b-1fc2-491b-b09c-a9d6c0d95636",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -last_tokens_logits.gather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a728ec-fd2c-4750-b6b7-e2404c2f82ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.split(x, split_size_or_sections=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f587801b-31bb-4479-a5d4-cdec0152479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.split(x, split_size_or_sections=[1, 3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f5300c-33fd-436e-8a21-b4a8b4938be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c6d91c-f5a1-4328-980b-1e2aa412f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = attn_weights.diagonal(dim1=-2, dim2=-1, offset=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06a4d31-158e-4d51-94fd-8f674b446409",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091cf8d5-754f-4fda-b34b-5d43a1a4db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tfms.Compose([\n",
    "    tfms.ToTensor(),\n",
    "    tfms.Normalize(0.3, 0.9)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14660159-b4ab-443e-b588-241612441a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.log_prob(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcfe3ec-70d1-4b11-84f0-732e3a7d9563",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.eps = eps\n",
    "        self.adds = nn.Parameter(torch.zeros(features))\n",
    "        self.mults = nn.Parameter(torch.ones(features))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean, var = x.mean(), x.var()\n",
    "        x = (x - mean) / (self.eps + var).sqrt()\n",
    "        x = self.adds + self.mults * x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b5b7d1-2dae-4a37-ba8d-27cf49219148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e25769-dcbc-47fa-992a-9d5ad5ef0d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "rref = rpc.remote(\"worker_1\", create_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a23faf-466b-4d19-8ef4-36e3a6981030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
