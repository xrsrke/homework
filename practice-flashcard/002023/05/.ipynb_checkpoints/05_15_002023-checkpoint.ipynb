{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e25ccffc-b0e3-4240-908b-214c3ce8bfa2",
   "metadata": {},
   "source": [
    "### MechInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c63f6-50f6-497b-a993-963a31fbdc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_func(act, hook):\n",
    "    act[:, 1, :] = clean_acts[hook.name][:, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97750b9a-0d68-4b22-9a19-6429287100d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run_with_hooks(\n",
    "    corrupted_tokens,\n",
    "    fwd_hooks=[(hook_name, hook_func)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a674911-1101-4608-9696-94ad46204cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ecae63-9e27-431d-bc81-286d87d0a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.embed(tokens) + model.pos_embed(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce3728-bcba-4bbb-9762-422fcdd924f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97b4f29-9e40-4dff-b961-e0dc2e6bb9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in model.blocks:\n",
    "    residual = block(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd7454d-fe65-4034-aaf4-8f4114895865",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = model.ln_final(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd850a7-bb8f-4a83-95cf-3aa10edb1ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.unembed(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e81a41-1150-44f2-a331-a32fedf1dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_prompt = \"When John and Mary went to the shops, Mary gave the bag to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1e0b13-813c-4522-aee6-78cac5b27ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = model.to_tokens(clean_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd376322-dc1f-42d4-843a-05c7c31ed72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_tokens = model.to_tokens(corrupted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69fe5d8-e11e-4d13-86f7-45aea65b2ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logits, clean_activations = model(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a8b18a-2baa-420c-971b-5880683a42ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = clean_tokens.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30295ffd-cd4f-4ed8-8385-a2fc5e1edde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_act(\n",
    "    corrupted_activations,\n",
    "    hook,\n",
    "    layer,\n",
    "    position,\n",
    "    clean_activations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe5ca65-7017-4bdd-920c-ff579b354920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6ce20a-1a28-4dda-8ca5-7a3861f00d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f612ab-6102-4d7f-8d89-12dab4f7db2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(n_layers):\n",
    "    for position in range(n_tokens):\n",
    "        hook_func = partial(patch_act, position=position, clean_activations=clean_activations)\n",
    "        hook_name = get_act_name(\"resid_pre\", layer)\n",
    "        \n",
    "        patched_logits = model.run_with_hooks(\n",
    "            corrupted_tokens,\n",
    "            fwd_hooks=[(hook_name, hook_func)]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174e3825-08ca-4ae9-871b-157627e7eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: create two prompts\n",
    "step 2: record act of clean prompt\n",
    "step 3: iterative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6f2dca-0ae9-4b8a-bacc-386fdd10928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_token = model.to_single_token(\" John\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b69945b-9226-4c8d-ba90-4d5431a8d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_token = model.to_single_token(\" Mary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d74236e-8dd9-4034-88ca-ca67071a83e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = model.to_tokens(clean_prompt)\n",
    "corrupted_tokens = model.to_tokens(corrupted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c119b8ee-9dc9-43f2-993e-d4f8add3fcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logits, clean_cache = model.run_with_cache(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db595f79-ff87-427a-9c5a-d78329b5a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = clean_tokens.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e25a878-ca26-4d3f-b253-09e164dc2c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51477a96-2158-4a9f-9441-bc4455450dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_act(\n",
    "    corrupted_activations,\n",
    "    hook,\n",
    "    position,\n",
    "    clean_activations\n",
    "):\n",
    "    corrupted_activations[:, position, :] = clean_activations[hook.name][:, position, :]\n",
    "    return corrupted_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671c92b2-ff0b-4f33-a053-defc73111e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logit_diff(logits):\n",
    "    last_token_logits = logits[:, -1, :]\n",
    "    correct_logit = logits[:, corrct_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e5f7b2-9d2d-405a-9a41-fc6db57836dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(n_layers):\n",
    "    for position in range(n_tokens):\n",
    "        hook_func = partial(patch_act, position, clean_activations=clean_activations)\n",
    "        hook_name = get_act_name(\"resid_pre\", layer)\n",
    "        patched_logits = model.run_with_hooks(\n",
    "            hook_func,\n",
    "            fwd_hooks=[(hook_name, hook_func)]\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d53aba-5876-404f-adf8-2a389af4f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b255543-2e10-49b6-ab67-871d746bcada",
   "metadata": {},
   "outputs": [],
   "source": [
    "interference = einsum(\n",
    "    W, W,\n",
    "    \"batch feature1 dim, batch feature2 dim -> batch feature1 feature2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2503df0-002d-4051-b24e-c0ce7c0261a7",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb334016-3b25-4d07-b1b1-b25df2981e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a5fa42-4d3a-4d3f-8d74-4328c81a5a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabParallelEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim_per_rank = embedding_dim // world_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            self.num_embeddings,\n",
    "            self.embedding_dim_per_rank\n",
    "        )\n",
    "        self.start_vocab_idx, self.end_vocab_idx = self.get_range_vocab_idx(self.embedding_dim_per_rank)\n",
    "    \n",
    "    def get_range_vocab_idx(self, embedding_dim_per_rank):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        start_idx = rank * embedding_dim_per_rank\n",
    "        end_idx = start_idx + embedding_dim_per_rank\n",
    "        \n",
    "        return start_idx, end_idx\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        mask = (tokens < self.start_vocab_idx) | (tokens >= self.end_vocab_idx)\n",
    "        tokens = tokens - self.start_vocab_idx\n",
    "        tokens[mask] = 0.\n",
    "        \n",
    "        embedding_parallel = self.embedding_dim_per_rank(tokens)\n",
    "        mask_idx = torch.where(tokens == False)[1]\n",
    "        embedding_parallel[mask_idx] = 0.\n",
    "        \n",
    "        torch.distributed.all_reduce(embedding_parallel)\n",
    "        return em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f75e33d-46b2-46cb-9ed8-e90a73dbbf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_params = sorted(\n",
    "    param_list,\n",
    "    key=param_list.numel(),\n",
    "    reverse=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcc928b-820d-408d-8eee-d5c4598c969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "numel_per_rank = [0 for _ in range(world_size)]\n",
    "param_per_rank = [[] for _ in range(world_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be13122-ddcd-4aff-947c-cff1efe23f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in sorted_param:\n",
    "    rank_to_go = numel_per_rank.index(min(numel_per_rank))\n",
    "    param_per_rank[rank_to_go].append(param)\n",
    "    numel_per_rank[rank_to_go] += param.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0471bf-dd90-4e38-8e1e-511c94ca2e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: scale the loss\n",
    "step 2: compute the gradient with respect to the scaled loss\n",
    "step 3: accmulate the gradient with the previous accumulatied gradient\n",
    "step 4: if update..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc2502b-dc87-4411-af7b-c020298e221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "register > cached memory > main memory > hard > backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7d4b6f-db08-46c5-bcbb-2dc448d08c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream1 = torch.cuda.Stream()\n",
    "stream2 = torch.cuda.Stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32816c0-c9f4-4e96-b329-ab3abf1a2781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bddc6ce-600b-4d3e-b63f-a52c06f3cb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "with torch.cuda.stream(stream1):\n",
    "    operation_a()\n",
    "    \n",
    "with torch.cuda.stream(stream2):\n",
    "    operation_b()\n",
    "    \n",
    "torch.cuda.syncro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116d4685-41dd-4a76-9deb-56aa3c33c305",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [0, 1, 3, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c4767c-3547-4e5e-b1ae-c865be3eadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = torch.distributed.get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d19e2-ff8e-45be-a025-0f85ce0af858",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6b5956-297e-438c-bd33-27cd3fbff45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rank in ranks:\n",
    "    group = torch.distributed.new_group(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7482acde-b834-402e-8d2e-fee425fee5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if group != None:\n",
    "    torch.distributed.broadcast(x, src=0, group=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdceda90-6270-4d1b-855f-0e8c4ac8e7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: determine checkpoint\n",
    "step 2: compute the activation and only save the checkpoint\n",
    "step 3: compute the gradient start from the checkpoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b40dd0-099c-4e3d-a3fa-2b5151841410",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_tensor_model_parallel_groups):\n",
    "    ranks = range(\n",
    "        (i*tensor_model_parallel_size),\n",
    "        (i*tensor_model_parallel_size)\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9e9fec-d4bf-4f6e-9017-c21342b46ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "new > ready > running > blocked > terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296f9792-825b-4dbd-bc69-6ab420197b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: determine checkpoint location\n",
    "step 2: calculate the activation and save the acti checkpoint\n",
    "step 3: delete the previous activation\n",
    "step 3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4e29a3-8b47-4efc-9f86-23551346a0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new > ready > running > blocked > terminated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0597f287-f6ef-49df-a677-f3d0d61106e9",
   "metadata": {},
   "source": [
    "### ML Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7509dd1f-a185-4bc9-a11d-0e743974d9cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb8155-0e3d-47a3-9949-e0697a4cec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f438e916-4e42-42e1-ba10-aa3ec88a47f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, validator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e143744-39a5-4e6f-9667-6aa3614f404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class User(BaseModel):\n",
    "    user_id: int\n",
    "    username: str\n",
    "    \n",
    "    @validator(\"username\")\n",
    "    def uppercase(cls, value):\n",
    "        return value.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2ba48b-5fb4-4f71-b95f-f542f0e747c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import FlowSpec, step, conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57bb7b3-0127-404e-a062-5b9ac82975c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingFlow(FlowSpec):\n",
    "    @step\n",
    "    def start(self):\n",
    "        self.next(self.train)\n",
    "    \n",
    "    @conda(python=\"3.11.0\", libraries={\"pytorch\": \"2.0.0\"})\n",
    "    @step\n",
    "    def train(self):\n",
    "        train()\n",
    "        self.next(self.end)\n",
    "    \n",
    "    @step\n",
    "    def end(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e674b478-bde1-40d3-be45-bce2169349cc",
   "metadata": {},
   "source": [
    "### AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925befac-6787-48ab-bc09-e951ffb72f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add503f5-851d-4819-887e-864edc696d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, ProfilerActivity, schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a171ac7-a07a-4599-9436-495b20d8a33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU],\n",
    "    schedule=schedule()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd90517-b04b-4c90-abaa-eee8a75d74da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8926cbe1-9be7-4162-a600-a439ca4085de",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.tree_map(square, xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b51087-06f6-4997-b131-4f43dff86643",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.add_special_tokens(SPECIAL_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fc19d2-58a0-4acd-aac2-3ad5e32fe3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resize_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bc4db7-b530-4596-b636-213e391cda3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42b638d-d63c-4544-a63c-8e3f386f2b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pack([image_rgb, image_depth], \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b0db6-3199-478b-9916-fb65d96393eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7bb57f-e407-4a5f-883e-934a5959404e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_images = pack([image_rgb, image_depth], \"h w *\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c254a89-d10a-41e8-9ef8-713def31e02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_token = model.to_single_token(\" John\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a56a92-8cf4-4c13-a782-869f63a8eedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_token = model.to_single_token(\" Mary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0688e7-64d9-4e5e-842d-63ab76a0af8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = model.to_tokens(clean_prompt)\n",
    "corrupted_tokens = model.to_tokens(corrupted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ebd47f-434c-42d2-ae99-ee4711b857cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logits, clean_activations = model.run_with_cache(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1311c607-e28d-4c92-9420-d3ae56809ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_it(\n",
    "    corrupted_activations,\n",
    "    hook,\n",
    "    position,\n",
    "    clean_activations\n",
    "):\n",
    "    corrupted_activations[:, position, :] = clean_activations[:, position, :]\n",
    "    return corrupted_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bedf5d7-796a-40d2-98f5-a5f13bbc5b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_positions = clean_tokens.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86edea93-6504-4f08-b5e3-5337b0e24e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from transformer_lens import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c8e1a-ec84-4ce2-9dfe-a1115ea1dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_diff(logits, correct_token, incorrect_token):\n",
    "    last_token_logits = logits[:, -1, :]\n",
    "    correct_l = last_token_logits[:, correct_token]\n",
    "    incorrect_token = last_token_logits[:, incorrect_token]\n",
    "    diff = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67750bc7-d835-4bd7-af59-b3459e0f98d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(n_layers):\n",
    "    for position in range(n_positions):\n",
    "        hook_func = partial(patch_it, position=position, clean_activations=clean_activations)\n",
    "        hook_name = utils.get_act_name(\"resid_pre\", layer)\n",
    "        corrupted_logits = model.run_with_hooks(\n",
    "            corrupted_tokens,\n",
    "            fwd_hooks=[(hook_name, hook_func)]\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a9d15c-cc3e-4339-83f0-c4352a57d98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_score(image_embedding, text_embedding):\n",
    "    image_norm = image_embedding.norm(dim=-1)\n",
    "    image_embedding = image_embedding / image_norm\n",
    "    text_norm = text_embedding.norm(dim=-1)\n",
    "    text_embedding = text_embedding / norm\n",
    "    \n",
    "    similarities = image_embedding @ text_embedding.T\n",
    "    probs = F.softmax(similarities, dim=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
