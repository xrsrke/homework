{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d9807cd-ec7c-4743-a03b-ae7f5a8128d0",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f73f4f1-d5f8-448c-857d-be58115d0227",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: partrition the parameters\n",
    "step 2: move to rank\n",
    "step 3: move to device\n",
    "step 4: init local optimizer\n",
    "step 5: local_optimizer.step()\n",
    "step 6: broadcast the gradient\n",
    "step 7: update the whole thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdefe02-c913-40f9-9ebf-36732a57ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea109954-cf10-459c-82e4-4ab03be4e94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def forward(zelf, x, labels):\n",
    "        output = self.net(x)\n",
    "        loss = loss_func(output, labels)\n",
    "        return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253ae8e1-2157-461f-a38b-e42faa1cd578",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, data in enumerate(data_loader):\n",
    "    _, loss = model(x, labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c3eab2-f453-49e9-a849-d3c24e487ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcb8198-1f74-4ff0-8373-8a2d58875099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_times(model, batch):\n",
    "    records = [[] for _ in model]\n",
    "    \n",
    "    for i, layer in enumerate(model):\n",
    "        start_time = time.time()\n",
    "        outputs = [layer(x) for x in batch]\n",
    "        outputs_with_grad = [x for x in outputs if x.requires_grad]\n",
    "        \n",
    "        if outputs_with_grad:\n",
    "            torch.autograd.grad(outputs_with_grad, outputs_with_grad)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        records[i].append(start_time, end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c09c451-a598-4cff-880d-4132b8b4d6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size, world_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output_size_per_partrition = output_size // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_partrition,\n",
    "            self.input_size\n",
    "        ))\n",
    "        \n",
    "        self.bias = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_partrition\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        output_parallel = F.linear(input, self.weight, self.bias)\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        outputs = [torch.empty_like(output_parallel) for _ in range(world_size)]\n",
    "        outputs = torch.cat(outputs, dim=-1)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e765a28-f378-4be0-8b77-227226d6b9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelMLP(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.dense_to_hidden4 = ColumnParallelLinear(\n",
    "            input_size=hidden_size,\n",
    "            output_size=hidden_size*4\n",
    "        )\n",
    "        self."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb31d4-c015-4d2a-971f-e4e2087e7883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_forward_pass_using_data_parallel(\n",
    "    model, input, device_ids, output_id\n",
    "):\n",
    "    models = nn.parallel.replicate(model, target_gpus=device_ids)\n",
    "    inputs = nn.parallel.scatter(input, target_gpus=device_ids)\n",
    "    \n",
    "    output_parallel = nn.parallel.parallel_apply(models, inputs)\n",
    "    output = nn.parallel.gather(output_parallel, target_device=output_id)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c4c01-3380-4025-8ff8-e7641b0865f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "- clock cycle 1: B_{m, n}\n",
    "- clock cycle 2: B_{m, n-1}, B_{m-1, n}\n",
    "- clock cycle 3: B_{m, n-2}, B_{m-1, n-1}, B_{m-2, n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c3ae82-73e4-4921-8e2c-2a206745044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model_parallel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf0994d-f0ec-45a1-ada7-c53c87ec1040",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_model_parallel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569b6ada-f5b8-425c-a913-faa7daee8523",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline_model_parallel_groups = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f97a131-171f-42b9-b0d9-d03bdaac29a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2]\n",
      "[1, 3]\n",
      "[4, 6]\n",
      "[5, 7]\n",
      "[8, 10]\n",
      "[9, 11]\n",
      "[12, 14]\n",
      "[13, 15]\n"
     ]
    }
   ],
   "source": [
    "for i in range(pipeline_model_parallel_size):\n",
    "    start_rank = i*num_pipeline_model_parallel_groups\n",
    "    end_rank = (i+1)*num_pipeline_model_parallel_groups\n",
    "    \n",
    "    for j in range(tensor_model_parallel_size):\n",
    "        ranks = list(range(\n",
    "            start_rank+j,\n",
    "            end_rank,\n",
    "            tensor_model_parallel_size\n",
    "        ))\n",
    "        print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef81bc5-8e0a-4b33-9322-b443edfc7b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = torch.distributed.get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addfccf5-a5bd-40b9-9e17-ae1b05c9f6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rank == 0:\n",
    "    torch.distributed.broadcast(x, src=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39720f7-8be9-4b48-adc5-213c14fbffed",
   "metadata": {},
   "source": [
    "### ML Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25cc7b9-4fb7-4ba8-8b6f-6a0b682a869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import parallel_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131372d2-9e21-4626-97ce-e89f01ad86e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = parallel_map(plus_69, numhers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60499459-d7ef-483a-a850-564a90d17d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72569de1-5318-4545-a147-d87155161b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "with S3() as s3:\n",
    "    res = s3.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9281659e-e284-4f3b-80b7-71b322f95412",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker rm 23a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5ef5b4-ff71-4619-bc66-d0526123cd7d",
   "metadata": {},
   "source": [
    "### MechInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d819034-9876-4618-a51b-dc8b72fbc6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3480f2e5-58dc-48db-98d3-f31e59850d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07cba33-0271-42d5-b3e4-792b7b3909ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff9f2b1-b50b-4704-849d-939bab1cf08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(attention_pattern, target_pattern):\n",
    "    score = attention_pattern * target_pattern\n",
    "    return score.sum() / attention_pattern.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e40858-da2c-41fd-bdc9-dd9ccaea9d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = tokens.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2203957c-cce0-4813-abe2-40391239c71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cfb52d-6018-493c-84f5-e4aca164052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.zeros(n_layers, n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b57b3c1-3cac-4fe7-bd33-593f0c38cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(n_layers):\n",
    "    hook_name = f\"blocks.{layer_idx}.attn.hook_pattern\"\n",
    "    layer_attention_pattern = cache[hook_name]\n",
    "    \n",
    "    for head_idx in range(n_heads):\n",
    "        attention_pattern = layer_attention_pattern[0, head_idx, :]\n",
    "        score = compute_score(attention_pattern, target_pattern)\n",
    "        data[layer_idx][head_idx] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d98ee0-4987-45a7-9ea0-ceb08c6fc4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_directions = W_U[:, tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05671939-1af7-45cf-a111-8cfeb07e1d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: start with a statement\n",
    "step 2: create two prompts\n",
    "step 3: extract the hidden states of the two prompts\n",
    "step 4: normalize the hidden states\n",
    "step 5: convert the hidden states into probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79441188-5429-4f24-9fd8-75493f9bf6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc276d8a-8e9a-486a-a9c9-efd0bd32b665",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d38bca-b57a-4fba-b358-3873603a9db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392dab06-1e75-436b-8bed-90d5b37da0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_neuron_activation(activations, hook):\n",
    "    data[neuron_idx] = activations[:, :, 69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c6cd3c-2207-4e6f-9981-a90f130a7943",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_name = f\"blocks.{layer_idx}.mlp.hook_post\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7e894d-656f-4217-a075-f7121719c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run_with_hooks(\n",
    "    tokens,\n",
    "    fwd_hooks=[(hook_name, extract_neuron_activation)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c9f2ee-3701-4eca-a145-e176325109f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_with_highest = torch.argmax(data[69])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8559b1-27c9-49e6-ab80-e9d19f8f7565",
   "metadata": {},
   "outputs": [],
   "source": [
    "consistent loss, confident loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ef37c2-4a5f-4ae5-a787-d00ca33800c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = cache[\"embed_hook\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4d7b48-0ff7-470f-a960-3ee6cb0ad9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_embeddings = cache[\"pos_embed_hook\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d96b2dd-0f28-45fa-adf3-f21ed1dddd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "components = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7e7d88-bc76-4019-99dc-27973f7608fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "components.append(text_embeddings)\n",
    "components.append(positional_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d14501-2ce0-4401-a609-ffb6444c5aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e81b13-1024-4066-a33b-267393acce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_layers):\n",
    "    attn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67288651-bf7c-4367-80ff-7e7954d06474",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f7e924-f415-4735-8ac6-39ec332ad2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = tokens.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91cf650-d3f6-410a-b123-c4b51b053893",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pattern = torch.zeros(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906429f2-bdda-4be1-b5df-14345a52b955",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pattern[torch.arange(seq_len), torch.arange(seq_len)] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b9a112-003c-4aba-ab7c-6a76d0751694",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pattern[0] = torch.zero_likes(target_pattern[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2293ee8c-89c1-4d02-80b8-2fb8806280a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "components = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0f9f24-7344-4825-a82e-eeec3b9f3928",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = cache[\"hook_embed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae305ba-d007-4374-87e9-5755b47d01f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_embeddings = cache[\"hook_pos_embed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b97ec7e-fd55-42b2-8b47-b554c9b7f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af07dee5-0ad7-4740-becf-ee9b74d2f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46795dc-9b27-4738-9428-9fb465605235",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_layers):\n",
    "    attn_out = get_act_name(\"attn_out\", i)\n",
    "    mlp_out = get_act_name(\"mlp_out\", i)\n",
    "    components.append(cache[attn_out])\n",
    "    components.append(cache[mlp_out])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a294e0-7f2a-4bd5-9f09-a0dfc0152ecd",
   "metadata": {},
   "source": [
    "### AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ccc4ce-7245-40e3-89c7-91b1b1ca1afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = get_returns(reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce046e5-4b05-4e58-9a7e-a23e88964888",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6304e4-7af8-46a2-8342-83fb46fdabb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for return_, prob in zip(returns, selected_action_probs):\n",
    "    loss += -return_*prob.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697a9c26-5adf-455e-a815-6202008c9484",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.roll(x, shifts=1, dims=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be18ee6-ff42-466d-83a0-a575921bfd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb69684-3c3f-4709-8600-c2d9f9a29d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentinon(nn.Module):\n",
    "    def __init__(self, d_head):\n",
    "        super().__init__()\n",
    "        self.d_head = d_head\n",
    "    \n",
    "    def forward(self, q, k, v, mask = None):\n",
    "        k = k.transpose(3, 2)\n",
    "        qk = torch.matmul(q, k)\n",
    "        scores = qk / math.sqrt(self.d_head)\n",
    "        \n",
    "        if mask != None:\n",
    "            scores = scores.mask_fill(mask == 0, 1e-9)\n",
    "        \n",
    "        attention_weights = F.softmax(scores)\n",
    "        output = torch.matmul(attention_weights, v)\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7a2fba-49dc-4cb2-86a8-138c4b229615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
