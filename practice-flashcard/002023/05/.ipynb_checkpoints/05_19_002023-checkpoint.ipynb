{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "223702ff-151d-4345-9a8c-35905cb31ac5",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4062fa59-0bf1-4e6c-a2bb-2730419714ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9fca17-0d56-4646-9da5-ac77b81fea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328dd8e0-9cc0-4091-8a13-e561f555bd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_times(model, batch):\n",
    "    records = []\n",
    "    \n",
    "    for layer in model:\n",
    "        start_time = time.time()\n",
    "        outputs = [layer(x) for x in batch]\n",
    "        backward_outputs = tuple(x for x in outputs if x.requires_grad)\n",
    "        \n",
    "        if backward_outputs:\n",
    "            torch.autograd.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66261180-83fe-40d4-ac79-d52357e36a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_model(model, balances, devices):\n",
    "    layer_idx = 0\n",
    "    layers = Ord\n",
    "    partritions = []\n",
    "    \n",
    "    for layer in model:\n",
    "        layers.append(layer)\n",
    "        \n",
    "        if len(layers) == balances[layer_idx]:\n",
    "            partrition = nn.Sequential(*layers)\n",
    "            device = devices[layer_idx]\n",
    "            partrition.to(device)\n",
    "            partritions.append(partrition)\n",
    "            layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067496ec-7745-4888-8948-92d76c06eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_grad_enabled(x):\n",
    "    return torch.is_grad_enabled and x.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e770f80-0119-47d2-8ee8-f15357ed52d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _broadcast(inputs):\n",
    "    return inputs.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbe3c0b-1ef0-42f7-9eb2-c67e70650b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reduce(inputs):\n",
    "    world_size_of_parallel_group = torch.distributed.get_world_size(group=parallel_group)\n",
    "    \n",
    "    if world_size_of_parallel_group == 1:\n",
    "        return inputs\n",
    "    \n",
    "    torch.distributed.all_reduce(inputs, group=parallel_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ec26f3-ebed-4b85-b245-2ff28bd871d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Broadcast(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return _broadcast(input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_outout):\n",
    "        return _reduce(grad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d98fae-737c-4b3c-8d5f-64d975bdb931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_with_forward_and_backward(x):\n",
    "    \n",
    "    if is_grad_enabled(x):\n",
    "        return Broadcast.apply(x)\n",
    "    else:\n",
    "        return _broadcast(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eda087-4f56-437d-ad38-3c1a95d722c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_model_parallel_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4abc89-7ec9-47f9-9b81-d75a8c47b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model_parallel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cca407-7e3e-473d-b193-b182e8064917",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dad59d3-7ba0-4ad3-9848-174f7a519704",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline_model_parallel_groups = world_size // pipeline_model_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d89659-62e0-4005-a39e-e6139d019621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5, 10, 15, 20]\n",
      "[1, 6, 11, 16, 21]\n",
      "[2, 7, 12, 17, 22]\n",
      "[3, 8, 13, 18, 23]\n",
      "[4, 9, 14, 19, 24]\n",
      "[25, 30, 35, 40, 45]\n",
      "[26, 31, 36, 41, 46]\n",
      "[27, 32, 37, 42, 47]\n",
      "[28, 33, 38, 43, 48]\n",
      "[29, 34, 39, 44, 49]\n",
      "[50, 55, 60, 65, 70]\n",
      "[51, 56, 61, 66, 71]\n",
      "[52, 57, 62, 67, 72]\n",
      "[53, 58, 63, 68, 73]\n",
      "[54, 59, 64, 69, 74]\n",
      "[75, 80, 85, 90, 95]\n",
      "[76, 81, 86, 91, 96]\n",
      "[77, 82, 87, 92, 97]\n",
      "[78, 83, 88, 93, 98]\n",
      "[79, 84, 89, 94, 99]\n"
     ]
    }
   ],
   "source": [
    "for i in range(pipeline_model_parallel_size):\n",
    "    start_rank = i*num_pipeline_model_parallel_groups\n",
    "    end_rank = (i+1)*num_pipeline_model_parallel_groups\n",
    "    \n",
    "    for j in range(tensor_model_parallel_size):\n",
    "        ranks = list(range(\n",
    "            start_rank+j,\n",
    "            end_rank,\n",
    "            tensor_model_parallel_size\n",
    "        ))\n",
    "        \n",
    "        print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf10be61-e789-43de-a7fc-f04fe7745b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee7f0e2-56d8-460e-8eeb-e66cc94498c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_times(model, batch):\n",
    "    records = [[] for _ in model]\n",
    "    \n",
    "    for layer in model:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        outputs = [layer(x) for x in batch]\n",
    "        outputs_with_grad = [x for x in outputs if x.requires_grad]\n",
    "        \n",
    "        if outputs_with_grad:\n",
    "            torch.autograd.backward(outputs_with_grad)\n",
    "            \n",
    "        end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f83df-fcf5-4e02-bd69-f815f26cfe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_grad_enabled(inputs):\n",
    "    return torch.is_grad_enabled() and inputs.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571d9811-0d67-43a1-8813-d2cb105e7580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _broadcast(inputs):\n",
    "    return inputs.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ab5fa-01d4-46b8-a504-9c1f758d4cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reduce(inputs):\n",
    "    world_size_of_parallel_group = torch.distributed.get_world_size(group=parallel_group)\n",
    "    \n",
    "    if world_size_of_parallel_group == 1:\n",
    "        return inputs\n",
    "    \n",
    "    torch.distributed.all_reduce(inputs, group=parallel_group)\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3d86b1-daa1-44d7-8d3d-ca968e543b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Broadcast(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs):\n",
    "        return _broadcast(inputs)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_outputs):\n",
    "        return _reduce(grad_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a049440-181f-4f57-a8d3-ddf2821719e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_with_forward_and_backward(inputs):\n",
    "    if is_grad_enabled(inputs):\n",
    "        outputs = Broadcast.apply(inputs)\n",
    "    else:\n",
    "        outputs = _broadcast(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410c993d-7af4-441a-883c-7bc58a78b238",
   "metadata": {},
   "source": [
    "### ML Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1588b026-7fbf-483a-a271-9bb0cb7e4575",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow, subdirectories, metalfow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0a7ef-dc33-421c-ab02-4fd7e91731d1",
   "metadata": {},
   "source": [
    "### MechInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9347d7aa-3d43-48cc-bb94-9daa800d89d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb3288d-6bef-4d35-914d-cb04e3005b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65afd2b5-0284-4cf9-be63-c0ec3a77789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_func(activations, hook):\n",
    "    data[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d19d5c-a5d0-45f2-9297-e0f5c4ec3b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_name = f\"blocks.{layer_idx}.mlp.hook_post\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94f6a7d-67d8-40c9-bcd4-5b59f06ebe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _ = model.run_with_hooks(\n",
    "    tokens,\n",
    "    fwd_hooks=[(hook_name)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b025c1b-b32f-4633-bbd2-ba0b58fa3cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(attention_pattern, target_pattern):\n",
    "    score = attern_pattern * target_pattern\n",
    "    return score.sum() / attention_pattern.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fca955-7299-4c1e-9df5-e3931550d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95a061c-36db-443d-843d-d62cc5b11a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(n_layers):\n",
    "    for head_idx in range(n_heads):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d330e56c-8c28-45db-972c-e8249db53154",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d269b83-6f98-46f7-8579-b20437ed5e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = tokens.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ed45c3-ed66-499d-87c2-a41c74f323fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pattern = torch.zeros(seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff69d37-0c12-4d39-8c9b-6c02e998b1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pattern[torch.arange(seq_len), torch.arange(seq_len)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849dec9a-5620-438a-90f5-17913114a0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pattern[0] = torc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69df008d-cc8f-4b1b-b204-f95303d5c3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd5e8b-3c59-4459-80bd-4d2b8f85875f",
   "metadata": {},
   "outputs": [],
   "source": [
    ", cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeb316e-5ab6-4419-b08b-84fa214d1a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.zeros(n_layers, n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61424232-270b-4294-804b-42c721e44301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(attention_pattern, target_pattern):\n",
    "    score = attention_pattern * target_pattern\n",
    "    return score.sum() / attention_pattern.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a477cc-70da-4169-958b-41309329b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(n_layers):\n",
    "    for head_idx in range(n_heads):\n",
    "        hook_name = f\"blocks.{layer_idx}.attn.hook_pattern\"\n",
    "        score = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb9beb5-673c-426e-8685-0f32bd81fcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bc90e9-072d-412b-b890-74a927a15e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ee5c9-fd58-4c43-98ca-6714b21a44e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.zeros(n_layers, n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bade1e-d9ed-40f8-87a5-0c3733983f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec148db-cc55-4b33-a4f7-592d3cdf6455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(attention_pattern, target_pattern):\n",
    "    score = attention_pattern * target_pattern\n",
    "    return score.sum() / attention_pattern.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9034bd78-d46b-44c1-9e30-8bc3deed4d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(n_layers):\n",
    "    hook_name = f\"blocks.{layer_idx}.attn.hook_pattern\"\n",
    "    layer_attn_pattern = cache[hook_name]\n",
    "    \n",
    "    for head_idx in range(n_heads):\n",
    "        head_attn_pattern = layer_attn_pattern[batch_idx, head_idx, :, :]\n",
    "        score = compute_score(head_attn_pattern, target_pattern)\n",
    "        data[layer_idx][head_idx] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4824ac39-c1d4-4af2-b430-a9ddb97b094b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e8b3e4-e0ce-4ce0-85d0-01df27399918",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672a9082-5c3a-47c7-bf93-6e7cbb553fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_neuron_activation(activations, hook):\n",
    "    data[neuron_idx] = activations[0, :, 69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225de89d-af61-4b8d-b85c-88bc97627537",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1867f1ad-8407-4544-acd3-d91326ce230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0, 1], [2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaf2bf4-857f-4b1c-9eda-674469af3e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1],\n",
       "        [2, 3]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.repeat((1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82500b12-2a9c-4873-b339-2e0bb18c1647",
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = torch.roll(x, shifts=-1, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ab98c8-7c80-4e62-abf1-97ccc6ec8e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = torch.cuda.Stream(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5f4e08-a777-4b22-8f05-0bf9171c63ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.device(device):\n",
    "    with torch.cuda.stream(stream):\n",
    "        mean = xs.mean(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942c5470-0238-492f-9f9a-f63de07e0e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.chunk(x, chunks=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8813226a-0b8c-42ec-b19a-44d51cc68c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3da118-5fa9-4e45-a3ff-dd02253b19f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tfms.Compose([\n",
    "    tfms.ToTensor(),\n",
    "    tfms.Normalize(0.3, 0.9)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3247326b-510e-45ff-b822-ec7b4ecaa0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1522845b-73fa-47d8-b02e-74698aa54a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune.uniform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9db1a4e-1042-48d7-a96d-c1221f22037c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributed.rpc.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd45fe46-13e9-49ca-9ece-f07b8b5c77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpc.RREF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca68219-d935-4302-a808-5c9319ae377b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.roll(x, shift=1, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1470b7c-b79b-4496-b714-5bb75cef3aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.repeat(size=(2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a35d9a1-2b06-4845-99ac-38f0234ba54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9577a848-c53e-4034-a4e6-e810cfc72c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logits(model, xb, yb):\n",
    "    logits = model(xb)\n",
    "    \n",
    "    logits = rearrange(\"b s n -> (b s) n\")\n",
    "    yb = rearrange(\"b s -> (b s)\")\n",
    "    \n",
    "    loss = F.cross_entropy(logits, yb)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237e9eef-5745-4aca-bc6c-7a84e88e17a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_score(image_embedding, text_embedding):\n",
    "    image_norm = image_embedding.norm()\n",
    "    image_embedding = image_embedding / image_norm\n",
    "    \n",
    "    text_norm = text_embedding.norm()\n",
    "    text_embedding = text_embedding / text_norm\n",
    "    \n",
    "    similarities = image_embedding @ text_embedding.T\n",
    "    probs = F.softmax(similarities, dim=-1)\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d45ae3f-4472-4c77-b61a-889cec89bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, n_heads)\n",
    "        self.norm_1 = ResidualLayerNorm(d_model, dropout)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.norm_2 = ResidualLayerNorm(d_model, dropout)\n",
    "    \n",
    "    def forward(self, embeddings):\n",
    "        mha_output, mha_attn = self.mha(embeddings)\n",
    "        norm_1 = self.norm_1(mha_output, embeddings)\n",
    "        feed_forward = self.feed_forward(norm_1)\n",
    "        norm_2 = self.norm_2(feed_forward, norm_1)\n",
    "        \n",
    "        return norm_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8470cce0-6ff4-408f-ac13-d5c8104788c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiHeadAttention(nn.Module):\n",
    "#     def __init__(self, d_head):\n",
    "#         super().__init__()\n",
    "#         self.d_head = d_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0498b63a-c0b6-44d0-a9eb-606d82b2c62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d577bb7-2227-407b-92a0-69bea2c74f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_head):\n",
    "        super().__init__()\n",
    "        self.d_head = d_head\n",
    "    \n",
    "    def forward(self, q, k, v, mask = None):\n",
    "        k = k.permute(3, 2)\n",
    "        \n",
    "        qk = q @ k\n",
    "        scores = qk / math.sqrt(self.d_head)\n",
    "        \n",
    "        if mask != None:\n",
    "            scores = scores.mask_fill(mask == 0, -1e9)\n",
    "            \n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "        output = torch.mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362b14f0-f2d8-41e5-a81f-389e32598aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.eps = eps\n",
    "        self.adds = nn.Parameter(torch.zeros(features))\n",
    "        self.mults = nn.Parameter(torch.ones(features))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True)\n",
    "        \n",
    "        x = (x - mean) / (self.eps + var).sqrt()\n",
    "        x = self.adds + self.mults * x\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d426ea3-9a51-4091-803b-10259999ad8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.roll(x, shifts=1, dims=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab76856-22a8-4c2c-b385-3815026c30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_head):\n",
    "        super().__init__()\n",
    "        self.d_head = d_head\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        k = k.permute(3, 2)\n",
    "        qk = torch.matmul(q, k)\n",
    "        scores = qk / math.sqrt(self.d_head)\n",
    "        \n",
    "        if mask != None:\n",
    "            scores.fill_mask(mask == 0, -1e9)\n",
    "        \n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        output = torch.matmul(attention_weights, v)\n",
    "        \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b24fbcd-2959-4ac8-9bff-fb1b0d6f8093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a572e0d6-bddc-4ad7-bbc4-6aecf9c812b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.repeat((3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d4c104-d8b8-4e62-9dca-4f8600dea615",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.roll(x, shift=1, dim=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
