{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95b7a5c8-602c-4e26-a461-ab7d4345a482",
   "metadata": {},
   "source": [
    "### Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f2d686-daff-4d89-8c1a-cba0a97c78de",
   "metadata": {},
   "outputs": [],
   "source": [
    "point mutation, silent mutation, frameshift mutation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85f1d58-ceed-48ff-afc8-ab48b30a1fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "carbonhydrates, lipids, proteins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bac8c3-5d5c-4261-ab35-59b93bb66947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904b3414-efa8-4470-b4b8-fdc08e529e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_1x, v_1x, p_2x, v_2x = smp.symbols(\"p_1x, v_1x, p_2x, v_2x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ef4ead-dd4d-42b0-a0a2-15962eb2551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = smp.symbols(\"m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651e9ffc-2ddd-4c3b-aa49-2de266eb984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_1x = m*v_1x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f532cb-6138-4fb9-aed9-2f69e282bbd2",
   "metadata": {},
   "source": [
    "### Software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85ce639-1906-4d05-921d-921e04fa7540",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vehicle:\n",
    "    def func(self):\n",
    "        return self.__class__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ea9bc-25a3-489c-a7b3-f5630ed588f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NewType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b907b7-8f1d-4e93-86f7-b90e19da17b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = NewType(\"ID\", int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e26f90-99f2-449d-982e-f163be9db2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "Color = NewType(\"Color\", str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1592b05-93e4-4489-92e4-6d103a68a3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    def __init__(self, package_id: ID, package_color: Color):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec584fb4-fa02-4595-8c27-d6cbe14d4beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(func):\n",
    "    def wrapper():\n",
    "        out = func()\n",
    "        return out\n",
    "\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab56c6e3-e6ef-473d-bed7-76fdcd17e773",
   "metadata": {},
   "source": [
    "SELECT users.name, likes.like FROM users INNER JOIN likes ON likes.user_id = users.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2886252-e7ed-4306-82e0-02fbee19059c",
   "metadata": {},
   "source": [
    "### AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42af88b4-33cf-46d4-a84a-877688d00c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85299b2e-7c1c-4fcb-b2fa-5e18d95693d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76402ec2-75bb-4f8a-a909-47012cee340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Predict the capital of a country.\n",
    "Country: {input}\n",
    "Capital:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb12ca8-c94d-4021-a119-dbed14b2052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(input_variables=[\"input\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1310ac5-e1ed-4480-9e41-904703f02b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33c37aa-55c9-42e8-8095-27c6d2907850",
   "metadata": {},
   "outputs": [],
   "source": [
    "have past_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acf6d63-a696-46c3-92c4-09f99f4c6993",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a9858e-8ca4-44b6-8325-acab1fe4e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "noramlization -> pre -> tokenize-> post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3667fa-f86d-4ab6-a038-cbaaf8e0ab9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362ee10e-e258-46ea-982e-30dc9846eb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = RobertaModel.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5639362a-6bb6-40f4-884c-7e69f980a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import clip_grad_norm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de09f777-1b90-4802-b85c-44a086493bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_grad_norm_(param_1, max_norm=GRAD_CLIP_NORM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910185bf-9086-4cc7-84d0-b9475a815684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aaf3f0-f0fe-4b45-a460-9e34c14bda41",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(ds, batch_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc452388-686b-4d68-a0f6-85c00c4a4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        self.attention = attention\n",
    "        self.d_model, self.n_heads = d_model, n_heads\n",
    "        self.d_head = d_model // n_heads\n",
    "        \n",
    "        self.w_q = nn.Linear(d_model, n_heads * self.d_head)\n",
    "        self.w_k = nn.Linear(d_model, n_heads * self.d_head)\n",
    "        self.w_v = nn.Linear(d_model, n_heads * self.d_head)\n",
    "        self.mha_linear = nn.Linear(n_heads * self.d_head, d_model)\n",
    "    \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_len, d_model = x.size()\n",
    "        return x.view(batch_size, self.n_heads, seq_len, d_model)\n",
    "    \n",
    "    def concat_heads(self, x):\n",
    "        batch_size, n_heads, seq_len, d_model = x.size()\n",
    "        return x.view(batch_size, seq_len, d_model)\n",
    "    \n",
    "    def forward(self, pre_q, pre_k, pre_v):\n",
    "        q, k, v = self.w_q(pre_q), self.w_k(pre_k), self.w_v(pre_v)\n",
    "        \n",
    "        # split heads\n",
    "        q, k, v = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
    "        \n",
    "        output, attn_weights = self.attention(q, k, v)\n",
    "        \n",
    "        # concat heads\n",
    "        output = self.concat(output)\n",
    "        projection = self.mha_linear(output)\n",
    "        \n",
    "        return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d0e343-4be8-4f89-b22e-1adcb3d71e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax -> 0<1 -> - -> +"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102039c5-b0f2-4480-aa8e-1103b3a46eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ce6e0d-bc10-49b7-ab48-fb071fee9bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1c2c36-8d7c-452f-b02e-750d9d223a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2tensor(x):\n",
    "    return tfms.ToTensor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61201139-9245-4014-ad59-f6b4d0c657c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lerp mean, varb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0c35f6-18b6-4f9c-b82e-d5b27ba6d9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        self.attention = attention\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        self.d_head = d_model // n_heads\n",
    "        \n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.mha_linear = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_len, d_model = x.size()\n",
    "        return x.view(batch_size, self.n_heads, seq_len, self.d_head)\n",
    "    \n",
    "    def concat_heads(self, x):\n",
    "        batch_size, n_heads, seq_len, d_head = x.size()\n",
    "        return x.view(batch_size, seq_len, n_heads*d_head)\n",
    "    \n",
    "    def forward(self, pre_q, pre_k, pre_v):\n",
    "        q, k, v = self.w_q(pre_q), self.w_k(pre_k), self.w_v(pre_v)\n",
    "        \n",
    "        # split heads\n",
    "        q, k, v = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
    "        \n",
    "        output, attn_weights = self.attention(q, k, v)\n",
    "        \n",
    "        # concat heads\n",
    "        output = self.concat_heads(output)\n",
    "        output = self.mha_linear(output)\n",
    "        \n",
    "        return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6220c8-809d-46e8-a2c1-b8c0b3195f79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219a9333-d4d4-4d7e-9dcd-bd2bf099d912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfa2d96f-2487-457f-b5d3-722756efe49b",
   "metadata": {},
   "source": [
    "In this passage, the authors are describing how they obtain a new dataset $\\mathcal{C}^$ from an initial dataset $\\mathcal{C}$. They first perform all the steps described in Section 2 (which are not specified in this passage), and then filter out any examples where all API calls were eliminated during the filtering step. The remaining examples form the new dataset $\\mathcal{C}^$.\n",
    "\n",
    "Next, the authors describe how they use a weighting function $w_t$ to determine the importance of each API call in the training data. They want to ensure that API calls are placed close to where the information provided by the API is actually helpful for the model. To achieve this, they use a weight function $\\tilde{w}_t$ that assigns higher weights to API calls that occur earlier in the sequence of tokens $x_1, \\ldots, x_n$. Specifically, they set $\\tilde{w}_t=\\max (0,1-0.2 \\cdot t)$, where $t$ is the position of an API call in the sequence. This means that the weight of the $t$-th API call is $w_t=\\frac{\\tilde{w}t}{\\sum{s \\in \\mathbb{N}} \\tilde{w}_s}$, which is proportional to the importance of that API call in the training data.\n",
    "\n",
    "Finally, the authors mention that they choose the thresholds $\\tau_s$ and $\\tau_f$ individually for each tool to ensure that they have a sufficiently large number of examples. They also provide some statistics about their final dataset, which has been augmented with API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3919e97-b807-4018-86ed-bc1260bc5087",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
