{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ed0880-e106-4e8f-bada-f4f59e1590e0",
   "metadata": {},
   "source": [
    "### Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf70f670-d69a-4193-836b-f4422fbb90ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell body, dendrite, synapse, axon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758ad5e7-3ba8-4efe-b3c6-b4dbec99ce21",
   "metadata": {},
   "source": [
    "### Software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcae0f9-4bd0-4af3-af8a-5304757031b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NewType"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2234dd5c-850c-47d3-b41f-6793f849df85",
   "metadata": {},
   "source": [
    "### AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1744914f-a317-4759-82ee-42b47a719f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4427bf55-8a2b-43f4-9e06-06b95de4f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        self.attention = attention\n",
    "        self.d_head = d_model // n_head\n",
    "        self.d_model, self.n_heads = d_model, n_heads\n",
    "        \n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.mha_linear = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_len, d_model = x.size()\n",
    "        return x.view(batch_size, self.n_heads, seq_len, self.d_head)\n",
    "    \n",
    "    def concat_heads(self, x):\n",
    "        batch_size, n_heads, seq_len, d_head = x.size()\n",
    "        return x.view(batch_size, seq_len, self.d_model)\n",
    "    \n",
    "    def forward(self, pre_q, pre_k, pre_v):\n",
    "        q, k, v = self.w_q(pre_q), self.w_k(pre_k), self.w_v(pre_v)\n",
    "        \n",
    "        # split heads\n",
    "        q, k, v = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
    "        \n",
    "        attn_output, attn_weights = self.attention(q, k, v)\n",
    "        output = self.concat_heads(attn_output)\n",
    "        output = self.mha_linear(attn_output)\n",
    "        \n",
    "        return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfdbe77-4653-4f5a-8ac8-4a5ee510fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d4bd8-be97-443b-a10b-7c5a02a780d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "This is ...\n",
    "\n",
    "{history}\n",
    "\n",
    "User: {input}\n",
    "AI:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b954b7-9148-4831-ba14-9f11801f4921",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(input_variables=[\"history\", \"input\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae215994-c9ec-478f-aef4-37ba800e8742",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d93d09e-a754-41d8-9716-8013ceb761ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import clip_grad_norm_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c948b510-f24d-4c28-bf3c-6050782146a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(sm_pred, targ):\n",
    "    return -sm_pred(range(targ.shape[-1], targ)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
