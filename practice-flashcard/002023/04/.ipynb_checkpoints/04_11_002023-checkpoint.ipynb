{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c3f4b9f-f0b4-43cb-9280-07efb6c6613d",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28d6ba3-49b7-4470-a263-157e14953ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[:, 1:::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c89595-c869-42d6-81a3-a3eb45b06f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Child(Parent):\n",
    "    def __init__(self, name):\n",
    "        super().__init__(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d35100-0b51-4898-88ce-693bf6239e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126acc75-e5be-4858-a63d-48e8de896cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x: List[Union[str, float, int]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7730abfb-cbb8-4e53-a971-9e3a6973acb0",
   "metadata": {},
   "source": [
    "### AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a65333a-cdec-4c7f-9f98-1115b20384b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e009c11a-fffe-4bd1-bd85-23258231d660",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0172a400-4277-4a7b-a6e9-2094cf4ff888",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"gpt2-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3caeda-9ecf-4255-827a-201c581a473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hook_func(act, hook):\n",
    "    logits = clean_logits[hook.name]\n",
    "    act[:, 1, :] = logits[:, 1, :]\n",
    "    return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df7ccd1-99c7-48eb-9ad3-6c481c04b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run_with_hooks(\n",
    "    tokens,\n",
    "    fwd_hooks=[(hook_name, hook_func)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c063995c-827c-4d70-a180-715f95d9f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to_tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b340f5-b106-4d6c-8f88-d38c4de43506",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run_with_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45211994-c2b9-4338-a657-705a8c80064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_token_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ddeb69-4afe-4f7f-a5c1-6146e72134f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens.utils import test_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abfd373-4410-447f-a8b4-d82f7e5b5e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130d1652-8b56-4875-bed9-4a1db407a809",
   "metadata": {},
   "outputs": [],
   "source": [
    "induction_stripe = attn_weights.diagonal(\n",
    "    dim1=-2, dim2=-1,\n",
    "    offset=1-seq_len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e84b3e-5aae-464b-bf28-e41a37c7dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b97f4c4-b346-467d-9e9d-11e06ad235b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "induction_stripe = torch.randn(5, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef60720f-4c70-487c-8868-466a0827801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "induction_score = einops.reduce(\n",
    "    induction_stripe,\n",
    "    \"head_idx n_weights -> head_idx\",\n",
    "    reduction=\"mean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f481d88-94f4-4f08-a41e-b9c338e3362c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "induction_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaa70d8-5ef2-43d1-9d5a-5738389a4eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagonal = x.diagonal(dim1=-2, dim2=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e952782f-e4c6-45d3-8075-bed9167fa210",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = [tokenize(x[\"text\"]) for x in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d5f493-703d-4495-9196-7c8643ffd90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443d23ad-2895-4e20-86e6-8abaf15ce7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e6b073-2ddb-41ee-af20-0ebea5a4e93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_jit = jax.jit(func, static_argnames=[\"n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78549470-f7c3-4074-9a61-f28a6307dc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.grad(squared_x, has_aux=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0498ad0-22aa-4ea1-8d02-a7f6fc9a5cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba7ab0-5e78-4f43-af25-b03656f28739",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def x_retrieve(x):\n",
    "    return retrieve(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1170dc-9932-4d37-a213-bf0d68cbde88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [x_retrieve(x) for x in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc55abd-1ed3-4736-802e-aeb0dfd14b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcd3c92-9d91-481c-bc3e-d6c499687c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([-1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7c5cdc-2d5a-4dac-b1da-b3d3e2a9df5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([\n",
    "    [0, 1, 2, 1],\n",
    "    [1, 0, 1, 2]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b346c647-b91a-4302-8ec1-56eefe56e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df73edb-71a3-46ea-b9ba-f647b8546d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_square = jax.jit(square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3856c40c-c4eb-4c33-9669-05b5cbf4c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1c67fc-e156-49dc-8f66-ccd3e1ac5122",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = rearrange(\n",
    "    images,\n",
    "    \"b (h p1) (w p2) -> b c (h w) (p1 p2 c)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aca3cb-c312-40fe-9a0f-9b2b43d8c74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_jit = jax.jit(func, static_argnames=[\"n\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494116bf-ccd7-41a7-af77-05e310e25678",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: tokenize obser\n",
    "step 2: tokenize prompt\n",
    "step 3: take action\n",
    "ste 4: exec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d497ef-17da-421f-b72f-aff7a3b1315d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProduct(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors):\n",
    "        super().__init__()\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors(x[:, 0])\n",
    "        movies = self.movie_factors(x[:, 1])\n",
    "        return (users*movies).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de43a4a-8aa0-44d4-b949-0cb40b8f64e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "16, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be2b4e0-ad9e-419b-9f17-95af2f28923a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25f56a1a-a9f7-484b-aa41-38bc5ce45ec9",
   "metadata": {},
   "source": [
    "This passage explains the equivalence between the original formulation of transformer attention layers and the concept of independent attention heads, which is useful for understanding transformers theoretically.\n",
    "\n",
    "In the original transformer paper by Vaswani et al., attention layers are described by stacking the result vectors from each head ($r^{h_1}, r^{h_2}, \\ldots$) and then multiplying by an output matrix $W_O^H$. To show the equivalence with the independent attention head concept, the output matrix $W_O^H$ is split into equal-sized blocks for each head: $\\left[W_O^{h_1}, W_O^{h_2}, \\ldots\\right]$.\n",
    "\n",
    "The mathematical expression then shows that the operation involving the output matrix and the stacked result vectors is equal to the sum of the product of each head's output matrix and its respective result vector: $\\sum_i W_O^{h_i} r^{h_i}$.\n",
    "\n",
    "This reveals that the attention layers can be thought of as independently additive, where each head operates independently, is multiplied by its own output matrix, and is added into the residual stream. Although the concatenate definition is more efficient computationally, the independent attention head concept is preferred for understanding transformers from a theoretical perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11470580-65c3-44cc-9d4a-5f3ceed9a72e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
