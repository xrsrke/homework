{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f1910e6-0abf-4494-b83b-e2ae2cafc1c3",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f0ed9bb-5956-4543-8ab6-081c65892883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad9761c-6aa4-4330-af35-555f6929cbde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hmac\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c45f7d38-86dd-48bd-99f9-030ead11e698",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_digest(key, serialized_message):\n",
    "    return hmac.new(key, serialized_message, hashlib.sha256).digest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50c7a4d-ed25-44f4-8f72-8e836826396e",
   "metadata": {},
   "outputs": [],
   "source": [
    "container runtime, kubelet, kube-proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c5749f-f2f1-46b9-bae6-d191e7e788ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment, configmap, service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d82a873-33a5-40e6-bb64-7f2ae6e4aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22c8652-7210-4edd-9fc1-5111815bd04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    std::cout << \"hello\" << std::endl;\n",
    "    std::cout << \"world\";\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b459846a-9728-4cae-9bef-9043a5cfbfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid > thread block > thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eec661-3bf8-47fa-8c3d-cd7fc653c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticdriver spots a change in worker nodes\n",
    "send a hostupdaterequest to the notification service\n",
    "-> notification manager\n",
    "-> trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047fbcff-922c-4c89-a43e-0217138ab1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_event = torch.cuda.Event(enable_timing=True)\n",
    "end_event = torch.cuda.Event(enable_timing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f8244b-be84-4c6f-bf05-b5911aafbf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cycles = 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa94fd5-962d-4ccb-a7e9-b5b0685fb6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_event.record()\n",
    "torch.cuda._sleep(n_cycles)\n",
    "end_event.record()\n",
    "elapsed_time = end_event.elapsed_time(start_event)\n",
    "cycle_per_ms = 1_000_000 / elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0429de01-86ae-4040-a554-6d22f39f773e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cuda_sleep(seconds):\n",
    "    ms = seconds * 1000\n",
    "    n_cycles = cycle_per_ms*ms\n",
    "    torch.cuda._sleep(n_cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc79bd83-55c5-40a1-b7f4-c3ef72816b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20881f5c-089f-449a-bf50-29539db66263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_grad_enabled(input):\n",
    "    return torch.is_grad_enabled() and input.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1a295aa-e563-4f34-a0c9-6316ae78a48d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def broadcast(input):\n",
    "    world_size = torch.distributed.get_world_size()\n",
    "    \n",
    "    if world_size == 1:\n",
    "        return input\n",
    "    \n",
    "    torch.distributed.broadcast(input, group=parallel_group)\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee6442f1-4528-46ae-b126-e2d12278e5fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce(input):\n",
    "    world_size = torch.distributed.get_world_size()\n",
    "    \n",
    "    if world_size == 1:\n",
    "        return input\n",
    "    \n",
    "    torch.distributed.all_reduce(input, group=parallel_group)\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e4a99f0-faf7-4298-ac03-fd37ffd4aafe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Broadcast(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return broadcast(input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        return reduce(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb5a3fcd-0e1e-4c5a-9df5-7b4c48cb9ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def broadcast_with_forward_and_backward(input):\n",
    "    if is_grad_enabled(input):\n",
    "        output = Broadcast.apply(input)\n",
    "    else:\n",
    "        output = broadcast(input)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d9435-ea3c-4c68-9f7e-dd38397d85ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready, running, succeed, failed, cooldown, blacklisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c79de03-53a0-4399-9fc0-a57ada24ae4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_handler(v):\n",
    "    for handler_name, handler_cls in handler_registry:\n",
    "        if isinstance(v, handler_cls):\n",
    "            return handler_cls(v)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce3f6c99-3915-4cc6-be3a-eff5bb7cf69c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_handlers(states):\n",
    "    handlers = {}\n",
    "    remainders = {}\n",
    "    \n",
    "    for k, v in states:\n",
    "        handler = get_handler(v)\n",
    "        \n",
    "        if handler is None:\n",
    "            remainders[k] = v\n",
    "        else:\n",
    "            handlers[k] = handler\n",
    "    return handlers, remainders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a485d5de-a934-4d9b-8c3c-04d95a4ab075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168401c2-7226-4959-8e35-d5ae02d8f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelStateHandler:\n",
    "    def __init__(self, model):\n",
    "        self.vlaue =\n",
    "        self._model_state_dict = copy.deepcopy(\n",
    "            model.state_dict()\n",
    "        )\n",
    "    \n",
    "    def commit(self):\n",
    "        self._model_state_dict = copy.deepcopy(self.value.state_dict())\n",
    "    \n",
    "    def restore(self):\n",
    "        self.value.load_state_dict(self._model_state_dict)\n",
    "        \n",
    "    def set_value(self, value):\n",
    "        self.value = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cc8122d-ee62-422c-b026-4cf95495a9bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Copy(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, prev_stream, next_stream, input):\n",
    "        ctx.prev_stream = prev_stream\n",
    "        ctx.next_stream = next_stream\n",
    "        \n",
    "        compute_stream = torch.cuda.default_stream(next_stream.device)\n",
    "        \n",
    "        with torch.cuda.use_stream(prev_stream), torch.cuda.use_stream(next_stream):\n",
    "            moved_input = input.to(next_stream.device)\n",
    "            input.record_stream(prev_stream)\n",
    "            moved_input.record_stream(compute_stream)\n",
    "        return moved_input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        prev_stream = ctx.prev_stream\n",
    "        next_stream = ctx.next_stream\n",
    "        \n",
    "        compute_stream = torch.cuda.default_stream(prev_stream.device)\n",
    "        \n",
    "        with torch.cuda.use_stream(prev_stream), torch.cuda.use_stream(next_stream):\n",
    "            moved_grad_input = grad_input.to(prev_stream.device)\n",
    "            grad_input.record_stream(next_stream)\n",
    "            moved_grad_input.record_stream(compute_stream)\n",
    "        return moved_grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64f9763-146d-4a86-bda3-b32b8c824b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clock_cycles = n_microbatches + n_partritions - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85e47853-4a05-4df2-a5b6-e572295a8929",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_clock_cycles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m clock_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mn_clock_cycles\u001b[49m):\n\u001b[1;32m      2\u001b[0m     start_partrition \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(clock_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mn_microbatches, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m     end_partrition \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(clock_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, n_partritions)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_clock_cycles' is not defined"
     ]
    }
   ],
   "source": [
    "for clock_idx in range(n_clock_cycles):\n",
    "    start_partrition = max(clock_idx+1-n_microbatches, 0)\n",
    "    end_partrition = min(clock_idx+1, n_partritions)\n",
    "    \n",
    "    tasks = []\n",
    "    for partrition_idx in range(start_partrition, end_partrition):\n",
    "        microbatch_idx = clock_idx-partrition_idx\n",
    "        tasks.append((microbatch_idx, partrition_idx))\n",
    "    print(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed7d861-e556-46ba-b4d5-8983eff9e27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_tensors(x):\n",
    "    world_size = torch.distributed.get_world_size()\n",
    "    \n",
    "    if world_size == 1:\n",
    "        return x\n",
    "    \n",
    "    xs = [torch.randn_like(x) for x in world_size]\n",
    "    torch.distributed.gather(xs, x)\n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3528cffd-8d95-4d22-abe8-a1421e212c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: partrition\n",
    "step 2: forward, gather, do computation, discard\n",
    "step 3: backward, gather, do computation discard\n",
    "step 4: reduce-scatter\n",
    "step 5: update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ab8ff8-0c79-4214-8ccd-9cca3af35eab",
   "metadata": {},
   "source": [
    "embed + pos_embed + attn00 + attn01 + mlp0 + attn10 + attn11 + mlp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9b88ff-352d-4458-9cf5-5e72a3394965",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = sigmoid(logit0 - logit1)\n",
    "\n",
    "logit0 = final_ln @ W_U[0]\n",
    "logit1 = final_ln @ W_U[1]\n",
    "\n",
    "logit_diff = final_ln @ W_U[0] - final_ln @ W_U[1]\n",
    "logit_diff = final_ln @ (W_U[0] - W_U[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39a1140-0701-4b0f-b228-b8704aa4b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_in = model.W_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad86b05-f77f-49ec-943f-d93d941b9134",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_in[layer_idx, :, neuron_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a77c85-9405-4b55-b8cc-dd96ab69da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: a list of failure cases\n",
    "step 2: record the activations of the target heads\n",
    "step 3: project each target heads to the direction of the failure case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d0aebb-8ed2-4ee5-a853-cd3d6e113a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_in[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0a7493-6a9d-43f0-bdc1-59bd5595ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ReLU(x@W_in[:, i]) @ W_out[i, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45cc1a5-c06c-4586-80d9-f6868ddea485",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cc8a56-41bc-4df2-a42a-9788fcb59d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "reset\n",
    "sync\n",
    "commit/save\n",
    "restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08949209-0c20-4379-bb9b-6ba019543826",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid > thread block > thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb626dcc-4a27-433b-88a3-bed3aea5197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: theirs + mine\n",
    "step 2: presence = (theirs + mine) / 2\n",
    "step 3: blank - presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9bbfa5-0c30-4d44-af84-24f0b8fea997",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_2 @ W_Q @ [v_0, v_1] @ W_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc28f95b-6c79-49a9-8ddf-3fbd3dfb4f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.unbind(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc241d4-649a-42f6-b4c9-315068600d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: ReLU(x@W_in[:, i])@W_out[i, :]\n",
    "step 2: sum over d_mlp neurons ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9257d0c-a87d-4e02-9ccc-dd45f24bbef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs @ W_V @ W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cab793-b61e-40a2-b949-9433e5079c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = embed + pos_embed + sum(12 heads)\n",
    "\n",
    "query = x @ W_Q\n",
    "value = x @ W_V\n",
    "\n",
    "query = [embed + pos_embed + sum(12 heads)] @ W_Q\n",
    "value = [embed + pos_embed + sum(12 heads)] @ W_V\n",
    "\n",
    "14 x 14 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63686cb9-bb36-46f7-a934-dd399c54f0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready, running, suceed, failed, blacklist, cooldown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224f926e-03f5-4ed8-ae9d-b27ec7d6de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(clock_idx+1, n_partritions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c86b558-b27f-4c0e-ab63-994cf3d0d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "global memory > shared memory > thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b46bb9-5bec-4466-8e5f-d96f86ba0c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: replica the model\n",
    "step 2: split a mini-batch into micro-batches\n",
    "step 3: forward and backward\n",
    "step 4: average the gradients\n",
    "step 5: update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f97aa2a-ec96-405b-b2f7-36b56488be86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RegularState:\n",
    "    def __init__(self, states):\n",
    "        self.states = states\n",
    "        self._saved_states = copy.deepcopy(states)\n",
    "        for k, v in states:\n",
    "            setattr(k, v)\n",
    "    \n",
    "    def commit(self):\n",
    "        new_states = {}\n",
    "        \n",
    "        for k in self.states.keys():\n",
    "            new_states[k] = getattr(self, k)\n",
    "        self._saved_states = copy.deepcopy(new_states)\n",
    "    \n",
    "    def restore(self):\n",
    "        for k, v in self._saved_states:\n",
    "            setattr(self, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "263bc8c2-7525-4a1b-ae1b-9ee79e7f966f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class State(RegularState):\n",
    "    def __init__(self, model, optim, **kwargs):\n",
    "        kwargs.update({\"model\": model, \"optim\": optim})\n",
    "        handlers, remainders = get_handlers(kwargs)\n",
    "        \n",
    "        self._handlers = handlers\n",
    "        \n",
    "        for k, handler in handlers:\n",
    "            setattr(k, handler)\n",
    "    \n",
    "    def commit(self):\n",
    "        for handler in self._handlers.values():\n",
    "            handler.commit()\n",
    "        RegularState.commit(self)\n",
    "    \n",
    "    def restore(self):\n",
    "        for handler in self._handlers.values():\n",
    "            handler.restore()\n",
    "        RegularState.restore(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193f5501-36a7-4950-9888-21b6daef5e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_model(model, balances, devices):\n",
    "    layers = {}\n",
    "    partrition_idx = 0\n",
    "    \n",
    "    for name, layer in model.named_children():\n",
    "        layers[name] = layer\n",
    "        \n",
    "        if len(layers) == balances[partrition_idx]:\n",
    "            partrition = nn.Sequential(*layers)\n",
    "            device = devices[partritions]\n",
    "            partrition.to(device)\n",
    "            layers.clear()\n",
    "            partrition_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3426597b-09d5-42ee-b7cb-4d6c97f69b65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26514fd9-5f73-49ae-8895-d18128d39d5a",
   "metadata": {},
   "source": [
    "Checkpoint.forward() > Recompute.forward() > Recompute.backward() > Checkpoint.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed2363-4404-4867-b713-7fefd79dfb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashlib, key, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f436d1e-8b4f-4dcf-bc1f-d3828eeb6831",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters, gradient, optimizer's states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dc24fc-6e6e-45da-8a5f-54618de6cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready, running, succeed, failed, cooldown, blacklisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931fc87c-5a49-454f-8941-af3de591a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "global distributed group, tensor, pipeline, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f8e183-f96e-4c26-9d38-b12c04217b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: partition\n",
    "step 2: forward, gather, x, discard\n",
    "step 3: backward, gather, x, discard\n",
    "step 4: reduce-scatter\n",
    "step 5: update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fb94a3-30a1-4178-8034-3f28c963d942",
   "metadata": {},
   "outputs": [],
   "source": [
    "friction, normal, air, applied force, gravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d08b133-e36f-443d-b13b-bca64b3900d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metallic, covalent, ionic, wall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064abb9b-51d0-45e3-aa0d-dd8687de7f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ReLU(x@W_in)@W_out\n",
    "\n",
    "sum of d_mlp neurons(ReLU(x@W_in[:, i])@W_out[i, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b1e0f8-ea33-4520-aaf7-f8e3087537b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.from_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c2bbc9-c94a-47c9-80c3-431a5cf7da5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = torch.cuda.Stream(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8347e2d4-a87d-4546-82c1-f52d2ec0d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.device(device):\n",
    "    with torch.cuda.stream(stream):\n",
    "        x = xs.mean(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c25d185-0492-4629-b569-d55fedd374ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastapi import HTTPException, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c10aaeb-ce8d-4303-a040-7f35e0c5e230",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/blog\")\n",
    "def blog():\n",
    "    raise HTTPException(status=status.HTTP_404_NOT_FOUND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c3bf142-fcda-4420-a3cd-bd7eaf31b6d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ed59084-269f-4253-8e74-16a848ba59d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def foo(collections: Sequence[str]) -> None:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60ffea20-4e29-4bb0-b8e1-8a89278fddb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6c871b46-ea05-4766-8265-d8a6066bff39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function functools.lru_cache(maxsize=128, typed=False)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functools.lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c846f2a-7e96-4af0-b680-249c2570a7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.bmm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f0726d-97c5-4472-ab15-93274d722818",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params:\n",
    "                p -= p.grad * self.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27ca22b5-45b9-44b4-8e5f-8a72ae073a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4df3a22c-18fd-4c8b-b32a-a82ccb598aeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_loss(model, xb, yb):\n",
    "    preds = model(xb)\n",
    "    \n",
    "    preds = rearrange(preds, \"bs seq_len d_model -> (bs seq_len) -> d_model\")\n",
    "    yb = rearrange(yb, \"bs seq_len -> (bs seq_len)\")\n",
    "    \n",
    "    loss = F.cross_entropy(preds, yb)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de905f1-86dc-42c9-aaf6-76e0a1883c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.kl_div(\n",
    "    input=F.log_softmax(student_logits, dim=-1),\n",
    "    target=F.softmax(teacher_logits, dim=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f421e690-667e-4e0f-862b-b70cf583a9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt\n",
    "observation\n",
    "pred\n",
    "actionb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02ba8e8-a2d9-46c8-acae-8c6d7fae1b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.kl_div(\n",
    "    input=F.log_softmax(student_logits),\n",
    "    target=F.softmax(teacher_logits)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
