{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "194af500-d516-48bf-80e6-bbf0451cf94f",
   "metadata": {},
   "source": [
    "### MechInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09607409-d498-45b4-9bd9-132c439388ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax(x@W_Q@W_K@x.T)@x@W_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df87e8-2611-4ed7-8825-085f96d26f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a42588-e32b-4670-8725-8014c2601e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated_resid = cache.accumulated_resid(\n",
    "    layer=-1,\n",
    "    pos_slice=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e078f-eb79-42d0-a7df-a8bf4d92472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_tokens, incorrect_tokens = answer_tokens.unbind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bd52cf-48e7-422f-a4f3-19d3235c1ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_difference(logit):\n",
    "    return logit[correct_token] - logit[incorrect_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a11bed-b1ad-4312-87d3-81267f8c98b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob(0) = sigmoid(logit0 - logit1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af25384-d308-4956-8195-9f674c7ef496",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit0 = final_resid @ W_U[0]\n",
    "\n",
    "logit1 = final_resid @ W_U[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d9a3b6-c0e1-45e9-849a-28bde91f1fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[\"\", ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab0419e-0254-423f-be6a-1cfb0320d582",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_2@W_E@W_Q@W_K@[v_0, v_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da388c9-56f5-40d9-b955-a82c08de315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmae mode, record activations, for each cell, empty, white, black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82bdd70-1be7-4d0a-b20e-7012a76af833",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d98a1768-046f-480b-b7c6-7a01b1db9a97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "143001ca-c847-4274-839f-8cb40171f9a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_name = get_act_name(\"resid_post\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcfd8305-b0c7-4697-b60f-406f8f54b1bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blocks.2.hook_resid_post'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a94822d-f623-4357-8027-58289588535b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_name = get_act_name(\"normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80f2b8-3abb-4bb1-8073-bb52dd3d1a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_activations = cache[input_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4e428d-b832-4fb7-b1cf-149db2270ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_activations = cache[output_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d2e804-dd06-40be-935b-4d3b04522077",
   "metadata": {},
   "outputs": [],
   "source": [
    "features are linear representations\n",
    "features are represented as directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc027094-665e-4a2a-8686-966ffc5b046e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1298b8c-50de-4682-9db3-95d8c0d8d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "interference = einsum(\n",
    "    W, W, \"instances feature1 dim, instances feature2 dim -> instance feature1 feature2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb4421d-bc45-41cd-ae87-72217194bf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: x = embed + pos_embed + sum(12 heads)\n",
    "step 2: q = x@W_Q, k=x@W_K\n",
    "step 3: q = [embed+pos_embed+sum(12 heads)]@W_Q\n",
    "\n",
    "k = [embed+pos_embed+sum(12 heads)]@W_K\n",
    "step 4:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e43baa9-7409-4b53-bf23-2ebab5d3275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = final_ln @ W_U\n",
    "\n",
    "final_ln = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577fde86-6c71-4018-aff7-17d75bbaf98c",
   "metadata": {},
   "source": [
    "rank, world_size, tensor_parallel_size, pipeline_parallel_size, data_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e048041-d49c-46f4-b893-d5b8b39900d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.storage().resize_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7e48e59-7a64-4735-bc95-8686e902cd4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a27d645-6ddf-456b-ac6d-06114e2d5473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GreedySharding:\n",
    "    def __init__(self, module, parallel_context):\n",
    "        self.module = module\n",
    "        self.parallel_context = parallel_context\n",
    "    \n",
    "    def shard(self):\n",
    "        self._shard_parameters()\n",
    "        return self.module\n",
    "    \n",
    "    def _shard_parameters(self):\n",
    "        module = self.module\n",
    "        \n",
    "        for param in module.parameters():\n",
    "            assert not hasattr(module, \"_is_sharded\")\n",
    "            orig_data = param.data\n",
    "            shard = self._get_shard(param.data)\n",
    "            free_storage(orig_data)\n",
    "            param.data = shard\n",
    "    \n",
    "    def _get_shard(self, data):\n",
    "        parallel_context = self.parallel_context\n",
    "        world_size = parallel_context.get_world_size()\n",
    "        rank = parallel_context.get_rank()\n",
    "        \n",
    "        chunks = list(data.flatten().chunks(world_size))\n",
    "        \n",
    "        while len(chunks) < world_size:\n",
    "            chunks.append(torch.empty(1))\n",
    "            \n",
    "        shard = chunks[rank]\n",
    "        num_elements = chunks[rank].numel()\n",
    "        num_to_pad = num_elements - shard.numel()\n",
    "        \n",
    "        if num_to_pad > 0:\n",
    "            shard = F.pad(shard, num_to_pad)\n",
    "        \n",
    "        return shard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dfa8639-4991-4f50-ba21-ea0bc4cd5583",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import hmac\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30c758a8-a8e9-4a25-a7b8-ec4a1f459865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_digest(key, serialized_message):\n",
    "    return hmac.new(key, serialized_message).digest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b70cd2-fd69-43c0-a760-1c2af4af52b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock cycle 1: F(0, 0)\n",
    "clock cycle 2: F(1, 0), F(0, 1)\n",
    "clock cycle 3: F(2, 0), F(1, 1)\n",
    "clock cycle 4: F(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cc8b07-df3a-46ec-9dc4-e998c086208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: replicate model\n",
    "step 2: split a mini-batch into microbatches\n",
    "step 3: forward and backward\n",
    "step 4: average the gradients\n",
    "step 5: update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb00d4a-07c6-427c-bdb2-f237496fd2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: get the global rank fo the current process\n",
    "step 2: resize embedding vocab size\n",
    "step 3: parallelize embedding layer, linear layer, attention, and layer norm\n",
    "step 4: resize the output size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fbb90d-513c-41d8-90fe-616030982616",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: determine a list of global rank in that parallel group\n",
    "step 2: check whether the process's global rank in that list\n",
    "step 3: if yes, init a distributed group\n",
    "step 4: determine local rank\n",
    "step 5: save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b112152-4507-4960-8764-973a8dc22928",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Copy(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, prev_stream, next_stream, input):\n",
    "        ctx.prev_stream = prev_stream\n",
    "        ctx.next_stream = next_stream\n",
    "        \n",
    "        compute_stream = torch.cuda.default_stream(\n",
    "            next_stream.device\n",
    "        )\n",
    "        \n",
    "        with torch.cuda.stream(prev_stream), torch.cuda.stream(next_stream):\n",
    "            moved_input = input.to(next_stream.device)\n",
    "            input.record_stream(prev_stream)\n",
    "            moved_input.record_stream(compute_stream)\n",
    "        \n",
    "        return moved_input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        prev_stream = ctx.prev_stream\n",
    "        next_stream = ctx.next_stream\n",
    "        \n",
    "        compute_stream = torch.cuda.default_stream(prev_stream.device)\n",
    "        \n",
    "        with torch.cuda.stream(prev_stream), torch.cuda.stream(next_stream):\n",
    "            moved_grad_input = grad_input.to(prev_stream.device)\n",
    "            grad_input.record_stream(next_stream)\n",
    "            moved_grad_input.record_stream(prev_stream)\n",
    "        return moved_grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4513156a-57b3-455b-9870-37ae2ff9bc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: \n",
    "step 2: bind\n",
    "step 3: accept\n",
    "step 4: communicate\n",
    "step 5: close connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15671a27-75a1-43a0-bc05-81bd9592640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Checkpoint(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, phony, recomputed, function, input):\n",
    "        ctx.recomputed = recomputed\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = function(input)\n",
    "        \n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        output, input_leaf = ctx.recomputed.pop()\n",
    "        \n",
    "        with torch.enable_grad():\n",
    "            torch.autograd.backward(output, input_leaf)\n",
    "        \n",
    "        return None, None, None, input_leaf.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b39b56-18bc-4de3-9867-94c604f5b0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected features vs non-correlated features\n",
    "adding relu\n",
    "vary sparity\n",
    "vary feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad73c4e-3013-454f-b4f8-1c715ebfc888",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: logit_diff = logit0 - logit1\n",
    "step 2: logit0 = final_ln @ W_U[0], logit1 = final_ln @ W_U[1]\n",
    "step 3: logit0 - logit1 = final_ln @ W_U[0] - final_ln @ W_U[1]\n",
    "\n",
    "= final_ln @ (W_U[0] - W_U1[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9191bd4-60d0-4a9c-99c2-0a1ac5bbda5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "270a2801-914a-4c95-961a-ce7b53b62503",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de9dc63-424f-49b2-b516-7f6d054c4b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "friction, applied force, normal, air, gravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8699c7f-b9b0-4dc6-b7eb-db4b1c3a8b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditioned, stimulus-evoked, population decoding, motor imagery,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3de6c99-e851-43b0-863f-d258d11fa5fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add(module, inp, out):\n",
    "    add_log(module, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ed15215-a40a-4f9b-9376-000cf5fdd5f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_hook(model):\n",
    "    for layer in model.modules():\n",
    "        layer.register_forward_hook(add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad872da-c87b-46ed-a399-4f5b97822206",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = torch.cuda.stream(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf7b263-4b40-4801-8be9-534c7b78d2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.device(device):\n",
    "    with torch.cuda.stream(stream):\n",
    "        mean = xs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9d9a95-7ea4-43a4-9eeb-b77fcd678459",
   "metadata": {},
   "outputs": [],
   "source": [
    "int* a;\n",
    "int* b;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87c4eb7-7fdc-4a13-ac9f-109393d50504",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_t bytes = size(int) * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462263e4-3247-4a57-afc7-1e74f471950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (int*)malloc(bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7b171b-8703-477a-ace3-0aeffd971d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = (int*)malloc(bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de883c7-cfec-4166-a4ba-a0fc79b3bc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize communication\n",
    "maximize memory storage\n",
    "minimize FLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aef802c-1bf1-43a5-8395-c7ca440ac347",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: rank\n",
    "step 2: resize vocab embedding\n",
    "step 3: parallelize embedding, linear, attention, layer norm\n",
    "step 4: resize lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9e2dd11-5306-418f-bb30-adc287ce2ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb78784e-d54f-4301-9596-8474c3d2c97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(model xb, yb):\n",
    "    logits = model(xb)\n",
    "    \n",
    "    logits = rearrange(preds, \"bs seq_len n_emed -> (bs seq_len) n_embed\")\n",
    "    yb = rearrange(yb, \"bs seq_len -> (bs seq_len)\")\n",
    "    \n",
    "    loss = F.cross_entropy(logits, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1475e518-8588-4a4d-a9a4-b93cb0db25d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "message passing, p2p, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f7d8244-752d-4473-8551-6d186d4b6520",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174ef873-5a06-41d1-9d49-19011f8c535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachedDataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        super().__init__()\n",
    "        self.filename = filename\n",
    "        self.data = None\n",
    "        self.cached_index = {}\n",
    "    \n",
    "    def prefetch(self, idxs):\n",
    "        if all([for i in idxs]): # wrong\n",
    "            return\n",
    "    \n",
    "        if self.data is None:\n",
    "            self.data = torch.load(self.filename)\n",
    "        \n",
    "        size = sum([self.data[i].numel() for i in idxs]) * size\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f96b9ce8-170e-4ef1-aad3-0c4ad337427e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, mom, eps):\n",
    "        super().__init__()\n",
    "        self.mom, self.eps = mom, eps\n",
    "        self.mean = nn.Parameter(torch.zeros(1))\n",
    "        self.var = nn.Parameter(torch.ones(1))\n",
    "        self.add = nn.Parameter(torch.zeros(1))\n",
    "        self.mult = nn.Parameter(torch.ones(1))\n",
    "        \n",
    "    def update_stats(self, x):\n",
    "        mean = x.mean(dim=0, keepdim=True)\n",
    "        var = x.var(dim=0, keepdim=True)\n",
    "        \n",
    "        self.mean.lerp_(mean, self.mom)\n",
    "        self.var.lerp_(var, self.mom)\n",
    "        return mean, var\n",
    "    \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            mean, var = self.update_stats(x)\n",
    "            \n",
    "        x = x-mean/(var+self.eps).sqrt()\n",
    "        x = self.add + self.mult * x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06125db7-1192-4829-8250-71ba0f8a4342",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5068bd-7b51-4019-be4a-b1bc148d5e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = rearrange(\n",
    "    images,\n",
    "    \"bs c (n_height p_height) (n_width p_width)\\\n",
    "    -> bs (n_height n_width) (p_height p_width c)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f734e19-ca27-4c19-a705-af2312773234",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06d4c71f-2b99-4304-9ed8-0d7e34f5bb05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Default process group has not been initialized, please make sure to call init_process_group.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:756\u001b[0m, in \u001b[0;36mget_backend\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[38;5;124;03mReturns the backend of the given process group.\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    753\u001b[0m \n\u001b[1;32m    754\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 756\u001b[0m     pg \u001b[38;5;241m=\u001b[39m \u001b[43m_get_default_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    758\u001b[0m     pg \u001b[38;5;241m=\u001b[39m group\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:707\u001b[0m, in \u001b[0;36m_get_default_group\u001b[0;34m()\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;124;03mGetting the default process group created by init_process_group\u001b[39;00m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_initialized():\n\u001b[0;32m--> 707\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefault process group has not been initialized, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease make sure to call init_process_group.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    710\u001b[0m     )\n\u001b[1;32m    711\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m GroupMember\u001b[38;5;241m.\u001b[39mWORLD\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Default process group has not been initialized, please make sure to call init_process_group."
     ]
    }
   ],
   "source": [
    "torch.distributed.get_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0baed8bc-00e5-4136-8b0d-16938f863728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([1., 2., 3.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f60fb431-b0fc-47b7-aa87-4dba34cd529c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = torch.tensor([0.1, 0.2, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c66161a-4454-419a-afba-7b249a53a1e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.4000, 0.9000])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3331704b-1f7f-4ee5-88cc-a66a28cef262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
