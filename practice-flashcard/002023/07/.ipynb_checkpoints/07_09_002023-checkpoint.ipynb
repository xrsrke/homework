{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c654fce6-380d-4264-b80d-4b2324e01158",
   "metadata": {},
   "source": [
    "Sure, let's break down the term $e W_{Q K}^{1.4}\\left(x^{0.7}\\right)^T$.\n",
    "\n",
    "$e$ : This represents the token embedding of a particular token. For example, let's say the token is \"cat\". The embedding \"e\" will be a vector representation of this token, which encodes the semantic meaning of the word \"cat\".\n",
    "\n",
    "$W_{Q K}^{1.4}$ : This represents the combined weights for the query and key matrices for the 4th head in the first layer. This combined matrix is what is used to transform the input embeddings to the query and key embeddings used in the attention mechanism.\n",
    "\n",
    "$x^{0.7}$ : This represents the output of the 7th head in the 0th layer (i.e., the previous layer) of the Transformer. This output is essentially the representation of the token at that particular position, as \"understood\" by that attention head.\n",
    "\n",
    "$e W_{Q K}^{1.4}$: This is the transformed query embedding of a token. It means that we are taking the token embedding \"e\" and transforming it using the query and key weight matrix $W_{Q K}^{1.4}$. This gives us the query embedding for the token, in the context of the 4th head in the 1st layer.\n",
    "\n",
    "$\\left(x^{0.7}\\right)^T$ : This represents the transposed output of the 7th head in the 0th layer. Transposing this matrix allows us to do a matrix multiplication with the transformed token embedding.\n",
    "\n",
    "Finally, the whole term $e W_{Q K}^{1.4}\\left(x^{0.7}\\right)^T$ represents the calculation of attention scores for the input token \"cat\" in the context of the 4th head in the 1st layer, particularly emphasizing the output of the 7th head from the previous layer. This score informs how much attention should be paid to this token when constructing the final sentence representation.\n",
    "\n",
    "In the case of the induction head discussed in the question, this score represents how much the model is attending to the previous tokens in the sequence to form the next-token prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8614fbe2-6936-48c6-a9db-5ba2d5f4da9b",
   "metadata": {},
   "source": [
    "### MechInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cbe0cae-eaac-422f-8eef-e2e38e20a93b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "362f9749-f09b-43f6-b10f-c9d3b08a9d9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-09 04:22:04.424 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/education/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator(_root_container=1, _parent=DeltaGenerator())"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.sidebar.header(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086ec376-f0fe-4129-af9c-7e916473f31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust():\n",
    "    layer_idx = st.sidebar.slider(\"layer_idx\", 0, 12, 5)\n",
    "    head_idx = st.sidebar.slider(\"head_idx\", 0, 12, 4)\n",
    "    return layer_idx, head_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0963d320-8679-45ea-a365-cfadbe6e0244",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx, head_idx = adjust()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6de47d-f458-4269-8e6f-c89b33e3d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_resid = pre_resid + output_attention_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458cf2b8-5390-4845-899c-7a63aceec616",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0b302b-03fc-4e16-a336-4a0abba5521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_pattern = cache[\"pattern\", 0, \"attn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01f394a1-3248-43f2-a540-5e94fc317f64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import circuitsvis as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13908d6-566f-4ce4-bf39-b0b0b6f0a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_strs = model.token_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0d3cb5-9a3b-4ac5-b898-3992eb6ceefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.attention.attention_pattern(tokens=tokens, attention=attention_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0c9e112-09db-41b5-bffb-b69dfd907b15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_activation(activations, hook):\n",
    "    activations[:, :, 4, :] = 0\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a60281c-e732-4aea-a012-25cde06d7c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model.run_with_cache(\n",
    "    tokens,\n",
    "    fwd_hooks=[(hook_name, set_activations)],\n",
    "    return=\"loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d30bd55-0a22-4482-a84e-70c56f23672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[\"attn\", 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5f3615-9b96-41ff-a2e8-c6c3a3c174a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embed(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf7c2667-d51b-4533-9b98-bc1a3adfa578",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4218d5df-6588-4fc5-bda5-8d105c1151d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = product(range(n_heads), range(n_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17012f70-4116-40d2-bb5c-f6653258157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: residual = embed(tokens) + unembed(tokens)\n",
    "step 2: reisudal = blocks(residual)\n",
    "step 3: residual = ln_final(residual)\n",
    "step 4: logits = unembed(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65296bc0-0cee-41d3-bc17-d70393203e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_pos = model.W_pos\n",
    "W_Q = model.W_Q[layer_idx, head_idx]\n",
    "W_K = model.W_K[layer_idx, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40632ae9-6677-4bf5-a95b-aefb6cff4054",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_by_pos_scores = W_pos @ W_Q @ W_K @ W_pos.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4085204-078a-497a-8bf5-aae4c079cb27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c4cecf-403b-4f26-9e47-c9ef893b69f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_score(scores):\n",
    "    mask = torch.triu(torch.ones_like(scores)).bool()\n",
    "    neg_inf = torch.tensor(-1e9)\n",
    "    return torch.where(mask, scores, neg_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5488f86-9498-4b5e-9c81-fa89861fbf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_pos_by_pos_score = mask_score(pos_by_pos_scores / (d_head**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5ac359-5db0-490a-b491-1d29227b4d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_by_pos_pattern = F.softmax(masked_pos_by_pos_score, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6fa151-21b2-4ac0-bec1-b7c322adbed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa006fb0-d9be-4d32-bb11-0bbf951e7479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621b064c-5c83-4549-b292-4abea1de32d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f0fb7-e674-4173-af6e-3468113858ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_residual_stream = cache[final_residual_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ab988c-f18b-4cc7-a904-8fd9acd1dcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_final_residual_stream = cache[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86847859-271f-4bfd-8df6-a2ee98dabe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_last_token_final_residual_stream = model.apply_ln_to_stack(\n",
    "    last_token_final_residual_stream,\n",
    "    layer=-1,\n",
    "    pos_slice=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da9b92d-6272-4de3-8a99-491e79ce7e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d85440-78fa-4afc-9360-e0821e4a4e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_residual_direction = W_U[: correct_token]\n",
    "incorrect_residual_direction = W_U[: incorrect_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839a84b7-bcf0-4535-87fc-1a71a8544982",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_difference_direction = correct_residual_direction - incorrect_residual_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "948924df-3486-4582-a3d9-34fac5aa062a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bc4de4-dc48-4674-8135-cbdda83f6861",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_difference = einsum(\n",
    "    scaled_last_token_final_residual_stream,\n",
    "    logit_difference_direction,\n",
    "    \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7143c9b1-f7e0-4461-83b0-40552d04b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf1443-2350-4dcb-a2f7-62a2e6ac1b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75beb04-2946-4f55-9275-10aa7513e00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = cache[\"hook_embed\"]\n",
    "pos_embed = cache[\"hook_pos_embed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf74021-a0d1-482f-be75-8f5de3a224b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_outputs = cache[\"result\", prev_layer_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7c67b9-bbba-49ad-b024-ec7cf8906e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_components = torch.cat([\n",
    "    embed, pos_embed, head_outputs\n",
    "], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cd5c73-2b97-4807-b291-f92dbc7ce474",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Q = model.W_Q[next_layer_idx, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34dfeb8-a5ab-4c2c-9f1b-f152ccace5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_components = einsum(input_components, W_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999d0982-70de-4daf-b340-4eeeb45254c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_contributions = query_components.pow(2).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2853d403-8d8b-40d3-bb3c-0a91df9c67e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[\"blocks.0.attn.hook_pattern\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ace148b-328b-4506-9bfa-323f91a01fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_resid = mlp + mid_resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017425bd-1ed1-41f0-891b-1d27ef363dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result: the output from all attention heads\n",
    "step 2: the output of the whole attention layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8427ca0b-f3f9-4670-b8b4-5c3485c481f7",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10ee0f80-6b48-4644-9207-82185cc9049d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60f4f2aa-03b3-4f2b-90f4-ebe2a4281f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_decorator(func):\n",
    "    @functools.wraps\n",
    "    def wrapper(*args, **kwargs):\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2797640d-300e-483b-a516-d175cb7f301b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_memory(model):\n",
    "    total_memory = 0\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        total_memory += param.numel() * param_siz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3df561-186f-459f-bf37-d476bad20bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4e073c-de40-449b-ab3b-fc639aa9e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "using namespace std;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a75a52b-cc7f-47f3-9fa3-364c2a1b606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Book() {\n",
    "    public:\n",
    "        string title;\n",
    "    \n",
    "        string Book(aTitle) {\n",
    "            title = aTitle;\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea67a82-a381-434c-a2b9-2df1a95fc85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (; i<10; i++) {\n",
    "    std::cout << \"i = \" << i << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d412762-cc91-45c2-8a1a-437eed896582",
   "metadata": {},
   "outputs": [],
   "source": [
    "typedef int age;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34f551cc-582d-4ace-bff8-9977dcf64f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0343401-7d99-458a-aefe-41d36236a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvenSampler(Sampler):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter([x for x in range(0, len(self.data), 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b275e975-a681-4908-8a4a-242795fda1e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_forward_pass_using_data_parallelism(model, input, device_ids, output_id):\n",
    "    models = nn.parallel.replicate(model, device_ids)\n",
    "    inputs = nn.parallel.scatter(input, device_ids)\n",
    "    \n",
    "    output_parallel = nn.parallel.parallel_apply(models, inputs)\n",
    "    outputs = nn.parallel.gather(output_parallel, target_device=output_id)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab772546-cd2d-45a6-9de0-21bb8b59166e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ranks = [0, 1, 3, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869c5fe9-cef3-4b62-a7bd-56bc8820f776",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = torch.distributed.get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e12a525-a82f-4991-9163-66d25b8a7df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = torch.distributed.ProcessGroup([0, 1, 3, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbcf4b4-5a2b-478c-828b-c263e913dd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rank == 0:\n",
    "    torch.distributed.send(x, group=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc95e9cf-0102-4df1-b9c4-643a5aba69b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "int* h_a, int* h_b, innt* h_c;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c79a49f-a6f7-4ea6-b279-c325d05ab487",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_t bytes = sizeof(int) * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dcb8ad-6451-4cb2-899f-76d56a509a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_a = (int*)malloc(bytes)\n",
    "h_b = (int*)malloc(bytes)\n",
    "h_c = (int*)malloc(bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f50b47-92eb-42b2-adc0-37f58fab106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_stream(source_stream, target_stream):\n",
    "    if isinstance(target_stream, torch.cuda.Stream):\n",
    "        if isinstance(source_stream, torch.cuda.Stream):\n",
    "            # GPU waits for GPU\n",
    "            source_stream.wait_stream(target_stream)\n",
    "        else:\n",
    "            target_stream.syncronous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1478de01-b3c2-4afd-8acb-b9a230e37710",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Wait(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, prev_stream, next_stream, input):\n",
    "        ctx.prev_stream = prev_stream\n",
    "        ctx.next_stream = next_stream\n",
    "        \n",
    "        wait_stream(\n",
    "            source_stream=next_stream,\n",
    "            target_stream=prev_stream,\n",
    "        )\n",
    "        \n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        wait_stream(\n",
    "            source_stream=ctx.prev_stream,\n",
    "            target_stream=ctx.next_stream\n",
    "        )\n",
    "        return tuple([None, None] + [grad_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d5e4625-77e1-4071-b9c9-50a32a34e8d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import socketserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54100fc-68fd-4659-9fc3-21271dac7795",
   "metadata": {},
   "outputs": [],
   "source": [
    "with socketserver.ThreadingTCPServer(\n",
    "    (MASTER_HOST, MASTER_PORT),\n",
    "    EchoRequestHandler\n",
    "):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18042386-83d0-4407-b84a-207742bff32a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80fcb6d3-52c1-4e83-bf39-a97cd1359f6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelStateHandler:\n",
    "    def __init__(self, model):\n",
    "        self.value = model\n",
    "    \n",
    "    def restore(self):\n",
    "        self.value.load_state_dict(self._model_state_dict)\n",
    "    \n",
    "    def save(self):\n",
    "        self._model_state_dict = copy.deepcopy(self.value.state_dict())\n",
    "    \n",
    "    def sync(self):\n",
    "        broadcast_parameters(self.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12c7397a-c04a-46b8-b7f5-e77da3fdbd19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_handler(v):\n",
    "    for handler_type, handler_cls in handler_registry:\n",
    "        if isinstance(v, handler_cls):\n",
    "            return handler_cls(v)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d58e92da-ebfb-4ab5-9059-d104d13c71fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_handlers(states):\n",
    "    handlers = {}\n",
    "    remainders = {}\n",
    "    \n",
    "    for k, v in states:\n",
    "        handler = get_handler(v)\n",
    "        if handler is None:\n",
    "            remainders[v] = handler\n",
    "        else:\n",
    "            handlers[v] = handler\n",
    "    return handlers, remainders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6c51430b-ca2c-4d0f-a263-d10d3d5eeea4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_microbatches, n_partritions = 4, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8913c5d0-e5f5-4a43-b9e0-3300d02ef72a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_clock_cycles = n_microbatches + n_partritions - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "821e2974-3c67-443e-89c9-2b71b1a421ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0)]\n",
      "[(1, 0), (0, 1)]\n",
      "[(2, 0), (1, 1), (0, 2)]\n",
      "[(3, 0), (2, 1), (1, 2)]\n",
      "[(3, 1), (2, 2)]\n",
      "[(3, 2)]\n"
     ]
    }
   ],
   "source": [
    "for clock_idx in range(n_clock_cycles):\n",
    "    start_partrition = max(clock_idx+1-n_microbatches, 0)\n",
    "    end_partrition = min(clock_idx+1, n_partritions)\n",
    "    \n",
    "    tasks = []\n",
    "    for partrition_idx in range(start_partrition, end_partrition):\n",
    "        microbatch_idx = clock_idx - partrition_idx\n",
    "        tasks.append((microbatch_idx, partrition_idx))\n",
    "    \n",
    "    print(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec94f6ba-4d42-4872-93a9-5b76e2df3c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = torch.distributed.get_rank()\n",
    "ranks = [0, 1, 3, 6]\n",
    "group = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb9c11d-d230-46b9-9028-7f499da08e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rank in ranks:\n",
    "    group = torch.distributed.ProcessGroup(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29546565-95e7-4e75-8e6a-2d27875265df",
   "metadata": {},
   "outputs": [],
   "source": [
    "if group is not None:\n",
    "    torch.distributed.send(x, src=0, group=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d138139e-293c-4b6a-bb7f-2141b6cdaa1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import socketserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80969f5-e6fe-4d70-9c11-ca014f6c13df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with socketserver.ThreadingTCPServer(\n",
    "    (MASTER_HOST, MASTER_PORT),\n",
    "    EchoRequestHandler\n",
    ") as server:\n",
    "    server.serve_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb9b9531-fa7f-4da8-87f4-826d91267b8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea06489-bda0-42ce-81f6-0f5d5d30dcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_model(model, balances, devices):\n",
    "    layers = OrderedDict()\n",
    "    partrition_idx = 0\n",
    "    partritions = []\n",
    "    \n",
    "    for name, layer in model.named_children():\n",
    "        layers[name] = layer\n",
    "        \n",
    "        if len(layers) == balances[partrition_idx]:\n",
    "            partritions.append(nn.Sequential(layers).to())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3fbf21-f14a-48bb-9941-613db492ae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: ln1 = ln1(resid_pre)\n",
    "step 2: head_outputs = head1(ln1) + head2(ln2)\n",
    "step 3: mid_resid = head_outputs. + resid_pre\n",
    "step 4: ln2 = ln2(mid_resid)\n",
    "step 5: mlp = mlp(ln2)\n",
    "step 6: post_resid = mlp + mid_resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573188d6-d115-41d3-af56-cda21a2d075a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2574d46-55f7-4f64-b41d-9c111b3d798a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_model(model, balances, devices):\n",
    "    partritions = []\n",
    "    layers = {}\n",
    "    partrition_idx = 0\n",
    "    \n",
    "    for name, layer in model.named_children():\n",
    "        layers[name] = layer\n",
    "        \n",
    "        if len(layers) == balances[partrition_idx]:\n",
    "            partritions.append(\n",
    "                nn.Sequential(layers).to(devices[partrition_idx])\n",
    "            )\n",
    "            layers.clear()\n",
    "            partrition_idx+=1\n",
    "        \n",
    "    return partritions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff245e22-90b3-456b-9c2b-8543389e2d9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc4b179-e443-4ce5-a386-c1fd0d0bf879",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.observa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3f7357-ba19-4714-81a5-84dd8046e4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79607fce-27e6-440c-b253-4c0987bbbef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, block in model.blocks:\n",
    "    if idx >= 5:\n",
    "        for param in block.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b968e896-98fe-49b1-a013-4c5dd7fec262",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.lm_head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in model.ln_final.parameters():\n",
    "    param.requires_grad = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
