{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d145cb-dde7-4636-b0a2-ea4553c48445",
   "metadata": {},
   "outputs": [],
   "source": [
    "friction, normal, gravity, air resistance, applied force"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaeff46-fb13-482e-8dc5-e326ac970e95",
   "metadata": {},
   "source": [
    "normal, friction, air resistance, applied force, gravity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316e370d-658e-49d8-9fbd-3bf7f323ac5d",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39704dca-723c-462a-b3d7-f10e3820a883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70d9e3eb-c73a-441b-90e0-d97385ac464a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Copy(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, prev_stream, next_stream, input):\n",
    "        ctx.prev_stream = prev_stream\n",
    "        ctx.next_stream = next_stream\n",
    "        \n",
    "        compute_stream = torch.cuda.default_stream(next_stream.device)\n",
    "        \n",
    "        with torch.cuda.use_stream(prev_stream), torch.cuda.use_stream(next_stream):\n",
    "            moved_input = input.to(next_stream.device)\n",
    "            \n",
    "            input.record_stream(prev_stream)\n",
    "            moved_input.record_stream(compute_stream)\n",
    "        \n",
    "        return moved_input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        prev_stream = ctx.prev_stream\n",
    "        next_stream = ctx.next_stream\n",
    "        \n",
    "        compute_stream = torch.cuda.default_stream(prev_stream.device)\n",
    "        \n",
    "        with torch.cuda.use_stream(prev_stream), torch.cuda.use_stream(next_stream):\n",
    "            moved_grad_input = grad_input.to(prev_stream.device)\n",
    "            \n",
    "            grad_input.record_stream(next_stream)\n",
    "            moved_grad_input.record_stream(compute_stream)\n",
    "        \n",
    "        return tuple([None, None, moved_grad_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9a4274-b778-4a33-8890-5175c105dded",
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticdriver\n",
    "notificationservice\n",
    "notificationmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb640a8-4ed6-4549-a426-ecb886f5ad44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08bfc618-8079-4e49-99d6-51d6cfb9c143",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MPU:\n",
    "    def __init__(self, master_addr, master_port, backend):\n",
    "        if not torch.distributed.is_initialized():\n",
    "            rank = os.getenv[\"RANK\"]\n",
    "            world_size = os.getenv[\"WORLD_SIZE\"]\n",
    "            \n",
    "            os.environ[\"MASTER_ADDR\"] = str(master_addr)\n",
    "            os.environ[\"MASTER_PORT\"] = str(master_port)\n",
    "            \n",
    "            torch.distributed.init_process_group(\n",
    "                rank=rank,\n",
    "                world_size=world_size,\n",
    "                backend=backend\n",
    "            )\n",
    "            \n",
    "            n_devices = torch.cuda.device_count()\n",
    "            if n_devices > 0:\n",
    "                torch.cuda.set_device(rank % n_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6f8f11-b750-4dd9-9d96-8e004b865527",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7d3cd5-4146-48ad-8883-cb1b73ee0d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    def __init__(self, batches, partritions, devices, scheduler=DetermisticScheduler()):\n",
    "        self.batches = batches\n",
    "        self.partritions = partritions\n",
    "        self.devices = devices\n",
    "        self.scheduler = scheduler\n",
    "        \n",
    "    def fit(self):\n",
    "        batches = self.batches\n",
    "        partritions = self.partritions\n",
    "        devices = self.device\n",
    "        scheduler = self.scheduler\n",
    "        \n",
    "        n_batches = len(batches)\n",
    "        n_partritions = len(partritions)\n",
    "        \n",
    "        with spawn_workers(devices) as (in_queues, out_queues):\n",
    "            for schedule in scheduler.generate(n_batches, n_partritions):\n",
    "                self.compute(schedule, in_queues, out_queues)\n",
    "    \n",
    "    def compute(self, schedule, in_queues, out_queues):\n",
    "        \n",
    "        for batch_idx, partrition_idx in schedule:\n",
    "            batch = batches[batch_idx]\n",
    "            \n",
    "            def compute(batch, partrition):\n",
    "                def wrapper():\n",
    "                    return partrition(batch)\n",
    "                return wrapper\n",
    "            \n",
    "            task = Task(compute=compute)\n",
    "            in_queues[partrition_idx].put(task)\n",
    "            \n",
    "        for batch_idx, partrition_idx in schedule:\n",
    "            output_queue = out_queues[partrition_idx].get()\n",
    "            batches[batch_idx] = output_queue.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29d5500-4cb0-4b7e-8665-8f47b2a8498e",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: wait for data transfer\n",
    "step 1: get input\n",
    "step 2: construct a task\n",
    "step 3: put the task into in_queues\n",
    "step 4: wait and get the output\n",
    "step 5: put the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8d76dc-1b37-4ee2-a490-61dc1b321340",
   "metadata": {},
   "outputs": [],
   "source": [
    "fence: backward dependency, data transfer\n",
    "compute: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2530611d-f3f4-4213-914b-9d18f88831a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: partrition\n",
    "step 2: split a mini-batch into micro-batches\n",
    "step 3: cuda stream\n",
    "step 4: pipe\n",
    "step 5: collect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4574a7b1-1a27-476c-85ee-4fdcc564b43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock cycle 1: f(0, 0)\n",
    "clock cycle 2: f(1, 0), f(0, 1)\n",
    "clock cycle 3: f(2, 0), f(1, 1)\n",
    "clock cycle 4: f(2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d73be93-cd7d-4b99-8f60-114b8c6b2d7c",
   "metadata": {},
   "source": [
    "### Mech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a1085b-3da3-46e0-ae40-454dfeb59dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "key=persis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12aa32d9-eed2-4652-af19-0debccafc90a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9adf410-ee25-4410-86d5-b538e7ef9003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hook_input = get_act_name(\"resid_post\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81fbec10-74c7-4828-96ac-ffd5025514ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hook_output = get_act_name(\"normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9fb2393-bf74-4d1a-9825-c6f435f0b828",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ln_final.hook_normalized'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hook_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53930e01-6aea-40fd-bef3-6580e648f35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(\n",
    "    tokens,\n",
    "    names_filter=lambda x: x in [hook_input, hook_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08720fd6-c571-4849-9498-e9116a8cf41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28feafc2-72c2-4948-8a56-addbc282c2d3",
   "metadata": {},
   "source": [
    "embed + pos_embed + attn00 + attn01 + mlp0 + \n",
    "\n",
    "attn01 + attn11 + mlp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f65e45-df62-41da-91fb-b298378e8263",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U\n",
    "logit_diffence_direction = W_U[:, 0] - W_U[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5ed1db-7074-400f-9fdd-46ea54c017eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_names = [get_act_name(\"result\", layer_idx) for layer_idx in range(n_layers)]\n",
    "mlp_names = [get_act_name(\"mlp_out\", layer_idx) for layer_idx in range(n_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903b0eda-4d38-44c1-ba70-a2a64ca49436",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_names = [\"hook_embed\", \"hook_pos_embed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fea75c-54ac-4826-ac3b-a00b8e08730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_names.append(head_names)\n",
    "hook_names.append(mlp_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63996f0-b9dd-40fd-aea3-a61c8a56c35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(\n",
    "    tokens,\n",
    "    names_filter=lambda x: x in hook_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19efc7a8-b28e-45cf-8ff9-3cacce23e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight x input = output\n",
    "\n",
    "input = weight.T @ ouput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ccbe85-8880-4cd3-9264-8a2bafa75807",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_ln = fn_ln_coefs.T @ fn_ln_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c288f13f-e4fe-46f1-8034-cc16cccf99fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_components = torch.tensor([cache[\"embed\"] + cache[\"pos_embed\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc5659f-1b82-4359-94a2-7307d95d29da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for head_name, mlp_name in zip(head_names, mlp_names):\n",
    "    input_components = torch.cat([\n",
    "        cache[head_name],\n",
    "        cache[mlp_name]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baf940ad-9329-4876-a81e-c06475c2dba7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa04cbd-1d15-44d9-8829-8849b84327ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions = einsum(\n",
    "    input_components,\n",
    "    pre_lnc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8507b84-4cec-48c3-bb51-17794c5a7bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight @ input = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd5a72d-a50f-4408-bf54-e0a003a3f7e2",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a8bcc0-17b4-4231-9ac0-a9fb6c089f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "main worker > worker thread > task > cuda stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f80d58-3348-407a-bb7e-daf863bc0baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: fp32, fp16 of the weight\n",
    "step 2: do forward and backward using fp16\n",
    "step 3: cast \n",
    "ipda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc28e3c-640b-4684-a4f3-01693e3b65ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def profile_times(model, batch):\n",
    "    records = []\n",
    "    \n",
    "    for layer in model:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52d7f0ae-55fb-4888-a9bd-3f064e196770",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import socketserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64b9b541-9c6d-4eac-8ff8-a2a26021bdaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_port(server_factory):\n",
    "    start_port = 1024\n",
    "    end_port = 65536\n",
    "    \n",
    "    for port in range(start_port, end_port):\n",
    "        try:\n",
    "            addr = (\"\", port)\n",
    "            server = server_factory(add)\n",
    "            return server, port\n",
    "        except Exception:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05baf68c-1eec-4873-af63-73e2cb3ac445",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RowParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        self.input_size_per_partrition = input_size // world_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.randn(\n",
    "            self.output_size,\n",
    "            self.input_size_per_partrition\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        dim_size_per_partrition = inputs.shape[-1] // rank\n",
    "        input_chunks = torch.split(input, dim_size_per_partrition)\n",
    "        \n",
    "        input_parallel = input_chunks[rank]\n",
    "        output_parallel = F.linear(input_parallel, self.weight)\n",
    "        \n",
    "        torch.distributed.all_reduce(output_parallel)\n",
    "        \n",
    "        return output_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6045033e-b77f-41bb-8781-a83f0d03ed06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor_model_parallel_size = 2\n",
    "num_tensor_model_parallel_groups = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6b1be7e-ba85-4ad6-8238-a6a3089b0746",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[2, 3]\n",
      "[4, 5]\n",
      "[6, 7]\n",
      "[8, 9]\n",
      "[10, 11]\n",
      "[12, 13]\n",
      "[14, 15]\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_tensor_model_parallel_groups):\n",
    "    ranks = list(range(\n",
    "        i*tensor_model_parallel_size,\n",
    "        (i+1)*tensor_model_parallel_size\n",
    "    ))\n",
    "    \n",
    "    print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023d664e-648b-4c54-8b5c-83a904c3144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: scale the loss using a scaling factor\n",
    "step 2: compute the grad with respect to the scaled loss\n",
    "step 3: unscale the grad using the scaling factor\n",
    "step 4: update params with respect to the unscaled grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b80450-36e5-4c26-b669-2f8ea16d47df",
   "metadata": {},
   "source": [
    "### MechInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49b8793-c7c4-4ef1-a656-f3a1b9a85e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: P(0) = sigmoid(logit0 - logit1)\n",
    "step 2: logit0 = final_ln @ unembed\n",
    "step 3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8ba905-dc6c-4942-b177-e1bee9ccce64",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: ln1 = ln1(resid_pre)\n",
    "step 2: attn_outputs = head1(ln1) + head2(ln1) + \n",
    "step 3: mid_resid = resid_pre + attn_outputs\n",
    "step 4: ln2 = ln2(mid_resid)\n",
    "step 5: mlp = mlp(ln2)\n",
    "step 6: pos_resid = mid_resid + mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f179a5-4f42-4e6b-abca-11dbe272667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(Attn(x@W_E))@W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3f33c1-fc26-41f7-9c6c-8a908d5b0177",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[\"blocks.0.attn.hook_pattern\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b555d1e3-2456-40c7-abb1-911d704b9597",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: approximate\n",
    "step 2: logit diff\n",
    "step 3: decompose logit\n",
    "step 4: project "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76968b3e-b5ef-4e2a-bbbe-0a92d5a1b776",
   "metadata": {},
   "source": [
    "### MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81a4a61f-73e2-437a-8f1e-0a1f28988f94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3886c31-6aa4-46e7-a680-cc2ffbac066e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'e', 'h', 'l', 'o'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{x for x in \"hello\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af16caac-78de-47a9-b06d-35ac051af304",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wizard(User):\n",
    "    def __init__(self):\n",
    "        super().__init__(self, email)\n",
    "        sel.fname = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "116b87d7-8ec1-450b-a7f1-1a7ccf756113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a4568-faab-4fde-a530-4341ffa23ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x: List[Union[int, float, str]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb792bf-8d09-4202-8da3-e603c5c6eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: approximate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "481d50af-c75f-455f-a737-1a4091fb8dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens import FactoredMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8a3532-c1ee-4463-aac7-f1aad26067ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "AB = FactoredMatrix(AB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40910fd-ce39-4bd6-b029-b7ecf3a32cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "AB.eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfebe429-a4af-4ae9-9c39-4816ab42658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight @ input\n",
    "weight-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccec2699-e798-4162-920d-c6ecea339ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax(x@W_Q@W_K@x) @ x@ W_V @ W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc25e958-5a4b-461d-a87f-cf2f12aba6c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c9a374-be11-4d7d-ace6-e8ce2121016b",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = product(n_heads, n_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5a05e-11b7-4e64-ae8f-c4b63e21d2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "step logit diff\n",
    "step 2: decompose logit\n",
    "step 3: compute logit difference direction\n",
    "step 4: project the output of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195fb2a3-b8b7-4dfd-b1c3-03de99b7b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: record all the interdimate activations\n",
    "step 2: check the attention pattern of heads\n",
    "step 3: spot induction head, if yes, dig further\n",
    "step 4: decompose the query and vector\n",
    "step 5: compute the contribution of each apir\n",
    "step 6: identify the pair that \n",
    "step 7: construct the full circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bc4944-d375-4bab-bd90-9bcb60d56e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: approximate layer norm\n",
    "step 2: reverse transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0da79e-c965-40dd-9968-251b7e822cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: decompose the logits\n",
    "step 2: compute logit difference direction\n",
    "step 3: apprxoimate\n",
    "step 4: reverse transformation\n",
    "step 5: project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ea6ac7-2156-445c-8581-2ea3e72787a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x@W_OV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd5dbe4-a148-450f-b973-46ca21a72724",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = model.to_tokens(clean_prompt)\n",
    "corrupted_tokens = model.to_tokens(corrupted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef0cb12-4d65-4f49-93c6-5e7877ec4ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_token = model.to_single_token(\" John\")\n",
    "incorrect_token = model.to_single_token(\" Mary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db650432-7361-4227-9d22-555db0de03eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = len(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0f0591-e27d-470e-afe6-6a71ff231bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.zeros(n_layers, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5cbf020-3977-4f7e-99bd-880ad57653db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_activation(activations, hook, position_idx):\n",
    "    activations = clean_activations[hook.name][:, position_idx, :]\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19bace0b-abce-421b-ba94-e731776766ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf6952f-cc8e-4a40-8d99-e43fd053a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logit_difference(logits, correct_token, incorrect_token):\n",
    "    logit = logits[:, -1, :]\n",
    "    return logit[correct_token] - logit[incorrect_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8017d9-ece9-4ae3-8cf6-2a792ef62e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(n_layers):\n",
    "    hook_name = get_act_name(\"resid_pre\", layer_idx)\n",
    "    for position_idx in range(seq_len):\n",
    "        hook_func = partial(patch_activation, position_idx=position_idx)\n",
    "        patched_logits = model.run_with_cache(\n",
    "            corrupted_tokens,\n",
    "            fwd_hooks=[(hook_name, hook_func)]\n",
    "        )\n",
    "        logit_difference = compute_logit_difference(patched_logits)\n",
    "        results[layer_idx][position_idx] = logit_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b0a562-561e-4fdc-a763-f83112cc69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d798e-5d79-497d-837e-fdda1526ba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(\n",
    "    tokens,\n",
    "    names_filter=lambda x: x in hook_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f196e3b8-ac4d-4091-aab7-63812b143efa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc8f40-d945-4df2-abe7-88bfc1c62884",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5753e78a-2c79-4a95-9574-e706e2058d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: approximate layer norm\n",
    "step 2: reverse transformation\n",
    "step 3: logit difference direction\n",
    "step 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d40e86-2ee5-429b-9071-bec2384a7146",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f419d4-8a75-44cc-bda2-d3dd3006f5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "interference[torch.arange(n_features), torch.arange(n_features)] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb6ac0e-d988-4922-9a44-00c0b1bf2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "polysemanticity = interference.pow(2).sum(dim=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
