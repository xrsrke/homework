{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59a77d03-6501-4ead-a2d3-7a12bd5db13d",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15229f79-0554-4a85-8129-74cf8e8dc0c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3288001b-62eb-427d-92fa-cdf53bfb2601",
   "metadata": {},
   "outputs": [],
   "source": [
    "new > ready > running > blocked > terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fc9517-1281-446b-abd8-d04db16e40c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_stream.record_event()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66b7464-dd0c-4ebd-aeb2-471f00f489cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler, control manager, ectd, api server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64cdafa-c877-4fa7-b101-81aeb59f5370",
   "metadata": {},
   "outputs": [],
   "source": [
    "node > pod > container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2a5064d-540a-41c4-96ef-b4ce63c96f37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VocabParallelEmbedding(nn.Module):\n",
    "    def __init__(self, num_embedding, embedding_dim):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        self.num_embedding_per_partrition = num_embedding // world_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.randn(\n",
    "            self.num_embedding_per_partrition,\n",
    "            self.embedding_dim\n",
    "        ))\n",
    "        self.vocab_start_idx, self.vocab_end_idx = self.get_vocab_range(\n",
    "            self.num_embedding_per_partrition\n",
    "        )\n",
    "    \n",
    "    def get_vocab_range(self, num_embedding_per_partrition):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        start_idx = num_embedding_per_partrition*rank\n",
    "        end_idx = start_idx+num_embedding_per_partrition\n",
    "        return start_idx, end_idx\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        masks = (tokens < self.vocab_start_idx) | (tokens > self.vocab_end_idx)\n",
    "        masked_tokens = tokens - self.vocab_start_idx\n",
    "        masked_tokens[masks] = 0.\n",
    "        \n",
    "        embeddings = F.embedding(masked_tokens, self.weight)\n",
    "        mask_idxs = torch.where(masks == False)[1]\n",
    "        embeddings[:, mask_idxs, :] = 0.\n",
    "        \n",
    "        torch.distributed.all_reduce(embeddings)\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354c40d9-976d-4d17-bddc-e600c6c212b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor\n",
    "reassign if a node leaves\n",
    "build a new communication ring if a new node join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23e7cbd3-da48-4088-bfba-998fe8a9dc5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Copy(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, prev_stream, next_stream, input):\n",
    "        ctx.prev_stream = prev_stream\n",
    "        ctx.next_stream = next_stream\n",
    "        \n",
    "        compute_stream = torch.cuda.default_stream(next_stream.device)\n",
    "        \n",
    "        with torch.cuda.use_stream(prev_stream), torch.cuda.stream(next_stream):\n",
    "            moved_input = input.to(next_stream.device)\n",
    "            \n",
    "            input.record_stream(prev_stream)\n",
    "            moved_input.record_stream(compute_stream)\n",
    "        \n",
    "        return moved_input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        prev_stream = ctx.prev_stream\n",
    "        next_stream = ctx.next_stream\n",
    "        \n",
    "        compute_stream = torch.cuda.default_stream(prev_stream.device)\n",
    "        \n",
    "        with torch.cuda.use_stream(prev_stream), torch.cuda.stream(next_stream):\n",
    "            moved_grad = grad_input.to(prev_stream.device)\n",
    "            \n",
    "            grad_input.record_stream(next_stream)\n",
    "            moved_grad.record_stream(compute_stream)\n",
    "        \n",
    "        return tuple([None, None, moved_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e19bf3-e0cc-4ed3-86af-a84730f01ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_microbatches, n_partritions, devices,\n",
    "        scheduler=DetermisticScheduler()\n",
    "    ):\n",
    "        self.n_microbatches = n_microbatches\n",
    "        self.n_partritions = n_partritions\n",
    "        self.devices = devices\n",
    "        self.scheduler = scheduler\n",
    "    \n",
    "    def fit(self):\n",
    "        n_microbatches = self.n_microbatches\n",
    "        n_partritions = self.n_partritions\n",
    "        devices = self.devices\n",
    "        scheduler = self.scheduler\n",
    "        \n",
    "        with spawn_worker(devices) as (in_queues, out_queus):\n",
    "            for schedule in scheduler.generate(n_microbatches, n_partritions):\n",
    "                self.compute(schedule, in_queues, out_queues)\n",
    "    \n",
    "    def compute(self, schedule, in_queues, out_queues):\n",
    "        batches = self.batches\n",
    "        partritions = self.partritions\n",
    "        \n",
    "        for microbatch_idx, partrition_idx in schedule:\n",
    "            batch = batches[microbatch_idx]\n",
    "            partritions = partritions[partritions]\n",
    "            \n",
    "            def compute(batch, partrition):\n",
    "                def wrapper():\n",
    "                    return partrition(batch)\n",
    "                return wrapper\n",
    "            \n",
    "            task = Task(compute=compute(batch, partrition))\n",
    "            in_queues[partrition_idx].put(task)\n",
    "        \n",
    "        for microbatch_idx, partrition_idx in schedule:\n",
    "            queue_output = out_queues[partrition_idx].get()\n",
    "            task, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4a55ee-99e2-45d1-9d4a-d7d495bb1611",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock cycle 1: F(0, 0)\n",
    "clock cycle 2: F(0, 1), F(1, 0)\n",
    "clock cycle 3: F(1, 1), F(2, 0)\n",
    "clock cycle 4: F(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b346174-7600-4234-b9b4-be55f6893aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: split a mini-batch into microbatches\n",
    "step 2: create cuda streams\n",
    "step 3: run the pipeline\n",
    "step 4: gather the output of all micro-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c4edf7-a4fb-49b3-8e99-d1604fbbb807",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "step 0: wait for data transfer\n",
    "step 1: get the input\n",
    "step 2: construct task\n",
    "step 3: put the task into the correspond partrition's in_queue\n",
    "step 4: wait and get the output\n",
    "step 5: put the output to the next partrition's in_queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d9da1-a04f-421a-8771-f811f7d9b6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "build backward dependencies, data transfer and compute, put the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c3cc57-2ea2-49e0-a19c-fe3406b804fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2afcd04-995b-4f0b-beeb-046a7a8407b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: backward(layer4), and backward(layer3)\n",
    "step 2: recompute the activations\n",
    "step 3: do backward 2\n",
    "step 4: continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3eda23-e1fd-402f-9290-92a31974dfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria 1: all cuda operations that associate with x in gpu0...\n",
    "criteria 2: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3d6235-955f-4c6f-abcb-851775adae4d",
   "metadata": {},
   "source": [
    "### MechInterp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfab5bd-bcb7-4665-be8d-72f5e4ecf821",
   "metadata": {},
   "source": [
    "output_layer2 = embed + pos_embed + layer1 + layer2\n",
    "= embed + pos_embed + attn00 + attn01 + mlp0 + attn10 + attn11 + mlp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dd4609-b32c-480d-9805-4b83e9bb888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(past_moves)\n",
    "log_probs = torch.log_softmax(logits[:, -1, :], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d10972c-2e96-400c-826f-c6e66423918d",
   "metadata": {},
   "outputs": [],
   "source": [
    "board_states = torch.zeros(board_size*board_size)\n",
    "board_states[next_possible_moves] = log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fad54b5-819c-4fa2-9156-96257725bd87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af91f2c7-2434-49ce-93ad-749371806338",
   "metadata": {},
   "source": [
    "step 1: approximate nonlinear\n",
    "step 2: probs => logit difference\n",
    "step 3: decompose logits\n",
    "step 4: project each input components to the target token in unembeding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a76db0-556d-4e27-bc5b-2d58589ffa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax(x@W_Q@W_K@x.T) @ W_V "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89664f28-2c63-49ab-a748-a36fcb2e7e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9454e0-f186-4419-b528-333b9678ca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3024b025-a8b4-4325-b8d9-9a4709de0ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = cache[\"hook_embed\"]\n",
    "pos_embed = cache[\"hook_pos_embed\"]\n",
    "head_outputs = cache[\"result\", layer_idx-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a137847-4c6d-457c-a5b5-57cd71578550",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_components = torch.cat([\n",
    "    embed,\n",
    "    pos_embed,\n",
    "    head_outputs\n",
    "], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33c14eef-1669-4dd8-af7d-888dd0a09943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e837ad-0d6a-4025-8a8e-ae00393cbe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Q = model.W_Q\n",
    "query_components = einsum(\n",
    "    input_components,\n",
    "    W_Q,\n",
    "    \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022acf36-12aa-41d2-9c09-5db28f451bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_K = model.W_K\n",
    "key_components = einsum(\n",
    "    input_components, W_K,\n",
    "    \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a991a9c2-4f9a-4fc7-b537-90258cf277e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_attention_scores = einsum(\n",
    "    query_components,\n",
    "    key_components,\n",
    "    \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8100b1-5377-4031-a835-66aa1945f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E @ W_QK^{1, 4} @ W_OV_{0, 7} @ W_E.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ee86a7-5eb0-4a4e-ae6d-19fc501a6227",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E\n",
    "W_Q = model.W_Q[1, 4]\n",
    "W_K = model.W_K[1, 4]\n",
    "W_O = model.W_O[0, 7]\n",
    "W_V = model.W_V[0, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d737a8-293e-4099-b3cf-6d96cfcf0f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = W_E @ W_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc24b78b-91b6-422b-9730-d9395705a827",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = W_E W_V @ W_O.T @ W_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2be6de-197a-424a-be4a-7e040988925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_rref.owner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af51799-5375-4eac-bf16-fa3e82f543ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04bfd7f-0188-42b1-8677-1d969a74b8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    for param in param_group.parameters():\n",
    "        print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef31988-85f7-46a4-be96-b2cca8cdd73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward(x) > output = forward(x) > backward(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196e68a3-967e-47da-bb73-3cae8b424f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    def __init__(\n",
    "        self,\n",
    "        microbatches, partritions, devices,\n",
    "        scheduler=DetermisticScheduler()\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.batches = microbatches\n",
    "        self.partritions = partritions\n",
    "        self.devices = devices\n",
    "        self.scheduler = scheduler\n",
    "    \n",
    "    def fit(self):\n",
    "        batches = self.batches\n",
    "        partritions = self.partritions\n",
    "        devices = self.devices\n",
    "        scheduler = self.scheduler\n",
    "        \n",
    "        n_microbatches = len(batches)\n",
    "        n_partritions = len(partritions)\n",
    "        \n",
    "        with spawn_worker(device) as (in_queues, out_queues):\n",
    "            for schedule in scheduler.generate(n_microbatches, n_partritions):\n",
    "                self.compute(schedule, in_queues, out_queues)\n",
    "    \n",
    "    def compute(self):\n",
    "        batches = self.batches\n",
    "        \n",
    "        for microbatch_idx, partrition_idx in schedule:\n",
    "            batch = batches[microbatch_idx]\n",
    "            \n",
    "            def compute(batch, partrition):\n",
    "                def wrapper():\n",
    "                    return partrition(batch)\n",
    "                return wrapper\n",
    "            \n",
    "            task = Task(compute=compute)\n",
    "            in_queues[partrition_idx].put(task)\n",
    "        \n",
    "        for microbatch_idx, partrition_idx in schedule:\n",
    "            output_queue = out_queues[partrition_idx].get()\n",
    "            batches[microbatch_idx] = output_queue.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0bb5b25-a601-4cf8-ba72-5d1874df2cc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b689baf-454a-4634-b9bf-792ae59f0316",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvenSampler(Sampler):\n",
    "    def __init__(self, data):\n",
    "        self.data = self.data\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter([x for x in range(0, len(self.data), 2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d490995-58e5-45bb-b309-85e414c9537f",
   "metadata": {},
   "source": [
    "ElasticDriver, HostDiscovery, NotificationManager, NotificationService, NotificationClient, TorchState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16e8e9ea-45d9-49b1-ad78-b1752b8131e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor_model_parallel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44cf8686-7006-4677-8c8d-f8974b4ef771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_tensor_model_parallel_groups = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf663ba-0688-4270-a940-d5635fd6d6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_tensor_model_parallel_groups):\n",
    "    ranks = range(\n",
    "        i*tensor_model_parallel_size,\n",
    "        i+1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b399017-cb92-48a1-9a51-dd7436270501",
   "metadata": {},
   "source": [
    "clock cycle 1: backward(m, n)\n",
    "clock cycle 2: backward(m-1, n), backward(m, n-1)\n",
    "clock cycle 3: backward(m-2, n), backward(m-1, n-1), backward(m, n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f6c89a-d13e-4458-a500-bd76aa45f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sync\n",
    "restore\n",
    "commit/save\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6846b1-1680-43ef-9e7f-202605b4550a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9000f752-6f10-4f1f-a73c-afd06a639790",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: two prompts\n",
    "step 2: record all the intedimate activations\n",
    "step 3: iteratively ...\n",
    "step 4: compute logit diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cdf3bb-28d1-4b21-b6d1-848659feeec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U[:, tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1628419-b80f-4ac6-adca-fa4130134e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob0 = sigmoid(logit0-logit1)\n",
    "\n",
    "logit0 = fn_ln @ W_U[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9b09b4-bbc2-4578-abf7-a43f8c1e7a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f7f8faf-7862-46a7-813a-6d1f074606c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed082623-aa35-40ca-acfd-3d1ef16275a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_neuron_activations(activations, hook):\n",
    "    data = activations\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a60fbe9-57ef-44f7-b46b-02bf30ea5cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_name = f\"blocks.{layer_idx}.mlp.hook_post\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f94672-b054-46c1-aecf-807e1d89a86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.run_with_cache(\n",
    "    tokens,\n",
    "    fwd_hooks=[(hook_name, extract_neuron_activations)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b63c5cf-42f5-45d5-8fe0-e60c07334c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_max = torch.argmax(data, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "832b1801-6ef8-47a9-b15c-5bdb739dac4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_shape(module, inp):\n",
    "    print(inp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38450dd-fe6b-4e34-9ad4-3e4825702027",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.blocks[1].register_forward_pre_hook(print_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bda1b0-f4fe-4fa7-9d9d-08b1720966af",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fd21d1-a4b7-43c7-bdaa-d4d9e2d11918",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_resid_direction = W_U[:, correct_token]\n",
    "incorrect_resid_direction = W_U[:, incorrect_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1f7194-c27a-4357-996a-4f57a2543c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_diff_direction = correct_resid_direction - incorrect_resid_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630c147e-0d18-42b9-955d-87b3a0a0cc8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c791b10e-47b9-40c5-926e-3ab09f3a980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df56b03f-c3e6-4a61-a339-d43f19c2919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interferences[\n",
    "    torch.arange(n_features),\n",
    "    torch.arange(n_features)\n",
    "] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49044cc5-eabb-4172-b5d8-aaff09a743c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "polysemanticity = inteference.pow(2).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848b1ae5-b7ed-4ff5-8f0b-0947b1c681a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.accumulated_resid(\n",
    "    layer=layer_idx,\n",
    "    pos_slice=target_positions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431caaa4-8c31-42f3-9746-5c9b86d3932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "QK, OV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3d92756-5b46-4293-b133-ad4c045a1649",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deb0705-179d-4940-876f-82d900e16d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\n",
    "    \"input, output\",\n",
    "    [(1, 1), (2, 4)]\n",
    ")\n",
    "def test_square(input, output):\n",
    "    assert square(input) == outpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2d1ec2-2417-4377-adc8-b97f43dee1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "setattr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063310c2-95af-4bf9-8160-6657c589fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0777a8-fa5c-4e6d-915a-af1fbea72151",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker network create mongo-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c838e6bf-6f1b-4d72-a556-b8a4a814ed7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e78d0-b263-46ef-9b0f-d6e8e7617a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "x: Union[str, int, float] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a86a08f5-37e5-4865-835a-bbdaeeb69fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc48873d-7561-4975-928b-761fcbd3acc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready, succeed, failed, cooldown, blacklisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a72b82fa-2a8f-4e52-bd64-bcc17bb2b87f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_model_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d590d783-3a63-4eb8-a10c-6b090dc29d76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tensor_model_parallel_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccced86c-0dcb-4b1c-bde0-1ac023dbf57e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[2, 3]\n",
      "[4, 5]\n",
      "[6, 7]\n",
      "[8, 9]\n",
      "[10, 11]\n",
      "[12, 13]\n",
      "[14, 15]\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_tensor_model_parallel_groups):\n",
    "    ranks = list(range(\n",
    "        i*tensor_model_parallel_size,\n",
    "        (i+1)*tensor_model_parallel_size\n",
    "    ))\n",
    "    \n",
    "    print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb75489-dc97-4465-917d-620c3705fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributed.Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "45428a71-c2d0-432d-8938-dc05f158990b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.profiler import profile, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5048994b-8a4a-4d34-8714-8f55808e4fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU]\n",
    ") as prof:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6809faf6-c188-4b13-b484-6fa749596d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    for param in param_group.parameters():\n",
    "        print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9477203e-673b-44b1-b31d-9e46f6020e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = torch.cuda.Stream(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cf3144-1f6a-4217-9571-cec8efdc6a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.device(device):\n",
    "    with torch.cuda.stream(stream):\n",
    "        mean = xs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff86dcd6-726e-441d-820a-73ee79b6301c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def probability_scores(image_embedding, text_embedding):\n",
    "    image_norm = image_embedding.norm()\n",
    "    image_embedding = image_embedding / image_norm\n",
    "    \n",
    "    text_norm = text_embedding.norm()\n",
    "    text_embedding = text_embedding / text_norm\n",
    "    \n",
    "    similarities = image_embedding @ text_embedding.T\n",
    "    probs = F.softmax(similarities, dim=-1)\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5034a6ce-ae49-49a3-9066-5af9e7b86063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f43e4039-0f0f-415d-a02a-387a4cb17dad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "handlers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9243a6-bb4b-4509-8bfd-24c538de5558",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ob_rref in ob_rrefs:\n",
    "    handlers.append(\n",
    "        rpc.async(\n",
    "            ob_rref.owner(),\n",
    "            func=ob_rref.rpc_sync().run\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13debb0-be30-497a-8b15-4f23f36f7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "for handler in handlers:\n",
    "    handler.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c418c93-6590-40f2-bc45-cfc1a692e113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e935c6b8-85f5-4b85-972c-f57bc3a912ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rearrange(\n",
    "    images, \n",
    "    \"b c (h w) -> b c h w\",\n",
    "    h=64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a689b-d737-4484-99bc-9adfc85d796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zero_likes(RANDOM_TENSOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c82a8343-4f6d-4f23-b50b-88c7985b382c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_head):\n",
    "        super().__init__()\n",
    "        self.d_head = d_head\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        k = k.permute(-2, -1)\n",
    "        scores = torch.matmul(q, k)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores.masked_fill(mask==True, -1e9)\n",
    "        \n",
    "        attn_patterns = F.softmax(scores / (self.d_head**0.5), dim=-1)\n",
    "        output = torch.matmul(attn_patterns, v)\n",
    "        return output, attn_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234f3958-c8fa-4fdc-90b7-4d600482b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleneckResidualBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41570a30-e699-459a-903d-699f6364c0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(first_part @ filter1).sum() + (first_part @ filter2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052cb570-da83-4690-ac4a-478bcee6032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_xs = xs.at[2].set(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdbc8f8-7d5b-4432-967d-835cb774d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_loss = jax.grad(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73beaa02-383a-45d0-bf8e-9f6c11d11cec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2563b74d-1b59-490c-b809-9886d780e322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_function(config):\n",
    "    x, y = config[\"x\"], config[\"y\"]\n",
    "    score = objective(x, y)\n",
    "    tune.report(score=score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1fd389-ea48-46d9-8aff-4f0b641238ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tune.run(\n",
    "    training_function,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e238961a-7fd8-4eec-8bde-1277ca399b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, latency, memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73884ac1-c83c-4dcc-80f4-b7bc4810fe05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbba8ccb-e89c-464e-a0c3-b8f1e8c0e27e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, n_observations, n_actions, n_hidden):\n",
    "        super().__init__()\n",
    "        self.actor_network = nn.Sequential(\n",
    "            nn.Linear(n_observations, n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, n_actions)\n",
    "        )\n",
    "        self.critic_network = nn.Sequential(\n",
    "            nn.Linear(n_observations, n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, observations):\n",
    "        logits = self.actor_network(observations)\n",
    "        dist = Categorical(logits=logits)\n",
    "        action = dist.sample()\n",
    "        log_prob = dist.log_prob(action)\n",
    "        entropy = dist.entropy()\n",
    "        critic_value = self.critic_network(observations)\n",
    "        return action, log_prob, entropy, critic_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4aac4cd4-6b57-4b23-8750-083f70b9b8c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1623415-7427-412d-a5f2-3d78d34dd1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = gym.vector.SyncVectorEnv([\n",
    "    lambda: gym.make(\"CartPole-v1\"), \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9798525-3cac-4258-ba59-7dcdff22d808",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clip(ratio, epsilon):\n",
    "    return torch.clamp(ratio, min=1-epsilon, max=1+epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111eed04-2da6-47a9-9af4-067be3b562ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
