{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e96bbe1-a9eb-4908-b027-f9362c90e2cb",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0815ba32-7a9c-4302-b584-119f5b2eab88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e67df1-093b-4bfc-bd29-f8540808b0d0",
   "metadata": {},
   "source": [
    "### MechInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de420b54-41ff-4d31-9db7-4a61eeb7303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: two prompts\n",
    "step 2: record the interdimate activations of the two prompts\n",
    "step 3: patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572d33da-4994-4b05-8cef-a0afe73cef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax(x@W_E@W_QK)@x@W_E^T@W_OV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc345a1-ef9f-4f4c-8ab7-f9c73fcdeccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "node > pod > container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d02c57c-e240-4422-88e9-0a13e95193c7",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edc0cfc-a386-4ed0-bb0f-4db6451e62df",
   "metadata": {},
   "outputs": [],
   "source": [
    "api servier, ectd, scheduler, control manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7db211-4c28-4b08-b68a-3122a5460fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_total_memory(model):\n",
    "    total_memory = 0\n",
    "    for param in model.parameters():\n",
    "        total_memory += param.storage.size() + param.numel()\n",
    "    \n",
    "    return total_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53866a31-1288-4056-b836-18c4743ea9b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import socketserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83bb4b5c-ecae-42ee-8bac-680d56f732de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EchoRequestHandler(socketserver.StreamRequestHandler):\n",
    "    def handle(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd12bd6-019c-4437-9c51-be8720962e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with socketserver.ThreadingTCPServer(\n",
    "    (MASTER_HOST, MASTER_PORT),\n",
    "    EchoRequestHandler\n",
    ") as server:\n",
    "    server.serve_forever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b90cea-4168-4932-a2bd-a62b1d00034e",
   "metadata": {},
   "source": [
    "elastic driver, notification service, notification manager, notification client, state, hostdiscovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f02ab32b-490f-465f-b7d1-5e67a6e15319",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6efb4f85-6931-4624-9069-10e64092a6cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RegularState:\n",
    "    def __init__(self, states):\n",
    "        self.states = states\n",
    "        self._saved_states = states\n",
    "    \n",
    "    def commit(self):\n",
    "        new_states = {}\n",
    "        for name in self._saved_states.key():\n",
    "            new_states[name] = getattr(self, name)\n",
    "        self._saved_states = new_states\n",
    "    \n",
    "    def restore(self):\n",
    "        for name, value in self._saved_states:\n",
    "            setattr(self, name, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bdebddc-80b7-49ad-b2cc-c0a6fbaebbc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class State(RegularState):\n",
    "    def __init__(self, model, optim, **kwargs):\n",
    "        kwargs.update({\"model\": model, \"optim\": optim})\n",
    "        handlers, regular_states = get_handlers(kwargs)\n",
    "        \n",
    "        for name, handler in handlers:\n",
    "            setattr(self, name, handler)\n",
    "        \n",
    "        self._handlers = handlers\n",
    "        super().__init__(self, states=regular_states)\n",
    "    \n",
    "    def commit(self):\n",
    "        for handler in self._handlers.values():\n",
    "            handler.commit()\n",
    "        super().commit(self)\n",
    "    \n",
    "    def restore(self):\n",
    "        for handler in self._handlers.values():\n",
    "            handler.restore()\n",
    "        super().restore(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80e67008-afd4-4d06-b2c7-e834c263b336",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelStateHandler:\n",
    "    def __init__(self, model):\n",
    "        self.set_value(model)\n",
    "        self._model_state_dict = copy.deepcopy(\n",
    "            model.state_dict()\n",
    "        )\n",
    "    \n",
    "    def set_value(self, value):\n",
    "        self.value = value\n",
    "    \n",
    "    def commit(self):\n",
    "        self._model_state_dict = copy.deepcopy(\n",
    "            self.value.state_dict()\n",
    "        )\n",
    "        \n",
    "    def restore(self):\n",
    "        self.value.load_state_dict(self._model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54fe6804-ba14-4c16-950e-fa50e4cb903f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_handler(v):\n",
    "    for handler_type, handler_cls in handler_registry:\n",
    "        if isinstance(v, handler_cls):\n",
    "            return handler_cls(v)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b50ca31e-98e5-4986-8101-b384ed7cb3ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_handlers(states):\n",
    "    handlers = {}\n",
    "    remainders = {}\n",
    "    \n",
    "    for k, v in states:\n",
    "        handler = get_handler(v)\n",
    "        if handler is None:\n",
    "            remainders[k] = v\n",
    "        else:\n",
    "            handlers[k] = handler\n",
    "        \n",
    "    return handlers, remainders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab4543ef-2bd9-4089-be2e-14fcb4c94294",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VocabParallelEmbedding(nn.Module):\n",
    "    def __init__(self, num_embedding, embedding_dim):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        num_embedding_per_partrition = num_embedding // world_size\n",
    "        self.weight = nn.Parameter(torch.randn(\n",
    "            num_embedding_per_partrition,\n",
    "            embedding_dim\n",
    "        ))\n",
    "        \n",
    "        self.vocab_start_idx, self.vocab_end_idx = self.get_vocab_range(\n",
    "            num_embedding_per_partrition\n",
    "        )\n",
    "    \n",
    "    def get_vocab_range(self, num_embedding_per_partrition):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        start_idx = rank*num_embedding_per_partrition\n",
    "        end_idx = start_idx + num_embedding_per_partrition\n",
    "        return start_idx, end_idx\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        mask = (tokens < self.vocab_start_idx) | (tokens > self.vocab_end_idx)\n",
    "        masked_tokens = tokens - self.vocab_start_idx\n",
    "        masked_tokens[mask] = 0.\n",
    "        \n",
    "        embeddings = F.embedding(tokens, weight=self.weight)\n",
    "        mask_idxs = torch.where(mask == True)[1]\n",
    "        embeddings[:, mask_idxs, :] = 0.\n",
    "        \n",
    "        torch.distributed.all_reduce(\n",
    "            embeddings\n",
    "        )\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21836ef9-5a15-4221-8984-964a3d6fc639",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast, reduce, scatter, gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e8338-097e-4291-a355-23aa7f5c08e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler, api server, control manager, ectd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65792b2-0231-4ce7-9a28-3eac5cb0d415",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_model(model, balances, devices):\n",
    "    layers = {}\n",
    "    partrition_idx = 0\n",
    "    partritions = []\n",
    "    \n",
    "    for name, layer in model.named_children():\n",
    "        layers[name] = layer\n",
    "        \n",
    "        if len(layers) == balances[partrition_idx]:\n",
    "            partrition = nn.Sequential(layers)\n",
    "            partrition.to(devices[partrition_idx])\n",
    "            partritions.append(partrition)\n",
    "            layers.clear()\n",
    "            partrition_idx += 1\n",
    "    \n",
    "    return partritions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d9dfeb7-b232-4693-af89-5d9f086ae754",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86ea5bbf-9ff6-4cb4-a120-6820d83cd92c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q = Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3af98d-5bdd-40d9-825c-23540bc648ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in xs:\n",
    "    q.put(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d66ac1-817c-4724-8846-5d34380fe5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready, succeed, failed, cooldown, blacklist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af0e444-ba5c-4f4e-8091-27d32f026008",
   "metadata": {},
   "source": [
    "### MechInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ca815a-9d12-4346-bab2-97335b424de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "other=query, no mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf9aee0-730b-4c06-85aa-4c68d695d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.W_O[layer_idx, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6722f5a8-c597-4c35-9483-ca61e3ad9c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E\n",
    "W_U = model.W_U\n",
    "\n",
    "\n",
    "W_Q = model.W_Q[1, 4]\n",
    "W_K = model.W_K[1, 4]\n",
    "\n",
    "W_O = model.W_O[0, 7]\n",
    "W_V = model.W_V[0, 7]\n",
    "\n",
    "Q = W_E @ W_Q\n",
    "\n",
    "K = W_E @ W_V @ W_O @ W_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c2f29e-1800-41bc-9be7-302676676e42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0de95bd-51d5-4933-acce-3c3d8bbdb9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(head_1 + head_2 + head_3) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42a63eb-458b-482a-b772-2f80a6e53922",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a85ad5-50c9-419f-8c51-2657387663a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04abc0a1-643b-47d5-91f0-d25663ec9fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs @ W_V @ W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a909ef-28b5-437c-882b-2f1b730235e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = the output of each heads\n",
    "attn_out = the output of an attention layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61593f3-e3bf-422c-a1a5-3ae967af69bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: 2 prompts\n",
    "step 2: record all the interdimate activations\n",
    "step 3: iteartive\n",
    "step 4: logit diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36961c8b-495d-4345-8db3-a2a16850de4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "induction_stripe = attn_weights.diagonal(-2, -1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc011c-6c0c-4880-a66e-ac489b1dd6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = model.to_tokens(clean_prompt)\n",
    "corrupted_tokens = model.to_tokens(corrupted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b22f1c-d81b-4a15-aa59-ec706b0f72ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_cache = model.run_with_cache(clean_tokens)\n",
    "_, corrupted_cache = model.run_with_cache(corrupted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cfa1a8-0cec-4555-8519-88a48aa4a336",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = clean_tokens.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2689123-df5a-4d95-beb4-fd7427e30a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "patched_residual_stream_diff = torch.zeros(n_layers, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ab6ada7-79b3-4817-bcb9-c9a336a38bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ffc7b4-97bc-4870-be5c-8670473d94c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_resid(activations, hook, position_idx, layer_idx):\n",
    "    activations[:, position_idx, :] = clean_activations[hook.name][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c736bc4-1bf5-4760-be80-e7baa82d07c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80bc28f4-3077-43a8-8778-4c9460370431",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_token = model.to_single_token(\"John\")\n",
    "incorrect_token = model.to_single_token(\"Mary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5aa24c0-3b1d-4c73-aa8a-9b9bb12833d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_logit_difference(logits, correct_token, incorrect_token):\n",
    "    last_token_logits = logits[:, -1, :]\n",
    "    return last_token_logits[correct_token, :] - last_token_logits[incorrect_token, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e43ff1-ccca-4fe3-b60c-a0ad3c0ec088",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for layer_idx in range(n_layers):\n",
    "    for position_idx in range(seq_len):\n",
    "        hook_func = partial(patch_resid, position_idx=position_idx, layer_idx)\n",
    "        hook_name = get_act_name(\"resid_pre\", layer_idx)\n",
    "        patched_logits = model.run_with_hooks(\n",
    "            corrupted_prompt,\n",
    "            hook_fwd=[(hook_name, hook_func)]\n",
    "        )\n",
    "        logit_diff = compute_logit_difference(patched_logits, correct_token, incorrect_token)\n",
    "        patched_residual_stream_diff[layer_idx][position_idx] = logit_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bb7f85-6c88-4113-a6c5-e86abc75b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: record all the interdimate activations\n",
    "step 2: logit differnece direction\n",
    "step 3: project residual stream to "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67bb453-e182-4786-97b2-7814fcddcec4",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55c63ce2-0b26-4f39-9c10-7028a7267091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee080f1-f3fc-46cd-869a-8f0f57d94db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.reparametrize(\n",
    "    \"input, output\",\n",
    "    [(1, 1), (2, 4)]\n",
    ")\n",
    "def test_square(input, output):\n",
    "    assert square(input) == output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cd1e20-ca58-443f-b44e-56a892b25bdb",
   "metadata": {},
   "source": [
    "### Mech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22896896-9947-4bbc-9472-ee1de36a4d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E @ QK @ W_OV @ W_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978f9e4c-45b0-4ce7-a02f-6660e9fda2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: record all the interdimate activations\n",
    "step 2: attention pattern\n",
    "step 3: induction head\n",
    "step 4: decompose attention scores\n",
    "step 5: identify which pair contribute the most to the attention score\n",
    "step 6: trace back the previous attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887d3dd-4499-4fd1-bf1a-27c82d4e8617",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: convert the command to string\n",
    "step 2: open a ssh session\n",
    "step 3: run the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4c5514-bc6f-448e-92d1-ad646e58edf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save\n",
    "restore\n",
    "reset\n",
    "commit\n",
    "sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb6a90c4-eb92-40fb-be54-70202169b75b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def probability_score(image_embedding, text_embedding):\n",
    "    image_embedding_norm = image_embedding.norm(dim=-1, keepdim=True)\n",
    "    image_embedding = image_embedding / image_embedding_norm\n",
    "    \n",
    "    text_embedding_norm = text_embedding.norm(dim=-1, keepdim=True)\n",
    "    text_embedding = text_embedding / text_embedding_norm\n",
    "    \n",
    "    similarities = image_embedding @ text_embedding.T\n",
    "    probs = F.softmax(similarities, dim=-1)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b545c66-f5e4-4ba8-905c-a12b1339cba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95523b90-f3a1-46e8-9320-4d67ddce4fd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, mom, eps):\n",
    "        super().__init__()\n",
    "        self.mom = mom\n",
    "        self.eps = eps\n",
    "        self.mults = nn.Parameter(torch.ones(1))\n",
    "        self.adds = nn.Parameter(torch.zeros(1))\n",
    "        self.register_buffer(\"means\", torch.zeros(1))\n",
    "        self.register_buffer(\"vars\", torch.ones(1))\n",
    "    \n",
    "    def update_stats(self, x):\n",
    "        mean = x.mean(dim=0, keepdim=True)\n",
    "        var = x.var(dim=0, keepdim=True)\n",
    "        \n",
    "        self.mean.lerp_(mean, self.mom)\n",
    "        self.var.lerp_(var, self.mom)\n",
    "        return mean, var\n",
    "    \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            mean, var = self.update_stats(x)\n",
    "        \n",
    "        x = (x - mean) / (self.eps + var)\n",
    "        x = self.adds + self.mults*x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da6ee0d-2ae7-43d2-9841-6d5d220e24ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
