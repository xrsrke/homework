{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3abb87b-f57c-4205-adb2-60a9280a238f",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f29c957-c962-4eaf-a64a-8f7a303ad49a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12e02d7-03aa-403e-8a4b-f9d91486aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750fc0bc-aac9-4b92-86e7-92a5be0c6c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {    \n",
    "    for (int i=1; i <= 5; i++) {\n",
    "        std::cout << i;\n",
    "    }\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9b080a-d75e-4ae5-957a-788f4b6110f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int i = 0;\n",
    "    \n",
    "    while (i <= 5) {\n",
    "        std::cout << i;\n",
    "        i++;\n",
    "    }\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ece40f-8132-4553-943b-47ff7dd7aa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "typedef int age_type;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae53b5d-b666-48df-8993-557ef3b2e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int a = 1;\n",
    "    int* p = &a;\n",
    "    \n",
    "    std::cout << p;\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c468f0a-4210-46a0-a714-b0c90131d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "using namespace std;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1594649d-7f3a-4342-a00f-0c6c0d8f2458",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Monster() {\n",
    "    public:\n",
    "       string Monster() {\n",
    "           std::cout << \"Creating a monster!\"\n",
    "       } \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2faac62-bc97-4917-942f-0ff1e5f3c15e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77caed73-aebe-463a-9afa-610b830726e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RowParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        self.input_size_per_partrition = input_size // world_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.randn(\n",
    "            self.output_size,\n",
    "            self.input_size_per_partrition\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.randn(\n",
    "            self.output_size\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        world_size = torch.distributed.get_world_size\n",
    "        rank = torch.distributed.get_rank()\n",
    "        \n",
    "        dim_size = input.shape[-1]\n",
    "        dim_size_per_partrition = dim_size // world_size\n",
    "        inputs = torch.split(input, dim_size_per_partrition, dim=-1)\n",
    "        \n",
    "        input_parallel = inputs[rank]\n",
    "        output_parallel = F.linear(input_parallel, self.weight, self.bias)\n",
    "        \n",
    "        torch.distributed.all_reduce(output_parallel)\n",
    "        \n",
    "        return output_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d6db56-eaa9-46a1-bed6-ba9a828b564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "__global__ void vectorAdd(int* a, int* b, int*c, int total_elements) {\n",
    "    int tid = (blockIdx.x * blockDim.x) + threadIdx.x\n",
    "    \n",
    "    if (tid < total_elements) {\n",
    "        c[tid] = a[tid] + b[tid]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8466efe-2a67-4d41-913f-fb89f47d5ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = torch.distributed.get_rank()\n",
    "\n",
    "if rank == 69:\n",
    "    torch.distributed.isend(x, dest=42)\n",
    "elif rank == 42:\n",
    "    torch.distributed.irecv(tensor_will_be_received_data, src=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65323ec3-bb32-4c1a-94e1-ea6c46a0be70",
   "metadata": {},
   "outputs": [],
   "source": [
    "message passing, collective communication, p2p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3738319-20b6-4d4f-8565-121169f4624e",
   "metadata": {},
   "source": [
    "step 1: bind\n",
    "step 2: conenct\n",
    "step 3: accept\n",
    "step 4: communicate\n",
    "send 5: close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0301d20-ee2d-4249-8e2e-d109de320696",
   "metadata": {},
   "source": [
    "### MechInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f134a4-4f56-4717-8448-2b07b2b962fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a28dd1-8a80-4b03-acdf-3e6248a2a47f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5feae85-70a0-4bb0-bd0d-42e13fe62723",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6510f3b-019d-40d9-b0ab-571adc2067ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U_correct = W_U[:, correct_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14744ea2-b1b8-4374-ae9a-3895e0650911",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U_incorrect = W_U[:, incorrect_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace2407-8d8a-40ac-aed1-f123d1fdb835",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_difference_direction = W_U_correct - W_U_incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d499da5-0e30-4e45-b06d-b0bac411457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_QK, W_OV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e738ae6-101c-4c2d-9a0e-99237c79963f",
   "metadata": {},
   "outputs": [],
   "source": [
    ", cache = model.run_with_cache(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496d2487-5f01-44f5-a66c-ba84f89c5a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_residual_stream = cache[final_residual_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caedf0c7-0135-4efd-8c8d-32ad7f8d77cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_final_residual_stream = final_residual_stream[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5462392f-0432-4580-ac1d-b8b74f980b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_last_token_final_residual_stream = model.apply_ln_to_stack(\n",
    "    last_token_final_residual_stream,\n",
    "    layer=11,\n",
    "    pos_slice=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ad2a8-3913-48e6-98b7-acca33eebbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4b2fef-4ca4-4102-ab7b-402aee270197",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U_correct = W_U[:, correct_token]\n",
    "W_U_incorrect = W_U[:, incorrect_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffd7306-5d45-413f-88f5-2a90e866001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_diff_direction = W_U_correct - W_U_incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85003c81-6187-47f5-bfce-b541daa0cab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbcdf4a-5f99-47dd-a454-7abd46790dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = einsum(\n",
    "    scaled_last_token_final_residual_stream,\n",
    "    logit_diff_direction,\n",
    "    \"b d_model b d_model -> \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38faff-06d4-4a57-a40b-f5e47d90496f",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_O = model.W_O[layer_idx, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b772856-0140-499f-a535-176463d48d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343d853d-4585-410f-b955-6e61b9ade179",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fa4843-ba87-462d-b092-408574178fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_OV_circuit = W_E @ OV_circuit @ W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70583152-7076-46b6-b300-c218f98fb3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = unembed @ final_residual_stream\n",
    "\n",
    "logits = unembed @ (embed + layer_1 + layer_2)\n",
    "logits = unembed @ embed + unembed @ layer_1 + unembed @ layer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef54d8ee-b434-48e6-b209-da1897029b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3059d761-7898-4d4d-91eb-102158c787c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_residual_streams = cache.accumulate_residual_stream(layer=-1, pos_slice=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758c2896-d542-428b-8e76-6465c81a74b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_acc_residual_streams = model.apply_ln_to_stack(\n",
    "    acc_residual_stream,\n",
    "    layer=-1,\n",
    "    pos_slice=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40944fa4-8f12-44de-8a03-4f93f98bd888",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_directions = model.tokens_to_residual_directions(answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bf100c-eafb-4be4-8daf-4896f9a8ad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_residual_direction, incorrect_residual_direction = residual_directions.unbind(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7a4e80-e009-4ac1-a769-ffbcb403c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_difference_direction = correct_residual_direction - incorrect_residual_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfab624c-ef8c-4bd5-bd5c-b33b44f90233",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_attributions = einsum(\n",
    "    scaled_acc_residual_streamsm,,tributio\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d66330-5133-4df2-8db3-aaa058f837ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: the vector of the third position in the residual stream\n",
    "step 2: extract the vector of the forth token in the unembedd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb487453-381c-400f-9706-822f43f46f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app\n",
    "def get_tasks(\"/tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6cd015f-9644-4463-9750-4427aab36e8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38965560-b132-40da-bad5-eb07309c1059",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpc.remote(to=\"worker_1\", func=create_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fbf82bb-c859-4910-80a8-f6e9fdb07d38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_rank = \"agent_{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89ddd06c-52c1-457c-be02-d41af6cd2716",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32e3a8aa-65a4-4925-971a-a6be2ebb4a66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c036baae-1465-4e86-ae4b-bd8735b4aa07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_worker(rank, world_size):\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"29500\"\n",
    "    \n",
    "    rpc.init_rpc(\n",
    "        name=agent_rank.format(rank),\n",
    "        rank=rank,\n",
    "        world_size=world_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00d9081-7f49-402f-848f-92779b3e6a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(world_size):\n",
    "    process = Process(\n",
    "        target=run_worker,\n",
    "        args=(rank, world_size)\n",
    "    )\n",
    "    process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c25306-51fd-4440-a8ed-9c017b4ca9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(probs, targs):\n",
    "    pred_idxs = torch.argmax(probs, dim=-1)\n",
    "    return (pred_idxs == targs).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a238f7d5-6234-4dad-bcf3-e7ea3de3372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_batch(article_batches, max_context_length):\n",
    "    outputs = []\n",
    "    \n",
    "    for article_batch in article_batches:\n",
    "        inputs = tokenizer(\n",
    "            article_batch,\n",
    "            return_tensors=\"pt\",\n",
    "            **tokenizer_params\n",
    "        )\n",
    "        \n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            **model_params\n",
    "        )\n",
    "        \n",
    "        decoded_summaries = [tokenizer.decode(x) for x in generated_ids]\n",
    "        outputs.append(decoded_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58323425-9c4b-460d-aa20-a8e442c1adf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    action = env.action_space.sample()\n",
    "    env.step(action)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
