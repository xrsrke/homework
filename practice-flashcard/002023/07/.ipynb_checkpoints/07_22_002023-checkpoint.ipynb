{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c21cc246-e567-460a-a997-6fc5d0320824",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "532ba763-8faa-4de7-b0c8-e5f40a6e337d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a0afd-6977-4cc5-b394-708964c64e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: record the elasped time\n",
    "step 2: determine the number of layers per partrition\n",
    "step 3: split\n",
    "step 4: move to target device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212f1052-eb61-4b6c-9ae1-976f623c9ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kube-proxy, kubelet, container runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecb1c3c-2766-4fca-adb6-1fbaedd518e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: scale the loss using a scaling factor\n",
    "step 2: calculate the gradient with respect to the scaled loss\n",
    "step 3: unscale the scaled loss using the scaling factor\n",
    "step 4: update params with respect to the unscaled loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b824e5-8389-4daa-bf73-1b1807745a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: get data\n",
    "step 2: construct a task\n",
    "step 3: put the task into a in_queue\n",
    "step 4: wait and get the output\n",
    "step 5: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6addb3-b28b-4875-aaf5-dfe69b4c23db",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: partrition\n",
    "step 2: split a mini-batch\n",
    "step 3: pipeline.run\n",
    "step 4: gather the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd515a-fe60-4c79-8471-bf7f7c31a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: gather the weights\n",
    "step 2: do the backward pass\n",
    "step 3: discard\n",
    "step 4: reduce-scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be276579-ed89-4843-b3c3-30eb2dbc6696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import socketserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "387c3aab-5325-47b4-a20c-d299f47ecb18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_port(server_factory):\n",
    "    min_port = 1024\n",
    "    max_port = 65536\n",
    "    \n",
    "    for port in range(min_port, max_port):\n",
    "        try:\n",
    "            addr = (\"\", port)\n",
    "            server = server_factory(addr)\n",
    "        except Exception:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab8c595-2e23-4cca-97a1-1f97ef762cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment, configmap, service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de530410-5c9c-4065-9f9e-5c30a875b218",
   "metadata": {},
   "outputs": [],
   "source": [
    "kubelet, kube-proxy, container runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ad19f0b-23f5-4b60-8015-ace8401bfdb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87fb0ea9-8453-45b8-9a49-0373714a19f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "307018b1-319d-49e1-a317-2deb8b527021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "025cc5f2-2bda-4a63-95bb-a488dba4564d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_worker(device, in_queue, out_queue):\n",
    "    while True:\n",
    "        task = in_queue.get()\n",
    "        \n",
    "        try:\n",
    "            output = task.compute()\n",
    "        except:\n",
    "            out_queue.put((None, False))\n",
    "            continue\n",
    "        \n",
    "        output_queue.put((output, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66536e4a-dc2b-4434-ab83-ad685315f585",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def spawn_workers(devices):\n",
    "    in_queues = []\n",
    "    out_queues = []\n",
    "    \n",
    "    for device in devices:\n",
    "        in_queue = Queue()\n",
    "        out_queue = Queue()\n",
    "        \n",
    "        t = threading.Thread(\n",
    "            target=run_worker,\n",
    "            args=(device, in_queue, out_queue),\n",
    "            daemon=True,\n",
    "        )\n",
    "        t.run()\n",
    "        \n",
    "        in_queues.append(in_queue)\n",
    "        out_queues.append(out_queue)\n",
    "    \n",
    "    yield (in_queues, out_queues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52846cc8-b24a-4cfb-bdd5-9c7db1698260",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory usage, optimizer's state, model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7d004a0-2bb7-40d8-b2e1-62e7cdb1c2d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "world_size = 16\n",
    "tensor_model_parallel_size = 2\n",
    "pipeline_model_parallel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d626ad40-1f0c-4668-a834-87d07781b265",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_pipeline_model_parallel_groups = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b78f9174-cf8d-40e3-b7fc-89a31797eea9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2]\n",
      "[1, 3]\n",
      "[4, 6]\n",
      "[5, 7]\n",
      "[8, 10]\n",
      "[9, 11]\n",
      "[12, 14]\n",
      "[13, 15]\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_pipeline_model_parallel_groups):\n",
    "    start_rank = i*pipeline_model_parallel_size\n",
    "    end_rank = (i+1)*pipeline_model_parallel_size\n",
    "    \n",
    "    for j in range(tensor_model_parallel_size):\n",
    "        ranks = list(range(\n",
    "            start_rank+j,\n",
    "            end_rank,\n",
    "            tensor_model_parallel_size\n",
    "        ))\n",
    "        \n",
    "        print(ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae79ea62-bec8-4acb-96c7-b75f47d2e11b",
   "metadata": {},
   "source": [
    "### MechInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbfd468-9817-478c-8a40-56b70e758c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax(x@W_Q@x.T@W_K)@x@W_V@W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d8018b-bef6-4692-a911-21b3ac4b7cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding, positional embedding, 12 heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b8bf41-1a1e-42e4-8327-ff2f57815919",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = (3, 3) => ReLU(A) = (3, 3)\n",
    "B = (-2, 2) => ReLU(B) = (0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f82cd-84b8-4094-a3f0-5780399cda15",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b024c6ee-750d-4b72-900f-a62f2c2ce7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = cache[\"resid_post\", 2]\n",
    "output = cache[\"normalized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dd8320-c646-4647-a561-127f1157f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=padding\n",
    "key=non-padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fb2c95-2765-41ea-a464-605db6ffdddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8c72ea-4d97-44d5-b762-f81ca4cf32fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e1ec9-fc60-4518-8621-47bdd6dd592c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d4d25c-1e15-459a-bfa7-0049966eed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U[:, target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cea99b9-b7fc-4740-9230-f188c377e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: calculate logit difference direction: W_U[0] - W_U[1]\n",
    "step 2: approximate layer norm\n",
    "step 3: do inverse transformation: pre_ln\n",
    "step 4: project pre_ln @ logit_diff_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683ea9fe-76a3-4b1e-b816-cff76d6f86db",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: decompose the input\n",
    "step 2: decompose query vector, and key vector\n",
    "step 3: matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca7a655-5098-4d74-808f-bb629ed4b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "blank - (theirs + mine)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d01dbb-0651-484e-bccb-575d98b68733",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight @ input = output\n",
    "input = weight.T @ output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118915ec-1fe0-489e-a512-72bc38566a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: partritioning\n",
    "step 2: forward pass: gather, do the computation, discard\n",
    "step 3: backward pass\n",
    "step 4: reduce-scater\n",
    "step 5: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c699a13f-4cb2-48ef-bee3-3a92bc83bc6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a16ad0b-2d24-49b2-996f-d019dfdebe36",
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = dist.broadcast(x, src=0, async_op=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a028df6-b082-4ef5-905c-9b430407629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "handler.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78e00fd9-f72f-4685-a13f-52a7707a59e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def foo(collections): pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9d3d95-ddec-475d-b5a2-5c551e01d266",
   "metadata": {},
   "source": [
    "Add type hints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1db84c0-d6a2-418c-bcf3-e7b2368907ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ef73950-7c56-44a1-a824-9e6d6ac9b157",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def foo(collections: Sequence[str]) -> None: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "760b55d2-5e5c-4989-80fe-4f894f06a3b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "foo((\"a\", \"b\", \"c\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab10950d-e0bc-4252-8125-5b56c2f1fdfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "foo([\"a\", \"b\", \"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d34d1a36-eb35-4332-9275-7b2ca2e347ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b4da8f-1d54-4548-8f27-56a7ec5152bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x: List[Union[str, int, float]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0023781-ce8f-489d-9148-81b09e14698e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c3d6f-60a9-45a4-a8fd-79c0b51bae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.skipif(a>b)\n",
    "def test_func3():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd18fae9-76eb-497c-8ede-3a7eb2ffb3e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8f5b019-be41-4283-8f30-ef1caeabd3eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def foo(collections: Sequence[str]) -> None:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86ea845-945b-47dc-ad5d-36169bb9cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "blank - [(their+mine)/2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f639e4eb-3af4-44e5-9ce3-0a4f8d9a97f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e147c150-54c0-4ffb-b3a9-f863158442c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Observer:\n",
    "    def __init__(self, env):\n",
    "        self.id = rpc.get_worker_info().id\n",
    "        self.env = env\n",
    "    \n",
    "    def run_episode(self, agent_rref):\n",
    "        observer_id = self.id\n",
    "        env = self.env\n",
    "        \n",
    "        state, _ = env.reset()\n",
    "        for _ in range(69):\n",
    "            action = rpc.rpc_sync(\n",
    "                to=agent_rref.owner(),\n",
    "                func=agent_rref.rpc_sync().select_action,\n",
    "                args=(observer_id, state)\n",
    "            )\n",
    "            \n",
    "            state, reard, done, _ = env.step(action)\n",
    "            if done: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64715562-78b8-48fb-adb5-9a3278eb71b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        for param in self.params:\n",
    "            if param.requires_grad:\n",
    "                p -= p.grad * self.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0a6155-f635-45b0-a9e9-8e0b452a2a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "61d876b9-343b-4952-a7c9-7ed982d03cae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for param in self.params:\n",
    "                p -= p.grad * self.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f70bdf3-8e1a-4c21-9ccd-85baefb137ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: tokenize the prompt\n",
    "step 2: tokenize the observation and append it to the tokenized prompt\n",
    "step 3: predict\n",
    "step 4: execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0284418b-ff46-457f-9b40-e13939c7c2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2c1f2b-6384-461c-8a25-5c4a03a32ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f897d533-3c92-418b-99be-98d256f935a1",
   "metadata": {},
   "source": [
    "The excerpt describes the analogy between the MLP (Multilayer Perceptron) and the concept of key-value pairs, which is often associated with attention layers in transformer models.\n",
    "\n",
    "Here's a detailed breakdown:\n",
    "\n",
    "Multilayer Perceptron (MLP): An MLP is a type of artificial neural network that consists of at least three layers of nodes: an input layer, one or more hidden layers, and an output layer. Each node in one layer is connected with all nodes in the next layer. Weights are associated with these connections, and the MLP learns the optimal values for these weights during training.\n",
    "\n",
    "The MLP as a function: An MLP can be represented as a function. In this case, we have $f(x^T W^{in})W^{out}$, where:\n",
    "\n",
    "$x$ is an input vector.\n",
    "$W^{in}$ and $W^{out}$ are the weights of the MLP, where $W^{in}$ are weights between the input and the hidden layer, and $W^{out}$ are the weights between the hidden layer and the output.\n",
    "$f$ is the activation function applied to the weighted input before it's sent to the next layer.\n",
    "The MLP as a sum of functions: This function can be broken down into a sum of functions for each node (neuron) in the hidden layer. This is what the formula $\\sum_{i=1}^{d_{mlp}} f(x^T W_{[:, i]}^{in}) W_{[i,:]}^{out}$ represents. Here:\n",
    "\n",
    "$d_{mlp}$ is the dimension of the hidden layer.\n",
    "$W_{[:, i]}^{in}$ represents the weight vector of the $i$-th node in the hidden layer for the input layer, and $W_{[i,:]}^{out}$ represents the weight vector of the $i$-th node for the output layer.\n",
    "The sum indicates that for each node, we multiply the input by the respective weight, apply the activation function, and then multiply by the output weight. We do this for each node and then sum the results.\n",
    "MLP as key-value pairs: The idea here is to interpret $W_{[:, i]}^{in}$ as the \"key\" and $W_{[i,:]}^{out}$ as the \"value\". The key, which is the input weight for a node, \"activates\" certain features in the input. When this feature is activated (i.e., when $f(x^T W_{[:, i]}^{in})$ is high), the output is influenced by the corresponding \"value\", $W_{[i,:]}^{out}$.\n",
    "\n",
    "Including biases: The last equation includes bias terms in the MLP. The bias is an additional parameter in the neuron that is used to adjust the output along with the weighted sum of the inputs to the neuron. Thus, $b_i^{in}$ is the bias for the $i$-th input-hidden connection, and $b^{out}$ is the bias for the hidden-output connection.\n",
    "\n",
    "Let's consider a simple example:\n",
    "\n",
    "Imagine we have an MLP with a single hidden layer with two nodes (neurons), and we use a ReLU (Rectified Linear Unit) activation function. Suppose our input $x = [1, 2]$.\n",
    "\n",
    "Let's say the weights and biases are as follows:\n",
    "\n",
    "$W^{in} = [[0.1, 0.2], [0.3, 0.4]]$ (each column corresponds to a neuron)\n",
    "$W^{out} = [0.5, 0.6]$\n",
    "$b^{in} = [0.01, 0.02]$\n",
    "$b^{out} = 0.03$\n",
    "Calculating the output of our MLP using the formula above would look like this:\n",
    "\n",
    "$MLP(x) = \\sum_{i=1}^{2} f(x^T W_{[:, i]}^{in}+b_i^{in}) W_{[i,:]}^{out}+b^{out}$\n",
    "= $f([1,2] \\cdot [0.1, 0.3]^T + 0.01) * 0.5 + f([1,2] \\cdot [0.2, 0.4]^T + 0.02) * 0.6 + 0.03$\n",
    "\n",
    "First, calculate the dot product between the input and weights, add the bias, apply the ReLU function (which sets negative values to zero), and multiply by the output weights. Sum these for each neuron in the hidden layer and finally add the output bias.\n",
    "\n",
    "This concrete example should give you a clear idea of how MLPs can be interpreted as key-value memory and how they can be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eba591e-9d7a-4532-96c5-df54bb61dba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transdd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
