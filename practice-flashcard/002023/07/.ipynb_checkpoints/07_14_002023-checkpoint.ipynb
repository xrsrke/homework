{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fb78d48-2a01-49ef-8fc7-6fff49c1a754",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e56fad81-d22a-4395-9993-f9b240203f76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddf9294-4945-4b87-b1c2-cbbaa3c96970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57034d80-b819-483b-a0a6-d7ad9666c018",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int numbers[] = {1, 2, 4, 4};\n",
    "    std::cout <<numbers[0];\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de6ce52-6dd6-4725-8376-bbe822e4dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int tensors[3][2] = {\n",
    "        {1, 2},\n",
    "        {3, 4},\n",
    "        {5, 6}\n",
    "    };\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0766e4ea-2a20-4a92-bbf5-609f06161fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler, api server, control manager, ectd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60490105-1f6f-40aa-9a9e-6d436e069942",
   "metadata": {},
   "outputs": [],
   "source": [
    "node > pod > container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a531eac-2a8d-469d-bd11-1a39871fe503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clock cycle 1: forward(0, 0)\n",
    "# clock cycle 2: forward(0, 1), forward(1, 0)\n",
    "# clock cycle 3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51cd95f-5fca-4bf0-b43b-ba7a3b002563",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready, suceed, failed, cooldown, and blacklisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b2f1ff5-3dc6-4285-9908-bb9f55ce65f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HostUpdatedInterrupt(RuntimeError):\n",
    "    def __init__(self, skip_sync):\n",
    "        self.skip_sync = skip_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fc35f8-c346-4a5d-af44-a84d8aeb6ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic driver, 3 notifications, torchstate, hostdiscovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efb3a423-845d-4d95-8e31-9dc7659f3fa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VocabParallelEmbedding(nn.Module):\n",
    "    def __init__(self, num_embedding, embedding_dim):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        self.num_embedding_per_partrition = num_embedding // world_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.randn(\n",
    "            self.num_embedding_per_partrition,\n",
    "            self.embedding_dim\n",
    "        ))\n",
    "        \n",
    "        self.vocab_start_idx, self.vocab_end_idx = self.get_vocab_range(\n",
    "            self.num_embedding_per_partrition\n",
    "        )\n",
    "    \n",
    "    def get_vocab_range(self, num_embedding_per_partrition):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        start_idx = rank*num_embedding_per_partrition\n",
    "        end_idx = start_idx+num_embedding_per_partrition\n",
    "        return start_idx, end_idx\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        masks = (tokens < self.vocab_start_idx) | (tokens > self.vocab_end_idx)\n",
    "        masked_tokens = tokens - self.vocab_start_idx\n",
    "        masked_tokens[masks] = 0.\n",
    "        \n",
    "        embeddings = F.embedding(masked_tokens, self.weight)\n",
    "        mask_idxs = torch.where(masks == True)[1]\n",
    "        embeddings[mask_idxs] = 0.\n",
    "        \n",
    "        torch.distributed.all_reduce(embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcd203c4-aa47-4197-b087-9b1ecc78b5d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StartBatch(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        phony = torch.randn(0, requires_grad=False)\n",
    "        return input, phony\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input, grad_phony):\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71b58e0c-1a1e-4de4-bcb1-3bb852817cf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EndBatch(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, phony):\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, input):\n",
    "        return input, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a2d04a-ecf3-4ed7-85cb-62d3c3d585b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dependency(start_batch, end_batch):\n",
    "    start_batch, phony = StartBatch.apply(start_batch)\n",
    "    end_batch = EndBatch.apply(end_batch, phony)\n",
    "    return start_batch, end_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f0273b-231d-40a6-809a-379fb4d35890",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recompute(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, phony, recomputed, function, input):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c9a432-5f47-4d25-b856-72251d3f4cf1",
   "metadata": {},
   "source": [
    "### MechInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9524107-4f50-4a6a-984e-f1808dd34c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embed(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fca0b64-a6df-4f9c-bde9-aaf133045248",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embed + embed + sum(12 heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d148ca3-0cc1-43d2-8c9f-9643140100e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3729a654-8b28-4641-a9a1-435e0f461488",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob1 = simoid(logit1 - logit2)\n",
    "\n",
    "logit1 = fn_ln  W_U[1]\n",
    "\n",
    "the higher the dot product, the higher the prob = similar direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ac0c4b-ca3e-4757-bcf0-ae097b970c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: approximate non-linear part if possible\n",
    "step 2: decompose the logits\n",
    "step 3: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad39a34-ace9-4189-a5c5-9e9d68a0d819",
   "metadata": {},
   "source": [
    "output_layer_2 = pos_embed + embed + attn00 + attn01 + mlp0 + attn01 + attn11 + mlp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644181d9-70ee-4803-bc46-76fbcfa56cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock cycle 1: forward(0, 0)\n",
    "clock cycle 2: forward(0, 1), forward(1, 0)\n",
    "clock cycle 3: forward(1, 1), forward(2, 0)\n",
    "clock cycl4 : backward(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f29c5e1c-af0b-46b9-a294-95211dbc0e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Recompute(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, phony, recomputed, function, input):\n",
    "        ctx.recomputed = recomputed\n",
    "        ctx.function = function\n",
    "        ctx.input = input\n",
    "        return phony\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, phony):\n",
    "        input = ctx.input\n",
    "        input_leaf = input.detach().requires_grad_(\n",
    "            input.requires_grad\n",
    "        )\n",
    "        function = ctx.function\n",
    "        \n",
    "        with torch.enable_grad():\n",
    "            output = function(input_leaf)\n",
    "        ctx.recompute.append((output, input_leaf))\n",
    "        \n",
    "        grads = [None, None, None]\n",
    "        \n",
    "        if input_leaf.requires_grad:\n",
    "            grads.extend([input_leaf.grad])\n",
    "        else:\n",
    "            grads.extend([None])\n",
    "        \n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52436c8e-8250-4b3e-be35-5644b5573cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPU:\n",
    "    def __init__(self, master_addr, master_port, backend):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c2aabc-0a93-4e6b-936e-5322d7208054",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E\n",
    "W_Q = model.W_Q[1, 4]\n",
    "W_K = model.W_K[1, 4]\n",
    "W_O = model.W_O[0, 7]\n",
    "W_V = model.W_V[0, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56667436-0d01-4440-8020-57dce23fde2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = W_E @ W_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f737c187-5c1c-429a-8a76-92bedfe792b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = W_E @ W_V @ W_O @ W_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c93c1-12c9-46aa-b230-ede9c1dc3486",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[\"pattern\", 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4623c7bb-12b9-4b89-b3f3-179a18dc6014",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit1 - logit2\n",
    "fn_ln @ W_U[1] - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564157c5-afa5-4712-acc4-220592c6b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: two "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4a32800-0c07-400e-be24-3a6f02a4a384",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum, reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb6cf4e-db25-4a9f-a2c7-fd51d642a8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "induction_score = reduce(\n",
    "    induction_stripe,\n",
    "    \"head_index positio\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efa844a-033e-4700-875d-775d7a3b9998",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: convert command to string\n",
    "step 2: open a ssh session\n",
    "step 3: execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ff5bb29-b968-46cf-9c1c-290fe43ebd77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4ecd95-8af6-4c84-8d4b-be1be5ce8717",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPU:\n",
    "    def __init__(self, master_addr, master_port, backend):\n",
    "        if not torch.distributed.is_initialized():\n",
    "            rank = os.getenv(\"RANK\")\n",
    "            world_size = os.getenv(\"WORLD_SIZE\")\n",
    "            os.environ[\"MASTER_ADDR\"] = master_addr\n",
    "            os.environ[\"MASTER_PORT\"] = master_port\n",
    "            \n",
    "            group = torch.distributed.init_process_group(\n",
    "                rank=rank,\n",
    "                world_size=world_size,\n",
    "                backend=backend\n",
    "            )\n",
    "            \n",
    "            self.set_device()\n",
    "            self.group = group\n",
    "    \n",
    "    def set_device(self):\n",
    "        rank = os.getenv(\"RANK\")\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        torch.cuda.set_device(rank % num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de44453-d2df-478d-88aa-b8e57b8fc1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: load the training data in memory\n",
    "step 2: idxs\n",
    "step 3: size(idxs)\n",
    "step 4: load size(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f33292-5937-4bb7-9cbb-fa71a40b9817",
   "metadata": {},
   "outputs": [],
   "source": [
    "partritions2(microbatch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a24aab-1c02-4b90-9daf-c20228080f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save\n",
    "sync\n",
    "restore\n",
    "reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d637fa8b-90b2-412d-8cb0-bad91dfde8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock cycle 1: forward(0, 0)\n",
    "clock cycle 2: forward(0, 1), forward(1, 0)\n",
    "clock cycle 3: forward(2, 0), forward(1, 1)\n",
    "clock cycle 4: forward(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d270e18b-33a9-4266-a774-d7cc2d61cad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: wait for the completion of the data copy operation\n",
    "step 2: constructs a computation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624f1502-98e8-48c2-8ca2-d19ee3e673a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: x = embed + pos_embed + sum(12 heads)\n",
    "step 2: query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86f46f9-ed25-4aa6-af67-8a853a6d9241",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: embed + pos_embed + layer_1 + layer_2\n",
    "step 2: = embed + pos_embed + attn00 + attn01 + mlp0 + attn10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b820db45-7b5b-403e-be06-5579d5f1c0cc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aae727-f10d-4b67-b247-947d2cf5f424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5831bc4f-8693-42c6-9e6a-bd62a3dc471b",
   "metadata": {},
   "source": [
    "In the transformer model, the attention mechanism is a key component. It determines how much importance or 'attention' each token should pay to others in the sequence. The attention scores, represented by the softmax function in the first equation, are calculated based on the query, key, and value vectors derived from the input embeddings.\n",
    "\n",
    "The equation:\n",
    "\n",
    "$$\n",
    "\\operatorname{Attn}(v)2=\\sum_h \\operatorname{softmax}\\left(\\frac{v_2^{\\top} W_Q^h\\left(W_K^h\\right)^T\\left[v_0 v_1\\right]}{\\sqrt{d{\\text {head }}}}\\right)\\left[v_0 v_1\\right]^T W_V^h W_O^h\n",
    "$$\n",
    "\n",
    "is the formal definition of the attention mechanism. Here:\n",
    "\n",
    "$v_2$ is the query vector from position 2 (the equals sign).\n",
    "$W_Q^h$ and $W_K^h$ are the query and key weight matrices for head $h$.\n",
    "$[v_0 v_1]$ is a matrix that concatenates the value vectors from positions 0 and 1 (the inputs to the addition operation).\n",
    "$W_V^h$ and $W_O^h$ are the value and output weight matrices for head $h$.\n",
    "The softmax function is applied over the scaled dot product of the query and key vectors. This generates the attention scores, which signify how much each value vector should contribute to the final output.\n",
    "The equation:\n",
    "\n",
    "$$\n",
    "\\sum_h\\left(\\alpha^h v_0+\\left(1-\\alpha^h\\right) v_1\\right)^T W_V^h W_O^h\n",
    "$$\n",
    "\n",
    "is a simplified form of the first equation, which makes the assumption that we're only interested in the attention paid by position 2 to positions 0 and 1. Here, $\\alpha^h$ represents the attention score from position 2 to position 0 in head $h$. The term $(1-\\alpha^h)$ then naturally represents the attention score from position 2 to position 1 in the same head, under the assumption that the attention scores sum up to 1.\n",
    "\n",
    "In this simplified equation, we've essentially replaced the softmax transformation with the attention scores $\\alpha^h$ and $(1-\\alpha^h)$, which are sufficient to describe the attention patterns under the given assumption. The sum of these two terms, weighted by the input vectors and passed through the value and output weight matrices, gives the final output of the attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a2f3a1a-848c-4447-8340-5568a2d141aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c99a4e-2404-464a-a3be-89a2bb51d60e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a2519f3-3b9d-48fb-951d-4ea75fc2a10c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0), tensor(1), tensor(2)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in torch.arange(0, 3).unbind()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d3daa9-0ecf-48f5-8474-8c5b0002c1f2",
   "metadata": {},
   "source": [
    "### Die trying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d5d562e-f850-4f02-890c-96ff94803385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d67da5-56ed-4811-8b70-f53516b60cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "other=query, key=persistence, no mask\n",
    "\n",
    "\n",
    "query=persistence, key=others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bda632-c2ed-4e26-85b4-1226125642ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E\n",
    "W_U = model.W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61657d4-5419-4a89-8b78-0f27d0871e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E @ OV_circuit @ W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8395d097-c77e-49d5-a08a-395967938205",
   "metadata": {},
   "outputs": [],
   "source": [
    "query, key, value, attn pattern, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0101df-3e53-456f-b0aa-6dc0354f2a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.W_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1dfa300-9802-45b8-afa0-a93682bd2a27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f41ab1-782e-4ff6-a2ff-d917b44cd3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "induction_score = reduce(induction_score, \"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
