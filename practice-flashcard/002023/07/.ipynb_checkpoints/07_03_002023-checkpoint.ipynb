{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17cd25b7-b9a8-4158-91ac-73a97a6f3420",
   "metadata": {},
   "source": [
    "### MechInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e8ac98-e6bc-45ea-a83a-f736d949c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: extract the output of the second head\n",
    "step 2: extract the unembedding of the target token\n",
    "step 3: einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9a3ed2-c343-4f9c-ba4d-dbf6a5d02845",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce3309a-4845-4899-bd4e-77bc4a66eec9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, neuron_idx = 3, 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f03fd-787e-4bb7-9d6c-af32d14ae017",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_name = f\"blocks.{layer_idx}.mlp.hook_post\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac504775-642e-4b30-b51a-574b77a73c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffae3be-1c16-43d7-a826-b71c380516b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = cache[hook_name][0, :, neuron_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59675036-b301-40e6-96b9-29b32dffdf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.argmax(activations, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65358f86-9cc8-409e-b300-ecea1620cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f9235-946f-4d2f-9b9c-41b2bf0c3f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e1e7ed-c383-4ed9-afd8-7ee7502251f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_OV_circuit = W_E @ OV_circuit @ W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f160cf-96f6-496e-8b13-1c0a7f6a5fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_O = model.W_O[layer_idx, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c685d77b-8248-49c4-a18d-b26925cad79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = unembed @ final_residual_stream\n",
    "\n",
    "logits = unembed @ (embed + layer_1 + layer_2)\n",
    "\n",
    "logits = unembed @ embed + unembed @ layer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a59b1b-6eee-4fbf-8f57-801e30b53c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, k, v, attention pattern, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5167d36-0c05-45e1-927a-0182a614bf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "A^T@W_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bdd274-b26b-46b1-90d3-77c810e6c6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "A^T @ W_E + A^T @ W_E @ W_O @ W_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35ef3c5-6024-4204-abfd-21fe2722e0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: final_residual_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a76e7-9549-4de8-8eae-5b6774faf0c3",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2c51163-450d-4a76-83b7-dbe06972ab67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2fcae72-3b36-43cd-b52d-876f22a3f182",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "321dd000-79b2-4378-a45f-47caa94bd540",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = threading.local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cae926-e615-4577-8f6b-bcf66ca0ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = threading.Thread(\n",
    "    target=print_and_modify,\n",
    "    args=(data,)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbabc7f4-8c80-4d46-aa0d-62e2893a414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: 3, 4\n",
    "step 2: recompute the activations of layer 2, do backward\n",
    "ste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c65bef1-9553-4231-a1f5-0477d4c259fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bd3ed3-66dd-4cb1-8ba8-b13a62fe6330",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int a = 59;\n",
    "    int* b = &a;\n",
    "    \n",
    "    std::cout << *p;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358352de-2a19-4c9c-a1df-6a13b511105d",
   "metadata": {},
   "outputs": [],
   "source": [
    "void getMax(int x1, int x2) {\n",
    "    if (x1 > x2) {\n",
    "        return x1;\n",
    "    } else {\n",
    "        return x2; \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b06645-9b62-4c10-b27a-8d6c4727ff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "void plus_one(int x) {\n",
    "    return x + 1;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "486a9afe-d4f9-4ac8-84b4-5e80cc5ae5f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import socketserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30cb20cb-5f8d-460b-92f0-f06d2bed28ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EchoRequestHandler(socketserver.StreamRequestHandler):\n",
    "    def handle(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df78f35a-fd3b-4732-9d02-64fbcae5a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: scale the loss using a scaling factor\n",
    "step 2: unscale the gradient using the scaling factor\n",
    "step 3: update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42955de6-47a8-4dc8-871d-334949cdfd4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_grad_enabled(input):\n",
    "    return torch.is_grad_enabled and input.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "936aebcb-7788-48b3-a5b2-870373dcd4b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def broadcast(input):\n",
    "    return input.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fbaaae1-c83a-4ffa-b777-03069ad54464",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce(input):\n",
    "    world_size = torch.distributed.get_world_size(group=parallel_group)\n",
    "    \n",
    "    if world_size == 1:\n",
    "        return input\n",
    "    \n",
    "    torch.distributed.all_reduce(\n",
    "        input, group=parallel_group\n",
    "    )\n",
    "    \n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da99d6be-6af8-4ddb-853a-c18efc5ac861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Broadcast(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return broadcast(input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx):\n",
    "        return reduce(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9741c77-e2bd-4622-981e-7f1af8ca193c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def broadcast_with_forward_and_backward(input):\n",
    "    if is_grad_enabled(input):\n",
    "        output = Broadcast.apply(input)\n",
    "    else:\n",
    "        output = broadcast(input)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be2b3b41-11fd-4722-9829-2bc2a654c3d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Recompute(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, phony, recomputed, function, input):\n",
    "        ctx.recomputed = recomputed\n",
    "        ctx.function = function\n",
    "        ctx.input = input\n",
    "        \n",
    "        return phony\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        input_leaf = ctx.input.detach().requires_grad(\n",
    "            ctx.input.requires_grad\n",
    "        )\n",
    "        \n",
    "        with torch.grad_enabled():\n",
    "            output = ctx.function(input_leaf)\n",
    "        \n",
    "        ctx.recompute.append((output, input_leaf))\n",
    "        \n",
    "        grads = [None, None, None]\n",
    "        if input_leaf.requires_grad:\n",
    "            grads.extend([input_leaf.grads])\n",
    "        else:\n",
    "            grads.extend([None])\n",
    "        \n",
    "        return tuple(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75b61312-bb0a-4ddb-bb14-99dce9411dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(d_model, n_heads)\n",
    "        self.norm_1 = ResidualLayerNorm(d_model, dropout)\n",
    "        self.position = PositionWiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.norm_2 = ResidualLayerNorm(d_model, dropout)\n",
    "    \n",
    "    def forward(self, embeddings):\n",
    "        attn_out, attn_weights = self.attention(embeddings)\n",
    "        norm_1 = self.norm_1(attn_out, embeddings)\n",
    "        position = self.position(norm_1)\n",
    "        norm_2 = self.norm_2(position, norm_1)\n",
    "        return norm_2, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e26ddfe8-f3fe-4d3a-88ec-fa0dd59c1af5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.func(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdcfb31-6ec6-4d0a-99ec-7ab07da669e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = unembed @ final_residual_stream\n",
    "= unembed @ (embed + layer_1 + layer_2)\n",
    "= unembed @ embed + unembed @ layer_1 + unembed @ layer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "189a3466-9771-413b-b2cc-4cf710914d8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.profiler import profile, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8465e43-4407-45d8-83c9-30b8a9835bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU]) as prof:\n",
    "    harcore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516c1315-4244-4f4b-842b-0bd3c218fd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.roll(x, shifts=1, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aa8864-f7c7-49ec-8b71-10f5f9072941",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestFruit:\n",
    "    def setup_method(self):\n",
    "        self.fruit = Fruit(\"banana\")\n",
    "    \n",
    "    def test_fruit(self):\n",
    "        assert self.fruit.name == \"banana\"\n",
    "    \n",
    "    def teardown_method(self):\n",
    "        del self.fruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a5beb8d-3496-42e1-8532-a447a0155b88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a799f3ed-5fbd-4a13-815e-1a1bc2b944bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpc.remote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2060a010-0772-4a9c-98dd-5735a5142f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "var, mean\n",
    "add, mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e2fdf-cf2d-4233-adac-ee7cbe3a64e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(pred, y_train):\n",
    "    return nll_loss(log_softmax(pred), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04f8d7a-246a-48af-9bbf-59d953dffdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = dist.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1803cad9-1384-4d17-8c1e-ec72b7e420a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_func = nn.KLDivLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a6d92f-b0ff-43fb-816a-4b20dbac9276",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_func(\n",
    "    input=F.log_softmax(student_logits),\n",
    "    teacher=F.softmax(teacher_logits)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259d0874-f5e1-4cc9-9a7e-aa35a0273816",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = Categorical(probs=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96af35b2-3bd3-44ec-8e7c-b7393af35960",
   "metadata": {},
   "outputs": [],
   "source": [
    "A^T@W_E + A^T@W_E@W_OV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc666a9d-67f7-4820-9dac-fefb08207b76",
   "metadata": {},
   "source": [
    "step 1: extract the corresponding embedding vector for the third position in the residual stream\n",
    "step 2: extract the corresponding embedding vector of the four position in the unembedding vector\n",
    "step 2: unembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05da5faf-e32d-4b9b-9b16-e431a686e1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pass\n",
    "except (ZeroDivisionError, ValueError) as err:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb5598f-9540-4c04-bf83-18d23d2bf505",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridBorg(Wizard, Archer):\n",
    "    def __init__(self, name, power, arrows):\n",
    "        Wizard().__init__(name, power)\n",
    "        Archer().__init__(name, arrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee6f0265-6f83-4981-b8df-da97df3ab885",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "futs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37e20ad-5ead-4059-b628-ed7094e962c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ob_rref in ob_rrefs:\n",
    "    futs.append(\n",
    "        rpc.rpc_async(\n",
    "            to=ob_rref.owner(),\n",
    "            func=run\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b44672-cfbf-4b01-81e5-af250e4b4a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fut in futs:\n",
    "    fut.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9668b186-9809-401f-ae64-06857709a7f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdde070-fc93-46c1-9db2-ac2f9f040fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Christmast():\n",
    "    def __init__(self):\n",
    "        self.color = \"red\"\n",
    "    \n",
    "    def __getitem(self, k):\n",
    "        if k in [\"color\"]:\n",
    "            return self.color\n",
    "        else:\n",
    "            return msg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c455c01-5c72-4fd2-9cb1-28f8274ca47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack([x, x, x, x], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6219d2fb-1069-4f76-94f7-db60873f0caa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import TYPE_CHECKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd68811-163f-48ad-8dd1-95c3eb4b7ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TYPE_CHECKING:\n",
    "    foo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee3226-c5d9-4b49-a7c9-f59a6eae4b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c12a7ff-4420-488d-bf91-dc5fb3c80ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U_correct_token = W_U[:, correct_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c3754e-1bda-4178-8a7d-7b2d4a27c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U_incorrect_token = W_U[:, incorrect_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1329a3-2160-4b25-8b8c-c54739ed647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_difference_direction = W_U_correct_token - W_U_incorrect_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8f6bd1-b780-43bc-acf3-69e88f507777",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f845a1f2-0b4c-4204-ba3b-8ab59131a172",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_residual_stream = cache[hook_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9aebea-a3bf-4466-910f-8446caa60e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_final_residual_stream = final_residual_stream[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb5db84-136d-4631-aa74-b59aaef5491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_last_token_final_residual_stream = model.apply_ln_to_stack(\n",
    "    last_token_final_residual_stream,\n",
    "    pos_slice=-1,\n",
    "    layer=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08dbea2e-0892-48d1-ba6e-14142cd698f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed49d8c7-5dc3-4d36-b8d1-53c22defd3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_attributions = einsum(\n",
    "    scaled_last_token_final_residual_stream,\n",
    "    logit_difference_direction,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5140cc11-6ccc-4143-8694-fe275ba3dbc5",
   "metadata": {},
   "source": [
    "step 1: extract the unembeding vector corresponds to the correct and incorrect token\n",
    "step 2: calculate the logit difference direction\n",
    "step 3: extract the accumulatived residual streams up to layer 3\n",
    "step 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c880ae6-68ea-4ce0-99d3-ba5eaa209157",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51ad70a8-4077-43d2-a6fa-72253e548fd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec48e70b-d6af-4669-87d2-a111127a88be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_worker(in_queue, out_queue, device):\n",
    "    while True:\n",
    "        try:\n",
    "            task = in_queue.get()\n",
    "            output = task()\n",
    "        except:\n",
    "            out_queue.append((None, False))\n",
    "            continue\n",
    "        \n",
    "        out_queue.append((output, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb0b783-1691-496a-bafa-173abef09a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def spawn_workers(devices):\n",
    "    in_queues = []\n",
    "    out_queues = []\n",
    "    \n",
    "    for device in devices:\n",
    "        in_queue = Queue()\n",
    "        out_queue = Queue()\n",
    "        worker = threading.Thread(target=run_worker)\n",
    "        worker.start()\n",
    "        \n",
    "        in_queues.append(in_queue)\n",
    "        out_queues.append(out_queue)\n",
    "    \n",
    "    yield (in_queues, out_queues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dc7160-db32-4c6e-92a5-79be92f1a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: clean prompt, corrupted prompt\n",
    "step 2: record all the interdimate activations of the clean prompt and corrupted prompt\n",
    "step 3: iteratively replace the activations from the clean prompt to corrupted prompt\n",
    "step 4: calculate the logit difference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479d8458-e760-4394-ac50-5b16cf8f493b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce57284-176e-42ba-b770-31b30abf1a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.net = nn.Sequential(\n",
    "            HookPoint(),\n",
    "            nn.Linear(42, 69),\n",
    "            HookPoint(),\n",
    "            nn.ReLU(),\n",
    "            HookPoint(),\n",
    "            nn.Linear(69, 42)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e54d7c-bc8a-470a-9bd5-c8586bd6c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_residual_direction = model.token_to_residual_directions(correct_token)\n",
    "incorrect_residual_direction = model.token_to_residual_directions(incorrect_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cbdc22-da9d-427c-ab09-d305bffe644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_difference_direction = correct_residual_direction - incorrect_residual_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1626d33b-c815-43c1-b6d9-51babaf88712",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_directions = model.tokens_to_residual_directions(answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2649f5a5-a4ba-4fc1-8426-ddace9fece82",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_residual_direction, incorrect_residual_direction = residual_directions.unbind(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f74c1c9-5803-48d6-b108-91798c52e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_difference_direction = correct_residual_direction - incorrect_residual_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695a6403-918c-45b2-97fe-e79e50ccc59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulatived_residual_streams = model.accu_residual_streams(layer=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836c888a-671c-492f-8ba2-77bb2fce4e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
