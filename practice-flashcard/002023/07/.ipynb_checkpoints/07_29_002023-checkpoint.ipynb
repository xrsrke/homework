{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a7fe1bc-f02d-4eac-bce9-8e3884f8e751",
   "metadata": {},
   "source": [
    "### MechInterp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746fb963-e16e-46d3-b84c-66d56f6e00c0",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abc97089-df37-4a79-a7fb-7cd5bc7bbac4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002f6c0b-58ed-46c5-b5c1-f2d5db1a0e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6624d39-4ecc-46a4-845a-9168d140858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Book() {\n",
    "    public:\n",
    "        std::string title;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fff4685-1b27-49c5-8035-69438c7cb534",
   "metadata": {},
   "source": [
    "step 1: get global rank\n",
    "step 2: resize embedding size\n",
    "step 3: parallelize embedding layers, linear layers, attention layers, layer norm\n",
    "step 4: resize lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a909c4a-a435-4871-9c16-918dee8ffa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: determine a list of global ranks in that parallel group\n",
    "step 2: check whether the process's global rank in that list\n",
    "step 3: if yes, initialize a distributed group\n",
    "step 4: get its local rank\n",
    "step 5: save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1f0f5c0-a5d9-44bf-abbe-7e375218bc7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Recompute(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, phony, recomputed, function, input):\n",
    "        ctx.recomputed = recomputed\n",
    "        ctx.function = function\n",
    "        ctx.input = input\n",
    "        return phony\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        function = ctx.function\n",
    "        input = ctx.input\n",
    "        recomputed = ctx.recomputed\n",
    "        \n",
    "        input_leaf = input.detach().requires_grad_(\n",
    "            input_leaf.requires_grad\n",
    "        )\n",
    "        \n",
    "        with torch.enable_grad():\n",
    "            output = function(input_leaf)\n",
    "        \n",
    "        ctx.recomputed.append((output, input_leaf))\n",
    "        return None, None, None, input_leaf.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a77e6e61-12d1-4fed-ac18-7ed2626484af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import socketserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10d14a7b-65ba-487a-b499-e44424878ac8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_port(socket_server):\n",
    "    min_port = 1024\n",
    "    max_port = 65536\n",
    "    \n",
    "    for port in range(min_port, max_port):\n",
    "        try:\n",
    "            addr = (\"\", port)\n",
    "            server = socket_server(addr)\n",
    "            return server\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93584226-c474-4cba-b61f-d183048129d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: fp16, fp32 of the weights\n",
    "step 2: do forward pass and backward pass using fp16\n",
    "step 3: cast grad to fp32\n",
    "step 4: update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25c9d63-9036-4f2c-9610-b88a4e257072",
   "metadata": {},
   "outputs": [],
   "source": [
    "void addVector(int* a, int* b, int* c, int total_elements) {\n",
    "    int gid = (blockIdx.x * blockThread.x) + threadIdx.x\n",
    "    \n",
    "    if (gid < total_elements) {\n",
    "        c[gid] = a[gid] + b[gid]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a250b5-de55-41ed-b56b-a95e7ee6ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_storage(x):\n",
    "    if x.storage().size() > 0:\n",
    "        x.storage().resize_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550c42ac-4c66-4f64-82e3-f0f36fec93d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ReLU(Attn(x@W_E))@W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39213d3-b9c1-48ed-b630-88153256b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed + pos_embed + attn00 + attn01 + mlp0 + attn10 + attn11 + mlp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a35c1f-332d-4247-810f-2bf3a71d4d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty = linear_probe[..., 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9786db3-6eaa-4a96-b8f9-239425c6f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "theirs = linear_probe[..., 1]\n",
    "mine = linear_probe[..., 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d5ca0-b284-4495-9eb3-d876104025e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_empty = (theirs+mine)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0289bc06-2aee-4804-b4a2-1387068a5ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty - not_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fd3e3d-5666-4504-9679-a1ee7c59f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[\"pattern\", 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4d9bae-616c-4735-bfb8-70ec7e97dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[\"result\", 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ec79f7-073e-4d12-ac3d-89f68885270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax(x@W_Q@x@W_K.T)@x@W_V@W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934de673-57f5-4298-a34c-1956b9b01c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "mine = linear_probe[..., 2]\n",
    "theirs = linear_probe[..., 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e75876-386c-4094-94bd-17fe61504a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "mine_vs_their = mine - theirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f091da-dd86-4115-b42b-c09f6632342b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_direction = mine_vs_their[5, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d7e49a-78ae-40c8-8592-ebc0ebd5b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: high-low, loss information\n",
    "step 2: low-to-high, a linear combination of its basis\n",
    "step 3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f179942e-10a4-4b23-b43f-842a9b8f8c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: prob[0] = sigmoid(logit0 - logit1)\n",
    "stpe 2: logit0 = resid2 @ W_U[0], logit1 = resid2 @ W_U[1]\n",
    "step 3: logit0 - logit1 = resid2 @ W_U[0] - resid2 @ W_U[1]\n",
    "\n",
    "=> resid2 @ (W_U[0] - W_U[1])\n",
    "\n",
    "step 4: resid2 = resid1 @ ln2 @ W_OV^{0, 2}\n",
    "step 5: resid1 @ ln2 @ W_OV^{0, 2} @ (W_U[0] - W_U[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a592727f-e4bc-43c7-a564-f8d44cf1b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d8a1675-92c4-45fc-9a83-72e794bf7c05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2307651d-5921-487a-b204-2546e8038a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_name = get_act_name(\"pattern\", layer_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ec08d62-c5e5-4cc0-b09d-1e3da609cae6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blocks.1.attn.hook_pattern'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hook_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a03879-4b0c-42e3-b4ac-0cb40d081022",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_pattern = cache[hook_name][:, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a253280b-1a5b-478a-ac99-36edd5f6e4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_attn_pattern = attn_pattern[target_query_positions].mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e9636-8cf4-4cf5-b042-c3ff232fd82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x@W_E + x@W_E@W_OV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ed27c7-f720-4412-9465-0ab7298e70e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af85ea1e-8404-42ac-8f37-cbb41e834eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_head = activations[:, 1, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a4eca4-b5cc-43f6-8358-38d87c2d85c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: weight @ input = output\n",
    "step 2: input = weight.T @ output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a138ce3-0031-464b-a485-9e06f3457d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear, layer norm, attention, embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d231d24-3042-42aa-96d7-c6778e9c3286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14c955fa-3d2d-4baf-b4b0-8d131fed96cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linear = nn.Linear(20, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d3d06c8-e2bb-4ddd-9a7e-9533ae5099fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1327,  0.1220, -0.0834, -0.1480,  0.1831, -0.1266, -0.1718, -0.1830,\n",
       "           0.0293, -0.0275, -0.0214,  0.0979,  0.2022, -0.0902,  0.0817,  0.2108,\n",
       "          -0.0904, -0.1317,  0.1866,  0.0716],\n",
       "         [-0.1635, -0.0999,  0.0754, -0.1380, -0.1577,  0.2131, -0.1829, -0.0988,\n",
       "          -0.0331, -0.0248,  0.0641,  0.0333, -0.0324,  0.1002, -0.1836,  0.0435,\n",
       "           0.2205,  0.0023,  0.1974, -0.1717],\n",
       "         [-0.2106, -0.0901,  0.0784, -0.0150, -0.0390,  0.1416,  0.1039,  0.1940,\n",
       "           0.0411,  0.2213, -0.1010,  0.1768, -0.1066,  0.1589,  0.1331, -0.2018,\n",
       "           0.1666,  0.0661,  0.1514, -0.0390],\n",
       "         [-0.1599,  0.1489,  0.0890,  0.0676, -0.2054, -0.2076, -0.0438,  0.1898,\n",
       "          -0.1438,  0.1681,  0.1141, -0.1975, -0.0594,  0.1592, -0.1273,  0.0805,\n",
       "           0.1163, -0.1926,  0.1419, -0.1351],\n",
       "         [-0.0501,  0.1292,  0.1565,  0.1284,  0.1530, -0.0463,  0.1284,  0.1595,\n",
       "          -0.1161, -0.0014, -0.0494,  0.0317, -0.0340, -0.1600,  0.0994, -0.1427,\n",
       "          -0.0345,  0.0711, -0.0212, -0.1247],\n",
       "         [-0.2171, -0.0317, -0.1821,  0.1396,  0.1661, -0.1632, -0.1901, -0.1669,\n",
       "          -0.0617,  0.0859,  0.1739,  0.0374, -0.0231, -0.1594,  0.1195, -0.0659,\n",
       "          -0.0381,  0.0304,  0.0010,  0.1138],\n",
       "         [ 0.0590,  0.0837,  0.0104,  0.1227,  0.1375,  0.2113,  0.2134,  0.0492,\n",
       "           0.0725,  0.1123,  0.0059, -0.2170, -0.1737, -0.1238, -0.1262,  0.1395,\n",
       "           0.2003,  0.1660,  0.2194,  0.1224],\n",
       "         [-0.0803, -0.0604, -0.1609, -0.1220, -0.0566,  0.1182,  0.0392,  0.2151,\n",
       "           0.0070, -0.0042, -0.2012, -0.0503,  0.2075,  0.0943, -0.0477, -0.1286,\n",
       "          -0.0332,  0.0251,  0.0647, -0.1628]], grad_fn=<SplitBackward0>),\n",
       " tensor([[ 0.2207,  0.1850,  0.1181, -0.0540, -0.1075, -0.0058,  0.0328,  0.1089,\n",
       "          -0.1005,  0.0844, -0.0752, -0.1564, -0.1527,  0.0868, -0.1157, -0.0801,\n",
       "          -0.0729,  0.2067,  0.0362, -0.1956],\n",
       "         [-0.0879, -0.0099, -0.2122, -0.0469,  0.1854,  0.1391,  0.0362, -0.2062,\n",
       "          -0.0402, -0.2117, -0.0095,  0.0302,  0.0704,  0.1880,  0.1244, -0.0263,\n",
       "           0.1135, -0.0506,  0.0944,  0.2095],\n",
       "         [-0.0125, -0.0589, -0.1853,  0.0098,  0.0122,  0.0142,  0.1327, -0.1154,\n",
       "           0.0709,  0.0183, -0.1893,  0.1831,  0.1945,  0.0525,  0.0922,  0.1355,\n",
       "           0.1599, -0.0785,  0.0297, -0.0803],\n",
       "         [-0.0077,  0.0053, -0.0551,  0.0641, -0.0854,  0.0598,  0.0323,  0.1441,\n",
       "           0.0213, -0.2047, -0.0268, -0.0577, -0.0811, -0.1814, -0.1606,  0.2058,\n",
       "           0.0123, -0.0975,  0.0708, -0.2116],\n",
       "         [ 0.0838,  0.0586, -0.1839, -0.1252,  0.1824,  0.1925,  0.1367, -0.0918,\n",
       "           0.0860, -0.0026, -0.0891,  0.2217, -0.0782,  0.0976,  0.0262,  0.0126,\n",
       "          -0.2121, -0.2202,  0.0501, -0.0271],\n",
       "         [ 0.0031,  0.2090,  0.0923,  0.1632,  0.1409, -0.2075,  0.0782, -0.2160,\n",
       "          -0.2135, -0.1615, -0.0880,  0.0409, -0.0900, -0.0055, -0.0036,  0.1554,\n",
       "          -0.0580, -0.0774, -0.0806, -0.0533],\n",
       "         [-0.0406,  0.1866, -0.0021,  0.0202, -0.2048, -0.1386, -0.0774, -0.0159,\n",
       "          -0.2117,  0.0723, -0.0461, -0.1529, -0.0432, -0.1702,  0.1940, -0.0843,\n",
       "          -0.0083, -0.1576, -0.0226, -0.0428],\n",
       "         [-0.1230, -0.1835, -0.2192, -0.0549, -0.0241, -0.0351,  0.1030, -0.1076,\n",
       "          -0.1002, -0.2231, -0.1279,  0.1136,  0.2137,  0.0359, -0.0773, -0.0737,\n",
       "          -0.0291, -0.0700, -0.2025,  0.1515]], grad_fn=<SplitBackward0>),\n",
       " tensor([[ 0.0365, -0.0975,  0.1481,  0.0479,  0.0307, -0.1135, -0.0126, -0.0872,\n",
       "           0.1123, -0.1871,  0.1008, -0.0944,  0.1098, -0.1707, -0.1292, -0.0875,\n",
       "           0.1435, -0.1354,  0.2227, -0.0101],\n",
       "         [ 0.0465, -0.1492, -0.1823, -0.0572, -0.0235,  0.0270, -0.0118, -0.1367,\n",
       "           0.0516, -0.1854,  0.1906,  0.0756,  0.1261, -0.1385,  0.2187, -0.0165,\n",
       "          -0.1574, -0.1004, -0.1378, -0.0179],\n",
       "         [ 0.0457,  0.0990,  0.0154,  0.1983,  0.0413,  0.1009,  0.0527, -0.1652,\n",
       "           0.2059, -0.1020,  0.1582, -0.1802, -0.0116,  0.2207,  0.0273, -0.1879,\n",
       "           0.0110, -0.1189, -0.1445, -0.0983],\n",
       "         [-0.0543, -0.1129, -0.1949, -0.0017, -0.2109,  0.1734,  0.1573, -0.2133,\n",
       "           0.0446,  0.1084,  0.0059, -0.1248, -0.1548,  0.1356, -0.1245,  0.1354,\n",
       "           0.0780,  0.1391,  0.2061, -0.1460],\n",
       "         [-0.0418,  0.2083, -0.1580,  0.2221, -0.0457,  0.1325, -0.0151,  0.1109,\n",
       "          -0.0807, -0.2228, -0.0855, -0.0032, -0.0507,  0.1074,  0.1486, -0.1044,\n",
       "           0.0225, -0.1427, -0.1242, -0.1216],\n",
       "         [ 0.1500, -0.2142, -0.1948,  0.1435,  0.1955, -0.0901,  0.1781,  0.0258,\n",
       "           0.1472,  0.0169,  0.1961,  0.1145,  0.1182,  0.1370,  0.0037,  0.1365,\n",
       "           0.0146, -0.1210,  0.1073, -0.1117],\n",
       "         [-0.1469, -0.0588, -0.0106, -0.1018, -0.1194, -0.2017, -0.0092, -0.2095,\n",
       "           0.0178, -0.0049, -0.0828,  0.1642, -0.1401, -0.1677,  0.0908,  0.0814,\n",
       "           0.2130, -0.0365,  0.1134,  0.1350],\n",
       "         [ 0.1156,  0.1024, -0.1531, -0.1951,  0.1141, -0.1540,  0.1704, -0.0232,\n",
       "          -0.0850,  0.0923,  0.0721,  0.0492, -0.0367, -0.1261, -0.0022, -0.1886,\n",
       "          -0.0264,  0.0881,  0.0074,  0.0261]], grad_fn=<SplitBackward0>),\n",
       " tensor([[ 0.1670, -0.1753,  0.0601, -0.0955, -0.2157,  0.1587, -0.0056,  0.1177,\n",
       "           0.1191, -0.0893, -0.0084,  0.0644, -0.1123, -0.0187, -0.2046,  0.0562,\n",
       "           0.0420,  0.1890,  0.1874, -0.0279],\n",
       "         [-0.0171, -0.2182,  0.1474, -0.1828,  0.1915,  0.1422,  0.1949,  0.1453,\n",
       "           0.0104,  0.1365,  0.1696,  0.0656, -0.1455,  0.0024, -0.1536, -0.0931,\n",
       "          -0.0250,  0.1777, -0.2202, -0.0776],\n",
       "         [ 0.0954,  0.1972, -0.0890, -0.2002,  0.0752,  0.0736, -0.0037,  0.1866,\n",
       "           0.0810, -0.0342, -0.1521,  0.0677, -0.2093, -0.0407, -0.1564, -0.0212,\n",
       "           0.2046, -0.0807, -0.0501,  0.1088],\n",
       "         [ 0.0689, -0.2134,  0.1320,  0.0959, -0.0135,  0.1870, -0.0212,  0.1196,\n",
       "           0.1128,  0.0535,  0.0772,  0.0171, -0.0502,  0.0718, -0.1983,  0.0067,\n",
       "          -0.1081,  0.0762,  0.1306, -0.2229],\n",
       "         [ 0.1329,  0.2185, -0.0479,  0.1828,  0.0533, -0.1780,  0.1409, -0.2093,\n",
       "           0.0384,  0.0725, -0.1772, -0.0406, -0.2073, -0.0741, -0.2048,  0.1372,\n",
       "           0.0441, -0.1611, -0.1537, -0.2040],\n",
       "         [ 0.0608, -0.2035, -0.0869, -0.0755,  0.0754, -0.0955,  0.0258,  0.1301,\n",
       "           0.0731,  0.0627, -0.0775,  0.0750, -0.0024,  0.0189,  0.0624,  0.1045,\n",
       "          -0.0187,  0.2230, -0.1910, -0.2171],\n",
       "         [-0.1210, -0.1162, -0.0723, -0.2208,  0.0477, -0.0274, -0.2047,  0.1528,\n",
       "           0.0738, -0.1754,  0.1383, -0.0715, -0.1244, -0.0215, -0.0970, -0.1957,\n",
       "          -0.0975,  0.1366,  0.0669, -0.0050],\n",
       "         [ 0.0719, -0.1239,  0.0248,  0.1801, -0.0031,  0.0463,  0.0110,  0.1043,\n",
       "           0.2161,  0.2008, -0.0346, -0.2004, -0.0312, -0.1192, -0.1660,  0.1084,\n",
       "          -0.1995, -0.1418,  0.1329, -0.2131]], grad_fn=<SplitBackward0>),\n",
       " tensor([[ 0.1384, -0.0031, -0.0538, -0.1429, -0.0012,  0.2204,  0.0044,  0.0847,\n",
       "           0.1014, -0.0326,  0.0792,  0.1258, -0.2033, -0.1841, -0.1377, -0.0497,\n",
       "           0.0119,  0.0401, -0.0909,  0.1200],\n",
       "         [-0.0718, -0.1774,  0.1488, -0.1012, -0.1537,  0.0136,  0.0183, -0.1080,\n",
       "          -0.0265,  0.0303, -0.0925, -0.0273, -0.1219,  0.1628,  0.0390, -0.0630,\n",
       "          -0.0276, -0.1118, -0.1603, -0.2094],\n",
       "         [-0.2103, -0.0836,  0.0686, -0.0047,  0.0542, -0.1509, -0.0011,  0.1885,\n",
       "          -0.0910, -0.1040, -0.0112,  0.1128, -0.1624, -0.0243, -0.0865, -0.0185,\n",
       "          -0.0752,  0.0645, -0.0938,  0.2146],\n",
       "         [-0.0805, -0.0606, -0.1074, -0.0682, -0.1701,  0.1648,  0.2047, -0.0196,\n",
       "          -0.1931,  0.0809,  0.0227,  0.2011, -0.0235, -0.0989, -0.1934,  0.1782,\n",
       "          -0.1274,  0.0566,  0.2010, -0.1665],\n",
       "         [ 0.2109, -0.0953, -0.1770,  0.1933,  0.1296, -0.0455, -0.1813, -0.0585,\n",
       "           0.2203,  0.0026,  0.0004, -0.1164,  0.0572,  0.0917,  0.0151, -0.2008,\n",
       "          -0.0178,  0.0193,  0.0889,  0.0730],\n",
       "         [-0.0242, -0.0128,  0.2127,  0.1855,  0.0348, -0.0481,  0.1699, -0.0230,\n",
       "          -0.0135,  0.1327, -0.1637,  0.2095, -0.0322,  0.1565, -0.0284,  0.0815,\n",
       "           0.1937, -0.0307, -0.1299, -0.1171],\n",
       "         [-0.1338, -0.1791, -0.0137,  0.1481, -0.2146, -0.2191,  0.1782,  0.1170,\n",
       "           0.1469,  0.1170,  0.0459,  0.1139,  0.0199, -0.0743, -0.0793,  0.0469,\n",
       "          -0.0899,  0.1849, -0.0415,  0.1980],\n",
       "         [ 0.0880,  0.1639, -0.1055, -0.0277, -0.0783,  0.1376, -0.0924, -0.1172,\n",
       "          -0.0355,  0.2127, -0.0593, -0.1800, -0.0756,  0.1299,  0.0252,  0.1790,\n",
       "          -0.0876,  0.1155, -0.0612,  0.1000]], grad_fn=<SplitBackward0>))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.weight.chunk(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfd70f79-00a7-4d6b-afaf-9763133d9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cd58290-e0ad-4dcb-a62b-3465cf7ad93d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.tensor([-2, -1, 0, 1, 2]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b853595a-dada-4e4b-8ce2-d8febc552744",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0455, -0.1587,  0.0000,  0.8413,  1.9545])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.gelu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6003a7fc-9da6-4d52-9e99-c192f7f76726",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0233, -0.0317,  0.0000,  0.2341,  1.2728])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(x, dim=0)*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8319924a-8426-4c39-8a92-96f1ad1b89ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pf/g3nr86yn4j71vzzmv6knwdhr0000gp/T/ipykernel_2294/1837365005.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  F.softmax(torch.tensor([1, 1, 1, 1], dtype=torch.float32))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2500, 0.2500, 0.2500, 0.2500])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(torch.tensor([1, 1, 1, 1], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cb4ced-791c-4559-8399-e54e63a398e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
