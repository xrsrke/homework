{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91132031-b9c3-4a2a-a312-5cfa9bfb2232",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e28d7f3e-4725-43b4-b907-6f3399bff421",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eaf317d-b2ce-4897-a961-ef1e77f5baad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03b8c34e-9899-4de6-a53e-8a8e52b01993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MPU:\n",
    "    def __init__(self, master_addr, master_port, backend):\n",
    "        if not torch.distributed.is_initialized():\n",
    "            rank = os.getenv[\"RANK\"]\n",
    "            world_size = os.getenv[\"WORLD_SIZE\"]\n",
    "            os.environ[\"MASTER_ADDR\"] = master_addr\n",
    "            os.environ[\"MASTER_PORT\"] = master_port\n",
    "            \n",
    "            torch.distributed.init_process_group(\n",
    "                rank=rank,\n",
    "                world_size=world_size,\n",
    "                backend=backend\n",
    "            )\n",
    "            \n",
    "            self.set_device(rank)\n",
    "            \n",
    "    def set_device(self, rank):\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        torch.cuda.set_device(rank%num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dd2caa-fe75-42a2-b25c-e1bd35f5c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb138d52-fdf8-4fb6-8ec1-090019f2db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: wait data\n",
    "step 2: construct a task\n",
    "step 3: put the task into the correspond worker's in_queue\n",
    "step 4: wait \n",
    "step 5: get\n",
    "step 6: put in into "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f794e8de-94d0-42ff-b417-faa19fb629e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "using namespace std;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f655e532-b283-4814-b00a-1d4ce698b113",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Book() {\n",
    "    public:\n",
    "        string title;\n",
    "        string author;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff866b-b408-466d-bd86-05d4ba9818ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "container runtime, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa93c6b-0bbb-4632-a0a0-180fba832cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new > ready > running > blocked > terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f73bc9-f7d3-4f7a-9ba9-f1cc89c0d9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer-related variables, grad, model param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea44c23-2fed-4729-91ed-a813a4b8945b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ranks = [0, 1, 3, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440ebfb0-0db8-42bd-8167-b6fc78d8bd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = torch.distributed.get_rank()\n",
    "group = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12afeec1-d4e2-46e5-a3c8-43b44bd0b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rank in ranks:\n",
    "    group = torch.distributed.new_group(ranks)\n",
    "    \n",
    "if group is not None:\n",
    "    torch.distributed.broadcast(x, src=0, group=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8309addc-72a2-4537-b278-c2b338a2ac12",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44db91ca-ba4d-49af-a1af-57b9089d5e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "message passing, collective communication, p2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9803ffcd-6d65-43d0-8aec-674d464ba54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new > ready> running > blocked > terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf39ff81-0653-45f1-ac6c-2e429c7afdaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "world_size = 16\n",
    "tensor_model_parallel_size = 2\n",
    "pipeline_model_parallel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9450092d-888b-475a-bf70-6273e7dfaff9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_pipeline_model_parallel_groups = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "effd43c9-dad4-44d1-888a-d724712118b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_parallel_groups = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffb16fe3-5681-486d-8b37-552c55b664b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2]\n",
      "[1, 3]\n",
      "[4, 6]\n",
      "[5, 7]\n",
      "[8, 10]\n",
      "[9, 11]\n",
      "[12, 14]\n",
      "[13, 15]\n"
     ]
    }
   ],
   "source": [
    "for i in range(pipeline_model_parallel_size):\n",
    "    start_rank = i*num_pipeline_model_parallel_groups\n",
    "    end_rank = (i+1)*num_pipeline_model_parallel_groups\n",
    "    \n",
    "    for j in range(tensor_model_parallel_size):\n",
    "        ranks = list(range(\n",
    "            start_rank+j,\n",
    "            end_rank,\n",
    "            tensor_model_parallel_size\n",
    "        ))\n",
    "        print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e28b8a7-c2cd-43de-b343-4592d326f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297d2623-28fc-423b-b56c-c8be59a132c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(1, 1) * 3 = (3, 3) = (3, 3)\n",
    "(1, -1) * -2 = (-2, 2) = (0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e18c4f0-53fa-4fed-affb-851fe053291a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=others, key=persistence => no token\n",
    "\n",
    "mask everything eke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa65ad90-8491-4469-b0f7-f2fff70835f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_residual_stream @ unembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e88a47-4d40-45bb-974b-8ce0a6bcecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: q@W_Q\n",
    "step 2: q = embed + pos_embed + 12 heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249d70bf-30e7-4ece-8808-8cd63bffb78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(\n",
    "    tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048043e2-d824-4810-8da3-df599e547efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_residual_stream = cache[final_residual_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c831a67-cc80-49dc-9e73-062444c91fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_final_residual_stream = final_residual_stream[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe724a0-4911-4dca-8821-e2c188230fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_last_token_final_residual_stream = model.apply_ln_to_stack(\n",
    "    last_token_final_residual_stream,\n",
    "    layer=-1,\n",
    "    pos_slice=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53894187-4cd1-4ba5-ba86-2706273fefa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639032ed-a488-4635-aac9-812eb70c9e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U\n",
    "correct_resid_direction = W_U[correct_token]\n",
    "incorrect_resid_direction = W_U[incorrect_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0abaee-0189-411b-a163-95c459a1dc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_resid_direction = correct_resid_direction - incorrect_resid_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea73de1-74e6-4a90-83d1-da6abbc1edda",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_difference = einsum(\n",
    "    scaled_last_token_final_residual_stream,\n",
    "    diff_resid_direction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96489e3-fd53-4adf-956d-7e7bbca6c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "previous token head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70051e6-ed5c-4169-b7bc-7b0f2a432d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "= embed + pos_embed + attn00 + attn01 + mlp0 + attn10 + attn11 +mlp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39b765a-4299-46fd-9810-54046d84cc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_directions = model.tokens_to_residual_directions(\n",
    "    answer_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60577ea-7d8a-4dd1-bdec-25028f9222ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_resid_direction, incorrect_resid_direction = resid_directions.unbind(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883a608b-abe1-444d-90c1-2b81c7d7b68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_diff_direction = correct_resid_direction - incorrect_resid_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04f293b-4f28-408d-b310-e83b11df95b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5daf41-bca7-4b43-ba0b-292e661ba425",
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated_resid_stream = cache.accumulated_resid(layer=-1, pos_slice=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734973cd-e8d0-447a-8806-40fa1caca0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_accumulated_resid_stream = accumulated_resid_stream[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c6a696b-63b3-4242-b401-29e1e91f524f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ee05c2-6584-49e9-ab34-98fb03ef08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_difference = einsum(\n",
    "    last_token_accumulated_resid_stream,\n",
    "    logit_diff_direction,\n",
    "    \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f037aa-504f-4061-87b9-08ba815d4eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: approximate the non-linear parts if possible\n",
    "step 2: convert the probs into logit difference\n",
    "step 3: decompose the logits\n",
    "step 4: project the output of each component into the unembed direction of target token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c45ac9-9dd1-4e19-b2b8-8e0216820498",
   "metadata": {},
   "outputs": [],
   "source": [
    ", cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82f872f-eb81-4605-8472-86391a520e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = cache[\"hook_embed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ee7205-654d-4e27-b4b5-2803e36ae071",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df33bc03-4401-4eb9-956d-8544d9f601ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tokens = tokens[1:]\n",
    "target_unembed_directions = W_U[target_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eba55a-3eea-4207-be6d-ce44e9c15c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_attributions = einsum(\n",
    "    embed[:-1],\n",
    "    target_unembed_directions,\n",
    "    \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "523cc0de-7d9b-4679-8834-db89e0f8bffe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8563a5-1bf3-4259-9591-845a2f7b3ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "induction_score = reduce(\n",
    "    induction_stripe,\n",
    "    \"seq_len head_idx -> seq_len\",\n",
    "    reduction=\"mean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf724920-d280-408a-9908-4ad7c3c19471",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = model.to_tokens(clean_prompt)\n",
    "corrupted_tokens = model.to_tokens(corrupted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122050f0-b366-4f22-8955-a0e75c73259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_token = model.to_single_token(\" John\")\n",
    "incorrect_token = model.to_single_token(\" Mary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f5654a-5fd8-4c1b-96c5-b114ca2a8f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_activations = model.run_with_cache(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f2a666-47d9-46de-95d0-07b148bed6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = clean_tokens.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eab5f85-1468-4d98-a0f6-368fe612461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.zeros(n_layers, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "218a0a9e-9ec0-48f6-97e7-2d4f1c26055b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_pre_resid(activations, hook, position_idx, clean):\n",
    "    target_activation = clean[hook.name][:, position_idx, :]\n",
    "    activations[:, position_idx, :] = target_activation\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f33d050-2e62-4aec-859a-472da8fe6f7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7fcbeba-79db-4755-bf6e-fe68afc893c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "902a29ba-7e5d-4ee0-9154-b7c19af5e335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_logit_difference(logits, correct_token, incorrect_token):\n",
    "    last_token_logits = logits[:, -1, :]\n",
    "    return last_token_logits[correct_token] - last_token_logits[incorrect_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fed67ef-f169-47cf-9bca-b03c0fe1658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(n_layers):\n",
    "    hook_name = get_act_name(\"resid_pre\", layer_idx)\n",
    "    for position_idx in range(seq_len):\n",
    "        hook_func = partial(\n",
    "            patch_pre_resid,\n",
    "            position_idx=position_idx,\n",
    "            clean=clean_activations\n",
    "        )\n",
    "        patched_logits = model.run_with_hooks(\n",
    "            corrupted_tokens,\n",
    "            fwd_hooks=[(hook_name, hook_func)]\n",
    "        )\n",
    "        logit_diff = compute_logit_difference(patched_logits, correct_token, incorrect_token)\n",
    "        results[layer_idx][position_idx] = logit_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a10fd50-6f66-4617-b6f0-078af3d700b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "components = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b97cdc-fbf1-46e4-b129-e49d4b43acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "components.append(cache[\"embed\"])\n",
    "components.append(cache[\"pos_embed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5522bb-1995-4f45-96a2-896b0b09abbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_layers):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c36a2c0-cd9c-4663-a023-6cd2c313e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = sigmoid(logit0 - logit1)\n",
    "\n",
    "logit0 = fn_resid @ unembed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf67bbfe-8752-47a6-85cf-0a8ff54a1614",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(Attn(x@W_E))_WUb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed3ec03-bc03-40ac-a4fa-7cc567d7c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RELU(x@W_in) @ W_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5882e1b8-4907-4df3-8272-3cf82b1b6633",
   "metadata": {},
   "outputs": [],
   "source": [
    "case 1:\n",
    "query=persistence, key=padding\n",
    "no mask\n",
    "\n",
    "case 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199525c7-e990-46c0-9c85-067e7da249f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_QK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f267895c-71b7-4e65-a671-d6ec1ea57abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_QK^(1,4) @ W_OV^(0, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e699ac-a837-42c0-9e99-1ab7bc9efe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(Attn(x@W_E))@W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e44db6a-732b-4ed1-82d7-ecb945924f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d5fcec-1650-4b41-9280-4b89eaba5cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=padding tokens\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b6667d-d73c-4f71-a0cf-e38f5a0befa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_2@W_OV@[v_1, v2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34386a0-a32e-44cd-b897-95b626d1ed99",
   "metadata": {},
   "source": [
    "step 1: record all interdimate activations\n",
    "step 2: analyze all attention patterns\n",
    "step 3: spot induction heads\n",
    "step 4: decompsoe attention scores\n",
    "step 5: trace back which pair in the decomposed attention score contributes to the induction pattern the most\n",
    "step 6: construct the full-circuit go from embedding, first head and second head?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cb76e5-02cb-4d61-81b3-77cceb3f2ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock cycle 1: forward(0, 0)\n",
    "clock cycle 2: forward(1, 0), forward(0, 1)\n",
    "clock cycle 3: forward(2, 0), forward(1, 1)\n",
    "clock cycle 4: forward(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a049d8-2616-4ebd-9b0e-eb2e170fda49",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: split mini-batch into micro-batches\n",
    "step 2: cuda stream\n",
    "step 3: run pipeline\n",
    "step 4: gather the microbatch outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4615e278-c45e-4fcf-96ce-c4d51ee1deee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9336d9ad-6d30-4fd0-b975-8921df8b0c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.roll(x, shifts=2, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "523384fb-0e7e-4118-8a23-95cca7d7c9e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 1, 5, 6, 3, 2, 4, 0, 8])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b0ba72-1931-4516-817f-7eab124c9852",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = torch.cuda.Stream(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf837d-fb34-40af-995f-ab7fde8120b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.stream(stream):\n",
    "    mean = x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "493e89ad-f8e1-4804-af36-c62306f94e0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6e6d163-2b05-420e-a874-987a9b0fcc2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sort' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msort\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sort' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3c2344-6b0e-4b51-a645-42bb69c5f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: partrition\n",
    "step 2: split mini-batch\n",
    "step 3: create cuda stream\n",
    "step 4: create and run pipeline\n",
    "step 5: gather output from all micro-batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e63c19c-f816-4314-9804-6331b5d06677",
   "metadata": {},
   "outputs": [],
   "source": [
    "docket network create mongo-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722e2d02-8b32-49c3-a9e5-515838979a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6893ac16-afda-432b-96a4-0b08992cbcee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55c37154-7f2a-4d81-bf61-8be4b3a60cda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def second_context():\n",
    "    print(\"entering the context\")\n",
    "    \n",
    "    yield \"hello, world\"\n",
    "    \n",
    "    print(\"leaving the context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b2923d-9e17-48ad-98f5-c09c8b382621",
   "metadata": {},
   "outputs": [],
   "source": [
    "notificationservice, notificationmanager, notificationclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472b679e-4e55-436b-9d2c-f4ce0c4066dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data parallel group, tensor parallel group, pipeline parallel group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc72ec2-cee0-4ce3-97e4-a9147cdefb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d3c39e8-35d0-4261-847a-c0f75aab4462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f37258-7ce2-4e5d-ad63-d3f10e47f38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache\n",
    "def expensive_function():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bcc314-310f-47d8-9337-8b294c983766",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416174e6-f522-47c4-9f3d-4b7ee0bd4143",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker network create mongo-network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed08303-100a-4531-a93e-1b675b8a1afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc286f99-8734-4339-ab30-4107d92f7e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "warps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46900236-8163-4bd9-a42b-7ae4d20d4ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hasattr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3825372-a369-46e9-bac0-d239020685ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "needs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a723386f-5862-4997-b972-3dc417fafc68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
