{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0ffdb34-2753-4689-9a35-9e0fbe5b4dc4",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7738411-c509-47b1-b83f-e5ca31143efb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d946bd-47f1-4742-a009-f9b0b2c4676a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor_model_parallel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a65f9cab-112f-4f3d-88b5-c65203420ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_tensor_model_parallel_groups = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d3a3538-fac5-4b23-8a0a-d345c16e944a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[2, 3]\n",
      "[4, 5]\n",
      "[6, 7]\n",
      "[8, 9]\n",
      "[10, 11]\n",
      "[12, 13]\n",
      "[14, 15]\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_tensor_model_parallel_groups):\n",
    "    ranks = list(range(\n",
    "        i*tensor_model_parallel_size,\n",
    "        (i+1)*tensor_model_parallel_size\n",
    "    ))\n",
    "    \n",
    "    print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2c83ef-3b92-4ca9-91c3-b1105fe9acf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17416a50-6636-4a51-82be-d91b4b28d85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    std::cout << \"hello\" << std::endl;\n",
    "    std::cout << \"world\";\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f981a07-7e3a-46af-968b-70e99579734a",
   "metadata": {},
   "outputs": [],
   "source": [
    "service, configmap, deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961acd93-baac-4e49-8b67-f54de87b3bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "__global__ void vectorAdd(int* a, int* b, int* c, int total_elements) {\n",
    "    int tid = (blockIdx.x * blockDim.x) + threadIdx.x\n",
    "    \n",
    "    if (tid < total_elements) {\n",
    "        c[tid] = a[tid] + b[tid];\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4741944-80a0-41a3-bda1-e5eed7057af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_tensors(x):\n",
    "    world_size = torch.distributed.get_world_size()\n",
    "    xs = [torch.zeros_like(x) for _ in range(world_size)]\n",
    "    torch.distributed.all_gather(xs)\n",
    "    xs = torch.cat(xs, dim=-1)\n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cb78c25-e3ae-4d41-91db-9d50b3259a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79efc12c-9747-4b71-b302-4a711cc362c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lock = threading.Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e894be0-ca2b-4c9d-841b-8fe603bfa8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with lock:\n",
    "    t1 = threading.Lock(target=print_numbers)\n",
    "    t1.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d079c-985e-4d7d-95f5-970ac6155f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "flop, memory bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36afeef5-4d2d-4523-9a18-452c4c86da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model parameters, gradient, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac8ca53-e67c-4c16-b6a3-9363699f9905",
   "metadata": {},
   "outputs": [],
   "source": [
    "message passing, p2p, collective communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a29752-9e70-4657-bf78-db52eca7573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: script\n",
    "step 2: peri\n",
    "step 3: compare\n",
    "step 4: return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cd04b8-aba7-444b-9908-e88c437f37cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: record\n",
    "step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ac8ff03-d75c-4577-a3c1-5ee5a9781e97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421bd701-fed9-4ff7-893b-45f73273d1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = list(product(n_heads, n_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf3b2a5-ba42-4e9c-aae4-0758edcffa1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d6fdd1-ffaa-4d25-a58f-dece0dd97a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(\n",
    "    names_filter=lambda x: x.endswith(\"mlp_out\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8532861-a582-4eff-a0a1-f0dd486ab4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.apply_ln_to_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f4f200-818c-434e-b64f-5aba594cc72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load, save, move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da1bd13-dbec-44b0-8b13-03b770bee856",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999eda9b-5306-426b-be84-d4467b663b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f644c97-e850-4bae-85e9-ac4945e713b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_residual_embedding = W_U[:, correct_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a28c59-c4a7-40db-9d3f-c0fbb4bbc460",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_residual_embedding = W_U[:, incorrect_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8da6c6-88d0-4611-a90c-2ae4b1755590",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_difference_direction = correct_residual_embedding - incorrect_residual_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e2ae3f-41e6-417b-80ac-b318c35f27b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_stream = cache[final_residual_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6bb4bc-bf39-4705-92f3-9d55351723f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_residual_stream = model.apply_lm_to_stack(stream, layer=layer_idx, pos_slice=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04bb3e16-6bb4-4217-82d0-7ab4a273bbc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f960e4d4-e2f9-4b0b-af56-b1628f40b356",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = einsum(\n",
    "    residual_stream,\n",
    "    logit_difference_directiom\n",
    "    \"b dim, b dim ->\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cc6e41-da9b-4d05-ae1a-9a31c3f9ba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5838904-2a3d-44f4-8b81-04d672df134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = cache[hook_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de6f19b-783c-47bf-9eb9-ec3175d4eef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09cb1c-5475-4ec6-8a98-23c313a3e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tokens = tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccb732e-51b9-4c62-9d8b-aae44c48ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U_correct_tokens = W_U[:, target_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e23aff6-ec7a-477a-b3c8-2429ec4d5c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_attributions = einsum(\n",
    "    W_U_correct_tokens,\n",
    "    embed[:-1],\n",
    "    \"seq embed, embed seq -> seq\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161c6ab9-86a8-4294-935d-1482553a7faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, n_layers, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.text_embedding = TextEmbedding(\n",
    "            vocab_size=10000, d_model=d_model,\n",
    "            padding_idx=0\n",
    "        )\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            d_model=d_model\n",
    "        )\n",
    "        \n",
    "        self.encoder_layers = [EncoderLayer(\n",
    "            d_model=d_model,\n",
    "            n_heads=n_heads,\n",
    "            d_ff=d_ff\n",
    "            dropout=dropout\n",
    "        ) in range(n_layers)]\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        text_embeddings = self.text_embedding(tokens)\n",
    "        positional_embeddings = self.positional_encoding(tokens)\n",
    "        embeddings = text_embedding + positional_embeddings\n",
    "        residual = embeddings\n",
    "        \n",
    "        for layer in self.encoder_layers:\n",
    "            residual = layer(residual)\n",
    "        \n",
    "        return residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da65dc7d-703b-4d0f-88d7-c2f0c04095c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33327a9d-c67f-4eaa-9337-63f28f0b895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: script\n",
    "step 2: peri\n",
    "step 3: compare\n",
    "step 4: return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ab8a2-6c1d-4982-8a40-565b1efb9a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributed.rpc.recv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496982d-b077-4343-af8e-9025a03e7f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "twp prompt\n",
    "record\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d314fd6b-416e-48c1-8c4f-891a0673e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: extract the unembedding vectors\n",
    "step 2: calculate the logit difference directions\n",
    "step 3: extract residual stream\n",
    "step 4: einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8044ff92-65b8-4a28-b4e6-17ffd8502af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9cdd5d-6737-4356-a0dc-3587243baf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_tokens(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e257e227-e3d8-47d4-8ba8-7eb4d3de3ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a95a84-05f5-4815-8059-07b3d7bf737b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_residual_direction = W_U[:, correct_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b658e5e3-c4df-4af7-acc2-9347191d9f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_residual_direction = W_U[:, incorrect_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe86b7d0-1737-4ec1-926a-19b193703258",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_difference_direction = correct_residual_direction - incorrect_residual_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7c72b4-acbd-4acc-bf24-664b55e7b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_residual_stream = cache[final_residual_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6eb886-c994-422d-8648-01b17a96705f",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_token_final_residual_stream = final_residual_stream[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030442e5-04ba-4686-ad36-c07a282e9bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_last_token_final_residual_stream = model.apply_ln_to_stack(\n",
    "    last_token_final_residual_stream,\n",
    "    layer=11,\n",
    "    pos_slice=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abe4d2c-8623-44b5-beb4-ed1dd3ea15ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = einsum(\n",
    "    logit_difference_direction,\n",
    "    scaled_last_token_final_residual_stream,\n",
    "    \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45651be-bccb-4ccd-ba61-da7035968017",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = final_residual_stream @ unembed\n",
    "\n",
    "logit_diff = (final_residual_stream @ unembed_1) - (final_residual_stream @ unembed_2)\n",
    "logit_diff = final_residual_stream @ (unembed_1 - unembed_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172799f0-fa3a-421b-8d88-f7c3c58bcc32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f6719e-1130-4d62-b350-5479fb55ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0531c79-e957-4aa4-a3d4-9568788799ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: logit resi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b64625-cc20-47fc-afbe-7d9f581fda90",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: bind\n",
    "step 2: connect\n",
    "step 3: accept\n",
    "step 4: communicate\n",
    "step 5: close the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f6b8fc-c141-4e92-969c-ada41a6a06d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a843ef72-43a6-4ad8-8a8b-a595bdded556",
   "metadata": {},
   "outputs": [],
   "source": [
    "save, restore, reset, commit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08df5a15-081e-4557-93af-78d5dbf01106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a4b68f-bfa4-49d9-b920-52599991f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_directions = model.tokens_to_residual_directions(answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b182f4f-df20-4e78-b311-7e2f83ccb5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_residual_directions, incorrect_residual_directions = residual_directions.unbind(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9405e6cc-7cfe-4fc4-b90d-97db46afa86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_difference_directions = correct_residual_directions - incorrect_residual_directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea8bc5f-d1ed-45c0-ba66-3d1b31e07f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e70a07-ad1d-469c-92ea-b31dbb77c3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulatived_residual_streams = cache.accumulated_residual_streams(layer=-1, pos_slice=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad2b34-44cd-45f7-8ccf-27d2e34f7f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_residual_direction = unembeding[:, correct_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a90c261-d944-4112-a8e4-22ddb0da8223",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_residual_direction = unembedding[:, incorrect_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b2a71e-eb0c-4adf-a642-f3e40ea3811f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_diff_direction = correct_residual_direction - incorrect_residual_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c676532-3a96-4fed-a8b9-7ef0c0b1ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: calculate the logit difference direction\n",
    "step 2: extract\n",
    "step 3: calculate the logit difference\n",
    "step 4: plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba14ee4-ca2e-4af4-8cc2-7ec7bfe32907",
   "metadata": {},
   "source": [
    "Sure! Let's go through each of the matrices described in the refresher, one by one:\n",
    "\n",
    "$W_{OV}^{h}$: This represents the OV (output-value) circuit for a specific head 'h'. The OV circuit is the mechanism by which the model determines what information gets moved from the source position to the destination position in the residual stream. It has the shape $(d_{model}, d_{model})$, which means it's a linear map operating on the vectors in the model's residual stream.\n",
    "\n",
    "$W_E W_{OV}^{h} W_U$: This represents the full OV circuit. It describes what information is moved from the source token to the destination token in a start-to-end sense. The components of this expression are:\n",
    "\n",
    "$W_E$: Embedding weight matrix\n",
    "$W_{OV}^{h}$: OV circuit for head 'h'\n",
    "$W_U$: Unembedding matrix\n",
    "It essentially maps from one-hot encoded input vectors (tokens) to the transformed residual stream vectors, and finally unembeds the vector to the output logits.\n",
    "\n",
    "$W_{QK}^{h}$: This represents the QK (query-key) circuit for a specific head 'h'. It has the shape $(d_{model}, d_{model})$ and describes where information is moved to and from in the residual stream. In other words, it determines the attention score between tokens 'i' and 'j' in the model's residual stream.\n",
    "\n",
    "$W_E W_{QK}^{h} W_E^T$: This represents the full QK circuit. It describes where information is moved to and from, among the words in our vocabulary. It essentially computes the attention score between two specific tokens.\n",
    "\n",
    "$W_{pos} W_{QK}^{h} W_{pos}^T$: This is a bilinear form that describes where information is moved to and from, in terms of the position of the tokens. It essentially computes the attention score between the tokens at two specific positions 'i' and 'j'.\n",
    "\n",
    "$W_E W_{OV}^{h_1} W_{QK}^{h_2} W_E^T$: This complex-looking form is describing where information is moved to and from in head $h_2$, given that the query-side vector is formed from the output of head $h_1$. This is an instance of Q-composition. It essentially computes the attention score paid to token 'B' by any token which attended strongly to an 'A'-token in head $h_1$.\n",
    "\n",
    "In each of these matrices, the term 'attention' relates to how much focus or consideration the model gives to specific tokens when generating its output. The 'residual stream' refers to the output of each layer in the transformer model, which includes information from the input as well as transformations performed by the model's self-attention mechanism.\n",
    "\n",
    "The matrix operations such as QK and OV circuits represent the mechanisms of how attention is calculated (QK) and how the attended information is transformed and passed along (OV) in the transformer model. The 'h' represents different attention heads in the transformer model, each of which can focus on different aspects of the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479bd75-f355-4b06-8bcf-12abd7bdfa72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad103d-fe77-44ca-b122-dc835fa6d469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9bbbaa-63cc-4b80-a4d0-d14f8f208b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "440c1e95-2c6d-4b32-aa3b-7d648b136950",
   "metadata": {},
   "source": [
    "Okay, here is a revised explanation of the QK and OV circuits in less formal language:\n",
    "\n",
    "The residual stream contains a vector for each token in the input sequence. Each attention head reads from and writes to this residual stream. The OV circuit of an attention head describes how vectors from the source positions (that the head attends to) are combined and written to each destination position. The residual stream is where information flows through the transformer, so by writing to a position in it, the attention head is giving that position relevant information from the source positions.\n",
    "\n",
    "To interpret $A^T W_E W_{QK}^h W_E^T B$:\n",
    "\n",
    "$A$ and $B$ are one-hot encodings representing two tokens, A and B.\n",
    "$A^T W_E$ gives the embedding for token A.\n",
    "Similarly, $B^T W_E$ gives the embedding for token B.\n",
    "$W_{QK}^h$ is the QK circuit for attention head h. It describes which tokens attend to which others.\n",
    "So, $A^T W_E W_{QK}^h$ gives the \"query\" for token A - it says which other tokens token A attends to.\n",
    "And $W_E^T B$ gives the \"key\" for token B - it's used to determine how much other tokens attend to B.\n",
    "Multiplying the query and key together gives the attention score paid by token A to token B.\n",
    "To compute $W_{QK}$ of an attention head h, we calculate $W_Q^h(W_K^h)^T$, where $W_Q^h$ and $W_K^h$ are the query and key weight matrices for head h.\n",
    "\n",
    "$W_{OV}^h$ is calculated as $W_V^hW_O^h$, where $W_V^h$ and $W_O^h$ are the value and output weight matrices for head h. $W_{OV}^h$ describes how information is combined from the source positions and written to the destination positions.\n",
    "\n",
    "$W_E W_{OV}^h W_U$ differs from $W_{OV}^h$ in that it represents this flow of information in an end-to-end sense, from the original input tokens to the final output logits. $W_E W_{OV}^h W_U$ can be interpreted as:\n",
    "\n",
    "$A^T W_E$ gives the embedding for token A\n",
    "$W_{OV}^h$ describes how information flows from source to destination positions\n",
    "$W_U$ \"unembeds\" the information, mapping it back to the logit space\n",
    "So, $A^T W_E W_{OV}^h W_U$ gives the output logit for token A, based on where the head attends from.\n",
    "$W_E W_{OV}^{h_1} W_{QK}^{h_2} W_E^T$ represents Q-composition between heads h1 and h2. It can be interpreted as:\n",
    "\n",
    "$W_E W_{OV}^{h_1}$ represents the information written to each position by head h1\n",
    "This information is used as the \"query\" for head h2, to determine where it attends from\n",
    "$W_{QK}^{h_2}$ is the QK circuit for head h2, describing where it attends to\n",
    "$W_E^T$ is used to \"unembed\" the keys, mapping them to the input token space\n",
    "So, $W_E W_{OV}^{h_1} W_{QK}^{h_2} W_E^T$ represents the attention in head h2 that results from using the output of h1 as its query.\n",
    "Hope this helps clarify the QK and OV circuits! Let me know if you have any other questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c458804-1939-4fd4-bdaa-5a075b7e45fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850c225f-f08c-4ff8-9056-1ab965d05e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1460e37a-5a8b-494c-846f-d0e7b1c320fc",
   "metadata": {},
   "source": [
    "The presented question prompts are an exploration of the Transformer architecture, particularly the attention mechanism. They are about understanding the role and significance of different components, particularly the QK (Query-Key) and OV (Output-Value) circuits in a Transformer model.\n",
    "\n",
    "Here are the responses to the prompts:\n",
    "\n",
    "What does $W_E W_{OV}^h W_U$ represent?\n",
    "\n",
    "$W_E W_{OV}^h W_U$ represents the entire OV circuit. It maps an input token, through its embedding, to the output of a given attention head, and finally back to the vocabulary space. This describes how information flows from the input token to the output token, mediated by the attention head in a \"start-to-end\" sense.\n",
    "\n",
    "How to interpret $A^T W_E W_{QK}^h W_E^T B$?\n",
    "\n",
    "This term represents the attention score of token B paid by token A. Here, token A acts as the query and token B as the key. If tokens A and B are one-hot encodings for their respective tokens, then this expression essentially measures the relevance of token B to token A, according to attention head h.\n",
    "\n",
    "How to compute $W_{QK}$ of an attention head h?\n",
    "\n",
    "$W_{QK}$ can be computed by $W_{QK}^h:=W_Q^h\\left(W_K^h\\right)^T$. This represents the Query-Key circuit for head h, which is a bilinear form describing how tokens in the residual stream attend to each other.\n",
    "\n",
    "How to compute $W_{OV}$ of an attention head h?\n",
    "\n",
    "$W_{OV}$ for an attention head h can be calculated by $W_{OV}^h:=W_V^h W_O^h$. This represents the Output-Value circuit of an attention head, which describes how source information is moved to the destination in the residual stream.\n",
    "\n",
    "How does $W_{OV}^h$ differ from $W_E W_{OV}^h W_U$?\n",
    "\n",
    "$W_{OV}^h$ refers to the Output-Value circuit for a particular attention head, describing how information is moved from source to destination in the residual stream. On the other hand, $W_E W_{OV}^h W_U$ represents the entire OV circuit which encapsulates the complete flow of information from the input token to the output token, taking into account token embeddings and reverse-embedding (unembedding).\n",
    "\n",
    "How to interpret $W_E W_{OV}^{h_1} W_{QK}^{h_2} W_E^T$?\n",
    "\n",
    "This expression represents Q-composition between two different attention heads, $h_1$ and $h_2$. It essentially describes how the query-side vector, formed from the output of head $h_1$, affects the attention scores in head $h_2$. If tokens A and B are one-hot encodings for their respective tokens, this term captures the attention score paid to token B by any token which attended strongly to an A-token in head $h_1$.\n",
    "\n",
    "As for the final question in the prompt - computing large matrices might indeed be inefficient and could cause out-of-memory errors. Instead of directly computing these large matrices, one could try to work with them in a factorized form or use methods that don't require explicit computation. Sampling techniques or approximations may also be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9779511b-817c-438e-ab41-457b2a2856d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69fd52c1-6bac-49c0-89c5-b2ce92505966",
   "metadata": {},
   "source": [
    "chatgpt2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1455cb-2ef6-40b6-9646-888053826e92",
   "metadata": {},
   "source": [
    "Let's answer these questions:\n",
    "\n",
    "1. What does $W_E W_{O V}^h W_U$ represent?\n",
    "\n",
    "$W_E W_{O V}^h W_U$ is the full OV circuit. This describes what information gets moved from source to destination, from the start of the input to the end of the output. For a given token A, it calculates the unembedding of the vector that would be written to the residual stream if the destination token only paid attention to token A.\n",
    "\n",
    "2. How to interpret $A^T W_E W_{Q K}^h W_E^T B$?\n",
    "\n",
    "This is a bilinear form that describes where information is moved to and from, among words in the vocabulary. It gives the attention score paid by token A to token B.\n",
    "\n",
    "3. How to compute $W_{QK}$ of an attention head h?\n",
    "\n",
    "$W_{Q K}^h$ is computed as the product of the query weight matrix and the transpose of the key weight matrix for a given head $h$: $W_{Q K}^h:=W_Q^h\\left(W_K^h\\right)^T$.\n",
    "\n",
    "4. How to compute $W_{OV}$ of an attention head h?\n",
    "\n",
    "$W_{O V}^h$ is computed as the product of the value weight matrix and the output weight matrix for a given head $h$: $W_{O V}^h:=W_V^h W_O^h$.\n",
    "\n",
    "5. How does $W_{O V}^h$ differ from $W_E W_{O V}^h W_U$?\n",
    "\n",
    "$W_{O V}^h$ describes what information gets moved from source to destination in the residual stream, while $W_E W_{O V}^h W_U$ describes the same process but in a start-to-end sense, converting the input from token space to the embedding space and finally unembedding it.\n",
    "\n",
    "6. How to interpret $W_E W_{O V}^h W_U$?\n",
    "\n",
    "As mentioned earlier, this is a matrix that describes what information is moved from source to destination, in a start-to-end sense. It represents the output of the OV circuit for a given head.\n",
    "\n",
    "7. How to interpret $W_E W_{O V}^{h_1} W_{Q K}^{h_2} W_E^T$?\n",
    "\n",
    "This matrix describes where information is moved to and from in head $h_2$, given that the query-side vector is formed from the output of head $h_1$. In other words, it describes Q-composition from head $h_1$ to head $h_2$. If $A$ and $B$ are one-hot encodings for tokens A and B, then the $(A, B)$-th element of the matrix is the attention score paid to token B, by any token which attended strongly to an A-token in head $h_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d237c6-4e39-4762-9374-73125a597f81",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95306d0c-7e20-4a61-902a-2310f6213753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import overload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be05db5d-6c77-40bb-84dd-120ac0cdadb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@overload\n",
    "def getitem(x: str) -> str:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09507306-1e6f-4fcc-a3d5-dc6fdfe7bfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@overload\n",
    "def getitem(x: List[int]) -> int:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f081cc9f-0a66-4cff-ae0a-4f2c57973ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: create a network\n",
    "step 2: attach\n",
    "step 3: get ip\n",
    "step 4: communicate through the ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48374690-9c9e-4082-b1c6-f5df5cc1d1b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc981b3-eea0-43e2-a82d-fc4b6f7f1184",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bb2554f-e202-468a-9272-db60472d6ef9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def one_hot(idx, length):\n",
    "    x = torch.zeros(length)\n",
    "    x[idx] = 1.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776d9b52-95dc-470a-bafb-c5ea62d1fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "have you been doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dd0105-bf0e-4f67-8094-8425dd95d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "two uncertainty principles\n",
    "quantization of action\n",
    "angular momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c231f7a-6744-4297-a985-385f24419ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "photoreceptor cell > bipolar cell > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f5a58d-b43f-49fa-b4ee-a40b56e19e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron 1 > axon > synapse > dendrite > neuron 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09add69e-2224-4cf9-aea7-ed5c071a59c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summary_batch(article_batches, max_context_length):\n",
    "    results = []\n",
    "    \n",
    "    for article_batch in article_batches:\n",
    "        tokens = tokenizer(\n",
    "            article_batch,\n",
    "            max_context_length=max_context_length,\n",
    "            **tokenizer_params\n",
    "        )\n",
    "        \n",
    "        outputs = model.generate(\n",
    "            **tokens,\n",
    "            **model_params\n",
    "        )\n",
    "        \n",
    "        decoded_summary = [tokenizer.decode(x) for x in outputs]\n",
    "        results.append(decoded_summary)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22a56fe9-9010-41c9-917f-be6bd486f2f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31d2bfb-8924-453e-ad53-d224183ae215",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = rearrange(\n",
    "    images,\n",
    "    \"b c (n_h p_h) (n_w p_w) -> b (n_h n_w) ()\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "260aac1e-888b-42f0-a097-7f1fddb9d169",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Agent(nn.Module):\n",
    "    def __init__(self, n_observations, n_actions, n_hidden):\n",
    "        super().__init__()\n",
    "        self.actor_network = nn.Sequential(\n",
    "            nn.Linear(n_observations, n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, n_actions)\n",
    "        )\n",
    "        \n",
    "        self.critic_network = nn.Sequential(\n",
    "            nn.Linear(n_observations, n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, n_actions),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, observations):\n",
    "        logits = self.actor_network(observations)\n",
    "        dist = torch.distributions.Categorical(logits=logits)\n",
    "        action = torch.argmax(probs, dim=-1)\n",
    "        log_prob = dist.log_prob(action)\n",
    "        critic_value = self.critic_network(observations)\n",
    "        return action, log_prob, dist.entropy(), critic_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934351e6-0f1c-4a19-8f75-f894e004bb51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
