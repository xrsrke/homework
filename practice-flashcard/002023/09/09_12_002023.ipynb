{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c31fb4a3-81d6-406e-84bd-4f3b392ef980",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b560ed4-d5fa-4c6a-b5d2-fd99e5a4a719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_gpus = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80ec9e2f-0b42-4ca4-8e9a-44f0a86022b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "world_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f6f5b8e-65a1-497e-b097-0cac846eb254",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank: 0 -> 0\n",
      "rank: 1 -> 1\n",
      "rank: 2 -> 2\n",
      "rank: 3 -> 3\n",
      "rank: 4 -> 0\n",
      "rank: 5 -> 1\n",
      "rank: 6 -> 2\n",
      "rank: 7 -> 3\n",
      "rank: 8 -> 0\n",
      "rank: 9 -> 1\n",
      "rank: 10 -> 2\n",
      "rank: 11 -> 3\n",
      "rank: 12 -> 0\n",
      "rank: 13 -> 1\n",
      "rank: 14 -> 2\n",
      "rank: 15 -> 3\n"
     ]
    }
   ],
   "source": [
    "for rank in range(world_size):\n",
    "    print(f\"rank: {rank} -> {rank%num_gpus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bead2107-6483-4c34-b815-b7889d0f3fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reassign workload, monitor, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec7af7a-cea8-404a-b412-bc03e7557fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "int *h_a, *h_b, *h_c;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528ebda9-aec5-402e-b779-59aa9451aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_a = (int*)malloc(h_a);\n",
    "h_a = (int*)malloc(h_a);\n",
    "h_a = (int*)malloc(h_a);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cfe5329-fcd7-4f8c-840a-efd9c7936c30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad44a8c5-acb4-40d2-b1fb-63e70b3693b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def use_hooks(model, hooks):\n",
    "    try:\n",
    "        handles = []\n",
    "        for hook in hooks:\n",
    "            model.transformer.h[1].register_pre_forward_hook(hook)\n",
    "        yield\n",
    "    finally:\n",
    "        for handle in handles:\n",
    "            handle.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53830340-5d2b-463f-b034-cd8568cfa19a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b986fd-59e3-4907-893e-06d6a0508e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_final_ln_name = get_act_name(\"post\", 2)\n",
    "post_final_ln = get_act_name(\"normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a51225-60c7-445c-8db3-dccb1c14c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259386f7-06cd-43fc-baf7-eef9307259bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_final_ln = cache[pre_final_ln_name]\n",
    "post_final_ln = cache[post_final_ln]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3efc6d3c-f955-4671-b069-35f945b9a680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e8374a-472b-4094-a2c0-c31127697305",
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearRegression().fit(pre_final_ln, post_final_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deebdf1-421a-4d8e-8773-3fc06f006799",
   "metadata": {},
   "outputs": [],
   "source": [
    "handles = []\n",
    "for hook in hooks:\n",
    "    handles.append(model.ln_f.register_forward_hook(hook))\n",
    "\n",
    "handles[1].remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e112bab6-83ee-4f09-993e-032eda7231e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15a492a3-9df9-482c-8840-a128ba5a7e6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataParallel:\n",
    "    def __init__(self, module, parallel_context):\n",
    "        self.module = module\n",
    "        self.parallel_context = parallel_context\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def parallelize(self):\n",
    "        module = self.module\n",
    "        \n",
    "        if self.parallel_context.data_parallel_size > 1:\n",
    "            self._register_backward_hook(module)\n",
    "        \n",
    "        return module\n",
    "    \n",
    "    def _register_backward_hook(self, module):\n",
    "        for p in module.parameters():\n",
    "            if p.requires_grad:\n",
    "                p.register_hook(self._avg_grad)\n",
    "    \n",
    "    def _avg_grad(self, grad):\n",
    "        data_parallel_size = self.parallel_context.data_parallel_size\n",
    "        process_group = self.parallel_context.get_group(ParallelMode.DATA)\n",
    "        \n",
    "        new_grad = grad / data_parallel_size\n",
    "        dist.all_reduce(new_grad, op=dist.ReduceOp.SUM, group=process_group)\n",
    "        \n",
    "        return new_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e02c15bb-e150-4435-b8e5-05dc5f6b36bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_partitions = 4\n",
    "n_microbatches = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eee0c46e-cbb8-48bc-bf1e-b444ed1972c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clock_cycles = n_partitions + n_microbatches - 1\n",
    "\n",
    "schedules = []\n",
    "for clock_idx in range(n_clock_cycles):\n",
    "    start_partrition = max(clock_idx + 1 - n_microbatches, 0)\n",
    "    end_partition = min(clock_idx + 1, n_partitions)\n",
    "\n",
    "    tasks = []\n",
    "    for partition_idx in range(start_partrition, end_partition):\n",
    "        microbatch_idx = clock_idx - partition_idx\n",
    "        tasks.append((microbatch_idx, partition_idx))\n",
    "\n",
    "    schedules.append(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0bc4246-dbe8-424d-96dc-1b77a9f97a47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0)],\n",
       " [(1, 0), (0, 1)],\n",
       " [(2, 0), (1, 1), (0, 2)],\n",
       " [(2, 1), (1, 2), (0, 3)],\n",
       " [(2, 2), (1, 3)],\n",
       " [(2, 3)]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19ef4968-d532-4f5c-8c70-6c0d99f1de12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reverse_nested_list(lst):\n",
    "    reversed_list = []\n",
    "    \n",
    "    for item in lst:\n",
    "        if isinstance(item, list):\n",
    "            reversed_list.append(reverse_nested_list(item)) \n",
    "        else:\n",
    "            reversed_list.insert(0, item)\n",
    "            \n",
    "    return reversed_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a3b911c-5f1b-48e3-84e8-0b40d8daf412",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0)],\n",
       " [(0, 1), (1, 0)],\n",
       " [(0, 2), (1, 1), (2, 0)],\n",
       " [(0, 3), (1, 2), (2, 1)],\n",
       " [(1, 3), (2, 2)],\n",
       " [(2, 3)]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_nested_list(schedules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c31244c7-dd17-4e28-bd79-7448d59aa7f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 5, 6], [2, 3], [1]]\n"
     ]
    }
   ],
   "source": [
    "lst = [[1], [2, 3], [4, 5, 6]]\n",
    "lsschedulest.reverse()\n",
    "print(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "766829a5-fc13-42ae-8ae4-3402f7a8bc39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schedules.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "861cae6f-158c-49bb-bd88-5b1a3f9bae0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2, 3)],\n",
       " [(2, 2), (1, 3)],\n",
       " [(2, 1), (1, 2), (0, 3)],\n",
       " [(2, 0), (1, 1), (0, 2)],\n",
       " [(1, 0), (0, 1)],\n",
       " [(0, 0)]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3722c5d9-080b-44ba-b78b-7118c75b7e6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def variance(x):\n",
    "    return (x-x.mean())/x.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa2826-97ad-4f8c-8fac-5b53e5c52bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_head):\n",
    "        super().__init__()\n",
    "        self.d_head = d_head\n",
    "    \n",
    "    def forward(self, q, k, v, mask = None):\n",
    "        k = k.permute(-1, -2)\n",
    "        qk = torch.matmul(q, k) / (self.d_head**0.5)\n",
    "        \n",
    "        if mask is not None:\n",
    "            qk.masked_scores(mask == True, 1e-9)\n",
    "        \n",
    "        scores = F.softmax(qk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1520fe-9851-4721-a25c-201e92e8869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_part @ filter_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83ece0fa-05f9-4f39-94e6-0e1079c10a90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "49a4ba4c-3301-4ce9-a8ad-5b55a9c35a04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "VALUE = 69"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24bd5fd-d6c2-4440-8ab4-daee06c5cfe3",
   "metadata": {},
   "source": [
    "Create a future object with the value equal to `VALUE`, and it automatically prints `69420` after setting a result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "86b92165-90a5-4f3a-8c82-867ff0908ac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def callback(fut):\n",
    "    print(69420)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e5f4eb87-97e6-44ef-ac34-c13af5e89674",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.jit.Future at 0x7ff2d2352680>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fut = torch.futures.Future()\n",
    "fut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "526b4efd-7dff-4ffb-95d4-bacd4b9d0818",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69420\n"
     ]
    }
   ],
   "source": [
    "fut.add_done_callback(callback)\n",
    "fut.set_result(VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3b226f75-e061-49c1-bd75-e069172f33b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fut.value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3337c937-dafd-4c16-9a4e-23d7e9d46b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
