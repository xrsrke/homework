{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25fbf923-817a-4720-92a8-638d52bdebac",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1933492-5dcf-467c-99a7-44729420b091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "242f5c83-1316-42b8-a76f-1c44b1321f77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef40fb-d0cf-4144-b11c-44bd5d94b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f62d14-5d3f-4667-9b9e-65d98adeee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize communication\n",
    "maximize storage\n",
    "minimize FLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f95e8b66-7c1c-4589-a4a6-bc52e6db5689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class _P2P:\n",
    "    def _recv_metadata(self, src_rank, parallel_context, parallel_mode):\n",
    "        process_group = parallel_context.get_group(parallel_mode)\n",
    "        \n",
    "        dtype = torch.tensor(0)\n",
    "        dist.recv(dtype, src=src_rank, group=process_group)\n",
    "        dtype = ID_TO_DYPE[dtype]\n",
    "        \n",
    "        requires_grad = torch.tensor(0)\n",
    "        dist.recv(requires_grad, src=src_rank, group=process_group)\n",
    "        requires_grad = True if requires_grad == 1 else False\n",
    "        \n",
    "        shape = torch.tensor(0)\n",
    "        dist.recv(shape, src=src_rank, group=process_group)\n",
    "        return dtype, requires_grad, shape\n",
    "    \n",
    "    def recv(self, src_rank, parallel_context, parallel_mode):\n",
    "        process_group = parallel_context.get_group(parallel_mode)\n",
    "        dtype, requires_grad, shape = self._recv_metadata(src_rank, parallel_context)\n",
    "        \n",
    "        data = torch.zeros(shape, requires_grad=requires_grad, dtype=dtype)\n",
    "        dist.recv(data, src=src_rank, process_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78506e98-e085-4c3d-87fb-e9073df3903c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recv(src_rank, dst_rank, parallel_context, parallel_mode = ParallelMode.PIPELINE):\n",
    "    rank = parallel_context.get_local_rank(parallel_mode)\n",
    "    if rank == dst_rank:\n",
    "        return _P2P().recv(src_rank, parallel_context, parallel_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db07f2a0-357e-4fad-8d2c-90de5df7aa51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d63d550-cfef-4a0c-9202-c8db0d40ea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPU:\n",
    "    def __init__(self, master_addr, master_port, backend):\n",
    "        if not dist.is_initialized():\n",
    "            init_method = f\"tcp://{master_addr}:{master_port}\"\n",
    "            rank = os.getenv(\"RANK\")\n",
    "            world_size = os.getenv(\"WORLD_SIZE\")\n",
    "            \n",
    "            self.set_device(rank)\n",
    "            \n",
    "            dist.init_process_group(\n",
    "                rank=rank,\n",
    "                world_size=world_size,\n",
    "                init_method=init_method,\n",
    "                backend=backend\n",
    "            )\n",
    "    \n",
    "    def set_device(self, rank):\n",
    "        n_devices = torch.cuda.device_count()\n",
    "        \n",
    "        if n_devices > 1:\n",
    "            torch.cuda.set_device(rank%n_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989818b0-6885-4708-a6d2-ca03ca60936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: mask targets\n",
    "step 2: calcualte the local predicted logits\n",
    "step 3: calculate the global predicted logits\n",
    "step 4: sum\n",
    "step 5: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e20526d-daf1-40e2-9a8e-2f7eb7be6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "using namespace std;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d1ea3-48a2-4740-a5fb-5acb588a1b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int x = 1;\n",
    "    std::cout << &x;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7980dc2-39e7-4ce8-b64f-8c7f1cfe9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pod > node > container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b17fa4a-5de4-400f-ac78-e7d40dfde081",
   "metadata": {},
   "outputs": [],
   "source": [
    "recompute, forward, backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4581a5a0-18ec-45ff-a1c6-17d287477300",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recompute(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, phony, recomputed, function, input):\n",
    "        ctx.recomputed = recomputed\n",
    "        ctx.function = function\n",
    "        ctx.input = input\n",
    "        \n",
    "        return phony\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        with torch.enable_grad():\n",
    "            output = ctx.function(ctx.input)\n",
    "        \n",
    "        ctx.recomputed.append((output, input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe8b827-dd62-426c-a860-d53d45b1015e",
   "metadata": {},
   "outputs": [],
   "source": [
    "node changes\n",
    "keep track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4ba771-99b3-47ae-80e6-a86c123a3ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08311261-608d-4add-9f69-5a2a31113f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = model.embed(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cdbb5e5-6459-4a61-a499-203f371680ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def by_row_parallelism(inputs, weights):\n",
    "    inp_per_partition = inputs.shape[-1] // 2\n",
    "    w_per_partition = weights.shape[-1] // 2\n",
    "    \n",
    "    inp1 = inputs[:, inp_per_partition:]\n",
    "    inp2 = inputs[:, :inp_per_partition]\n",
    "    w1 = weights[:w_per_partition, :]\n",
    "    w2 = weights[w_per_partition:, :]\n",
    "    \n",
    "    out1 = inp1 @ w1\n",
    "    out2 = inp2 @ w2\n",
    "    \n",
    "    return out1 + out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf269712-54ac-493a-b966-1a9aa91c3719",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "world_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e48541e8-ccf5-41db-b293-51d03aaa75f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor_parallel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90558d9b-99f5-4931-b6fa-63712f5416a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_parallel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb536191-d029-4c21-989b-7fed9d9090c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_pipeline_parallel_groups = world_size // pipeline_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "839de449-869a-48c1-9843-35d437f55e5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_parallel_groups = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91f85667-a1ca-414f-b626-1b1658fa8daa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2]\n",
      "[1, 3]\n",
      "[4, 6]\n",
      "[5, 7]\n",
      "[8, 10]\n",
      "[9, 11]\n",
      "[12, 14]\n",
      "[13, 15]\n"
     ]
    }
   ],
   "source": [
    "for i in range(pipeline_parallel_size):\n",
    "    start_rank = i*num_pipeline_parallel_groups\n",
    "    end_rank = (i+1)*num_pipeline_parallel_groups\n",
    "    \n",
    "    for j in range(tensor_parallel_size):\n",
    "        ranks = list(range(\n",
    "            start_rank+j,\n",
    "            end_rank,\n",
    "            tensor_parallel_size\n",
    "        ))\n",
    "        \n",
    "        print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7de33f-2f41-4206-8cc3-8ac19779a41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx + partition_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b2b157a-cbab-45c7-84fe-e581724e12d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import cast, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425bc04d-631e-4ccf-ad65-cdf4ff892f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = cast(List[int], numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c9c3c79-36a0-48ce-bb17-6c2c0b3eca94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0578e3-1efd-42b6-81fb-efd4c6fb25e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "job selector > spawn workers > pool monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd0dd13-a983-4f6d-a56c-96717d8a04cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ad5909-b5ca-4883-9fe8-673587853cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln02 = model.blocks[0].ln2\n",
    "mlp0 = model.blocks[0].mlp0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06c2cd0-4fd4-44df-ad56-ceb08e9cd561",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8174ccf0-849c-4727-bfc5-7f9074692bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    " ep_info = [\n",
    "    {\"enc\": dict(), \"dec\": dict()}\n",
    "    for i in range(len(ExpertParallelGroupInitializer.BASE_ELEMENT))\n",
    "]\n",
    "\n",
    "# Encoder\n",
    "# if \"enc\" in self.expert_parallel_size:\n",
    "#     self.construct_stack_parallel_info(ep_info, stack=\"enc\")\n",
    "\n",
    "# Decoder\n",
    "if \"dec\" in self.expert_parallel_size:\n",
    "    self.construct_stack_parallel_info(ep_info, stack=\"dec\")\n",
    "\n",
    "ep_info += [ParallelMode.EXPERT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c033ec-f6f2-4de7-8ad3-1b1017f6a740",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in self.expert_parallel_size[stack].items():\n",
    "    cur_ep_info = self.init_dist_group_per_unit(v)\n",
    "\n",
    "    for i, info in enumerate(cur_ep_info):\n",
    "        ep_info[i][stack][k] = info\n",
    "\n",
    "return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50fb0f45-f090-49c3-85c2-66fd3a90b7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddb85e10-daac-42ec-9379-5df76dc601a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Metadata:\n",
    "    idx: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56a18ad5-be29-4307-b49d-1e9f08f6bfb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Back(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, metadata, input):\n",
    "        ctx.metadata = metadata\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        return ctx.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b43ede34-444b-414f-904c-37e0a31d1375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor = torch.randn(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "260dc7ea-627e-437e-9458-513558610bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = Metadata(idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "62a97b99-1ff4-461e-832e-ae747cb8c838",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "attribute 'metadata' of 'torch._C._FunctionBase' objects is not writable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mBack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_context \u001b[38;5;241m==\u001b[39m _SingleLevelFunction\u001b[38;5;241m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[41], line 4\u001b[0m, in \u001b[0;36mBack.forward\u001b[0;34m(ctx, metadata, input)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(ctx, metadata, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m \u001b[38;5;241m=\u001b[39m metadata\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: attribute 'metadata' of 'torch._C._FunctionBase' objects is not writable"
     ]
    }
   ],
   "source": [
    "Back.apply(metadata, tensor).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4abc8303-e9c0-4d77-864f-cfb7c2fce1f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def function(self):\n",
    "    return self.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc9d34ca-54aa-448a-9cff-42923746daa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Job:\n",
    "    def __init__(self, function):\n",
    "        self.function = function\n",
    "        self.x = 1\n",
    "    \n",
    "    def run_func(self):\n",
    "        return self.function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "12537cbd-8092-4420-9eb0-3d345a2130b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job = Job(function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2eb0726b-4276-4fd7-b659-251e9b56be0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "function() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[48], line 7\u001b[0m, in \u001b[0;36mJob.run_func\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_func\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: function() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "job.run_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115b27b2-11ac-4d14-8973-c107264c647a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
