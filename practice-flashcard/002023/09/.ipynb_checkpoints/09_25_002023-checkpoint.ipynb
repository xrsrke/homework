{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a65bcb8d-5316-482f-bad5-861a57592ba9",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c32eb52-5cbc-4c37-9cb4-762107e9227e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1221bf99-ba54-489d-88ac-d09ec26ede8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2db9402-3ed8-47e2-81ce-257c2f11a819",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_cross_entropy(logits, targets):\n",
    "    log_probs = F.log_softmax(logits, dim=-1)\n",
    "    return -log_probs[range(targets.shape[0]), targets].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f50c662-796f-406c-b803-024376b49045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gymnasium.spaces import Discrete, Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24e5061-2078-4f49-9b48-8ae3fb853f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv:\n",
    "    def __init__(self):\n",
    "        self.observation_space = Box(\n",
    "            low=np.array([0]),\n",
    "            high=np.array([100])\n",
    "        )\n",
    "        self.action_space = Discrete(3)\n",
    "    \n",
    "    def step(self):\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        self.temperature = 20\n",
    "        self.shower_length = 60\n",
    "        return self.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b02196fa-fb03-4169-9660-cac137d919e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def discount_reward(rewards, discount_factor):\n",
    "    return rewards*discount_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcab45da-1a85-4973-937f-be046fbbc438",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rewards = torch.tensor([1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "187f2051-5e32-4eac-87ca-f032aa7f33ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9900, 1.9800, 2.9700, 3.9600])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discount_reward(rewards, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888d0ab3-daf6-4457-9b6e-6c3a4f67aee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: group dispatching\n",
    "step 2: local capacity constrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edaed0d-db32-4d0b-b0ae-0ca8e5aa72cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: determine global rank\n",
    "step 2: \n",
    "step 3: parallelize embedding, head, mlp, layer norm\n",
    "step 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb651e2-560f-41c4-961a-3523af18c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "job selector > spawn initial workers > job monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8eb630-b893-4a6e-acf4-b57e5294e53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "syncronization, handshake, job queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385a1ffb-6d63-4a78-88c5-37254f4675cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.broadcast(x, src=0, async_op=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79e5f73-296a-49d6-8af6-f9a70042958d",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_handler = dist.broadcast(x, src=0, async_op=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4114ac4-6668-4449-932b-1b2c2e0300ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_handler.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d50fd3b-3c46-4f90-bfbf-a4aa0865bdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready, running, failed, succeed, cooldown, blacklisted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11d71c4a-5acd-4108-a6a9-63ac40731f5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Broadcast(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        return dist.all_reduce(grad_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c22fcf9f-ef0b-4f7b-aeeb-05c03bcbc4da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Gather(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        world_size = dist.get_world_size()\n",
    "        inputs = [torch.randn_like(input) for _ in range(world_size)]\n",
    "        dist.all_gather(inputs, input)\n",
    "        inputs = torch.cat(inputs, dim=0)\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        rank = dist.get_rank()\n",
    "        world_size = dist.get_world_size()\n",
    "        chunks = torch.chunk(grad_input, chunks=world_size)\n",
    "        return chunks[rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3c8cf6d-d676-474b-a3de-6706fe8ed590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ColumnParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size, world_size):\n",
    "        super().__init__()\n",
    "        per_partition = output_size // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.randn(\n",
    "            self.per_partition,\n",
    "            self.input_size\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.randn(\n",
    "            self.per_partition,\n",
    "            self.input_size\n",
    "        ))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input_parallel = Broadcast.apply(input)\n",
    "        output_parallel = F.linear(\n",
    "            input_parallel,\n",
    "            self.weight,\n",
    "            self.bias\n",
    "        )\n",
    "        outputs = Gather.apply(output_parallel)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d793d4e-8cd3-44e6-a3e0-0348f1bd9e24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ranks = [0, 1, 3, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea4bd85-2ea2-4245-b369-49c18309cefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = dist.get_rank()\n",
    "process_group = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0000cc-7571-4edc-8047-ca485b1e7d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rank in ranks:\n",
    "    process_group = dist.new_group(ranks=rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b03e97-c25d-4189-8ec6-29d4bfe442ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if process_group is not None:\n",
    "    dist.broadcast(0, group=process_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f97b421-8fdd-4e6f-888f-6b0a13f042e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "message passing, shared memory, file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1210ac53-826f-4159-b919-1893b9ed4d31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "world_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7fc6da8-8797-4846-8e28-00074c37b995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor_parallel_size = 2\n",
    "pipeline_parallel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8d49161-7566-4375-a27a-91bbb580f57c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_pipeline_parallel_groups = world_size // pipeline_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "550f5652-be3f-410c-80ec-7fd00ff10ac4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2]\n",
      "[1, 3]\n",
      "[4, 6]\n",
      "[5, 7]\n",
      "[8, 10]\n",
      "[9, 11]\n",
      "[12, 14]\n",
      "[13, 15]\n"
     ]
    }
   ],
   "source": [
    "for i in range(pipeline_parallel_size):\n",
    "    start_rank = i*num_pipeline_parallel_groups\n",
    "    end_rank = (i+1)*num_pipeline_parallel_groups\n",
    "    \n",
    "    for j in range(tensor_parallel_size):\n",
    "        ranks = list(range(\n",
    "            start_rank+j,\n",
    "            end_rank,\n",
    "            tensor_parallel_size\n",
    "        ))\n",
    "        \n",
    "        print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395ae4a0-be93-48fb-bc34-a842cd6c3e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic driver, torchstate, hostdiscovery,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a288d658-84f2-40b9-945e-37a22bafe09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f73003-58ba-4487-88c3-b6b288b3bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = F.softmax(switch(inputs), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f380ddca-5176-4cf6-a3c4-efa546a527ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, idxs = torch.max(probs, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbf7a01-7804-4d7d-87c1-4fb78d2d585b",
   "metadata": {},
   "source": [
    "step 1: tokens are split into G group that dispatch experts in parallel\n",
    "step 2: calculate local capacity\n",
    "step 3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afbb786-1acb-49d8-af3e-53024137ac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, k, v, output projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efbb7345-94fd-4524-abee-42891c28dfcb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import rearrange, einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e492ea3-3f7f-40dc-ad7e-69eb3601d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "einsum(x, y, \"batch dim, batch dim ->\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eed44019-1d12-42d4-b93a-a1480e5db402",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import overload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b197eea-1d1f-4af5-a67d-77e4d2f02fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@overload\n",
    "def getitem(x: str) -> str:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aeea8b23-abe1-4c79-a155-6ad9290ba27d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8a608f4-a924-47b4-b9af-38177abf852d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@overload\n",
    "def getitem(x: List[int]) -> int:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e802b4e7-a6e5-4ee5-b9a8-f2db9c7dea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c2ad5a1-4bd6-4678-a0a0-ceacad28359b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a19f26-1bce-40a6-abb5-7c905d1b5a99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb5b8c0-4be8-4d8e-9693-76bb9f906d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_worker(rank, world_size):\n",
    "    rpc.init_rpc(\n",
    "        name=AGENT_NAME.format(rank),\n",
    "        rank=rank,\n",
    "        world_size=world_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac20e42-4cdb-4dc7-801c-fb41dbcf145f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rank in range(world_size):\n",
    "    p = mp.Process(run_worker, args=(rank, world_size))\n",
    "    p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564fecdc-5b98-4646-86b8-099cabdc404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert, router, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9744b67-9773-426c-a422-9bf1ebb3304c",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U\n",
    "logit_diff_dir = W_U[:, 0] - W_U[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeb3d43-f458-4d19-8e4e-2f793881581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83c428b-abf6-4fcd-84af-fbd247b4e09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_components = torch.cat([\n",
    "    cache[\"embed\"],\n",
    "    cache[\"pos_embed\"],\n",
    "    cache[\"\"]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b78893-a399-48ae-9bd0-a5a28dcb3e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df59ded2-21cd-4f8a-b191-e4a409795bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, head_idx = 2, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f766db-1719-42a3-92b8-77b05e1d47b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_OV = model.W_V[layer_idx, head_idx] @ model.W_O[layer_idx, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84b17ba2-bba4-4915-863b-26d848462e87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73916ee8-b969-46d3-890e-e5cddff04e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_final_ln_name = get_act_name(\"resid_post\", 2)\n",
    "head20_pre_ln_name = get_act_name(\"resid_pre\", 2)\n",
    "head_20_post_ln_name = get_act_name(\"normalized\", 2, \"ln1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4691497c-bbc3-446c-890c-f4cf49e5a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6f63f7-7a47-4a3a-8352-8fa39fd23944",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_final_ln_acts = cache[pre_final_ln_name]\n",
    "post_final_ln_acts = cache[post_final_ln_acts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "294ee0b3-7224-4f81-a6d3-850c4bed2461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "head_idx, layer_idx = 6, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72926e3d-c67e-47e9-bf5f-7138b29b6cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E\n",
    "W_U = model.W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3accaeb-982e-4a9d-8e41-4e00675ca52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_O = model.W_O[layer_idx, head_idx]\n",
    "W_V = model.W_V[layer_idx, head_idx]\n",
    "\n",
    "full_OV_circuit = W_E @ W_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474f52fb-f039-4c2f-958e-f5cbc46afe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch im"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
