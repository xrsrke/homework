{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b13e76ce-21f0-49d0-a62e-b0bdd3e89106",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1728a30-bfb1-47fb-b1fb-8a1e996b9fe0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa80611a-09ab-4f86-82f0-6887d9114d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: resize vocab size\n",
    "step 2: split weight\n",
    "step 3: assign "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab93dce-44fa-41e8-993b-95114c427e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight @ input = output\n",
    "input = weight.T @ output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9472dfcf-7a20-46d4-840f-d757edca48cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "W /= W.norm(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8407cbbc-1dc7-4645-a1a2-b59663367673",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = W @ W.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f26011f-c792-4c2d-827b-dd34abb7b5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E\n",
    "W_Q model.W_Q[1, 4]\n",
    "W_K = model.W_K[1, 4]\n",
    "W_OV = model.W_V[0, 7] @ model.W_O[0, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a664b7-19d8-42c2-9040-adf96b616101",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = W_E @ W_Q\n",
    "K = W_OV @ W_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00ea4e71-dcb4-4b1f-bf72-d6378d460803",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "receiver_heads = [(7, 3), (7, 9), (8, 6), (8, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edba9e31-b0f9-44ee-9026-cca6c13ed1da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "receiver_layers = [7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eb8295c-9840-4ba5-b9e6-a0172c20326c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4112e4e-d408-47d1-8533-15443fd4f2d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_heads = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d40442c-7406-40a4-957f-8138ccd28da6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sender_heads = list(product(range(max(\n",
    "    receiver_layers)), range(n_heads)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c153d105-7a7b-4262-a0e1-807c7b256545",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_sender_head_output(\n",
    "    acts, hook,\n",
    "    clean_cache, corrupted_cache, trg_head\n",
    "):\n",
    "    trg_layer_idx, trg_head_idx = trg_head\n",
    "    \n",
    "    if hook.layer() == trg_layer_idx:\n",
    "        acts[:, :, trg_head_idx] = corrupted_cache[hook.name][:, : trg_head_idx]\n",
    "    else:\n",
    "        acts = clean_cache[hook.name]\n",
    "    \n",
    "    return acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90e434ab-0651-42f0-9775-60536eec4d82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_receiver_head_input(acts, hook, receiver_heads):\n",
    "    # patch all receiver head inputs at once\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d919cbec-801e-4ea4-b7b8-bbaaa1e346cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55dc0e74-0cb0-48a8-ae92-9d33380feab6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55497ac2-d352-4039-b028-84f76d3ce84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_cache = model.run_with_cache(clean_tokens)\n",
    "_, corrupted_cache = model.run_with_cache(corrupted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c41755-08b7-4a7d-8b1d-af29d3bf3b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.zeros(n_layers, n_heads)\n",
    "\n",
    "for layer_idx, head_idx in sender_heads:\n",
    "    model.reset_hooks()\n",
    "    hook_name = get_act_name(\"z\", layer_idx)\n",
    "    hook_func = partial(\n",
    "        patch_sender_head_output,\n",
    "        clean_cache=clean_cache,\n",
    "        corrupted_cache=corrupted_cache,\n",
    "        trg_head=(layer_idx, head_idx)\n",
    "    )\n",
    "    model.add_hook(hook_name, hook_func)\n",
    "    _, patched_cache = model.run_with_cache(clean_tokens)\n",
    "    \n",
    "    hook_name = get_act_name(\"v\", layer_idx)\n",
    "    hook_func = partial(\n",
    "        patch_receiver_head_input\n",
    "    )\n",
    "    \n",
    "    patched_logits = model.run_with_hooks(\n",
    "        clean_tokens,\n",
    "        fwd_hooks=[(hook_name, hook_func)]\n",
    "    )\n",
    "    results[layer_idx, head_idx] = compute_ioi_metric(patched_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fdf694-6779-4df3-9e91-4c859a575079",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: prob[0] = sigmoid(logit0 - logit1)\n",
    "step 2: logit0 = resid2 @ W_U[0], logit1 = resid2 @ W_U[1]\n",
    "step 3: logit0 - logit1 = resid2 @ (W_U[0] - W_U[1])\n",
    "step 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05b581c-2f09-409f-94b6-1a60680cffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U\n",
    "\n",
    "open_embedding = W_U[:, open_idx]\n",
    "close_embedding = W_U[:, close_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ec8879-4e58-41da-892b-c08fd2dbce55",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_OV = model.W_V[0, 0] @ model.W_O[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb49f3-dc68-46c6-9fc2-3bbd5929e25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_embedding = open_embedding @ layer0_ln_coefs.T @ W_OV \n",
    "close_embedding = close_embedding @ layer0_ln.coefs.T @ W_OV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adbb4476-e74a-4759-9d2d-d1bac1c8e763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dda55b-9768-4c0d-bdc2-dac1e32dc67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce(induction_stripe, \"n_heads seq_len -> n_heads\", reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef26594-b77e-41fc-9826-0c5e198b0705",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = x.repeat(2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb641354-f2cf-449f-a3b0-14fdd19d26e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(clock_idx+1-n_microbatches, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14923d80-41ac-4f80-8942-28e0df53418e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler, api server, ectd, control manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bfa136d-732b-4dcb-9e70-48f1c8bb3212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87942e12-3503-41eb-b8eb-0fb32e53481e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class _ParallelCrossEntropy(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, parallel_logits, targets):\n",
    "        def get_vocab_range(rank, partition_size):\n",
    "            start_idx = rank*partition_size\n",
    "            end_idx = start_idx+partition_size\n",
    "            return start_idx, end_idx\n",
    "        \n",
    "        rank = parallel_context.get_local_rank(ParallelMode.TENSOR)\n",
    "        partition_size = parallel_logits.shape[0]\n",
    "        vocab_start_idx, vocab_end_idx = get_vocab_range(rank)\n",
    "        \n",
    "        mask_targets = (targets < vocab_start_idx) | (targets >= vocab_end_idx)\n",
    "        masked_targets = targets.clone() - mask_targets\n",
    "        masked_targets[masked_targets] = 0\n",
    "        \n",
    "        masked_targets_1d = rearrange(\n",
    "            masked_targets, \"batch_size seq_len -> (batch_size seq_len)\"\n",
    "        )\n",
    "        parallel_logits = rearrange(\n",
    "            parallel_logits, \"batch_size seq_len vocab_size -> (batch_size seq_len) vocab_size\"\n",
    "        )\n",
    "        predicted_logits = parallel_logits[masked_targets_1d.shape[0], masked_targets_1d]\n",
    "        predicted_logits = torch.where(masked_targets == True, 0., predicted_logits)\n",
    "        predicted_logits = all_reduce(predicted_logits, parallel_context, parallel_mode=ParallelMode.TENSOR)\n",
    "        \n",
    "        exp_logits = parallel_logits.exp(dim=-1).sum(dim=-1)\n",
    "        exp_logits = all_reduce(exp_logits, parallel_context, parallel_mode=ParallelMode.TENSOR)\n",
    "        loss = exp_logits.log() - predicted_logits\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2de063e1-0908-430b-9b0b-b427ac1e0857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParallelCrossEntropy(nn.Module):\n",
    "    def __init__(self, parallel_context):\n",
    "        super().__init__()\n",
    "        self.parallel_context = parallel_context\n",
    "    \n",
    "    def forward(self, logits, targets):\n",
    "        loss = _ParallelCrossEntropy.apply(logits, targets, self.parallel_context)\n",
    "        loss = loss.mean() / len(targets)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db27288c-f6c5-48eb-bcc2-0946b589b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor\n",
    "reassign works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9f856f2-d8b2-41f4-8868-fc64386fecb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e2a8441-031e-4dbb-bfd7-3ca4b8e9a7bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "event = threading.Event()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e15ee0e-3cff-4198-95b7-6bd7da2a02ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    print(\"waiting\")\n",
    "    event.wait()\n",
    "    print(\"received\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cf6a89-f22c-4530-8ffb-b72873bb4b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_thread = threading.Thread(target=run)\n",
    "worker_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3dfb1a-cbd1-4c96-b6f7-6fa8392af571",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter > all-reduce > identity > gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "798025da-fcae-42fd-8975-d94bb4defce6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d4e2df-829e-4c5c-b773-93c913101293",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\"x, y\", [(1, 1), (2, 4)])\n",
    "def test_square(x, y):\n",
    "    assert square(x) == y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b235f3-e574-4464-8e09-2a76b43073e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: logit_diff_dir = W_U[0] - W_U[1]\n",
    "step 2: approximate\n",
    "step 3: inverse\n",
    "step 4: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956fb410-11aa-4979-8708-bce59df098cf",
   "metadata": {},
   "source": [
    "step 1: prob[0] = sigmoid(logit0 - logit1)\n",
    "step 2: logit0 = resid2[0] @ W_U[0], logit1 = resid2[0] @ W_U[1]\n",
    "step 3: logit0 - logit1 = resid2[0] @ (W_U[0] - W_U[1])\n",
    "step 4: resid2[0] = resid1[1] @ ln2 @ W_OV^{2, 0}\n",
    "step 5: logit0 - logit1 = resid1[1] @ ln2 @ W_OV^{2, 0} @ (W_U[0] - W_U[1])\n",
    "step 6: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0ac0dca-6bfc-4b54-8e30-3598d4d2269d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "receiver_heads = [(7, 3), (7, 9), (8, 6), (8, 10)]\n",
    "receiver_layers = [7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "887a420d-71a9-48ef-8bbd-af40ffa84650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "797c0879-8206-4d31-90bb-b698d460ce47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sender_heads = list(product(range(max(receiver_layers)), range(n_heads)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61203538-5099-4943-b579-6d90e84f2aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_cache = model.run_with_cache(clean_tokens)\n",
    "_, corrupted_cache = model.run_with_cache(corrupted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d16eed0-d9ed-41eb-9cd8-4744d074757d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_sender_head_output(acts, hook, clean_cache, corrupted_cache, target_head):\n",
    "    target_layer_idx, target_head_idx = target_head\n",
    "    \n",
    "    if hook.layer() == target_layer_idx:\n",
    "        acts[:, :, target_head_idx] = corrupted_cache[hook.name][:, :, target_head_idx]\n",
    "    else:\n",
    "        acts = clean_cache[hook.name]\n",
    "    \n",
    "    return acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b073376e-3652-438e-a09f-a6913a9609ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_receiver_head_input(acts, hook, patched_cache, receiver_heads):\n",
    "    head_idxs = []\n",
    "    for layer_idx, head_idx in receiver_heads:\n",
    "        if hook.layer() == layer_idx:\n",
    "            head_idxs.append(head_idx)\n",
    "        \n",
    "    acts[:, :, head_idxs] = patched_cache[hook.name][:, :, head_idxs]\n",
    "    return acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da3d29c7-05a6-4cbf-bc76-943227e1e884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df29f77e-45d0-4876-b136-045a1c5b400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.zeros(n_layers, n_heads)\n",
    "\n",
    "for layer_idx, head_idx in sender_heads:\n",
    "    model.reset_hooks()\n",
    "    hook_name = get_act_name(\"z\", layer_idx)\n",
    "    hook_func = partial(\n",
    "        patch_sender_head_output,\n",
    "        clean_cache=clean_cache,\n",
    "        corrupted_cache=corrupted_cache,\n",
    "        target_head=(layer_idx, head_idx)\n",
    "    )\n",
    "    model.add_hook(hook_name, hook_func)\n",
    "    _, patched_cache = model.run_with_cache(clean_tokens)\n",
    "    \n",
    "    hook_name = get_act_name(\"v\", layer_idx)\n",
    "    patched_logits = model.run_with_hooks(\n",
    "        clean_tokens,\n",
    "        fwd_hooks=[(hook_name, partial(\n",
    "            patch_receiver_head_input,\n",
    "            patched_cache=patched_cache,\n",
    "            receiver_heads=receiver_heads\n",
    "        ))]\n",
    "    )\n",
    "    results[layer_idx, head_idx] = compute_ioi_metric(patched_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0531f90-f021-4a4c-b64c-4b89cde922fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: q = x @ W_Q, k = x @ W_K\n",
    "step 2: x = embed + pos_embed + sum(12 heads)\n",
    "step 3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45b24d46-05af-4c1d-8122-4e37f7f5b711",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import socketserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f293b664-2288-41aa-8357-0fa41c7baede",
   "metadata": {},
   "outputs": [],
   "source": [
    "with socketserver.ThreadingTCPServer((MASTER_HOST, MASTER_ADDR), EchoRequestHandler) as se:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a680f33-8bb0-4c58-9b2f-5dad76f14602",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"worker_1\": {\"cuda:0\": \"cuda:1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91c5696d-bdb2-49de-a62f-8ff7e0a556a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e356d2ec-33ea-4d76-a2d7-a9134f06de18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelContext:\n",
    "    def init_rpc_workers(self, host, port):\n",
    "        if self.pipeline_parallel_size > 1:\n",
    "            rank = self.get_local_rank(ParallelMode.GLOBAL)\n",
    "            world_size = self.get_world_size(ParallelMode.GLOBAL)\n",
    "            init_method = f\"tcp://{host}:{port}\"\n",
    "            \n",
    "            options = rpc.RpcBackendOptions(\n",
    "                init_method=init_method\n",
    "            )\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                ranks = self.get_ranks_in_group(ParallelMode.GLOBAL)\n",
    "                rpc_worker_map = {\n",
    "                    rank: WORKER_NAME.format(rank)\n",
    "                    for rank in ranks\n",
    "                }\n",
    "                \n",
    "                for other in ranks:\n",
    "                    if other == rank:\n",
    "                        continue\n",
    "                    options.set_device_map(\n",
    "                        WORKER_NAME.format(other),\n",
    "                        {rank: other}\n",
    "                    )\n",
    "            \n",
    "            rpc.init_rpc(\n",
    "                name=WORKER_NAME.format(rank),\n",
    "                rank=rank,\n",
    "                world_size=world_size,\n",
    "                rpc_backend_options=options\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51246060-717e-4394-9053-0877363271ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast > gather > scatter > reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d594f6-5f28-4f14-b919-dab4ea4d3e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U\n",
    "logit_diff_dir = W_U[:, correct_token] - W_U[:, incorrect_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a483de-8b16-474f-ac07-a6faf8b4bb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1bfd01-5f8e-4fcb-a1d1-4e3abea70649",
   "metadata": {},
   "outputs": [],
   "source": [
    "resid = model.apply_ln_to_stack(cache[final_residual_name][:, -1], layer=-1, pos_slice=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52af09c-7726-44a5-a1c6-9fba9d154a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "resid @ logit_diff_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a170aade-20dd-4725-91e1-f641ead0c07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tokens = model.to_tokens(names, prepend_bos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b79bb0e-398a-4e12-809a-df37b1a700fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.W_E[:, name_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b52aeca-591e-44db-8216-19e604592dd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resid2logit(resid, model):\n",
    "    return model.unembed(model.final_ln(resid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f69b276-1c4d-4cbc-adc8-3e39e6e0b58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.zeros(n_layers, n_heads)\n",
    "\n",
    "for layer_idx in range(n_layers):\n",
    "    for head_idx in range(n_heads):\n",
    "        W_V = model.W_V[layer_idx, head_idx]\n",
    "        W_O = model.W_O[layer_idx, head_idx]\n",
    "        W_OV = W_V @ W_O\n",
    "        \n",
    "        resid = embeddings @ W_OV\n",
    "        logits = resid2logit(resid)\n",
    "        top_predictions = torch.argmax(logits[:, -1, :], dim=-1)\n",
    "        percentage = (top_predictions == name_tokens).any().mean()\n",
    "        result[layer_idx, head_idx] = percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "69eb9700-82a6-4278-868d-7275e0c78baa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def probability_scores(image_embedding, text_embedding):\n",
    "    image_norm = image_embedding.norm(dim=-1)\n",
    "    image_embedding /= image_norm\n",
    "    \n",
    "    text_norm = text_embedding.norm(dim=-1)\n",
    "    text_embedding /= text_norm\n",
    "    \n",
    "    similarities = image_embedding @ text_embedding.T\n",
    "    probs = F.softmax(similarities, dim=-1)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8461698e-9b9d-4a68-9b5c-5886b4f442b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_discounted_return_at_each_timestep(rewards, discount_factor):\n",
    "    discounted_returns = []\n",
    "    \n",
    "    for i in range(len(rewards)):\n",
    "        discounted_return = 0\n",
    "        \n",
    "        for k, reward in enumerate(rewards[i:]):\n",
    "            discounted_return += (discount_factor**k) * reward\n",
    "        \n",
    "        discounted_returns.append(discounted_return)\n",
    "    \n",
    "    return discounted_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "96cb02b3-f2ae-4a6d-8c57-e23104391add",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rewards = torch.tensor([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4105ba9-96dc-4ee5-8baa-4dbc01acb4dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(14.6045), tensor(13.7419), tensor(11.8605), tensor(8.9500), tensor(5.)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_discounted_return_at_each_timestep(rewards, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc721425-fab3-4c38-b6da-b75490be2145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62990ba9-c74b-46a9-a144-e0e56f7d9c92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83f674f-91f8-4be4-8a61-960233a016f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
