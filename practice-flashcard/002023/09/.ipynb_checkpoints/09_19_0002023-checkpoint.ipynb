{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "947366f4-8cc8-4805-aeb9-cd0ea1544563",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05e35913-7581-41c5-aa27-9e0a9572e847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b260e-75d5-4209-a593-b8d8dfcbf25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_storage(x):\n",
    "    x.storage().resize_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b1ef6b-57de-4cd4-ab4f-458a1a080656",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Copy(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, prev_stream, next_stream, x):\n",
    "        ctx.prev_stream = prev_stream\n",
    "        ctx.next_stream = next_stream\n",
    "        \n",
    "        compute_stream = torch.cuda.default_stream(next_stream.device)\n",
    "        \n",
    "        with torch.cuda.stream(prev_stream), torch.cuda.stream(next_stream):\n",
    "            moved_x = x.to(next_stream.device)\n",
    "            \n",
    "            x.record_stream(prev_stream)\n",
    "            moved_x.record_stream(compute_stream)\n",
    "        \n",
    "        return moved_x\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        prev_stream = ctx.prev_stream\n",
    "        next_stream = ctx.next_stream\n",
    "        \n",
    "        compute_stream = torch.cuda.default_stream(prev_stream.device)\n",
    "        \n",
    "        with torch.cuda.stream(prev_stream), torch.cuda.stream(next_stream):\n",
    "            moved_grad = grad_input.to(prev_stream.device)\n",
    "            \n",
    "            grad_input.record_stream(next_stream)\n",
    "            moved_grad.record_stream(compute_stream)\n",
    "        \n",
    "        return (None, None, moved_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e1c866-41ed-4b28-a9de-a9f5ff90cc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready, running, suceed, failed, cooldown, blacklisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d780dd53-f260-4a9b-abd1-cc47030b66fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d2b92f-ff19-433d-b284-bd17e86d052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataParallel:\n",
    "    def __init__(self, module, parallel_context):\n",
    "        self.module = module\n",
    "        self.parallel_context = parallel_context\n",
    "    \n",
    "    def parallelize(self):\n",
    "        module = self.module\n",
    "        \n",
    "        if self.parallel_context.data_parallel_size > 1:\n",
    "            for p in module.parameters():\n",
    "                if p.requires_grad:\n",
    "                    p.register_hook(_average_grad_hook)\n",
    "        \n",
    "        return module\n",
    "    \n",
    "    def _average_grad_hook(p):\n",
    "        data_parallel_size = self.parallel_context.data_parallel_size\n",
    "        process_group = self.parallel_context.get_group(ParallelMode.DATA)\n",
    "        p /= data_parallel_size\n",
    "        \n",
    "        dist.all_reduce(p, op=dist.ReduceOp.SUM, group=process_group)\n",
    "        \n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b691442-5d09-4429-aea8-3773f80f8655",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: make "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e10b02a-dc5f-467e-8918-3b416a031673",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(clock_idx+1, n_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690e7379-97f9-41c2-beb2-fdc2ff131218",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_group, ranks in group, local_rank, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee261f-3451-4969-a281-033b4f12bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1:\n",
    "step 2: init global distributed group\n",
    "step 3: init parallel groups\n",
    "step 4: set device\n",
    "step 5: set seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835e0aa2-4fc7-427c-9038-edbfae5db91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast > gather > scatter > all-reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd6c469-35d1-4bde-baab-ee76b216d1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e7bff-2ec8-4c06-943e-8a4834fb8099",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_empty = (linear_probe[..., 1] + linear_probe[..., 2]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bb7b49-0411-4a55-82b3-564999dd640c",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_vs_not_empty = linear_probe[.., 0] - not_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3bdabd-4a5c-4a05-a4f6-cc44dc631772",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f93b483-fe4b-4b4e-9c62-222eaa176507",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = cache[hook_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0546b72c-e426-4f06-9802-6c63a0c38779",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed[:, -1] @ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec40ed87-a7e4-4df0-bd44-7a44ffa84092",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tokens = tokens[1:]\n",
    "W_U_targets = model.W_U[:, target_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d067b5e-4c33-4a92-b20e-20f694d74a30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971e8cc-e0eb-4ab6-8e30-af5efa225745",
   "metadata": {},
   "outputs": [],
   "source": [
    "einsum(\n",
    "    embed, W_U_targets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57a8cfa-b651-4246-9e5b-6667d5c78e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdae458-df90-4c35-b3ec-0c6fba61e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln0 = model.blocks[0].ln1\n",
    "mlp = model.blocks[0].mlp\n",
    "embed = model.embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a32419-028a-410b-86d7-0bac9b80d780",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embed(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcbc85f-a8b9-47fd-83f9-7b46ecaaf646",
   "metadata": {},
   "outputs": [],
   "source": [
    "emebddings = embeddings + mlp(ln0(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba9fe4a-9dde-49e6-ba30-d5c4210904c8",
   "metadata": {},
   "source": [
    "tensor_parallel_size, pipeline_parallel_size, data_parallel_size, host, port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d53aaf4-5d92-4896-b2ab-91cb50274eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: mask input tokens\n",
    "step 2: local embeddings\n",
    "step 3: global embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541d5c97-3e5e-4948-841e-b6ca6ff95b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "job selector > spawn initial workers > pool watcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e77a20-40cb-4e4f-97ba-6f2da462cfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: autograd\n",
    "step 2: user\n",
    "step 3: pytorch\n",
    "step 4: trigger\n",
    "step 5: run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f374114-79e5-4432-a028-6a59da3af4dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import cast, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ed9f4e-4500-4219-9af7-ee325b8b1f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = cast(List[int], numbers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
