{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11a22646-5fca-4678-91ba-094710261f0e",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d39d691-5743-408d-aff0-22d71fc5993b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5197d7ad-60fb-4343-a8f8-310e07209ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aabbfa-a067-4f0a-8a01-b5815837c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kubelet, kube-proxy, container runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf199ce-bd03-44a5-ae5e-42cc1b217ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd104c0-9da9-405f-b3f5-c2d2b0c1845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = F.softmax(switch(inputs), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfab2699-8c7c-43b1-9640-4bcde29b083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, idxs = torch.max(probs, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab75a838-1297-4524-89e6-5d54bb8c4e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: mask input\n",
    "step 2: calcualte local embedding\n",
    "step 3: calculate global embedding\n",
    "step 4: sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caa72cb-2c63-4b5d-873a-3578d85db1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast > gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b694c292-c042-4674-b0d1-7b1281b7e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_row_parallelism(inputs, weights):\n",
    "    inp_per_partition = inputs.shape[-1] // 2\n",
    "    w_per_partition = weights.shape[0] // 2\n",
    "    \n",
    "    inp1 = inputs[:, :inp_per_partition]\n",
    "    inp2 = inputs[:, inp_per_partition:]\n",
    "    w1 = weights[:w_per_partition, :]\n",
    "    w2 = weights[w_per_partition:, :]\n",
    "    \n",
    "    out1 = inp1 @ w1\n",
    "    out2 = inp2 @ w2\n",
    "    \n",
    "    return out1 + out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f976af7-1998-4ec7-b410-ae709ae9263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: wait data\n",
    "step 2: construct task\n",
    "step 3: put\n",
    "step 4: execute\n",
    "step 5: wait\n",
    "step 6: get the output\n",
    "step 7: put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449feff7-8dad-418b-9706-35fd5dbdc2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: \n",
    "step 2: resize embedding size, and lm_ea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279615ed-77bd-4b6d-9c01-716cf55e44b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "job selection > initial workers > pool watcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b505b455-d1af-4d28-81d6-ebf4d26a3074",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26eb5f94-b75a-4fac-a793-043fa9209ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "event = threading.Event()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "549e2c1d-d83b-4d95-8c62-b15e285335cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_worker():\n",
    "    event.wait()\n",
    "    print(\"received\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c6aa3-185a-4982-868e-a14b63472951",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_thread = threading.Thread(\n",
    "    target=run_worker\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd43e3b-8dec-4b8e-868a-9e7f52b412df",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29083b0-3740-4eb9-bd16-e0259fef3501",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready, running, suceed, failed, cooldown, blacklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3d55b17-2343-4677-8cd7-2f267a13bd99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import overload, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a81251f-3876-431f-8728-63b2d5bd9a04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@overload\n",
    "def getitem(x: str) -> str:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19a18e70-d397-4ee8-81cd-b42dc57fd194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@overload\n",
    "def getitem(x: List[int]) -> int:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8532491-d669-4893-a601-37226ea4b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter > reduce > iden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c23dc54-bd04-45d8-8b36-77decd7805f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "792c22ce-0680-4c2b-9cdd-82962f86ced4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "top1_idx = torch.tensor([1, 3, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3256f730-3eb4-4a4c-8918-b75b718c586a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask = F.one_hot(top1_idx, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7d94d17-85f9-47e1-8f45-010f11919473",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0],\n",
       "        [0, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91dbefbc-580b-4619-b565-6c11bb40b82d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.3333, 0.3333, 0.3333, 0.0000])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(mask.float(), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e278b6ad-6d71-46cd-b7f3-4ab51295a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intervene_resid(resid, position, feature):\n",
    "    feature /= feature.norm(dim=-1)\n",
    "    feature_projection = resid[0, position] @ feature\n",
    "    resid[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e84de2c-989f-47dc-aa98-8488cf0dd80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "receiver_heads = [(7, 3), (7, 9), (8, 6), (8, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec294a3d-7b30-45fb-8291-8de195740648",
   "metadata": {},
   "outputs": [],
   "source": [
    "receiver_layers = [7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39475dd-4791-48ee-8afe-1b86837dfe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_cache = model.run_with_cache(clean_tokens)\n",
    "_, corrupted_cache = model.run_with_cache(corrupted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b40caf5-6987-451f-a699-46101a4b56b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_sender_head(resid, hook, clean_cache, corrupted_cache, target_head):\n",
    "    trg_head_idx, trg_layer_idx = target_head\n",
    "    \n",
    "    if hook.layer() == trg_layer_idx:\n",
    "        resid[:, :, head_idx] = corrupted_cache[hook.name][:, :, head_idx]\n",
    "    else:\n",
    "        resid = clean_cache[hook.name]\n",
    "    \n",
    "    return resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06e76a5d-9045-4ec8-9d3e-6e914a9b2214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0d83e6-f442-4e2e-8d2d-241443320aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_heads = list(product(range(n_heads), range(max(receiver_layers))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd881071-3600-4b2d-8a6d-02edc0d4366c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac66bf-26b0-4f3b-8965-7c8103a23a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for head_idx, layer_idx in sender_heads:\n",
    "    hook_name = get_act_name(\"z\", layer_idx)\n",
    "    hook_func = partial(\n",
    "        patch_sender_head,\n",
    "        clean_cache=clean_cache,\n",
    "        corrupted_cache=corrupted_cache,\n",
    "        target_head=(head_idx, layer_idx)\n",
    "    )\n",
    "    \n",
    "    model.add_hook(hook_name, hook_func)\n",
    "    _, patched_cache = model.run_with_cache(tokens)\n",
    "    \n",
    "    # filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fa9046-1312-4580-97d3-de12f4b1a2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_scores(image_embedding, text_embedding):\n",
    "    image_embedding /= image_embedding.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dddc7f2e-592f-4eb7-84ed-bc219bc357de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define function to calculate memory, FLOPs, and training time\n",
    "def calculate_training_metrics(tensor_parallel_size, data_parallel_size, pipeline_parallel_size,\n",
    "                               num_layers, num_params, num_heads, hidden_size, throughput_gpu,\n",
    "                               context_length, batch_size, num_epochs):\n",
    "    # Constants\n",
    "    bytes_per_param_fp32 = 4  # fp32 uses 4 bytes per parameter\n",
    "    \n",
    "    num_gpus = tensor_parallel_size*data_parallel_size*pipeline_parallel_size\n",
    "    \n",
    "    # Memory Calculations\n",
    "    ## Model Memory\n",
    "    model_memory = num_params * bytes_per_param_fp32\n",
    "    ## Optimizer Memory (Vanilla AdamW uses 12 bytes per parameter)\n",
    "    optimizer_memory = 12 * num_params\n",
    "    ## Activation Memory\n",
    "    ### Using equation for memory_activations^Selective Recomputation\n",
    "    activation_memory = context_length * batch_size * hidden_size * num_layers * (10 + 24 / tensor_parallel_size) * \\\n",
    "    (5*((num_heads*context_length)/(hidden_size*tensor_parallel_size)))\n",
    "    ## Gradient Memory (Stored in fp32)\n",
    "    gradient_memory = num_params * bytes_per_param_fp32\n",
    "    ## Total Training Memory (3D-parallelism with ZeRO-1)\n",
    "    total_memory = (model_memory / (pipeline_parallel_size * tensor_parallel_size)) + \\\n",
    "                   (optimizer_memory / num_gpus) + \\\n",
    "                   (activation_memory / tensor_parallel_size) + \\\n",
    "                   (gradient_memory / pipeline_parallel_size)\n",
    "\n",
    "    # FLOPs Calculations\n",
    "    ## Using C = tau * T => T = C / tau\n",
    "    ### Forward Pass FLOPs\n",
    "    forward_flops = 2 * num_params * (context_length * batch_size)\n",
    "    ### Backward Pass FLOPs\n",
    "    backward_flops = 4 * num_params * (context_length * batch_size)\n",
    "    ## Total FLOPs per Epoch\n",
    "    total_flops_per_epoch = (forward_flops + backward_flops)\n",
    "    ## Total Training Time per Epoch in seconds\n",
    "    training_time_per_epoch = total_flops_per_epoch / (throughput_gpu * 1e12)\n",
    "    ## Total Training Time for all Epochs in seconds\n",
    "    total_training_time = training_time_per_epoch * num_epochs\n",
    "\n",
    "    # Print Results\n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"Model Memory: {model_memory / 1e9} GB\")\n",
    "    print(f\"Optimizer Memory: {optimizer_memory / 1e9} GB\")\n",
    "    print(f\"Activation Memory: {activation_memory / 1e9} GB\")\n",
    "    print(f\"Gradient Memory: {gradient_memory / 1e9} GB\")\n",
    "    print(f\"Total Training Memory: {total_memory / 1e9} GB\")\n",
    "    print(f\"Total FLOPs per Epoch: {total_flops_per_epoch:.2e}\")\n",
    "    print(f\"Training Time per Epoch: {training_time_per_epoch:.2f} seconds\")\n",
    "    print(f\"Total Training Time: {total_training_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a9a867be-f7db-4c78-9d07-7d595731d124",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results:\n",
      "Model Memory: 500.0 GB\n",
      "Optimizer Memory: 1500.0 GB\n",
      "Activation Memory: 20273.9023872 GB\n",
      "Gradient Memory: 500.0 GB\n",
      "Total Training Memory: 10699.4511936 GB\n",
      "Total FLOPs per Epoch: 3.75e+18\n",
      "Training Time per Epoch: 31248.00 seconds\n",
      "Total Training Time: 781200.00 seconds\n"
     ]
    }
   ],
   "source": [
    "calculate_training_metrics(\n",
    "    tensor_parallel_size=2,\n",
    "    data_parallel_size=2,\n",
    "    pipeline_parallel_size=2,\n",
    "    num_layers=12,\n",
    "    num_params=125e9,\n",
    "    num_heads=12,\n",
    "    hidden_size=768,\n",
    "    throughput_gpu=120,\n",
    "    context_length=512,\n",
    "    batch_size=9765,\n",
    "    num_epochs=25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fecada-0703-47f5-9c3f-06895f028fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5328d-40f2-4b41-93af-251fabd4cdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(n_layers):\n",
    "    for head_idx in range(n_heads):\n",
    "        _, cache = model.run_with_cache(tokens)\n",
    "        target_pattern = cache[\"pattern\", layer_idx][:, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1473d7-a81e-4d65-9eca-dba0f38a154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = model.to_tokens(clean_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e4927c-ee92-4bac-8490-e5b1f1cd8411",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_tokens = modell.to_tokens(\"Mary Tom\", prepend_bos=False)\n",
    "incorrect_tokens = modell.to_tokens(\"John James\", prepend_bos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0e35cd-ed6d-471b-b9bb-8dde909a6649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ioi_metric(logits):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf768625-b5d1-43ea-bd7d-d59d2f82504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logits = model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4310b78e-c8d6-45af-9706-f705b8aba15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProduct(nn.Module):\n",
    "    def forward(self, x):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf805607-4da9-48d5-9035-d5a39df22dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "state, reward, done, truncated, info = env.step()\n",
    "\n",
    "while done:\n",
    "    #reward\n",
    "    # max action\n",
    "    # take action\n",
    "    #predicte the enxt reward\n",
    "    #target\n",
    "    # loss\n",
    "    # update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17f4f62-653e-4958-aa42-55563a3489df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_distributions(states):\n",
    "    q_values = q_function(states)\n",
    "    z = q_values.sum(dim=-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
