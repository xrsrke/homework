{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b805d667-74d0-4165-aee1-3a3a577ff8ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b45869d-a007-4d9c-9378-243e95fe0c7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ffa3a382-86df-4122-be81-db0137b48fe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Hello(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, meta):\n",
    "        ctx.meta = meta\n",
    "        print(\"hello\")\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        print(\"bw\")\n",
    "        print(ctx.meta)\n",
    "        xs.append(1)\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6652e2a7-8e90-4c58-a8c7-6dc98df0da79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.randn(2, 4, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23bfbd83-a37b-4d5d-8e03-5b9419272b30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f1 = nn.Linear(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d97fab1f-7081-4838-89db-29a39267f683",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "loss = f1(Hello.apply(x, 22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7381d4bb-d941-4722-91ab-2631cdb955e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bw\n",
      "22\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "function HelloBackward returned an incorrect number of gradients (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: function HelloBackward returned an incorrect number of gradients (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "loss.sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7341d6d0-944c-41ef-a1b2-9556acca1b22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c83d4f4-8027-43f9-944f-1d5911be79ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "786b4926-5d19-48f8-9b86-6414cf2e22f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f119ac20-1aff-4a97-85fd-0d9f6354636d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert, router, loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3a389f-c2b6-40b7-b5c9-ab7974f1bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(current_rank - 1) % local_world_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add204d6-4ed5-42a4-ace1-a684de8989db",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_max = torch.max(xs, dim=-1)\n",
    "global_max = dist.all_reduce(local_max, op=dist.ReduceOp.MAX)\n",
    "normalized_xs = xs - global_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c590d240-285c-4755-b289-e4de55ee941b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9715dc29-feb5-4fd7-bc90-a80a7e80ad04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class _ParallelCrossEntropy(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, parallel_logits, targets, parallel_context):\n",
    "        rank = parallel_context.get_local_rank(ParallelMode.TENSOR)\n",
    "        world_size = parallel_context.get_world_size(ParallelMode.TENSOR)\n",
    "        \n",
    "        partition_size = parallel_logits.shape[0] // world_size\n",
    "        vocab_start_idx = rank*partition_size\n",
    "        vocab_end_idx = vocab_start_idx + partition_size\n",
    "        \n",
    "        mask_targets = (targets < vocab_start_idx) | (targets >= vocab_end_idx)\n",
    "        masked_targets = targets.clone() - vocab_start_idx\n",
    "        masked_targets[mask_target] = 0\n",
    "        \n",
    "        masked_targets_1d = rearrange(\n",
    "            masked_targets,\n",
    "            \"batch_size seq_len -> (batch_size seq_len)\"\n",
    "        )\n",
    "        predicted_logits = parallel_logits[range(masked_targets.shape[0]), masked_targets_1d]\n",
    "        predicted_logits = torch.where(mask_targets, 0, predicted_logits)\n",
    "        \n",
    "        predicted_logits = all_reduce(predicted_logits, op=dist.ReduceOp.MAX, parallel_context=parallel_context)\n",
    "        exp_logits = torch.exp(parallel_logits).sum(dim=-1)\n",
    "        loss = exp_logits.log() - predicted_logits\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dfb52d7a-3563-4c36-ada7-3b3c1e0fe13a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParallelCrossEntropy(nn.Module):\n",
    "    def __init__(self, parallel_context):\n",
    "        super().__init__()\n",
    "        self.parallel_context = parallel_context\n",
    "    \n",
    "    def forward(self, logits, targets):\n",
    "        loss = _ParallelCrossEntropy.apply(logits, targets, self.parallel_context)\n",
    "        loss /= len(targets)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f6e069-a716-4144-ba90-d9dbfe6432d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_package(package, src, dst, parallel_context):\n",
    "    dst_worker_name = parallel_context.get_worker_name(dst)\n",
    "    \n",
    "    rpc.rpc_sync(\n",
    "        to=dst_worker_name\n",
    "        fuc=recv_package,\n",
    "        args=(package, src, dst)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72588c0-8744-4cd6-b44a-076a6cde3417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recv_package(package, src, dst):\n",
    "    RECV_QUEUE.put(package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4600af54-e4ef-4911-be7c-7af4f14da0f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fut = torch.futures.Future()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bee1d9e3-9ccb-4dca-b676-eb0e4f0a4a2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def f(fut):\n",
    "    print(6942)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31a47ef-8b75-4f35-be52-25eaf196b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "fut.add_done_callback(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85266427-eaa2-48de-84d2-1be5f6cb6f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fut.set_result(VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cddb68-1e6c-4190-851d-8f3be2f0b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: parallelize qkv\n",
    "step 2: acts\n",
    "step 3: do local attention\n",
    "step 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792cd8fb-779d-4127-9758-3cb44c125259",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = torch.cuda.Stream(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f272cae-9dde-4d05-8ae0-ec1c409bb1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.device(device):\n",
    "    with torch.cuda.stream(stream):\n",
    "        mean = xs.mean(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c262624-ff20-41e6-9226-88410a6e3739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9523b08e-eb37-4953-a306-8f02a102023b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe91260-8528-4381-87d7-1dce101e93b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: register autograd\n",
    "step 2: loss.backward()\n",
    "step 3: torch trigger backward\n",
    "step 4: schedule\n",
    "step 5: execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c56a55-5693-497b-a233-db86cc4b74d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: profile\n",
    "step 2: determine the number of partitions\n",
    "step 3: split\n",
    "step 4: move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b27e17b-89ca-443f-b925-198141d5c8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "host dis, elastic driver, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9fe1ed85-2098-494b-a274-c4157061a849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "world_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a5c271bd-1309-47f5-9327-b27e2e72642a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor_model_parallel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ad039136-f6f6-4cc2-8fcb-438b404ccb34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_model_parallel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9f6e524a-9090-417b-8655-45a89f05f4ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_parallel_groups = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dd6e68-1be2-48fb-8895-e8d4e7d9bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_parallel_groups = world_size // da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c594975-b282-4371-a3e8-bcc4adacc4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(pipeline_model_parallel_size):\n",
    "    start_rank = i*pipeline_model_parallel_size\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3bf381-58bc-43f7-855f-4368d0704769",
   "metadata": {},
   "outputs": [],
   "source": [
    "- step 1: prob[0] = sigmoid(logit0 - logit1)\n",
    "- step 2: logit0 = resid2[0] @ W_U[0], logit1 = resid2[0] @ W_U[1]\n",
    "- step 3: logit0 - logit1 = resid2[0] @ (W_U[0] - W_U[1])\n",
    "- step 4: resid2[0] = resid1[1] @ ln2 @ W_OV^{2, 0}\n",
    "- step 5: logit0 - logit1 = resid1[1] @ ln2 @ W_OV^{2, 0} @ (W_U[0] - W_U[1])\n",
    "- step 6: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "814b8145-cc80-4a41-9b85-3fda37e03ffa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, neuron_idx = 5, 1393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa6662d-d762-484d-a0af-0ca9d599b80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_in = model.W_in[layer_idx, :, neuron_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1951cdad-9587-43f4-8a1f-db05e1c304bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f434f53-d166-4dc0-85ce-74bf2fc62bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_consine_similarity(w_in, feature):\n",
    "    w_in /= w_in.norm(dim=-1)\n",
    "    feature /= feature.norm(dim=-1)\n",
    "    \n",
    "    return einsum(w_in, feature, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7887f25-f60b-429d-a11b-a968bd1590e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: dest pos\n",
    "step 2: identify which head \n",
    "step 3: where does it get information from\n",
    "step 4: disrupt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9272782-2017-4f69-ad81-5292fd0ead05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0180982a-9ecd-4d69-829b-822fb9a4aaef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CachedDataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.cache = None\n",
    "    \n",
    "    def prefetch(self, idxs):\n",
    "        data = torch.load(self.filename)\n",
    "        total_elements = sum([data[idx].numel() for idx in idxs])\n",
    "        \n",
    "        self.cache = torch.zeros(total_elements, dtype=data.dtype)\n",
    "        \n",
    "        offset = 0\n",
    "        for idx in idxs:\n",
    "            n_elements = data[idx].numel()\n",
    "            self.cache[offset:offset+total_elements] = data[idx].view(-1)\n",
    "            offset += n_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "906863bb-0517-4e90-afa7-8d5ae69c1210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "world_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac3c4438-78c5-430d-a125-706359bbc8ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor_parallel_size = 2\n",
    "pipeline_parallel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5540ec35-7aa4-4fdc-a639-953775d68f17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_pipeline_model_parallel_groups = world_size // pipeline_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b77c7286-f4ad-47f4-81b9-5fe96f7b032a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_parallel_groups = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c201eb9-63a0-4fb6-a0b5-24307cb583ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2]\n",
      "[1, 3]\n",
      "[4, 6]\n",
      "[5, 7]\n",
      "[8, 10]\n",
      "[9, 11]\n",
      "[12, 14]\n",
      "[13, 15]\n"
     ]
    }
   ],
   "source": [
    "for i in range(pipeline_parallel_size):\n",
    "    start_rank = i*num_pipeline_model_parallel_groups\n",
    "    end_rank = (i+1)*num_pipeline_model_parallel_groups\n",
    "    \n",
    "    for j in range(tensor_parallel_size):\n",
    "        ranks = list(range(\n",
    "            start_rank+j,\n",
    "            end_rank,\n",
    "            tensor_parallel_size\n",
    "        ))\n",
    "    \n",
    "        print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d185fca4-199a-4893-9639-c92355da2ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "applied force, gravity, normal force, air friction, friction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60705ff-44ac-45e2-be94-297a5b2bdc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "two uncertain principles, quantization of action, angular momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cbf07c-06d4-47f5-96c1-b54feb8c2b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "strong weak, gravity, electromagntic radiation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
