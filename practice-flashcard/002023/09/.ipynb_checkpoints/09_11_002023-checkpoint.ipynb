{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41330a8a-8048-4ab1-9383-519d55725f4c",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2384d89b-dd54-4e01-945a-60170ad29acb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0adad78d-7172-47fe-a382-4076115df68b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6ab6e5d-7a6e-4e8f-b030-0277b8cacc84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataParallel:\n",
    "    def __init__(self, module, parallel_context):\n",
    "        self.module = module\n",
    "        self.parallel_context = parallel_context\n",
    "    \n",
    "    def parallelize(self):\n",
    "        module = self.module\n",
    "        \n",
    "        if self.parallel_context.data_parallel_size > 1:\n",
    "            self._register_hook(module)\n",
    "                \n",
    "        return module\n",
    "    \n",
    "    def _register_hook(self, module):\n",
    "        for p in module.parameters():\n",
    "            if p.requires_grad:\n",
    "                p.register_hook(self._register_bw_hook())\n",
    "    \n",
    "    def _register_bw_hook(self, grad):\n",
    "        data_parallel_size = self.parallel_context.data_parallel_size\n",
    "        process_group = self.parallel_context.get_group(ParallelMode.DATA)\n",
    "        \n",
    "        new_grad = grad / data_parallel_size\n",
    "        dist.all_reduce(new_grad, op=dist.ReduceOp.SUM, group=process_group)\n",
    "        \n",
    "        return new_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c18ddb-9d06-4269-bc7e-0112484cbf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria 1: num_running = num_workers\n",
    "criteria 2: num_workers < max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768310e4-2f74-4482-b68c-4a632c659e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobselector > spawn initial workers > pool watcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c262c-e51e-424b-ae6b-f7569a055d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "node > pod > container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f01f9107-98c9-44a3-8b75-726a2fe6c606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import socketserver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71420bc-e10d-4bde-a827-18adec93e505",
   "metadata": {},
   "outputs": [],
   "source": [
    "with socketserver.ThreadingTCPServer(\n",
    "    (MASTER_HOST, MASTER_PORT),\n",
    "    EchoRequestHandler\n",
    ") as server:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb54d0c8-b99f-48db-a4ef-5e2c2004a37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition2(microbatch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d3ad6a4-7105-4868-a582-8f06048fc2ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479e88f1-70fb-448a-8345-c056a31d711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00e2631-002c-4341-9b20-7749b8a8c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_final_ln_name = get_act_name(\"post\", 2)\n",
    "\n",
    "pre_head20_ln_name = get_act_name(\"pre\", 1)\n",
    "post_head20_ln_name = get_act_name(\"normalized\", 1, \"ln1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3973b9a0-b8fa-41ea-b8f4-3d1d5256ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_final_ln = cache[pre_final_ln_name][:, :, 0]\n",
    "post_final_ln = cache[post_final_ln_name][:, :, 0]\n",
    "\n",
    "pre_head20_ln = cache[pre_head20_ln_name][:, :, 1]\n",
    "post_head20_ln = cache[post_head20_ln_name][:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5a8506-0753-4a4c-9375-61cb9bd9e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ln_coefs = fit_ln(pre_final_ln, post_final_ln)\n",
    "head20_ln_coefs = fit_ln(pre_head20_ln, post_head20_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec0ec22-4f0a-42e0-af66-d735de964099",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_diff = model.W_U[:, 0] - model.W_U[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e822415-2706-45b3-9dda-b3d5bc1cf376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, head_idx = 2, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666e7153-bf7a-4130-82a7-8711c084d89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_OV = model.W_V[layer_idx, head_idx] @ model.W_O[layer_idx, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec4e5f5-9cb4-44be-b53f-a931b0e30e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "head20_ln_coefs.T @ W_OV @ final_ln_coefs.T @ logit_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "124c7cbc-9823-42b8-9006-0de98cfc3966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_k(tokens, layer_idx, head_idx):\n",
    "    _, cache = model.run_with_cache(tokens)\n",
    "    hook_name = get_act_name(\"k\", layer_idx)\n",
    "    return cache[hook_name][:, :, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87ad46fd-1752-4b86-a9c1-8f637bc061bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, head_idx = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ec7a68-7f01-438f-b16a-df97843a7335",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_open_k = get_k(all_open_tokens, layer_idx, head_idx)\n",
    "all_close_k = get_k(all_close_tokens, layer_idx, head_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d60018-78e2-4175-a94a-c896c896708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_k_avg = (all_open_k + all_close_k) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbab1e56-ede3-4530-a25e-0b5e9cb78555",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_k(acts, hook, new_k, head_idx):\n",
    "    acts[:, :, head_idx] = new_k\n",
    "    return acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b0a4320-622d-4266-949b-bccc266bb0c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113b2ca7-7a04-4ee1-9289-c94fc405d866",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_func = partial(\n",
    "    patch_k,\n",
    "    new_k=all_k_avg,\n",
    "    head_idx=head_idx\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53210c95-0b9d-42a1-8ab3-ab56654952a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_name = get_act_name(\"k\", layer_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d2d64e-ae92-4750-883a-6ac5c9ffdc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_hook(hook_name, hook_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16827fdb-29b9-4be2-8669-711ed0f152ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, patched_cache = model.run_with_cache(all_open_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a95420-9fe3-4496-a8f1-8103f0280c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = patched_cache[\"pattern\", layer_idx][:, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5a4806-5b8f-4d25-a85f-53f05103c373",
   "metadata": {},
   "outputs": [],
   "source": [
    "W /= W.norm(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dede6e35-1ceb-472b-baa9-90375c8c0d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = torch.cosine_similarity(W, W.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046210e6-868a-4098-a54f-d024602f1027",
   "metadata": {},
   "outputs": [],
   "source": [
    "microbatch n > microbatch n-1 > microbatch n-2 > ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0344da4-7a16-4b97-b744-6ca30874bc6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Scatter(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self, input):\n",
    "        world_size = dist.get_world_size()\n",
    "        rank = dist.get_rank()\n",
    "        \n",
    "        chunks = torch.chunk(\n",
    "            input,\n",
    "            chunks=world_size,\n",
    "            dim=-1\n",
    "        )\n",
    "        return chunks[rank]\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(self, grad_input):\n",
    "        world_size = dist.get_world_size()\n",
    "        grads = [torch.zeros_like(grad_input) for _ in range(world_size)]\n",
    "        dist.all_gather(grads, grad_input)\n",
    "        grads = torch.cat(grads, dim=-1)\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0d17129-9b5d-46af-8260-475b4143a059",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Reduce(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self, input):\n",
    "        dist.all_reduce(input)\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(self, grad_input):\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "701175a0-ab93-48c4-9807-341dbf331291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RowParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        world_size = dist.get_world_size()\n",
    "        \n",
    "        input_per_partition = input_size // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.randn(\n",
    "            output_size, input_per_partition\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.randn(\n",
    "            output_size\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_parallel = Scatter.apply(input)\n",
    "        output_parallel = F.linear(input_parallel, self.weight)\n",
    "        outputs = Reduce.apply(output_parallel)\n",
    "        return outputs + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb04420-7853-4d60-9054-79ed89ff39e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new > ready > running > blocked> terminalted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bda51ec-235e-4386-9a45-b61af9b568b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b309199-98da-4aa1-96ed-a03e656d1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPU:\n",
    "    def __init__(self, master_addr, master_port, backend):\n",
    "        if not dist.is_initialized():\n",
    "            rank = os.getenv(\"RANK\")\n",
    "            world_size = os.getenv(\"WORLD_SIZE\")\n",
    "            \n",
    "            init_method = f\"tcp://{host}:{port}\"\n",
    "            \n",
    "            dist.init_process_group(\n",
    "                rank=rank,\n",
    "                world_size=world_size,\n",
    "                backend=backend\n",
    "            )\n",
    "            \n",
    "            self.set_device(self, rank)\n",
    "    \n",
    "    def set_device(self, rank):\n",
    "        n_devices = torch.cuda.device_count()\n",
    "        \n",
    "        if n_devices > 0:\n",
    "            torch.cuda.set_device(rank%n_devices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb7c470-ce05-482f-93e5-e3adedb75cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.broadcast(x, src=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef7b7e4-4f0f-4083-8472-50d17995ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "data prefetching, memory mapping, lazy loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b232961a-526f-42a3-8146-eaf321f3e789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a892c-4124-4116-9fe8-ccb32d5fcd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: calculate the gradients\n",
    "step 2: average\n",
    "step 3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79249705-28b8-48ca-8200-b8ae155ef2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.broadcast(x, src=0, async_op=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bf1f63-1d26-4dbb-9dd7-61b2440a8af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.split(x, split_size_or_sections=3, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d53e3ee-230a-4867-b19c-8d03679e86aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus_for_each_model = tensor_model_parallel_size * pipeline_model_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c33bc2-4e12-4214-a117-905a23c0fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.clamp_min_(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e34766-c4af-4784-9bc0-6073739c222d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpc.get_worker_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2484562d-5f6b-4181-97eb-0a12ef0cfc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb86f1c1-b423-41b4-89c9-45c625f435da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def intervene_resid(resid, hook, scale, feature, position):\n",
    "    feature /= feature.norm(dim=-1)\n",
    "    feature_projection = resid[:, position] @ feature\n",
    "    resid[:, position] -= feature_projection*scale\n",
    "    return resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60c4794f-2494-4f31-b27e-bd08cda82264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d194d654-714f-4dd4-81ee-2078745fbab1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6d0b65f-6d6c-4c6d-b258-9c98849a1961",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " model = nn.Sequential(OrderedDict([\n",
    "    ('layer1', nn.Sequential(OrderedDict([\n",
    "        ('fc', nn.Linear(4, 8)),\n",
    "        ('relu', nn.ReLU())\n",
    "    ]))),\n",
    "    ('layer2', nn.Sequential(OrderedDict([\n",
    "        ('fc', nn.Linear(8, 4)),\n",
    "        ('relu', nn.ReLU())\n",
    "    ]))),\n",
    "    ('layer3', nn.Sequential(OrderedDict([\n",
    "        ('fc', nn.Linear(4, 8)),\n",
    "        ('relu', nn.ReLU())\n",
    "    ]))),\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2bf934f-05d8-4ff3-8a33-e7f8f693ead0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (fc): Linear(in_features=4, out_features=8, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27ad9dad-da00-45ad-ac82-8a2aba568738",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_head):\n",
    "        super().__init__()\n",
    "        self.d_head = d_head\n",
    "    \n",
    "    def forward(self, q, k, v):\n",
    "        k = k.permute(-1, -2)\n",
    "        scores = torch.matmul(q, k) / (self.d_head**0.5)\n",
    "        probs = F.softmax(scores)\n",
    "        output = torch.matmul(probs, v)\n",
    "        return output, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8540fb3-84bc-4f4a-9d23-6f40e867e733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APvaqEsh2Y76QvE\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "def generate_random_string(length=15):\n",
    "    characters = string.ascii_letters + string.digits\n",
    "    return ''.join(random.choice(characters) for i in range(length))\n",
    "\n",
    "random_string = generate_random_string() \n",
    "print(random_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d96c58-1de7-4277-b2cc-805701159500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
