{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6dfb4b0-3dbb-4191-92f1-87a33724c67e",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c876f9c-e6a0-4796-8e14-19b8f8214cec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88daf7e0-9e1d-4496-b728-df94fb2e3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding, linear, layernorm, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f942570-f4a1-47d2-8c93-5639ebf855ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: global rank\n",
    "step 2: resize embedding size\n",
    "step 3: resize lm_head\n",
    "step 4: parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66870a29-3d90-441e-9bd4-286c36c06049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b165cc-c55c-4422-9e10-4ed9c437e056",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.id = rpc.RRef(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5dabb8-f895-4875-b6fb-a09f7704df38",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_event = torch.cuda.Event(enable_timing=True)\n",
    "end_event = torch.cuda.Event(enable_timing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51ecdef-871e-4dfe-b322-87407fe3021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_event.record()\n",
    "hardshit()\n",
    "end_event.record()\n",
    "\n",
    "elapsed_time_ms = end_event.elapsed_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e456952-4700-40ce-be95-551eae206cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6385fa0-43fc-48a9-8467-cd5282ecf41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorGroupInitializer(ProcessGroupInitializer):\n",
    "    def init_dist_group(self):\n",
    "        num_tensor_parallel_groups = self.world_size // self.tensor_parallel_size\n",
    "        local_rank = None\n",
    "        local_world_size = None\n",
    "        \n",
    "        for i in range(num_tensor_parallel_groups):\n",
    "            ranks = list(range(\n",
    "                i*tensor_parallel_size,\n",
    "                (i+1)*tensor_parallel_size,\n",
    "            ))\n",
    "            process_group = dist.new_group(ranks=ranks)\n",
    "            if self.rank in ranks:\n",
    "                local_rank = ranks.index(self.rank)\n",
    "                local_world_size = len(ranks)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f54491-a1f7-406b-8e8f-c8cc15d48739",
   "metadata": {},
   "outputs": [],
   "source": [
    "void addTwoNumber(int* a, int* b, int* c, int total_elements) {\n",
    "    int gid = (BlockIdx.x * BlockDim.x) + ThreadIdx.x\n",
    "    \n",
    "    if (gid < total_elements) {\n",
    "        c[gid] = a[gid] + b[gid]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947b5cd8-cc13-4240-a056-2078f142b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(local_rank+1)%local_world_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a4347ca-4db8-4c51-9cc3-3c49c524fe71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b267c146-8f3a-400d-9870-b7b66c81d3c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class _VocabParallelCrossEntropy(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, parallel_logits, targets, parallel_context):\n",
    "        def get_vocab_range(partition_size, rank):\n",
    "            start_idx = partition_size*rank\n",
    "            end_idx = start_idx+partition_size\n",
    "            return start_idx, end_idx\n",
    "            \n",
    "        def get_predicted_logits(parallel_logits):\n",
    "            partition_size = parallell_logits.shape[-1]\n",
    "            rank = parallel_context.get_local_rank(ParallelMode.TENSOR)\n",
    "            vocab_start_idx, vocab_end_idx = get_vocab_range(partition_size, rank)\n",
    "            \n",
    "            target_mask = (targets < self.vocab_start_idx) | (targets >= self.vocab_end_idx)\n",
    "            masked_targets = targets.clone() - self.vocab_start_idx\n",
    "            masked_targets[target_mask] = 0\n",
    "            \n",
    "            masked_targets_1d = rearrange(\n",
    "                masked_targets,\n",
    "                \"batch_size seq_len -> (batch_size seq_len)\"\n",
    "            )\n",
    "            parallel_logits = rearrange(\n",
    "                parallel_logits,\n",
    "                \"batch_size seq_len vocab_size -> (batch_size seq_len) vocab_size\"\n",
    "            )\n",
    "            predicted_logits = parallel_logits[masked_targets_1d.size(0), masked_targets_1d]\n",
    "            predicted_logits = all_reduce(\n",
    "                predicted_logits,\n",
    "                op=dist.ReduceOp.SUM,\n",
    "                parallel_context=parallel_context,\n",
    "                parallel_mode=ParallelMode.TENSOR\n",
    "            )\n",
    "            return predicted_logits\n",
    "        \n",
    "        predicted_logits = get_predicted_logits(parallel_logits)\n",
    "        exp_logits = parallel_logits.exp(dim=-1).sum(dim=-1)\n",
    "        exp_logits = all_reduce(exp_logits, parallel_context, parallel_mode=ParallelMode.TENSOR)\n",
    "        loss = exp_logits.log() - predicted_logits\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "455c19c8-ca19-473b-b96b-15bbcd667935",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VocabParallelCrossEntropy(nn.Module):\n",
    "    def __init__(self, parallel_context):\n",
    "        super().__init__()\n",
    "        self.parallel_context = parallel_context\n",
    "    \n",
    "    def forward(self, logits, targets):\n",
    "        loss = _VocabParallelCrossEntropy.apply(logits, targets, parallel_context)\n",
    "        return loss / len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1139ce19-8ab9-4042-8daa-c90d93589102",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.broadcast(x, src=0, async_op=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fa8d9d-1556-4864-a470-561c4e4f3f34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e635eebe-5d0a-4a8b-a286-911974c2c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: prob[0] = sigmoid(logit0 - logit1)\n",
    "step 2: logit0 = resid2[0] @ W_U[0], logit1 = resid2[0] @ W_U[1]\n",
    "step 3: logit0 - logit1 = resid2[0] @ (W_U[0] - W_U[1])\n",
    "step 4: resid2[0] = resid1[1] @ ln1 @ W_OV^{2, 0}\n",
    "step 5: resid1[1] @ ln1 @ W_OV^{2, 0} @ (W_U[0] - W_U[1])\n",
    "step 6: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e07eb50-6490-40f3-96fc-f244e2600dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new > ready > running > blocked > terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a4fbb5-e337-4334-8d63-fc0360896286",
   "metadata": {},
   "outputs": [],
   "source": [
    "int *h_a, *h_b, *h_c;\n",
    "\n",
    "size_t bytes = sizeof(int) * n;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc241d-1cdc-4da4-aa06-ec567756e3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_a = (int*)malloc(bytes)\n",
    "h_b = (int*)malloc(bytes)\n",
    "h_c = (int*)malloc(bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a977527e-4114-4d70-a26d-132a54885069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def intervene_resid(resid, hook, feature, scale):\n",
    "    feature /= feature.norm(dim=-1)\n",
    "    feature_projection = resid[0, position] @ feature\n",
    "    resid[0, resid] -= feature_projection * feature * scale\n",
    "    return resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efc46faa-e1a8-480f-b8c2-92b04c3e0cb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47866fb-4951-4a09-938e-65cf23874f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_name = get_act_name(\"resid_pre\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fce285-7445-4ba9-a94f-2f6519249a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x @ W_Q @ W_K.T @ x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d16920b6-a54f-4e54-b56b-7c5fac96159f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_score(pattern, target_pattern):\n",
    "    return (pattern*target_pattern).sum() / pattern.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee27bef-8e29-43f7-8310-1db9591f9551",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.zeros(n_layers, n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e04320-d2b4-4edd-a96a-98e789437bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c73dc4d-d6ed-47fa-90ce-9e72f37c98d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5223fd1d-09d8-43a1-a4b8-9cad22e3c357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964cf6a1-7925-4660-85e0-9b4456c148eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(n_layers):\n",
    "    hook_name = f\"blocks.{layer_idx}.attn.hook_pattern\"\n",
    "    for head_idx in range(n_heads):\n",
    "        pattern = cache[hook_name][:, head_idx]\n",
    "        data[layer_idx, head_idx] = compute_score(pattern, target_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fd87fd-d5d2-4679-910a-a009116ed991",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(board_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd4cc8-c119-4172-97dc-b360727d7794",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_acts = cache[hook_name][:, 1393]\n",
    "threshold = mlp_acts.quantile(0.99)\n",
    "top_neurons = mlp_acts > threashold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33cd94e-2619-4830-963c-66dc75f5fbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(board_states == 1)[top_neurons].float().mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f2ad1e-81c5-4863-a1b7-4c646be680ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: diverse\n",
    "step 2: record\n",
    "step 3: extract query=0\n",
    "step 4: average\n",
    "step 5: plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd97efb-def8-4738-a238-992fb39a217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln(final_residual_stream) @ W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10808b8-9c40-40b7-8772-06b5673896b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90db667b-5273-41a7-a035-53d41609da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_final_ln_name = get_act_name(\"resid_post\", 2)\n",
    "\n",
    "pre_head20_ln_name = get_act_name(\"resid_post\", 1)\n",
    "post_head20_ln_name = get_act_name(\"normalized\", 2, \"ln1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5dd545-d14c-4c5d-9c0d-4ca40e445a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_final_ln_acts = cache[pre_final_ln_name][:, 0]\n",
    "post_final_ln_acts = cache[post_final_ln_name][:, 0]\n",
    "\n",
    "pre_head20_ln_acts = cache[pre_head20_ln_name][:, 1]\n",
    "post_head20_ln_acts = cache[post_head20_ln_name][:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666c7f4e-6886-413e-9592-bdd3febb927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U\n",
    "logit_diff_dir = W_U[:, 0] - W_U[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933bb860-01f0-4b4d-bf32-2ea92524a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ln_coefs = fit_ln(pre_final_ln_acts, post_final_ln_acts)\n",
    "head20_ln_coefs = fit_ln(pre_head20_ln_acts, post_head20_ln_acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582daec1-3bb4-41e8-8336-63f2d76b2545",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_OV = model.W_V[2, 0] @ model.W_O[2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87eb540-f4d3-497f-8162-ad6fdef4aeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_20_dir = head20_ln_coefs @ W_OV @ final_ln_coefs @ logit_diff_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9c06c03-73c7-4005-92ac-35b3b1158014",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, head_idx = 5, 1393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9ff806c-e02d-42df-b6ca-4b9663032e38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hook_name = f\"blocks.{layer_idx}.mlp.hook_post\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be5e4919-b1cb-4615-8c37-95d3ae24c4a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blocks.5.mlp.hook_post'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hook_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ff4d45-c39f-4d3a-8ef7-f3b4f9538448",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(board_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f38f6c-aec0-4e46-a741-d33c7cdf7908",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_activations = cache[hook_name][:, neuron_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3172fc6b-ae97-4086-912a-1b80a5d5d0af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import rearrange, einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5b6160-6ee7-48d1-aa59-4187e3bfe824",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = einops(\n",
    "    W, W,\n",
    "    \"b\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df66f7f-86b7-4f80-ba20-ac4d39eded4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d070dd0-799d-4eae-8290-0d74e288f93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac143f71-967d-4b3b-bc7e-a85c33556ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_components = torch.tensor([\n",
    "    cache[\"embed\"],\n",
    "    cache[\"pos_embed\"],\n",
    "    cache[\"result\", prev_layer_idx]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3437b0-8444-4ce9-bc94-c6b5b41d10f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Q = model.W_Q[next_layer_idx, head_idx]\n",
    "query_components = einops(\n",
    "    input_components,\n",
    "    W_Q\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658ec550-ef54-471d-a36a-3d7f1443c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_contributions = query_components.pow(2).sum(dim=-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b489a0-3672-4f3e-903f-93f5b4ffe632",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f345f9c-8928-4356-bf3b-c5c65caf81d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0016c068-9340-4ba3-9cfa-72b00fb0600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_components = torch.tensor([\n",
    "    cache[\"embed\"],\n",
    "    cache[\"pos_embed\"],\n",
    "    cache[\"result\", layer_idx-1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98253e1-d598-462e-9700-194eb8433bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Q = model.W_Q\n",
    "query_components = einops(\n",
    "    input_components,\n",
    "    W_Q\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3205e88a-214b-4565-9a3c-2007197f8896",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_K = model.W_K\n",
    "key_components = einops(\n",
    "    input_components,\n",
    "    W_K\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae74b0d8-a7dc-400a-bc1a-bcfbc6dfab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_attention_scores = einops(\n",
    "    query_components,\n",
    "    key_compoentns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e664c809-ea02-49d3-88b6-008a313f2378",
   "metadata": {},
   "outputs": [],
   "source": [
    "x @ W_E @ W_OV @ W_OV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4944c121-e917-4042-a03e-ca4786d07437",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E\n",
    "W_OV = model.W_V[layer_idx, head_idx] @ model.W_O[layer_idx, head_idx]\n",
    "W_U = model.W_U\n",
    "\n",
    "full_OV_circuit = W_E @ W_OV @ W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0802e3c-5fab-429c-a0a9-5ea7659e84e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_prompt = [\n",
    "    \"When X and Y went to the shops, Z gave the bag to\",\n",
    "    \"When K and H went to the park, V gave the ball to\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7568fb00-7d0b-4878-9cbd-6433cd684b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_tokens = model.to_tokens(\"Mary Jame\", prepend_bos=False)\n",
    "incorrect_tokens = model.to_tokens(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9bcbcf-bafc-46a0-b813-0e744e3d7f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = model.to_tokens(clean_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe6b82c-86db-432f-bbc1-9bc317caa9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logits, _ = model.run_with_cache(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61dd515e-22fa-4841-b97b-4b88a8fca9ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_logit_diff(logits, correct_tokens, incorrect_tokens):\n",
    "    final_logits = logits[:, -1, :]\n",
    "    return final_logits[:, correct_tokens] - final_logits[:, incorrect_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15facdf-c481-44de-9a9e-b930d8a4945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logit_diff = compute_logit_diff(clean_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e02fe51-05b4-4fdd-9b1e-2201b4e8f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ioi_metric(patched_logits, clean_logit_diff, corrupted_logit_diff):\n",
    "    patched_logit_diff = compute_logit_diff(patched_logits, correct_tokens, incorrect_tokens)\n",
    "    return (patched_logit_diff - corrupted_logit_diff) / (clean_logit_diff - corrupted_logit_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61fc39a4-f085-4559-938d-e239a9be704c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6bbc09-9d17-49d6-aac8-c83dc390fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachedDataset:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91062755-dc3b-46c8-ae70-a8e144f44340",
   "metadata": {},
   "outputs": [],
   "source": [
    "W /= W.norm(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb77f24-1680-4bbe-85c5-60f061b6e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "simi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfc3cb6-9c94-435d-adee-e61242fbd60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: logit_diff = W_U[:, 0] - W_U[:, 1]\n",
    "step 2: approximate layer norm\n",
    "step 3: coefs\n",
    "step 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be82cf2a-9aba-42bb-b613-5c6151d987b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: w_u[0] - w_u[1]\n",
    "step 2: approximate\n",
    "step 3: coefs\n",
    "step 4: coefs.T\n",
    "step 5: coefs.T @ logitdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbc2513-7963-4e43-a625-7036a2d4e810",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(past_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c2e6aa-7169-465a-8a07-e04b25899792",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_neurons = cache[\"post\", 3].std(dim=[0, 1]).argsort(descending=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523073e3-0be4-4849-8328-36f8fd71e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_consine_similarity(neuron_idx, feature):\n",
    "    W_out = model.W_out[layer_idx, neuron_idx]\n",
    "    W_out /= W_out.norm(dim=-1)\n",
    "    \n",
    "    feature /= feature.norm(dim=-1)\n",
    "    \n",
    "    return einops(\n",
    "        W_out,\n",
    "        feature\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105efc94-ff7d-4c6a-a3bc-ca5cc097c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: prob[0] = sigmoid(logit0 - logit1)\n",
    "step 2: logit0 = resid2[0] @ W_U[0], logit1 = resid2[0] @ W_U[1]\n",
    "step 3: logit0 - logit1 = resid2[0] @ (W_U[0] - W_U[1])\n",
    "step 4: resid2[0] = resid[1] @ ln1 @ W_OV^{2, 0}\n",
    "step 5: logit0 - logit1 = resid[1] @ ln1 @ W_OV^{2, 0} @ (W_U[0] - W_U[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a1019209-43af-439d-beb5-86dd280a7144",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a41f4ad6-ea6d-4637-bb8e-7f8febc4380b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54379552-8825-4528-8fee-819b027012ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CacheDataset(Dataset):\n",
    "    def __init__(self, file_name):\n",
    "        super().__init__()\n",
    "        self.file_name = file_name\n",
    "        self.data = None\n",
    "        self.cache = None\n",
    "        self.cache_index = {}\n",
    "        \n",
    "    def prefetch(self, idxs: List[int]):\n",
    "        if all(i for self.cache_index in idxs):\n",
    "            return\n",
    "        \n",
    "        if not self.data:\n",
    "            self.data = torch.load(self.file_name)\n",
    "        \n",
    "        total_elements = sum([self.data[i].numel() for i in idxs])\n",
    "        self.total_elements = total_elements\n",
    "        self.cache = torch.zeros(total_elements, dtype=self.data.dtype)\n",
    "        self.cache_index.clear()\n",
    "        \n",
    "        offset = 0\n",
    "        for i in idxs:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7f05f1-c05c-4928-befe-9ce1e0f6edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre-fix[] prefix -die"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "387eabdc-dc19-4e11-bdc4-888dc9e699e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1174b1df-4fb4-4035-b5e8-964805cf7643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(func: Callable[[int, int], int]) -> str:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbf7160-93f4-4e1a-af44-0b700220dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge, server, database, service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd6307f-6086-43b6-9fd2-c3725be898d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_encoding = encoding.mask_fill(mask == False, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd587810-af91-406d-bdd7-93c6559bb422",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96456b0-4225-482c-85f1-263084dcc069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CachedDataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "    \n",
    "    def prefetch(self, idxs):\n",
    "        data = torch.load(self.filename)\n",
    "        total_elements = sum([self.data[i].numel() for i in idxs])\n",
    "        self.cache = torch.zeros(total_elements, dtype=data.dtype)\n",
    "        offset = 0\n",
    "        for i in idxs:\n",
    "            n_elements = data[i].numel()\n",
    "            self.cache[offset+offset+n_elements] = data[i].view(-1)\n",
    "            offset += n_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25e9fd0-64d5-4e0b-a2d2-eb2a99b6b57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "state, _ = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    pred_rewards = model(state)\n",
    "    action = torch.argmax(pred_rewards, dim=-1)[0]\n",
    "    \n",
    "    state, reward, done, _, _ = model(action)\n",
    "    \n",
    "    if done is False:\n",
    "        next_pred_rewards = model(state)\n",
    "        max_next_pred_reward = torch.max(next_pred_reward)[0]\n",
    "        expected_reward = reward + gamma*max_next_reward\n",
    "    else:\n",
    "        expected_reward = reward\n",
    "    \n",
    "    loss = loss_func(pred_rewards[action], expected_reward)\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f66d579-f06c-479a-ae6e-6256687bd6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_distribution(states):\n",
    "    q_values = q_function(states)\n",
    "    return q_values.exp() / q_values.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59c6af84-0a2d-4c56-bd00-bde53396a823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_partritions = 4\n",
    "n_microbatches = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b677fa27-9047-4894-851c-8223da887211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clock cycle 0:  [(0, 0)]\n",
      "Clock cycle 1:  [(1, 0), (0, 1)]\n",
      "Clock cycle 2:  [(2, 0), (1, 1), (0, 2)]\n",
      "Clock cycle 3:  [(3, 0), (2, 1), (1, 2), (0, 3)]\n",
      "Clock cycle 4:  [(4, 0), (3, 1), (2, 2), (1, 3)]\n",
      "Clock cycle 5:  [(4, 1), (3, 2), (2, 3)]\n",
      "Clock cycle 6:  [(4, 2), (3, 3)]\n",
      "Clock cycle 7:  [(4, 3)]\n"
     ]
    }
   ],
   "source": [
    "n_clock_cycles = n_partritions + n_microbatches - 1\n",
    "for clock_idx in range(n_clock_cycles):\n",
    "    start_partrition = max(clock_idx+1-n_microbatches, 0)\n",
    "    end_partrition = min(clock_idx+1, n_partritions)\n",
    "\n",
    "    tasks = []\n",
    "    for partrition_idx in range(start_partrition, end_partrition):\n",
    "        microbatch_idx = clock_idx-partrition_idx\n",
    "        task = (microbatch_idx, partrition_idx)\n",
    "        tasks.append(task)\n",
    "    \n",
    "    print(f\"Clock cycle {clock_idx}: \", tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67847951-ace3-4346-8946-b0421e794fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
