{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403ffea1-d1ba-42b6-b77e-76ce5c60c0c8",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26bab418-f2b5-476b-a4ca-f54ba2483388",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0bc7f8-f5de-488b-bc42-ba4cc6673327",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5ab7158-c63c-4afe-b87d-711c4e9cfad5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038c726-a48e-4672-9139-3d6e8ac60796",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_final_ln_name = get_act_name(\"resid_post\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db41e6dc-ffb1-4d0d-b633-6f8041a6863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_head20_ln_name = get_act_name(\"resid_pre\", 2)\n",
    "post_head20_ln_name = get_act_name(\"normalized\", 2, \"ln1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72554b7f-cfb9-4ff1-996d-bb3c64ac8c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15d379bb-71e4-4d66-9477-b096a0dbce36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, head_idx = 2, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e57ac4-72bc-46a4-a955-b2194381c9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_final_ln = cache[pre_final_ln_name][:, 0]\n",
    "post_final_ln = cache[post_final_ln_name][:, 0]\n",
    "\n",
    "pre_head20_ln = cache[pre_head20_ln_name][:, 1]\n",
    "post_head20_ln = cache[post_head20_ln_name][:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec07a3-bafe-48fd-a8a8-a550332fc513",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_OV = model.W_V[layer_idx, head_idx] @ model.W_O[layer_idx, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9938a95-455b-4f40-810a-349bff238617",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_diff_dir = W_U[:, 0] - W_U[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae031c3-f5d5-412c-bfb1-6f96e43f1f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ln_coefs = fit_ln(pre_final_ln, post_final_ln)\n",
    "head20_ln_coefs = fit_ln(pre_head20_ln, post_head20_ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a352641-74ef-4951-9984-cdad36ebb59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "head20_ln_coefs @ W_OV @ final_ln_coefs @ logit_diff_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4927f4dc-300d-4e34-a3c6-704c8ada3163",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E\n",
    "open_embedding = W_E[:, open_idx]\n",
    "close_embedding = W_E[:, close_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8cad0e-29ec-4367-b6a3-f1025d73d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_OV = model.W_V[0, 0] @ model.W_O[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83faf47-5f89-494a-b70e-1ad2fcc87c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_embedding = layer0_ln_coefs.T @ W_OV @ open_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc689fce-da0e-4cd6-9d98-d2f322d68c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "close_embedding = layer0_ln_coefs.T @ W_OV @ close_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a19658-b50f-47f6-8456-d17781c15376",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed(\"(\") @ ln.T @ W_OV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8803dc8-2936-4b17-a1e9-929d4e915174",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, head_idx = 5, 1393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9a14429-d117-44e6-8e9a-7349cfee7a03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hook_name = f\"blocks.{layer_idx}.mlp.hook_post\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0176707d-2d33-400d-8c37-14e0b5225072",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blocks.5.mlp.hook_post'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hook_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf5d6f1-f0e9-4373-830b-caedcd305258",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(board_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2eebe9-9c45-4638-9061-ebe28922b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_activations = cache[hook_name][:, neuron_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b2866a-f4e6-4a33-aa35-1f2487a8ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: send metadata\n",
    "step 2: send "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08e30faf-f28d-4766-82ff-d3d04d5bca04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c31c44-a57c-4a52-ad72-23d898399d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(world_size):\n",
    "    p = Process(target=say_hello)\n",
    "    p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1860d0af-7412-4c56-929f-3eb371faee3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01e796d-3cca-4cd9-aa88-11cff870c721",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.broadcast(x, src=0, async_op=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2878d3ce-221e-48a4-905b-d1f5212d58e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: qkv\n",
    "step 2: split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a7a2b9-28d5-4166-93b5-5b9b80014803",
   "metadata": {},
   "outputs": [],
   "source": [
    "new > ready > running > blocked > terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ce0c823-8fd2-4057-9172-31c0dedfa54e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "world_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac967749-4157-4655-b890-de614f29d87a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor_model_parallel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5af1458d-6f8e-4036-85d6-28b14ae53b41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_model_parallel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df7e4acd-5af7-49ca-8d81-ed61df256cd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_pipeline_model_parallel_groups = world_size // pipeline_model_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebb31e67-6a09-4fd5-b3f8-a53ebfdcd839",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline_model_parallel_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdef574e-3e33-4975-ab79-c784f02f46ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_parallel_groups = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d3e9317-e9f8-43c5-8a95-a304ec965454",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2]\n",
      "[1, 3]\n",
      "[4, 6]\n",
      "[5, 7]\n",
      "[8, 10]\n",
      "[9, 11]\n",
      "[12, 14]\n",
      "[13, 15]\n"
     ]
    }
   ],
   "source": [
    "for i in range(pipeline_model_parallel_size):\n",
    "    start_rank = i*num_pipeline_model_parallel_groups\n",
    "    end_rank = (i+1)*num_pipeline_model_parallel_groups\n",
    "    \n",
    "    for j in range(tensor_model_parallel_size):\n",
    "        ranks = list(range(\n",
    "            start_rank+j,\n",
    "            end_rank,\n",
    "            tensor_model_parallel_size\n",
    "        ))\n",
    "        \n",
    "        print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8fe911-07ba-488d-8315-9da41858f579",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_max = torch.max(xs, dim=-1)\n",
    "global_max = dist.reduce(\n",
    "    local_max,\n",
    "    op=dist.ReduceOp.MAX\n",
    ")\n",
    "normalized_xs = xs - global_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bafeafb-e0a0-4757-86ce-e14fc6ee98b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gather\n",
    "execute\n",
    "release\n",
    "reduce-scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a80b2f-24ab-49de-bfe8-bab8ae6e4bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "RRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4062967e-0c6b-4d8d-9095-3f4439e31402",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelContext:\n",
    "    def init_rpc_workers(self, host, port):\n",
    "        if self.pipeline_parallel_size > 1:\n",
    "            rank = self.get_local_rank(ParallelMode.GLOBAL)\n",
    "            world_size = self.get_world_size(ParallelMode.GLOBAL)\n",
    "            \n",
    "            init_method = f\"tcp://{host}/{port}\"\n",
    "            options = rpc.RpcBackendOptions(init_method)\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                ranks = self.get_ranks_in_group(ParallelMode.GLOBAL)\n",
    "                rpc_worker_mapping = {\n",
    "                    rank: WORKER_NAME.format(rank)\n",
    "                    for rank in ranks\n",
    "                }\n",
    "                \n",
    "                for other in ranks:\n",
    "                    if rank == other:\n",
    "                        continue\n",
    "                    options.set_device_map(WORKER_NAME.format(rank), {rank: other})\n",
    "            \n",
    "            rpc.init_rpc(\n",
    "                name=WORKER_NAME.format(rank),\n",
    "                world_size=world_size,\n",
    "                rpc_backend_options=options\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68722133-51ca-4d4f-86eb-bdb79f341b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CacheDataset:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "    \n",
    "    def prefetch(self, idxs):\n",
    "        data = torch.load(self.filename)\n",
    "        total_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80a9a8d-1f09-4f91-90be-c0bce0f79f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_cache = model.run_with_cache(clean_tokens)\n",
    "_, corrupted_cache = model.run_with_cache(corrupted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8d85494-0996-43d3-8f6a-f51d4e45caf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_sender_head_output(acts, hook, clean_cache, corrupted_cache, target_head):\n",
    "    trg_layer_idx, trg_head_idx = target_head\n",
    "    \n",
    "    if trg_layer_idx == hook.layer():\n",
    "        acts[:, :, trg_head_idx] = corrupted_cache[hook.name][:, :, trg_head_idx]\n",
    "    else:\n",
    "        acts = clean_cache[hook.name]\n",
    "    \n",
    "    return acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de637a07-a1c2-4124-b3b6-b2b6d70272dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_receiver_head_input(acts, hook, new_v, head_idx):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4230e0-bf38-4e18-9d75-46e62eb9ddee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83bf632c-d4ba-468f-8509-7307a804a8a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "receiver_heads = [(7, 3), (7, 9), (8, 6), (8, 10)]\n",
    "receiver_layers = [7, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41c5e0cd-2a35-4727-8f5e-8bc8be3ca718",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b2925-64b5-4095-9694-c9088dcdf667",
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_heads = product(\n",
    "    range(max(receiver_layers)),\n",
    "    range(n_heads)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729f22ce-742f-438e-a216-afbb67bc0383",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx, head_idx in list(sender_heads):\n",
    "    # corrupt the sender output\n",
    "    hook_name = get_act_name(\"z\", layer_idx)\n",
    "    hook_func = partial(\n",
    "        patch_sender_head_output,\n",
    "        clean_cache=clean_cache,\n",
    "        corrupted_cache=corrupted_cache,\n",
    "        target_head=(layer_idx, head_idx)\n",
    "    )\n",
    "    model.add_hook(hook_name, hook_func)\n",
    "    _, patched_cache = model.run_with_cache(clean_tokens)\n",
    "    \n",
    "    \n",
    "    # corrupt the receiver input\n",
    "    patched_logits = model.run_with_hook(\n",
    "        clean_tokens,\n",
    "        fwd_hooks=[(\n",
    "            get_act_name(\"v\", layer_idx),\n",
    "            partial(\n",
    "                patch_receiver_head_input,\n",
    "                new_v = patch\n",
    "            )\n",
    "        )]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "641fe058-d69d-404b-931e-882724a69b5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def intervene_resid(resid, hook, scale, feature, position):\n",
    "    feature /= feature.norm(dim=-1)\n",
    "    feature_projection = resid[0, position] @ feature\n",
    "    resid[0, position] -= feature_project * scale * feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da98a39-5df8-4d02-8cf9-97fb5671a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.run_with_hook(\n",
    "    past_moves,\n",
    "    fwd_hooks=[()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "406c1173-e9f8-4ce6-9e16-1cd2f4f884d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_k(tokens, layer_idx, head_idx):\n",
    "    _, cache = model.run_with_cache(tokens)\n",
    "    hook_name = get_act_name(\"k\", layer_idx)\n",
    "    k = cache[hook_name][:, :, head_idx]\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "740d4e0c-ce44-4d15-80f7-20ed471f039b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, head_idx = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7812b43-7360-4ca5-86df-f235bdc98863",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_open = get_k(all_open_tokens, layer_idx, head_idx)\n",
    "k_close = get_k(all_close_tokens, layer_idx, head_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3eb584-7b70-44dc-94ef-c9a048a70c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_avg = (k_open + k_close) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f58988-f540-4680-a64d-3a04483fd289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_k(acts, hook, new_k):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e904c3c-1ed6-4803-8e9b-51d2a48bf285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89060bdd-bd42-4222-a5e8-cf41c6c23c56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def variance(x):\n",
    "    return (x-x.mean()).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94f2895b-46d8-4081-9c28-278b638eb843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def variance(x):\n",
    "    return (x-x.mean()).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9797e572-287b-48b8-be1c-d175debe6775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_discounted_return_each_timestep(\n",
    "    rewards, discount_factor=0.99\n",
    "):\n",
    "    n_rewards = len(rewards)\n",
    "    discounted_returns = torch.zeros(n_rewards).float()\n",
    "    \n",
    "    for i in range(n_rewards):\n",
    "        discounted_return = 0\n",
    "        \n",
    "        for k, reward in enumerate(rewards[i:]):\n",
    "            discounted_return += (discount_factor**k)*reward\n",
    "        \n",
    "        discounted_returns[i] = discounted_return\n",
    "    \n",
    "    return discounted_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6404d259-7321-4fb6-9681-cb46eb5a96b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, policy, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b5978a-d621-4a1b-b881-0e042faa69ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "state, _ = env.reset()\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    predicted_rewards = model(state)\n",
    "    action = torch.argmax(predicted_rewards, dim=-1)[0]\n",
    "    \n",
    "    state, reward, done, _, _ = env.step(action)\n",
    "    \n",
    "    if done is False:\n",
    "        next_predicted_rewards = model(state)\n",
    "        max_next_predicted_reward = torch.max(next_predicted_rewards)\n",
    "        target_reward = reward + max_next_predicted_reward\n",
    "    else:\n",
    "        target_reward = reward\n",
    "    \n",
    "    loss = loss_func(predicted_rewards[max_next_predicted_reward], target_reward)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1558f678-3853-401c-ae88-dbc5b151bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "representation, dynamic, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3cbe75-0d4a-4273-a0d2-b41c2e0f9659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_reward(rewards, discount_factor):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed663061-95cf-4466-b3ca-289a57cc2b11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rewards = torch.tensor([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa553d-ce4e-48af-b972-2070304f3fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_discounted_return_at_each_timestep(rewards, discount_factor):\n",
    "    n_rewards = len(rewards)\n",
    "    discounted_returns = []\n",
    "    for i in range(n_rewards):\n",
    "        discount_return = 0\n",
    "        \n",
    "        for k, reward in enumerate(rewards[i:]):\n",
    "            discounted_return += (discount_factor**k)*reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2041748b-8e95-472d-8ca6-5b82dbf2bf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "two uncertainty principles, quantization of angular momentum, quantization of action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228de46b-f11b-4a9e-9875-913f4b6dd648",
   "metadata": {},
   "outputs": [],
   "source": [
    "strong, weak, electromagntic radiation, gravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8555642-a038-403c-9765-d5af60841b55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_partitions = 5\n",
    "n_microbatches = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8a5af82-8568-4dfb-9b5f-743f147adc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clock_cycles = n_partitions + n_microbatches - 1\n",
    "\n",
    "schedules = []\n",
    "for clock_idx in range(n_clock_cycles):\n",
    "    start_partrition = max(clock_idx + 1 - n_microbatches, 0)\n",
    "    end_partition = min(clock_idx + 1, n_partitions)\n",
    "\n",
    "    tasks = []\n",
    "    for partition_idx in range(start_partrition, end_partition):\n",
    "        microbatch_idx = clock_idx - partition_idx\n",
    "        tasks.append((microbatch_idx, partition_idx))\n",
    "    \n",
    "    schedules.append(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dae351e9-ddb1-43fc-8f40-65039fffdd4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0)],\n",
       " [(1, 0), (0, 1)],\n",
       " [(2, 0), (1, 1), (0, 2)],\n",
       " [(3, 0), (2, 1), (1, 2), (0, 3)],\n",
       " [(3, 1), (2, 2), (1, 3), (0, 4)],\n",
       " [(3, 2), (2, 3), (1, 4)],\n",
       " [(3, 3), (2, 4)],\n",
       " [(3, 4)]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6c3a92b-487c-4c5e-a1c1-0e3890a65e96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_partitions = 5  # Replace with your number of partitions\n",
    "n_microbatches = 10  # Replace with your number of micro-batches\n",
    "\n",
    "task_completion_status = {\n",
    "    partition_idx: {microbatch_idx: False for microbatch_idx in range(n_microbatches)}\n",
    "    for partition_idx in range(n_partitions)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11829f71-9b7a-4080-92a0-a6da5cad6047",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: False,\n",
       "  1: False,\n",
       "  2: False,\n",
       "  3: False,\n",
       "  4: False,\n",
       "  5: False,\n",
       "  6: False,\n",
       "  7: False,\n",
       "  8: False,\n",
       "  9: False},\n",
       " 1: {0: False,\n",
       "  1: False,\n",
       "  2: False,\n",
       "  3: False,\n",
       "  4: False,\n",
       "  5: False,\n",
       "  6: False,\n",
       "  7: False,\n",
       "  8: False,\n",
       "  9: False},\n",
       " 2: {0: False,\n",
       "  1: False,\n",
       "  2: False,\n",
       "  3: False,\n",
       "  4: False,\n",
       "  5: False,\n",
       "  6: False,\n",
       "  7: False,\n",
       "  8: False,\n",
       "  9: False},\n",
       " 3: {0: False,\n",
       "  1: False,\n",
       "  2: False,\n",
       "  3: False,\n",
       "  4: False,\n",
       "  5: False,\n",
       "  6: False,\n",
       "  7: False,\n",
       "  8: False,\n",
       "  9: False},\n",
       " 4: {0: False,\n",
       "  1: False,\n",
       "  2: False,\n",
       "  3: False,\n",
       "  4: False,\n",
       "  5: False,\n",
       "  6: False,\n",
       "  7: False,\n",
       "  8: False,\n",
       "  9: False}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_completion_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a51be96-2e02-477b-b2aa-18ad7c8e4780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
