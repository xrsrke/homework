{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e95f027e-fb8b-483d-a37d-43ac47b1cad5",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a47b2b5f-c54d-4530-ac45-83c771b7c09f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e10499-072a-421b-bfa8-9f5619f726c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "132373c7-943a-4c39-bb34-f5b8a210c4dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParameterSharding:\n",
    "    def __init__(self, param_groups, parallel_context):\n",
    "        self.param_groups = param_groups\n",
    "        self.parallel_context = parallel_context\n",
    "    \n",
    "    def shard(self):\n",
    "        world_size = self.parallel_context.get_world_size()\n",
    "        partition_params = [[] for _ in range(world_size)]\n",
    "        sizes = [0 for _ in range(world_size)]\n",
    "        \n",
    "        for param_group in self.param_groups:\n",
    "            params = [[] for _ in range(world_size)]\n",
    "            \n",
    "            # split params in a param group\n",
    "            for p in param_group[\"params\"]:\n",
    "                next_rank = sizes.index(min(sizes))\n",
    "                params[next_rank].append(p)\n",
    "                sizes[next_rank] += p.numel()\n",
    "            \n",
    "            # set partitioned params\n",
    "            for rank, p in params:\n",
    "                param_group_rank = copy.copy(param_group)\n",
    "                param_group_rank[\"params\"] = pg\n",
    "                partition_params[rank] = param_group_rank\n",
    "        \n",
    "        return partition_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ad7e09-4c3d-464e-a016-2bb2cdd46de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "(local_rank-1)%world_Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71956757-3db0-45f1-abdc-c954497e2095",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployments, services, secret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58eee31-05b0-4b15-a983-2632887bf6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kublet-proxy, kubelet, container runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfb17551-4849-41b3-80f8-a31f45578261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8089ed88-4d69-4613-9343-f4b3c18a41bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in groups:\n",
    "    dist.barrier()\n",
    "    dist.destroy_process_group(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "868c77fb-41ac-4d7f-9822-95c4e4687c30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Scatter(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        world_size = dist.get_world_size()\n",
    "        rank = dist.get_rank()        \n",
    "        chunks = torch.split(input, input.shape[-1]//world_size)\n",
    "        return chunks[rank]\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        world_size = dist.get_world_size()\n",
    "        grads = [torch.empty_like(grad_input) for _ in range(world_size)]\n",
    "        dist.all_gather(grads, grad_input)\n",
    "        grads = torch.cat(grads)\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c164f331-54fb-4cbd-b113-73b8cfd8d0cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Reduce(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        dist.all_reduce(input)\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6bd576a-1128-4a69-9d6b-cb64ab4d4e6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RowParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        world_size = dist.get_world_size()\n",
    "        inp_per_partition = input_size // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.randn(\n",
    "            output_size,\n",
    "            inp_per_partition\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.randn(\n",
    "            output_size\n",
    "        ))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        input_parallel = Scatter.apply(input)\n",
    "        output_parallel = F.linear(input_parallel, self.weight)\n",
    "        outputs = Reduce.apply(output_parallel)\n",
    "        return outputs + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e341664e-557a-4aac-9ca5-4a7c57cf850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(local_rank+1)%local_world_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ac7478-fa1b-43e7-a790-afe8475b0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: fp16, fp32 of weight\n",
    "step 2: do forward and backward using fp16\n",
    "step 3: cast grads to fp32\n",
    "step 4: update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9ad5fd-fcd2-40b4-9c36-bbdb5bd04a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank*partition_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df643c5-48b8-48eb-8e62-f6f36f442403",
   "metadata": {},
   "source": [
    "step 1: a clean prompt and a corrupted prompt\n",
    "step 2: record the interdimate activations of the clean prompt and corrupted prompt\n",
    "step 3: run the clean prompt again\n",
    "step 4: patch the activation from the corrupted: 4.2 and all components in between, patch other components from clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5536dd8-526a-4228-b5b3-9b7da704fa1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abe27a96-f385-428e-9bfb-b9c4cd30c7f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faef18f2-888f-4942-b56c-d5094fb5f2bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_layers = 12\n",
    "n_heads = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "821b8c3a-b9aa-4da8-9c37-6778fdf5eaa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combinations = product(range(n_heads), range(n_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "871e75ee-e6e5-4006-b51a-17dcd491afca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (0, 4),\n",
       " (0, 5),\n",
       " (0, 6),\n",
       " (0, 7),\n",
       " (0, 8),\n",
       " (0, 9),\n",
       " (0, 10),\n",
       " (0, 11),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (1, 4),\n",
       " (1, 5),\n",
       " (1, 6),\n",
       " (1, 7),\n",
       " (1, 8),\n",
       " (1, 9),\n",
       " (1, 10),\n",
       " (1, 11),\n",
       " (2, 0),\n",
       " (2, 1),\n",
       " (2, 2),\n",
       " (2, 3),\n",
       " (2, 4),\n",
       " (2, 5),\n",
       " (2, 6),\n",
       " (2, 7),\n",
       " (2, 8),\n",
       " (2, 9),\n",
       " (2, 10),\n",
       " (2, 11),\n",
       " (3, 0),\n",
       " (3, 1),\n",
       " (3, 2),\n",
       " (3, 3),\n",
       " (3, 4),\n",
       " (3, 5),\n",
       " (3, 6),\n",
       " (3, 7),\n",
       " (3, 8),\n",
       " (3, 9),\n",
       " (3, 10),\n",
       " (3, 11),\n",
       " (4, 0),\n",
       " (4, 1),\n",
       " (4, 2),\n",
       " (4, 3),\n",
       " (4, 4),\n",
       " (4, 5),\n",
       " (4, 6),\n",
       " (4, 7),\n",
       " (4, 8),\n",
       " (4, 9),\n",
       " (4, 10),\n",
       " (4, 11),\n",
       " (5, 0),\n",
       " (5, 1),\n",
       " (5, 2),\n",
       " (5, 3),\n",
       " (5, 4),\n",
       " (5, 5),\n",
       " (5, 6),\n",
       " (5, 7),\n",
       " (5, 8),\n",
       " (5, 9),\n",
       " (5, 10),\n",
       " (5, 11),\n",
       " (6, 0),\n",
       " (6, 1),\n",
       " (6, 2),\n",
       " (6, 3),\n",
       " (6, 4),\n",
       " (6, 5),\n",
       " (6, 6),\n",
       " (6, 7),\n",
       " (6, 8),\n",
       " (6, 9),\n",
       " (6, 10),\n",
       " (6, 11),\n",
       " (7, 0),\n",
       " (7, 1),\n",
       " (7, 2),\n",
       " (7, 3),\n",
       " (7, 4),\n",
       " (7, 5),\n",
       " (7, 6),\n",
       " (7, 7),\n",
       " (7, 8),\n",
       " (7, 9),\n",
       " (7, 10),\n",
       " (7, 11),\n",
       " (8, 0),\n",
       " (8, 1),\n",
       " (8, 2),\n",
       " (8, 3),\n",
       " (8, 4),\n",
       " (8, 5),\n",
       " (8, 6),\n",
       " (8, 7),\n",
       " (8, 8),\n",
       " (8, 9),\n",
       " (8, 10),\n",
       " (8, 11),\n",
       " (9, 0),\n",
       " (9, 1),\n",
       " (9, 2),\n",
       " (9, 3),\n",
       " (9, 4),\n",
       " (9, 5),\n",
       " (9, 6),\n",
       " (9, 7),\n",
       " (9, 8),\n",
       " (9, 9),\n",
       " (9, 10),\n",
       " (9, 11),\n",
       " (10, 0),\n",
       " (10, 1),\n",
       " (10, 2),\n",
       " (10, 3),\n",
       " (10, 4),\n",
       " (10, 5),\n",
       " (10, 6),\n",
       " (10, 7),\n",
       " (10, 8),\n",
       " (10, 9),\n",
       " (10, 10),\n",
       " (10, 11),\n",
       " (11, 0),\n",
       " (11, 1),\n",
       " (11, 2),\n",
       " (11, 3),\n",
       " (11, 4),\n",
       " (11, 5),\n",
       " (11, 6),\n",
       " (11, 7),\n",
       " (11, 8),\n",
       " (11, 9),\n",
       " (11, 10),\n",
       " (11, 11)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5d1461f-1879-44da-a31e-2171063e9128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_head, d_model = 4, 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2aecfb13-d5da-4ec7-9535-358436a6aebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W_V = torch.zeros(d_head, d_model)\n",
    "W_V[torch.arange(4), torch.arange(4)] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4758187-95b6-4f82-ae22-65027e56e331",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3da5e2-6ed5-4b5b-a53b-29f6695737ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_O = torch.zeros(d_model, d_head)\n",
    "W_O[8:11] = torch.eye(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d00ff07-d6b9-4287-976b-efa51504a49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hook_func in hooks:\n",
    "    model.ln_f.register_forward_hook(hook_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c97d44-9528-4607-91d7-9c10bd333b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: diverse distribution\n",
    "step 2: record all the interdimate neuron activations\n",
    "step 3: color\n",
    "step 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551db9cb-cf71-4336-ac54-a48a05546045",
   "metadata": {},
   "outputs": [],
   "source": [
    "resigter > cache > sram > disk > external disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56092f2b-6b54-47cb-b2e2-6cab7ea36dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "elasticdriver, torchstate, hostdiscovery, 3 notifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16691423-a75b-431f-ae7a-8192897157a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready, running, finished, failed, blacklisted, cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd384ed-2621-424c-85e0-71aeb02b9809",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: determine a list of global ranks in that group\n",
    "step 2: if the process's global rank in that list\n",
    "step 3: initialize a parallel group\n",
    "step 4: local rank\n",
    "step 5: save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680918b9-8bfc-4191-a079-8985acdc4231",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a831cf29-d5ce-419e-80f4-088be6c48c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_consine_similarity(x, y):\n",
    "    x /= x.norm()\n",
    "    y /= y.norm()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb7fc19-74de-4558-9dbb-340f7713b33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: split weight\n",
    "step 2: determine vocab_start_idx, end_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1e741e3-4b67-4fa8-afd5-55a0d00e394e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d122bf94-f9c5-4008-9cd3-59074a600d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelStateHandler:\n",
    "    def __init__(self, model):\n",
    "        self.set_value(model)\n",
    "    \n",
    "    def set_value(self, value):\n",
    "        self.model = model\n",
    "    \n",
    "    def commit(self):\n",
    "        self._saved_state_dict = deepcopy(self.model)\n",
    "    \n",
    "    def restore(self):\n",
    "        self.model.load_state_dict(self._saved_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304cbd15-23aa-4c46-8e79-8342ed856a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: initialize paritioned weight\n",
    "step 2: determine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad93fcb1-fa65-4292-be3c-ce712c6e8b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy loading, data prefetch, memory mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af694c78-e6e8-4ebf-bf76-36071505ec11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95079d9f-ebb9-4364-81b2-ed6eb3ba3185",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cb54a0-0d0c-4cb7-9b2b-3aac2728fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce, scatter, gather, broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6380981-ab30-4623-810d-047c31a1025e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46b75ff-6161-411a-b0e2-db94c76776a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d81517-438c-444e-a9cc-f8fcc346afa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock cycle 1: F(0, 0)\n",
    "clock cycle 2: F(1, 0), F(0, 1)\n",
    "clock cycle 3: F(2, 0), F(1, 1)\n",
    "clock cycle 4: F(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873d31f6-17a7-43e8-8ae3-3c9161f03a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: set environment variables\n",
    "step 2: init global distributed group\n",
    "step 3: initialize parallel groups\n",
    "step 4: set device\n",
    "step 5: set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528a9d54-4c1a-4247-aaae-9cae9c2e4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_pos = model.W_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a957c0c0-9da8-43b6-91a7-57b337d5765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cosine_similarity(W_pos[:, 0], W_pos[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d8be556-dbb1-4e90-b9cb-bfba9ca9e5cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W_V = torch.zeros(d_head, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7681e705-610f-4dee-8b55-84e8774c9fd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W_V[torch.arange(3), torch.arange(3)] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9eb641f8-482a-4ba2-8357-2ff71808cc11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7e858e4-0555-41c6-956f-231a671268f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W_O = torch.zeros(d_model, d_head)\n",
    "W_O[7:11, :] = torch.eye(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9339de6-f1cc-4922-abf2-a07909304793",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc922fe6-c04a-4376-a178-4658e9a92bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: early heads detect S2 token. Write s2 is \n",
    "step 2: middle head "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b9b68-da34-4a33-b82c-0500272c43bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(board_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3482d7-ac23-4d5e-bceb-cabed1abd878",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_neurons = cache[hook_name][:, 1393]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d6ce87-d45a-43c5-bd60-ea23a4ec6c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "threashold = mlp_neurons.quantile(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d929f13f-12f6-4b73-b489-d643079949be",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_neurons = mlp_neurons > threashold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69cb4a7-adf8-4394-b92b-489793df235a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(board_states == 2)[:, top_neurons].float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57282604-3e0d-4ac9-a41b-c87eb4bc7e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[\"result\", 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042225ad-85ff-402c-a9da-05309befb42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "handles = []\n",
    "for hook_func in hooks:\n",
    "    handles.append(model.ln_f.register_forward_pre_hook(hook_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ec8d52-ee97-45e8-9cd5-c7031fcd644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "handles[1].remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e870b7d7-f317-47e8-a816-197a613189a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: q = x @ W_Q\n",
    "step 2: x = embed + pos_embed + sum(12 heads)\n",
    "step 3: q = [embed + pos_embed + sum(12 heads)] @ W_Q\n",
    "step 4: q = embed @ W_Q + pos_embed @ W_Q + ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a42488-ccb9-4bcb-b381-948b487f67c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "A @ x @ W_OV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4b3c0-594d-4e1c-8335-86dfe04d3d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619433db-39cc-4c21-a5bd-a26b4f8c240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0764f4f-ba46-4c9b-b16d-aa83a896516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_components = torch.tensor([\n",
    "    cache[\"embed\"],\n",
    "    cache[\"pos_embed\"],\n",
    "    cache[\"result\", prev_layer_idx]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1325b458-c405-4969-af5e-85261092f2b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e486ba-3e78-4ed7-bb8e-776bf03a1646",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Q = model.W_Q[layer_idx, head_idx]\n",
    "query_components = einsum(\n",
    "    input_components,\n",
    "    W_Q\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7a883-5526-45d8-836d-311b0fa02a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_contributions = query_components.pow(2).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3d326-f682-4b4a-ba2a-3906811cc664",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995d6266-26ed-47fa-8d5e-9477ab20c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tokens = tokens[1:]\n",
    "\n",
    "W_U = model.W_U\n",
    "W_U_target_tokens = W_U[:, target_tokens]\n",
    "\n",
    "embed = cache[\"emed\"][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a220d69-c116-4cff-a450-d6e6fd0d2fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_attributions = einsum(\n",
    "    embed,\n",
    "    W_U_target_tokens,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c70e19-cabf-4274-ba4b-4a1a96e7e9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\n",
    "    \"q\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8593780c-3b7f-4ed8-962d-0b4132e8ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Q, W_K = model.W_Q, model.W_K\n",
    "W_V, W_O = model.W_V, model.W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5931acf1-3588-4ec6-a1c2-5cd487113426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc01e91-4173-4119-852b-87ce5b78562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_QK = torch.matmul(\n",
    "    W_Q,\n",
    "    rearrange(W_K, \"... d_model d_head -> ... d_head d_model\")\n",
    ")\n",
    "W_OV = W_V @ W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f5aa96-5437-4e64-9bfa-fd5d9c468f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_composition_scores(W_A, W_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed8ce93-f1bf-4642-bde5-7233eaef9da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: weight\n",
    "step 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dc12d6-b505-4ac5-9a71-100eb13b3141",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\n",
    "    \"q\": torch.zeros(n_heads, n_heads),\n",
    "    \"k\": torch.zeros(n_heads, n_heads),\n",
    "    \"v\": torch.zeros(n_heads, n_heads)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67fde0ad-f5c1-498c-bea6-989346d689e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1084317-a26b-4ba5-8243-ed0a9702034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Q, W_K = model.W_Q, model.W_K\n",
    "W_O, W_V = model.W_O, model.W_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8beb1fa9-bb8a-4eec-b6a5-9d8753080799",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_QK = torch.matmul(\n",
    "    W_Q,\n",
    "    rearrange(W_K, \"... d_model d_head -> ... d_head d_model\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525537ff-038d-4da7-b40b-996071e13c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_OV = W_V @ W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec3f97f-5cd1-42c1-adcd-0826702a51d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_composition_score(W_A, W_B):\n",
    "    W_AB_norm = (W_A @ W_B).pow(2).sum().sqrt()\n",
    "    W_A_norm = W_A.pow(2).sum().sqrt()\n",
    "    W_B_norm = W_B.pow(2).sum().sqrt()\n",
    "    return W_AB_norm / (W_A_norm * W_B_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f498f2f-aa2a-44b6-a227-c45e4018abdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_heads):\n",
    "    for j in range(n_heads):\n",
    "        scores[\"q\"] = compute_attn_score(W_OV[0, i], W_QK[0, j])\n",
    "        scores[\"k\"] = compute_attn_score(W_OV[0, i], W_QK[0, j].T)\n",
    "        scores[\"v\"] = compute_attn_score(W_OV[0, i], W_OV[0, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dccc2e3-cb96-49c9-b667-5d1a5fbb105d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fc9bcc-e2e4-4ff5-bd41-bf17ff2b96b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: head0 = L0H00(pre_resid)\n",
    "step 2: mid_resid = pre_resid + head0\n",
    "stpe 3: mlp0 = MLP0(mid_resid)\n",
    "step 4: resid0 = mid_resid + mlp0\n",
    "step 5: mlp1 = MLP1(resid0)\n",
    "step 6: resid1 = resid0 + mlp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f247704-d9b1-459e-a69f-4ab0620a7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: diverse distribution\n",
    "step 2: record the attention pattern of the target head\n",
    "step 3: determine the query position\n",
    "step 4: average\n",
    "step 5: plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79a3f9-7a20-47f6-827d-bdd8b79ca096",
   "metadata": {},
   "outputs": [],
   "source": [
    "A@x@W_OV@W_OV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7760611e-4873-484c-9461-9f3f27347ead",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corrupted_prompt = [\n",
    "    \"When X and Y went to the shops, Z gave the bag to\",\n",
    "    \"When K and V went to the park, H gave the ball to\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dade9f-c59b-4cf0-96c2-530b1d8f86c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = model.to_tokens(clean_prompts)\n",
    "corrupted_tokens = model.to_tokens(corrupted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2213495e-bd68-4f69-9712-b722ea9bae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_tokens = model.to_tokens(\"Mary Tom\")\n",
    "incorrect_tokens = model.to_tokens(\"John James\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9c9c9e-f223-45a6-a7d2-0c3538fc249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logits, _ =  = model.run_with_cache(clean_tokens)\n",
    "corrupted_logits, _ = model.run_with_cache(corrupted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf38bf8e-f307-45d4-a6da-ea0410afd76f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_avg_logit_diff(logits, correct_tokens, incorrect_tokens):\n",
    "    final_logits = logits[:, -1, :]\n",
    "    return (final_logits[:, correct_tokens] - final_logits[:, incorrect_tokens]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051969f-7a47-4506-93a8-9903a93c68ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logit_diff = compute_avg_logit_diff(clean_logits, correct_tokens, incorrect_tokens)\n",
    "corrupted_logit_diff = compute_avg_logit_diff(corrupted_logits, correct_tokens, incorrect_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca7c5e5-9090-4a28-bae9-95f0a4f9eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ioi_metric(patched_metric):\n",
    "    patched_logit_diff = compute_avg_logit_diff(patched_logit_diff)\n",
    "    return (patched_logit_diff - corrupted_logit_diff)/(clean_logit_diff-corrupted_logit_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3b97b2-205f-4b15-8903-4295f36f7607",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: prob[0] = sigmoid(logit0 - logit1)\n",
    "step 2: logit0 = resid2 @ W_U[0], logit1 = resid2 @ W_U[1]\n",
    "step 3: logit0 - logit1 = resid2 @ (W_U[0] - W_U[1])\n",
    "step 4: resid2 = resid1 @ ln1 @ W_OV^{2, 0}\n",
    "step 5: target_direction = resid1 @ ln1 @ W_OV @ (W_U[0] - W_U[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40d2367-b8c7-4229-bf24-daee73ad03fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4555e8d4-a686-465d-be70-57e18868f2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.run_with_hooks(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873b11ac-4cc6-4325-acc1-5e61f9485dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = F.log_softmax(logits[:, -1, :], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2a7d7e-a339-4783-a039-d052641cfe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tokens = tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecccd18-0c84-46da-bab1-0526393ab4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_log_probs = -torch.gather(log_probs, dim=1, index=target_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00735f8-7fcc-4451-9673-feb1d81857ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_rank * partition_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729d4437-f82d-4589-af73-91d8802720ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: f1\n",
    "step 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa1c875-ad55-4948-bafd-5c5c66412b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast, gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255921c5-85d5-4746-a1ca-6261ddf5163a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = attn_weights.diagonal(dim1=-2, dim2=-1, offset=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d4bb9-c911-4689-992e-465ab0928389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfa4bc6-b5d4-46c3-b642-80079a395c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast > gather > scatter > all-reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65481f1f-361d-49e5-9d91-a60cc4b7e5aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f82437b-5ee1-413b-bdff-896a1914d468",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_O = model.W_O\n",
    "W_V = model.W_V\n",
    "W_K = model.W_K\n",
    "W_Q = model.W_Q\n",
    "\n",
    "\n",
    "W_QK = torch.matmul(\n",
    "    W_Q,\n",
    "    rearrange(W_K, \"... d_model d_head -> ... d_head d_model\")\n",
    ")\n",
    "W_OV = W_V @ W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72b151-f212-4aa0-95a9-5636eb9987a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\n",
    "    \"Q\": torch.zeros(n_heads, n_heads),\n",
    "    \"K\": torch.zeros(n_heads, n_heads),\n",
    "    \"V\": torch.zeros(n_heads, n_heads)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b9a221d6-8628-4e4d-a08e-6ee18f93cdac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_composition_score(W_A, W_B):\n",
    "    W_AB_norm = (W_A@W_B).pow(2).sum()\n",
    "    W_A_norm = W_A.pow(2).sum()\n",
    "    W_B_norm = W_B.pow(2).sum()\n",
    "    return (W_AB_norm)/(W_A_norm*W_B_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d743c96-8844-4b00-9a89-2dc4c88ddbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_heads):\n",
    "    for j in range(n_heads):\n",
    "        scores[\"Q\"][i][j] = compute_composition_score(W_OV[0, i], W_QK[1, j])\n",
    "        scores[\"K\"][i][j] = compute_composition_score(W_OV[0, i], W_QK[1, j].T)\n",
    "        scores[\"V\"][i][j] = compute_composition_score(W_OV[0, i], W_OV[1, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170594f8-601f-4329-960b-78d58f124d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: init partitioned weight\n",
    "step 2: mask input\n",
    "step 3: reduce\n",
    "step 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8434426-9d6d-42d9-a7e1-6eb3de9572bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: head0 = L0H00(pre_resid)\n",
    "step 2: resid1 = pre_resid + head0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af72b84f-42aa-4f7f-a7d8-5fcbc95b2785",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: wait\n",
    "step 2: get\n",
    "step 3: construct\n",
    "step 4: put\n",
    "step 5: wait\n",
    "step 6: get\n",
    "step 7: put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf93fb-0241-4523-8112-e9a7a37783a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scatter > Reduce > Identity > Gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a91ccc-82a8-47d2-ab56-e63ca8a216d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_cache = model.run_with_cache(clean_tokens)\n",
    "_, corrupted_cache = model.run_with_cache(corrupted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49fa0065-2598-429b-acfd-fcb06532d781",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_head(\n",
    "    head_vector,\n",
    "    hook,\n",
    "    clean_activations,\n",
    "    corrupted_activations,\n",
    "    target_head\n",
    "):\n",
    "    target_layer_idx = target_head[0]\n",
    "    target_head_idx = target_head[1]\n",
    "    if hook.layer() == target_layer_idx:\n",
    "        head_vector[:, target_head_idx] = corrupted_activations[hook.name][:, target_head_idx]\n",
    "    else:\n",
    "        head_vector = clean_activations\n",
    "    \n",
    "    return head_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16fc9d94-1680-455a-93ef-4cb2a89f7bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88439b16-099d-41c5-a387-ea2940103c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = product(range(n_layers), range(n_heads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c55199a8-cb0f-4a9b-9257-d571dfaed7de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b4262c9-1f4d-4285-8b84-cecd1cb08bb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3665528e-6ef5-4983-8f1d-a77cf220b7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resid_to_logit(cache):\n",
    "    hook_name = get_act_name(\"resid_post\", n_layers-1)\n",
    "    resid = cache[hook_name][:, -1, :]\n",
    "    return model.unembed(model.ln_final(resid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f344503-39c2-4bb0-910d-0b7cdf041e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.zeros(n_layers, n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fb5687-e6b9-420a-a10d-e517a0de8fe9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for layer_idx, head_idx in combinations:\n",
    "    model.reset_hooks()\n",
    "    hook_name = get_act_name(\"z\", layer_idx)\n",
    "    hook_func = partial(\n",
    "        patch_head,\n",
    "        clean_activations=clean_activations,\n",
    "        corrupted_activations=corrupted_activations,\n",
    "        target_head=(layer_idx, head_idx)\n",
    "    )\n",
    "    \n",
    "    _, cache = model.run_with_cache(\n",
    "        clean_tokens,\n",
    "        fwd_hooks=[(hook_name, hook_func)]\n",
    "    )\n",
    "    \n",
    "    patched_logits = resid_to_logit(cache)\n",
    "    results[layer_idx, head_idx] = compute_ioi_metric(patched_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1822d9b4-1e73-441b-9d4f-8851e2aeadeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: convert input tokens to fourier basis\n",
    "step 2: do addition using trig identities\n",
    "step 3: map back to logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7c2d5d-19df-4e52-9875-3986b2a22d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_OV = model.W_V[0, 1] @ model.W_O[0, 1]\n",
    "W_QK = model.W_Q[1, 2] @ model.W_K[1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bfa5ff-dad2-43bd-9abe-bfde9ddd181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_weight = W_OV @ W_QK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fdb3e5-6f93-4dd0-91ec-43bfa67fb5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c14a2ad-9eb2-42b5-b3cc-23675a0c691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e80b76-4c77-45db-a8bb-178f249c139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_acts = cache[\"post\", layer_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3ec4f1-044e-4008-af0f-a5e67509ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = inp_acts @ model.W_out[layer_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2b3645-d713-4e8d-bce8-3a26d50d0a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualLayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, dropout):\n",
    "        super().__init__()\n",
    "        self."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65815f9b-df25-4c75-9767-7e88fd5a1f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: determine global rank\n",
    "step 2: initialize global group\n",
    "step 3: initialize parallel groups\n",
    "step 4: set device\n",
    "step 5: set seed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
