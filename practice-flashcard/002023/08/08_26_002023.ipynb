{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28f64001-168e-4139-bcb9-6273bf5ef727",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d765039b-abbf-43ad-9e0f-e853275a3a58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccffafa3-f5c7-4870-b9fa-ef8794e5db76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824f22a1-1d0f-460e-8a7e-9d2f4dd76f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b9578a-5270-4f43-8338-8f66ac8df5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cycles = 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583b5849-8f17-4d28-8d30-37df2fef80d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start.record()\n",
    "torch.cuda._sleep(n_cycles)\n",
    "end.record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3720dd2-d254-4066-bec2-6889dada8439",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycle_per_ms = n_cycles / start.elapsed_time(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27f2f4b-0a29-4610-a63b-605581337185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuda_sleep(seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb82415b-8b33-47d3-bd32-2c1eeb70c780",
   "metadata": {},
   "outputs": [],
   "source": [
    "received queue, job queue, output queue, syncronization queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9c81ac-8a66-4f44-ae70-c36b079003eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool thread, job selector, worker thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc15769-b43e-4cf7-a737-58bea596755c",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition2(microbatch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49923c31-4338-4b10-a6b4-c77e2d541fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "int zero() {\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea2241b-f7de-488e-b7b3-882bfd0a69fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821920c1-859a-4612-805e-895dc49e164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Book() {\n",
    "    public:\n",
    "        std::string title;\n",
    "        std::string author;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbe89c5-ecfd-4ac0-ab98-529871ec45b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.repeat((3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90203fa-5b33-4a99-a23d-a437024172ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(clock_idx+1, n_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef85c751-2eb0-48e9-bbae-17b6ec610783",
   "metadata": {},
   "outputs": [],
   "source": [
    "notification service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ebc845-0833-4827-8bd7-05c334431cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelContext:\n",
    "    def init_rpc_workers(self, host, port):\n",
    "        if self.pipeline_parallel_size > 1:\n",
    "            rank = self.get_local_rank(ParallelMode.PIPELINE)\n",
    "            world_size = self.get_world_size(ParallelMode.PIPELINE)\n",
    "            init_method = f\"rpc://{host}:{port}\"\n",
    "            \n",
    "            options = rpc.RpcBackendOptions(\n",
    "                init_method=init_method\n",
    "            )\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                ranks = self.get_ranks_in_group(ParallelMode.PIPELINE)\n",
    "                \n",
    "                device_mapping = {\n",
    "                    rank: WORKER_NAME.format(rank)\n",
    "                    for rank in ranks\n",
    "                }\n",
    "                \n",
    "                for other in ranks:\n",
    "                    if other == rank:\n",
    "                        continue\n",
    "                    options.set_device(WORKER_NAME.format(rank), rank: other)\n",
    "            \n",
    "            rpc.init_rpc(\n",
    "                name=WORKER_NAME.format(rank),\n",
    "                world_size=world_size,\n",
    "                rpc_backend_options=options\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f74a8093-81ef-45a2-923f-8c8ef117477f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class _P2P:\n",
    "    def _send_metadata(self, data, dst, parallel_context, parallel_mode):\n",
    "        group = parallel_context.get_group(ParallelMode.PIPELINE)\n",
    "        \n",
    "        dtype = torch.tensor(DTYPE_TO_ID[data.dtype])\n",
    "        dist.send(dtype, dst=dst, group=group)\n",
    "        \n",
    "        shape = torch.tensor(data.shape.to_list())\n",
    "        dist.send(shape, dst=dst, group=group)\n",
    "        \n",
    "        requires_grad = torch.tensor(1 if data.requires_grad == True else 0)\n",
    "        dist.send(requires_grad, dst=dst, group=group)\n",
    "    \n",
    "    def send(self, data, dst, parallel_context, parallel_mode):\n",
    "        group = parallel_context.get_group(ParallelMode.PIPELINE)\n",
    "        self._send_metadata(data, dst, parallle_context, parallel_mode)\n",
    "        dist.send(data, dst, group=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942be8f1-16f4-4410-b0f7-2082d653c12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send(data, src_rank, dst_rank, parallel_context, parallel_mode=ParallelMode.PIPELINE):\n",
    "    rank = parallel_context.get_local_rank(parallel_mode)\n",
    "    if rank == src_rank:\n",
    "        _P2P().send(data, dst_rank, parallel_context, parallel_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2ac811-a222-48ab-922b-6349cc882fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabParallelCrossEntropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e321806-7598-450f-b068-d5e2502a91e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad84dc-5bf6-4233-aa52-4d1fd7cc616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_names = [get_act_name(\"mlp_out\", layer_idx) for layer_idx in range(n_layers)]\n",
    "attn_names = [get_act_name(\"attn_out\", layer_idx) for layer_idx in range(n_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e52977-1607-4484-bedd-dd03e4fd9cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b806e95-bd8e-45a7-b09c-cbbf4b98d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_components = torch.tensor([cache[\"embed\"], cache[\"pos_embed\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555a38ac-eead-42be-ac06-243a9535a5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for attn_name, mlp_name in zip(mlp_names, attn_names):\n",
    "    input_components = torch.cat([\n",
    "        input_components,\n",
    "        cache[attn_name],\n",
    "        cache[mlp_name]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2b7869-65da-4191-bf69-8f3a0a29923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ln = cache[\"final_ln\"]\n",
    "pre_ln = final_ln @ final_ln_coefs.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e086c1bf-b837-4f9d-8c51-0b2c64816f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U\n",
    "pre_ln_dir = pre_ln @ (W_U[:, 0], W_U[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed9457ef-0d9d-479a-89c6-a795737908a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "contributions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef5ea9a-d5be-47e1-b394-3e61f4c29dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a6ade89-39d0-4dca-8c63-c00fed10892f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, head_idx = 9, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03233fb2-e11d-4256-960c-b8bd0eb7cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output = cache[\"z\", layer_idx][:, : head_idx] @ model.W_O[layer_idx, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0953ae0-f14d-4845-9626-d577c63b3167",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E\n",
    "io_embeddings = model.W_E[:, io_tokens]\n",
    "s_embeddings = model.W_E[:, s_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b1ba1-010a-4a0d-b2eb-0d1657683fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_in_io_dir = attn_output @ io_embeddings\n",
    "projection_in_s_dir = attn_output @ s_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c123c41-b533-4b64-abdb-80990912b51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_probs = cache[\"attn_prob\", layer_idx][:, :, head_idx]\n",
    "attn_from_end_to_io = attn_probs[:, -1, io_idxs]\n",
    "attn_from_end_to_s = attn_probs[:, -1, s_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec87946-28d6-49aa-aa78-9cd8ebb40cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: logits = final_resid @ W_U\n",
    "step 2: final_resid = embed + pos_embed + layer0 + layer1\n",
    "step 3: logits = [embed + pos_embed + layer0 + layer1] @ W_U\n",
    "step 4: logits = embed @ W_U + pos_embed @ W_U + layer0 @ W_U + layer1 @ W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c2ee4ce-2cae-40ce-b05c-180e760014b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b22f03-9675-46f7-b4ff-67726979ddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "interference = einsum(\n",
    "    W, W,\n",
    "    \"b f1 d, b f2 d -> b f1 f2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b88d867-bb61-40fc-a87b-c1569c452327",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, head_idx = 6, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc62ab9f-2785-4b78-b62e-db560cc52b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_V = model.W_V[layer_idx, head_idx]\n",
    "W_O = model.W_O[layer_idx, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e8f804-da5b-4f96-bdec-d7e1d1e736b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E\n",
    "W_U = model.W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5da5d7-c406-4a20-a5b4-27d778f791a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_OV = W_V @ W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fabb83-8b3f-4250-aeae-5aaadcb02436",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E\n",
    "W_Q = model.W_Q[1, 4]\n",
    "W_K = model.W_K[1, 4]\n",
    "W_O = model.W_O[0, 7]\n",
    "W_V = model.W_V[0, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adeb508e-85ad-46c2-b197-ce40baccd3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = W_E @ W_Q\n",
    "K = W_E @ W_V @ W_O @ W_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4772f3-20a4-447b-bd67-0d8a0e0802e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "int zero() {\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95262f18-8bbd-4e65-996f-27a4b976d77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "received queue, job queues, output queues, syncronization queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b746ff1-e3fd-4bce-a240-a2b16c47c4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: 0 send ready\n",
    "step 2: other received and send back\n",
    "step 3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09776799-1f8e-4361-924f-635d146b4f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter, reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469f767e-e41a-45c9-8dca-4ea7cfd59028",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.layer_norm(input, normalized_shape=(5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "460fa7f1-4444-4607-b721-73b384064dd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4222d22e-3e39-46dc-a2a0-a87f57f32c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabParallelCrossEntropy(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, parallel_logits, targets, parallel_context):\n",
    "        def get_vocab_range(parallel_logits, parallel_context):\n",
    "            partition_size = parallel_logits.shape[-1]\n",
    "            rank = parallel_context.get_local_rank(ParallelMode.TENSOR)\n",
    "            start_idx = rank*partition_size\n",
    "            end_idx = start_idx+partition_size\n",
    "            return start_idx, end_idx\n",
    "        \n",
    "        def get_predicted_logits(parallel_logits, targets):\n",
    "            start_idx, end_idx = get_vocab_range(parallel_logits, parallel_context)\n",
    "            target_mask = (targets < start_idx) | (targets >= end_idx)\n",
    "            masked_targets = targets = targets.clone() - start_idx\n",
    "            masked_targets[target_mask] = 0\n",
    "            \n",
    "            parallel_logits = rearrange(\n",
    "                parallel_logits,\n",
    "                \"batch_size seq_len vocab_size -> (batch_size seq_len) vocab_size\"\n",
    "            )\n",
    "            masked_target_1d = rearrange(\n",
    "                masked_targets,\n",
    "                \"batch_size seq_len -> (batch_size seq_len)\"\n",
    "            )\n",
    "            predicted_logits = parallel_logits[\n",
    "                torch.arange(masked_target.size(0)),\n",
    "                masked_target_1d\n",
    "            ]\n",
    "            predicted_logits = all_reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad507f0-4937-456b-b2c3-08ee2f3b6923",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: define a mapping\n",
    "step 2: mapping\n",
    "step 3: send idx\n",
    "step 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d885aa8e-df1b-41ac-a643-385a8ff550cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorParallelGroupInitialize(ProcessGroup):\n",
    "    def init_dist_group(self):\n",
    "        num_tensor_parallel_groups = self.world_size // self.tensor_parallel_size\n",
    "        local_rank = None\n",
    "        local_world_size = None\n",
    "        process_group = None\n",
    "        ranks_in_group = None\n",
    "        parallel_mode = ParallelMode.TENSOR\n",
    "        \n",
    "        for i in range(num_tensor_parallel_groups):\n",
    "            ranks = list(range(\n",
    "                i*self.tensor_parallel_size, (i+1)*self.tensor_parallel_size\n",
    "            ))\n",
    "            process_group = dist.new_group(ranks=ranks)\n",
    "            \n",
    "            if self.rank in ranks:\n",
    "                local_rank = ranks.index(self.rank)\n",
    "                local_world_size = len(ranks)\n",
    "                ranks_in_group = ranks\n",
    "        \n",
    "        return {\n",
    "            \"\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a465480e-7ac0-475b-8533-ce54877a4636",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    def __init__(\n",
    "        self,\n",
    "        microbatches,\n",
    "        partitions,\n",
    "        devices,\n",
    "        scheduler=DetermisticScheduler()\n",
    "    ):\n",
    "        self.microbatches = microbatches\n",
    "        self.partitions = partitions\n",
    "        self.devices = devices\n",
    "        \n",
    "    def fit(self):\n",
    "        n_microbatches = len(self.microbatches)\n",
    "        n_partitions = len(self.partitions)\n",
    "        \n",
    "        with spawn_workers(self.devices) as (in_queues, out_queues):\n",
    "            for schedule in self.scheduler(n_microbatches, n_partitions):\n",
    "                self._compute(in_queues, out_queues, schedule)\n",
    "    \n",
    "    def _compute(self, in_queues, out_queues, schedule):\n",
    "        for microbatch_idx, partition_idx in schedule:\n",
    "            batch = self.microbatches[microbatch_idx]\n",
    "            \n",
    "            def compute_func():\n",
    "                def inner():\n",
    "                    return partitions[partition_idx](batch)\n",
    "                return inner\n",
    "            \n",
    "            task = Task(compute=compute_func)\n",
    "            in_queues[partition_idx].put(task)\n",
    "        \n",
    "        for microbatch_idx, partition_idx in schedule:\n",
    "            output = out_queues.get(partition_idx)\n",
    "            batches[microbatch_idx].put(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e96674-d9e5-4a1c-a5ff-82f91afeb3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: pack data + metadata\n",
    "step 2: invoke rpc + data\n",
    "step 3: receive\n",
    "step 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741c2942-1474-4906-ba85-8aec7ccb1f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.roll(x, shifts=1, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27af63f0-0782-4af7-94e6-549a0d0ce1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: wait input\n",
    "step 2: get input\n",
    "step 3: construct task\n",
    "step 4: put \n",
    "step 5: wait\n",
    "step 6: get\n",
    "step 7: put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff491299-5c53-4061-94e3-eeeb1e6235ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: determine t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a4b97f8-39dc-40fb-8050-fcf6cbd5d9eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, head_idx = 6, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efdc3af-a0d3-4875-accc-deca2fd373a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E\n",
    "W_U = model.W_U\n",
    "\n",
    "W_V = model.W_V[layer_idx, head_idx]\n",
    "W_O = model.W_O[layer_idx, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c64a12-41f2-4d62-b978-f61635887c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OV_circuit = W_V @ W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f23cb71-0c60-4bc8-b860-575c80cd8450",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_OV_circuit = W_E @ OV_circuit @ W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39a364bb-82f9-4a48-be5c-0a29d663e40e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, head_idx = 0, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520707c0-a1ae-42af-88a3-d51521afcc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c48e60-8715-42e6-86fb-a6e90be7c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[\"z\", layer_idx][:, :, head_idx] @ model.W_O[layer_idx, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b211ab2b-056b-48f7-990b-0235f0d341fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E @ W_OV^{0, 7} @ W_QK^{T}{1, 4} @ W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fd1d30-6a3c-4efe-a552-5a9982925239",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E\n",
    "W_E[:, tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d82e2b-a7c4-44eb-a049-32bd4e11bde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(past_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2e0b5a2-5ad1-4b64-a081-8b62c1c8c049",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f97d582-b7a8-4068-b5a0-6f3ae38fa033",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_name = get_act_name(\"resid_post\", layer_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddba877c-4a43-404e-a9ae-8f399d45f8c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def intervene_resid(resid, hook, scale, feature):\n",
    "    normalized_feature /= feature.norm()\n",
    "    feature_projection = resid[0, position] @ normalized_feature\n",
    "    resid[0, position] -= scale*feature_projection*normalized_feature\n",
    "    return resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25b7e75e-78cd-403b-af60-a6446543297e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7740d444-5a30-46ba-8dee-cb209554d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_func = partial(\n",
    "    intervene_resid,\n",
    "    scale=scale_factor,\n",
    "    feature=target_feature\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16345e80-c7ec-432f-a6c4-4da010a3a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervened_logits = model.run_with_hooks(\n",
    "    past_moves,\n",
    "    fwd_hooks([hook_name, hook_func])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9217e6d1-a67a-4f61-ba7a-ca3cd095e0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervened_logits = interven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3b54c4-06ed-4f82-b947-304930977a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = model.W_E\n",
    "unembed = model.W_U\n",
    "\n",
    "mlp0 = model.blocks[0].mlp\n",
    "ln1 = model.blocks[0].ln1\n",
    "\n",
    "final_ln = model.final_ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68010609-1bc7-4091-91eb-84c956d18b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tokens = model.to_tokens(name_tokens, prepend_bos=True)\n",
    "embeddings = embed(name_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6914574-7b7f-4f64-b802-03af8a8ff5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_after_mlp0 = embeddings + mlp0(ln1(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e223b4f2-78b9-46b6-80dc-0489b9c29a56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def resid2logits(resid):\n",
    "    return unembed(final_ln(resid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4cc15d-1951-4b63-98c2-b00aad01ec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(n_layers):\n",
    "    for head_idx in range(n_heads):\n",
    "        W_OV = model.W_V[layer_idx, head_idx] @ W_O[layer_idx, head_idx]\n",
    "        attn_output = resid_after_mlp0 @ W_OV\n",
    "        \n",
    "        logits = resid2logits(attn_output)\n",
    "        top_predictions = torch.topk(logits, dim=-1, k=5)\n",
    "        percentage = (top_predictions == name_tokens).any(dim=-1).float().mean(dim=-1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8418ce76-bc12-4215-91d1-d3aa420c04ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorProcessInitializer(ProcessGroupInitializer):\n",
    "    def init_process_group(self):\n",
    "        num_tensor_parallel_groups = self.world_size // self.tensor_parallel_size\n",
    "        local_rank = None\n",
    "        local_world_size = None\n",
    "        \n",
    "        for i in range(num_tensor_parallel_groups):\n",
    "            ranks = list(range(\n",
    "                i*self.tensor_parallel_size,\n",
    "                (i+1)*self.tensor_parallel_size\n",
    "            ))\n",
    "            process_group = dist.new_group(ranks=ranks)\n",
    "            \n",
    "            if self.rank in ranks:\n",
    "                local_rank = ranks.index(self.rank)\n",
    "                local_world_size = len(ranks)\n",
    "                \n",
    "        return {\n",
    "        \n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409d5435-df7d-41ba-a7b4-c66acabc5069",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactor, boundary, entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fdffef61-df26-4c5e-bde2-84bfb3446e9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f766604c-4d83-4534-b6bd-d317a3b840d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "event = threading.Event()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42947076-6e6a-4517-ac4f-63e6d32c7155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    print(\"waiting\")\n",
    "    event.wait()\n",
    "    print(\"received\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "692d36c0-ff32-41df-abb0-d46078f6f65e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "thread = threading.Thread(target=run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3847de4d-a258-4102-9788-ff38e26a2b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe1ab4d-0aa1-40e3-b7fb-31197bf90045",
   "metadata": {},
   "outputs": [],
   "source": [
    "job selector > worker threads > pool watcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c7b512-d91a-481c-b5bf-7854eed5708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared memory, file system, message passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ec8bc7-1f10-43e6-b936-74abf4c9d049",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter, broadcast, reduce, gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9064b5f3-1bbb-4297-bdcd-2179f2f13cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_row_parallelism(inputs, weights):\n",
    "    inp_partition_size = inputs.shape[-1] // 2\n",
    "    w_partition_size = weights.shape[-1] // 2\n",
    "    \n",
    "    inp1, inp2 = inputs[:, :inp_partition_size], inputs[:, inp_partition_size:]\n",
    "    w1, w2 = weights[:w_partition_size, :], weights[w_partition_size:, :]\n",
    "    \n",
    "    out1 = inp1 @ w1\n",
    "    out2 = inp2 @ w2\n",
    "    \n",
    "    return out1 + out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55127d1-14cd-4cd6-8c59-424194dae931",
   "metadata": {},
   "outputs": [],
   "source": [
    "microbatch n > microbatch n-1 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45e3105-b3ab-4efb-b969-ebaf8895e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data prefetching, lazy loading, memory mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334724e2-432e-4d15-b098-b72964181db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatteer, reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e25f99-a1d3-4be5-8bf6-ea8165bec9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast > gather > scatter > all-reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b544e9-10ed-4c50-9639-925ff3c8e8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast, gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10c3124-f2f7-470a-873b-a66f78f66bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter > reduce > identity > gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "443669bf-b5d1-4eb4-933e-3aaab9b31bfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3015729-8ea5-46b5-885a-209e89128a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lock = threading.Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "176429c8-0117-4b30-87d5-781d90893b20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def intervene_resid(resid, hook, feature, scale, position):\n",
    "    feature /= feature.norm(dim=-1)\n",
    "    feature_projection = resid[0, position] @ feature\n",
    "    resid[0, position] -= scale * feature * feature_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ad2f015-b248-4ceb-a7e3-b51cf5d1708e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07f13492-4102-47b6-a473-7b8ffa0640cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hook_name = get_act_name(\"resid_post\", layer_idx)\n",
    "hook_func = partial(\n",
    "    intervene_resid,\n",
    "    position=2,\n",
    "    feature=target_feature,\n",
    "    scale=scale_factor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afd48cb-5711-4a6d-8da9-1f77de18358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, _ = model.run_with_cache(\n",
    "    past_moves,\n",
    "    fwd_hooks=[hook_name, hook_func]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaf2b8d-8e37-423b-bac6-f21c8866c59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_distribution(states):\n",
    "    q_values = q_function(states)\n",
    "    return torch.exp(q_values)/q_values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066d0f9e-ddcb-46b1-87ca-20f5e9140955",
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_returns = discounted_return_at_each_timestep(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa07f5-3aff-4325-b83b-37e966275201",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0\n",
    "\n",
    "for discount_return, prob in zip(discount_returns, selected_action_probs):\n",
    "    total_loss += discount_return * -prob.log(0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
