{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a366c5d-90fe-40cd-bc8f-bc218125945b",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70615020-83a7-4c7e-8f0f-d5af69b0338c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951a8503-64b7-4188-86b9-67ca21c7a1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, received, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1560c14-0ba4-4be9-bb2f-445b845f9a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: parititon weights\n",
    "step 2: mask targets\n",
    "step 3: calculate local embeddings\n",
    "step 4: calculate global embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fc430a-c61c-44f5-a70a-fad1fc081824",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: 1000/4=250\n",
    "step 2: 1*250=250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf7a10a-7d79-4d23-a41e-c2204d58794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx+partition_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae449a4-039c-460a-a10b-a929498924f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: partition weights\n",
    "step 2: mask targets\n",
    "step 3: calculate local predicted logits\n",
    "step 4: calculate global predicted logits\n",
    "step 5: log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55d2bc7-42cd-40e3-8bf7-a1737e37b82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: send m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b872757a-78db-428d-95a0-a8d35b0fccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "parititon_size*rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61671a95-0d35-4515-acab-97d604c42cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu 0: [0, 122, 0]\n",
    "gpu 1: [567, 0, 888]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bc84bf0-bbb0-467f-9186-ec9223c344ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce649824-5442-4917-9f1c-6ffe24c07d45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Reduce(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, parallel_context):\n",
    "        group = parallel_context.get_group(ParallelMode.TENSOR)\n",
    "        dist.all_reduce(input, group=group)\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        return tuple([grad_input, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c7b80b5-d73f-4eb8-814f-044306a9cf6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParallelEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, parallel_context):\n",
    "        super().__init__()\n",
    "        world_size = parallel_context.get_world_size(ParallelMode.TENSOR)\n",
    "        per_partition = num_embeddings // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.randn(\n",
    "            per_partition,\n",
    "            embedding_dim\n",
    "        ))\n",
    "        self.vocab_start_idx, self.vocab_end_idx = self._get_vocab_range(\n",
    "            per_partition, parallel_context\n",
    "        )\n",
    "        self.parallel_context = parallel_context\n",
    "    \n",
    "    def _get_vocab_range(self, per_partition, parallel_context):\n",
    "        rank = parallel_context.get_local_rank(ParallelMode.TENSOR)\n",
    "        start_idx = rank*per_partition\n",
    "        end_idx = start_idx+per_partition\n",
    "        return start_idx, end_idx\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        input_mask = (inputs < self.vocab_start_idx) | (inputs >= self.vocab_end_idx)\n",
    "        masked_input = inputs.clone() - self.vocab_start_idx\n",
    "        masked_input[input_mask] = 0\n",
    "        \n",
    "        parallel_embeddings = F.embedding(masked_input, self.weight)\n",
    "        parallel_embeddings[input_mask, :] = 0.\n",
    "        \n",
    "        embeddings = Reduce.apply(parallel_embeddings, self.parallel_context)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de19d142-9f83-4bfa-b593-6eadee2a7306",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Broadcast(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        dist.all_reduce(grad_input)\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef8c8de9-435f-401b-a4f2-e7b891c0913d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Gather(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        world_size = dist.get_world_size()\n",
    "        inputs = [torch.zeros_like(input) for _ in range(world_size)]\n",
    "        dist.all_gather(inputs, input)\n",
    "        inputs = torch.cat(inputs)\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        world_size = dist.get_world_size()\n",
    "        rank = dist.get_rank()\n",
    "        \n",
    "        chunks = torch.split(\n",
    "            grad_input,\n",
    "            split_size_or_sections=grad_input.shape[-1] // world_size\n",
    "        )\n",
    "        return chunks[rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78e79cf0-4cd8-41fb-b3b6-e0a76a192b05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ColumnParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size, world_size):\n",
    "        super().__init__()\n",
    "        per_partition = output_size // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.randn(\n",
    "            per_partition,\n",
    "            input_size\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.randn(\n",
    "            per_partition\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_parallel = Broadcast.apply(input)\n",
    "        output_parallel = F.linear(input_parallel, self.weight, self.bias)\n",
    "        outputs = Gather.apply(output_parallel)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6decba-d10d-4e76-8c62-509097ecd8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c09a7-5d8a-4e65-8e1c-63c378dbaf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_rref.rpc_sync().your_mom(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51064a1f-1e2f-4013-8f2a-104df16bea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "no userrrefs, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70b20ed7-f391-4bbd-a68a-2eb1bcd017e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56d77696-bc81-4d64-bc8e-73ece1ec206d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def use_stream(stream):\n",
    "    if not isinstance(stream, torch.cuda.Stream):\n",
    "        yield\n",
    "        return\n",
    "    \n",
    "    with torch.cuda.stream(stream):\n",
    "        yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1b23de-fa28-4f29-814b-ae4a115cd0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.isend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e226d744-43e1-414d-8448-ed321f152e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "no userrrefs references, no referecences in owner node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c3304-d4af-45cd-bf59-473d7f4bf8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c5c7b4-b83f-4736-ad8c-b824ffcbe9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: send metadata\n",
    "step 2: send raw data\n",
    "step 3: receiver received data, construct placeholder tensor\n",
    "step 4: receive the raw data, fill into the placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b277fd2f-3367-44c3-99ec-ce3a358a3648",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.new_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ab4c33-37af-4fd0-99ef-93ce706e5c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _P2P:\n",
    "    def _recv_metadata(self, src_rank, parallel_context, parallel_mode):\n",
    "        group = parallel_context.get_group(parallel_mode)\n",
    "        \n",
    "        dtype = torch.tensor(0)\n",
    "        dist.recv(dtype, src=src_rank, group=group)\n",
    "        dtype = ID_TO_DTYPE[dtype]\n",
    "        \n",
    "        requires_grad = torch.tensor(0)\n",
    "        dist.recv(requires_grad, src=src_rank, group=group)\n",
    "        requires_grad = True if requires_grad = 1 else 0\n",
    "        \n",
    "        shape = torch.tensor(0)\n",
    "        dist.recv(shape, src=src_rank, group=group)\n",
    "        \n",
    "        return dtype, requires_grad, shape\n",
    "        \n",
    "    def recv(self, src_rank, parallel_context, parallel_mode):\n",
    "        group = parallel_context.get_group(parallel_mode)\n",
    "        \n",
    "        dtype, requires_grad, shape = self._recv_metadata(src_rank, parallel_context, parallel_mode)\n",
    "        data = torch.zeros(size=shape, requires_grad=requires_grad, dtype=dtype)\n",
    "        dist.recv(data, src=src_rank, group=group)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "847b30bc-fefe-4b52-866d-446de0623e4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def recv(src_rank, dst_rank, parallel_context, parallel_mode):\n",
    "    rank = parallel_context.get_local_rank(parallel_model.PIPELINE)\n",
    "    \n",
    "    if dst_rank == rank:\n",
    "        return _P2P().recv(src_rank, parallel_context, parallel_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f954915-23c3-4190-bd41-491e9b8af8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize communication\n",
    "maximize storage\n",
    "minimize flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59fd21-a268-4f74-af27-9720301f786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: raw_data + metadata = package\n",
    "step 2: invoke rpc call, along with the local data\n",
    "step 3: destination node invoked the call, \n",
    "step 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeac1d6a-3917-4be9-83fd-9d8eb17b6487",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape, dtype, requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786729f5-8017-450a-8eb7-706d32c1dbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: mask targets\n",
    "step 2: calculate the local predicted logits\n",
    "step 3: calcualte the global predicted logits\n",
    "step 4: log(...)\n",
    "step 5: calculate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "274ae464-554a-4cc4-aad0-fedaa2e32b32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_microbatches = 4\n",
    "n_partitions = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf7d6e6c-3c58-4c2e-9b5c-09c39e683529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_clock_cycles = n_microbatches+n_partitions-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ba76e47-9e86-4b6e-855f-ca33b71fc26e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_clock_cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e6ecc80-020a-4d11-804e-ae9affb616c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0)]\n",
      "[(1, 0), (0, 1)]\n",
      "[(2, 0), (1, 1), (0, 2)]\n",
      "[(3, 0), (2, 1), (1, 2)]\n",
      "[(3, 1), (2, 2)]\n",
      "[(3, 2)]\n"
     ]
    }
   ],
   "source": [
    "for clock_idx in range(n_clock_cycles):\n",
    "    start_partition_idx = max(clock_idx+1-n_microbatches, 0)\n",
    "    end_partition_idx = min(clock_idx+1, n_partitions)\n",
    "    \n",
    "    xs = []\n",
    "    for partition_idx in range(start_partition_idx, end_partition_idx):\n",
    "        microbatch_idx = clock_idx - partition_idx\n",
    "        xs.append((microbatch_idx, partition_idx))\n",
    "    \n",
    "    print(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3881724e-f377-4558-b221-9439af33e96c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ade76-b54e-438c-85ca-fde43ebd9854",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: determine global rank\n",
    "step 2: resize embedding\n",
    "step 3: parallelize embedding, linear, attn, layer norm\n",
    "step 4: resize lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f548324a-4ee2-44f8-8658-44ebce86532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: normalize the loss / n_epochs\n",
    "step 2: calculate the gradients with respect to the normalzied loss\n",
    "step 3: accumulate the grads\n",
    "step 4: if current_epoch == n_epoch, update, otherwise, repeat step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c693cd32-4b03-4ce2-814b-7a1fe57db21a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cd5d59-ca5c-4612-a9b7-6994e6951cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestFruit:\n",
    "    def setup_method(self):\n",
    "        self.fruit = Fruit(\"x\")\n",
    "    \n",
    "    def test_fruit(self):\n",
    "        assert self.fruit.name == \"x\"\n",
    "    \n",
    "    def teardown_method(self):\n",
    "        del self.fruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b893a511-bfc3-42d1-85fd-8e4d4bc8646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = model.embed\n",
    "mlp0 = model.blocks[0].mlp\n",
    "ln0 = model.blocks[0].ln2\n",
    "unembed = model.unembed\n",
    "ln_final = model.ln_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4ebaa7-8f3b-45ee-85fc-eaa174f22884",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tokens = model.to_tokens(names)\n",
    "name_embeddings = embed(name_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196ddc31-c932-477f-8ab5-816e67c7659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_after_mlp0 = name_embeddings + mlp0(ln0(name_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44714393-2518-4220-b6eb-84f5286952a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_OV = model.W_V[0, 1] @ model.W_O[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec781056-50bb-4c4a-a94f-601ae78264c9",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbed8fb-852e-4528-801b-194c0545d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: prob[0] = sigmoid(logit0 - logit1)\n",
    "step 2: logit0 = resid @ W_U[0], logit1 = resid @ W_U[1]\n",
    "step 3: logit0 - logit1 = resid @ (W_U[0] - W_U[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509dc717-dec7-4d04-8485-e9dbe6f2089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_cache = model.run_with_cache(clean_tokens)\n",
    "_, corrupted_cache = model.run_with_cache(corrupted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a2ac108-8140-406f-9d83-434b0be7d4af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_head(acts, hook, clean_cache, corrupted_cache, target_head):\n",
    "    target_layer_idx, target_head_idx = target_head\n",
    "    \n",
    "    if target_layer_idx == hook.layer():\n",
    "        acts[:, :, target_head_idx] = corrupted_cache[hook.name][:, :, target_head_idx]\n",
    "    else:\n",
    "        acts = clean_cache[hook.name]\n",
    "    \n",
    "    return acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b220c148-9b3f-485f-88d8-7cebdc09ee17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2115893-acad-4d75-9a6f-c690f78486b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c058f45-4fbc-4e4c-90ea-a0c9950c7293",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.zeros(n_layers, n_heads)\n",
    "\n",
    "for layer_idx in range(n_layers):\n",
    "    for head_idx in range(n_heads):\n",
    "        model.reset_hooks()\n",
    "        hook_name = get_act_name(\"z\", layer_idx)\n",
    "        hook_func = partial(\n",
    "            patch_head,\n",
    "            clean_cache=clean_cache,\n",
    "            corrupted_cache=corrupted_cache,\n",
    "            target_head=(layer_idx, head_idx)\n",
    "        )\n",
    "        \n",
    "        model.add_hook(hook_name, hook_func)\n",
    "        patched_logits, _ = model.run_with_cache(clean_tokens)\n",
    "        results[layer_idx, head_idx] = compute_ioi_metric(patched_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd574c14-0596-42e5-a885-b4fd166551e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3da0c69-ab0b-4768-a042-4e6ce0f0efd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a6b09a1-ce8c-4eea-9440-caa54bc72248",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def first_context():\n",
    "    print(\"your mom\")\n",
    "    \n",
    "    yield\n",
    "    \n",
    "    print(\"xxx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb2b9417-7038-4bee-a009-7bb107365bd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.distributed.rpc import RRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95d6fddf-622a-4660-94ee-f07a377366e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Observer:\n",
    "    def __init__(self, env):\n",
    "        self.id = RRef(self)\n",
    "        self.env = env\n",
    "    \n",
    "    def run_episode(self, agent_rref):\n",
    "        state, _ = self.env.reset()\n",
    "        for _ in range(69):\n",
    "            action = rpc.rpc_sync(\n",
    "                to=agent_rref.owner(),\n",
    "                func=agent_rref.rpc_sync().select_action,\n",
    "                args=(self.id, state)\n",
    "            )\n",
    "            \n",
    "            state, reward, done, _ = env.step(action)\n",
    "            if done:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62d43fd2-1bc0-45f4-904c-87e83c1481ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff4b152-5fcd-402f-ab00-2987ac298044",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = threading.Thread(\n",
    "    target=print_numbers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b867b1d-4199-4400-ac94-44419813e52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(\n",
    "    tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4688a3ee-ec57-4f63-89ab-f87977ee43f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_names = [get_act_name(\"mlp_out\", layer_idx) for layer_idx in range(n_layers)]\n",
    "act_names = [get_act_name(\"attn_out\", layer_idx), for layer_idx in range(n_layers)]\n",
    "\n",
    "components = [\n",
    "    \"embed\", \"pos_embed\",\n",
    "    mlp_names,\n",
    "    act_name\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc1b8ca-f2a2-4cba-be64-c43cb8dc9c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "theirs = linear_probe[..., 1]\n",
    "mine = linear_probe[..., 2]\n",
    "\n",
    "mine_vs_theirs = mine - theirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360c0f39-83f6-4503-9189-4eeaeb1654e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(\n",
    "    board_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "875b5db6-0f64-48b3-8db7-e76c160428c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44d023d-5109-4881-a34d-35aba5b444f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_contributions = []\n",
    "\n",
    "for layer_idx in range(n_layers):\n",
    "    attn_contributions.append(einsum(\n",
    "        cache[\"attn_out\", layer_idx],\n",
    "        mine_vs_theirs\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255ed1f5-46d3-4d49-8052-268ada19ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = model.embed\n",
    "mlp0 = model.blocks[0].mlp\n",
    "ln0 = model.blocks[0].ln2\n",
    "unembed = model.unembed\n",
    "ln_final = model.ln_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae57c7-3360-43d3-97bc-bca7af2c8b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tokens = model.to_tokens(names, prepend_bos=False)\n",
    "name_embeddings = embed(name_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa35813e-1f10-4b13-9042-3ff1a495ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_after_mlp0 = name_embeddings + mlp0(ln0(name_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d7af43-0903-42b9-b461-f81f4d40ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dce7bbec-1019-46f9-bae1-41320f47ae8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def probability_scores(image_embedding, text_embedding):\n",
    "    image_norm = image_embedding.norm(dim=-1)\n",
    "    image_embedding /= image_norm\n",
    "    \n",
    "    text_norm = text_embedding.norm(dim=-1)\n",
    "    text_embedding /= text_norm\n",
    "    \n",
    "    similarities = image_embedding @ text_embedding.T\n",
    "    probs = F.softmax(similarities, dim=-1)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aae8fb-64ed-4d80-ace4-7ae7f24f0427",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = model.embed\n",
    "mlp0 = model.blocks[0].mlp\n",
    "ln01 = model.blocks[0].ln2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea302a4-55ea-4057-99b5-33fbb055e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf17d4f-6413-48aa-9b3d-d6f84df976f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = embed(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb11af6b-d0e9-43e0-8355-a8faa66d8efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_after_mlp0 = text_embeddings + mlp0(ln01(text_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae39164b-6d75-4976-806f-dbcc0c1be4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.zeros(n_layers, n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1663dba6-3514-4a0b-afe2-f6fcf3138e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tokens = model.to_tokens(names)\n",
    "name_embeddings = model.embed(name_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959c633f-4653-48e1-b961-48e60e191cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2262aabe-d5fd-4fbb-8976-849d25632655",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(n_layers-1):\n",
    "    for head_idx in range(n_heads):\n",
    "        W_OV = model.W_V[layer_idx, head_idx] @ model.W_O[layer_idx, head_idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1bc0d7-250b-402e-a8f7-d48417770258",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_tokens = model.to_tokens(names)\n",
    "name_embeddings = model.embed(name_tokens)\n",
    "\n",
    "mlp0 = model.blocks[0].mlp\n",
    "ln2 = model.blocks[0].ln2\n",
    "\n",
    "resid_after_mlp0 = name_embeddings + mlp0(ln2(name_emebddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb454993-4330-437d-b218-df1c36e18420",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(n_layer-1):\n",
    "    for head_idx in range(n_heads):\n",
    "        W_OV = model.W_V[layer_idx, head_idx] @ W_O[layer_idx, head_idx]\n",
    "        output = resid_after_mlp0 = W_OV\n",
    "        outpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a80582-1272-459d-b048-4129e4544ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "population decoding, stimulus evoked, motor imagery, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
