{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ff5e74b-c447-43dc-857e-043038d5f1c8",
   "metadata": {},
   "source": [
    "### MechInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a9dce-0231-47b9-b2d4-239414554053",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: F1\n",
    "step 2: board "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daae037-6ebf-4ef9-b428-bd046c069676",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff35bc4a-fe64-4139-a869-60cd6c68f15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01e666bb-761a-4929-9877-5308897f6f2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b1804f-28dc-4acc-b755-60148bab0ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = F.log_softmax(logits[:, -1, :], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac0ddcb-c43e-48f2-8d5e-940ff1594f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tokens = tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d53e8e-9c26-494e-bfe2-2048f27d7df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "-log_probs.gather(dim=-1, index=target_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697e2c52-f6b9-4181-a082-dfd929c91128",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: ln1 = ln1 @ resid_pre\n",
    "step 2: head_outputs = head1(ln1) + head2(ln2) ...\n",
    "step 3: mid_resid = head_outputs + resid_pre\n",
    "step 4: ln2 = ln2 @ mid_resid\n",
    "step 5: mlp = mlp(ln2)\n",
    "step 6: final_resid = mid_resid +mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0815c4-e044-46fd-af2a-a80381c7af72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0f8cb7-5386-444d-9232-6403997defc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[\"hook_embed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec3512f-dea4-4705-95c7-a86dace2fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embed(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b510f-a909-42af-8e7f-e992c25cd3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: diverse batch of data\n",
    "step 2: record the attention pattenr of the target head\n",
    "step 3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087e38c2-2049-4f0b-bf27-04c7f3696206",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_out = model.W_out[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9596cb-ff63-49bc-a262-eca984eae5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5025351-5a32-4281-a943-640fb9478b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_in = cache[\"out\", 2][:, 42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "215c624b-bc20-41e9-bb7c-29486ae06b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c0f7d-18a6-4032-a5d5-c7a33b897a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = einsum(\n",
    "    w_in, w_out\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e67742c-e43b-451b-b17c-2cdc82fb4be4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corrupted_prompts = [\n",
    "    \"When John and Mary went to the shops, Mary gave the bag to\",\n",
    "    \"When Tom and James went to the park, Tom gave the ball to\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8507bcc1-f3a3-46b4-87f0-766a673d8aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_tokens = model.to_tokens(\"Mary Tom\", prepend_bos=False)\n",
    "incorrect_tokens = model.to_tokens(\"John James\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1159ff8-adc1-4429-8451-6fc537f153ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_avg_logit_difference(logits, correct_tokens, incorrect_tokens):\n",
    "    final_logits = logits[:, -1, :]\n",
    "    correct_logits = final_logits[:, correct_tokens]\n",
    "    incorrect_logits = final_logits[:, incorrect_tokens]\n",
    "    return (correct_logits-incorrect_logits).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998ecd58-c778-4366-adc5-d6f1e656abde",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = model.to_tokens(clean_prompts)\n",
    "corrupted_tokens = model.to_tokens(corrupted_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b166c686-fb80-4b05-9966-484d57f1642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logits = model.run_with_hooks(clean_tokens)\n",
    "corrupted_logits = model.run_with_hooks(corrupted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52005fb-d390-42ab-af9d-5ec8b0a5b64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logit_diff = compute_avg_logit_difference(clean_logits, correct_tokens, incorrect_tokens)\n",
    "corrupted_logit_diff = compute_avg_logit_difference(corrupted_logits, correct_tokens, incorrect_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c1467-9f48-4d66-aeb8-ee39cef0189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ioi_metric(logits):\n",
    "    logit_diff = compute_avg_logit_difference(logits, correct_tokens, incorrect_tokens)\n",
    "    return (logit_diff-corrupted_logit_diff)/(clean_logit_diff-corrupted_logit_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568ca7d7-942f-49a6-892d-fef9c0b712a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3097be-423b-4d5a-9ac9-ecdd1ca432ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache, _ = model.run_with_cache(\n",
    "    tokens,\n",
    "    names_filter=lambda x: x.endswith(\"mlp_out\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2ae7a6-3857-4380-9086-5eb78d2b1d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef62a120-7be6-4227-8299-5ef9386b70b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.run_with_hooks(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b3a7d3-7728-4bfa-8678-5b63225e888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = F.log_softmax(logits[:, -1, :], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b892e075-9389-45bf-9598-db84f1a6eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tokens = tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d44e5cb-c499-41b5-97e8-240eaf26f529",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_log_probs = log_probs.gather(index=target_tokens, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcb884b-1194-4b8a-83b0-ade10f6da4fd",
   "metadata": {},
   "source": [
    "step 1: choose a start component, and a receiver component\n",
    "step 2: a clean prompt and a corrupted prompt\n",
    "step 3: patch the activations fromt the clean corrupted prompt to the clean prompt, start_component\n",
    "step 4: record the activations of the receiver component\n",
    "step 5: rerun and patch the activations of the receiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160b35bc-5e15-4517-9724-3933245f4f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(past_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393b16ed-1469-415e-9e7e-9c8d925aeafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92789406-ef9d-487d-b1e6-e8202e73dc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_neurons = cache[\"post\", layer_idx].std(dim=[0, 1]).argsort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c8dcefc-a9ea-49ac-a542-d14a72e052a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "heatmap_blanks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d6bf994-b9d6-4683-b63f-c8a186bef0aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b32afb6-7074-40c5-a55c-d34ed9112093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(neuron_idx, feature):\n",
    "    w_out = model.W_out[layer_idx, neuron_idx, :]\n",
    "    w_out /= w_out\n",
    "    feature /= feature\n",
    "    return einsum(\n",
    "        w_out,\n",
    "        feature,\n",
    "        \"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f64009-27be-4f19-a128-f58d02a16e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for neuron_idx in top_neurons:\n",
    "    heatmap_blanks.append(compute_similarity(\n",
    "        neuron_idx, feature\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5388449d-3807-493c-899d-64799ad60ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_direction = model.W_in[layer_idx, :, neuron_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dcacf4-dacc-41d3-9c4c-fecd22c065b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: decompose all the inputs of the target head\n",
    "step 2: calculate query and value component\n",
    "step 3: query*value for each pair component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420e6dfc-e69a-4f8f-8070-569d240f03f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = model.embed(tokens) + model.pos_embed(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac76fe3-8407-4195-a7f5-ecb32c0c0396",
   "metadata": {},
   "outputs": [],
   "source": [
    "reisdual = embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b016aa62-9fb1-40b0-9ff8-bc12ea42e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in model.blocks:\n",
    "    resid = block(resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eb4f62-9406-4e8e-868e-30699b312d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "resid = model.ln_final(resid)\n",
    "logits = model.unembed(resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49e690c-b1f5-4851-af88-73284880ec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mine = linear_probe[..., 2]\n",
    "theirs = linear_probe[..., 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6913d7f9-257a-425c-80c8-0922efce6c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "mine_vs_theirs = mine-theirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4ebb41-812c-4416-8cd6-e25fa835ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(board_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab312e54-fc5b-4893-ae02-f2a91858850c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_layers = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07f54fdc-d6f6-4fde-b2e3-719f276dbb72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1829674-55aa-41f9-a722-a12d49b32168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_contribution(output, feature):\n",
    "    return einsum(\n",
    "        output, feature,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bc6c9b6-ab51-4ccf-8fc8-5ede705d67e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attn_contributions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde69f83-ea83-4113-a12b-50de4f29de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(n_layers):\n",
    "    hook_name = get_act_name(\"attn_out\", layer_idx)\n",
    "    attn_out = cache[hook_name][2, 20, :]\n",
    "    attn_contributions.append(compute_contribution(\n",
    "        attn_out, mine_vs_theirsb\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169cc29-880f-4c23-b713-1db943734903",
   "metadata": {},
   "source": [
    "step 1: start with a diverse batch of data\n",
    "step 2: record the activations of the target head\n",
    "step 3: extract the attn pattern\n",
    "step 4: average the attention pattern between the target query position and all other positions across batch\n",
    "step 5: plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85be6f3-1339-47fd-a1ac-69542a7d8875",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: record activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826985a9-df0e-4123-a377-b5d8de380f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "the training task: training distribution, goal function\n",
    "the base optimizer: architecture, sgd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4aa816-a9ec-4f9c-a423-42ca12ef08b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reachability\n",
    "possible space\n",
    "inductive biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a693d5-5dff-4b00-88ee-7dd90f5af246",
   "metadata": {},
   "outputs": [],
   "source": [
    "register > cache > ram > disk > ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6fe48f6-9068-4a3d-a499-762b4ae70dcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RegularStates:\n",
    "    def __init__(self, states):\n",
    "        self.states = states\n",
    "    \n",
    "    def restore(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1a7121-7f25-43bb-8212-fef556d9af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "    def __init__(self, model, optim, **kwargs):\n",
    "        kwargs.update({\"model\": model, \"optim\": optim})\n",
    "        handlers, remainders = get_handlers(kwargs)\n",
    "        \n",
    "        for name, handler in handlers:\n",
    "            setattr(self, name, handler)\n",
    "        \n",
    "        self.handlers = handlers\n",
    "        \n",
    "        super().__init__(remainders)\n",
    "    \n",
    "    def restore(self):\n",
    "        for name, handler in self.handlers:\n",
    "            handler.restore()\n",
    "            \n",
    "        super().restore()\n",
    "    \n",
    "    def commit(self):\n",
    "        for name, handler in self.handlers:\n",
    "            handler.commit()\n",
    "        super().commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce996db-6728-4990-ac69-d2540f608f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "node > pod > container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762b9794-fb80-464e-a47b-c64f44fcc779",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    def __init__(self, batches, partitions, devices, scheduler=DetermisticScheduler()):\n",
    "        self.batches = batches\n",
    "        self.partitions = partitions\n",
    "        self.devices = devices\n",
    "        self.scheduler = scheduler\n",
    "    \n",
    "    def fit(self):\n",
    "        n_batches = len(self.batches)\n",
    "        n_partitions = len(self.partitions)\n",
    "        \n",
    "        with spawn_workers(self.devices) as (in_queues, out_queues):\n",
    "            for schedule in self.scheduler.generate(n_batches, n_partitions):\n",
    "                self._compute(schedule, in_queues, out_queue)\n",
    "    \n",
    "    def _compute(self, schedule, in_queues, out_queues):\n",
    "        for microbatch_idx, parition_idx in schedule:\n",
    "            batch = self.batches[microbatch_idx]\n",
    "            partition = self.partitions[parition_idx]\n",
    "            \n",
    "            def compute_func():\n",
    "                def wrapper():\n",
    "                    return partition(batch)\n",
    "            \n",
    "            task = Task(compute_func)\n",
    "            \n",
    "            in_queues[microbatch_idx].put(task)\n",
    "        \n",
    "        for microbatch_idx, parition_idx in schedule:\n",
    "            output = out_queues[microbatch_idx].get()\n",
    "            in_queues[microbatch_idx] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4da42e-3fd1-47f7-b69b-d0ec9063ad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_rank, local_world_size, ranks in a group, ProcessGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bdd379-c825-4d3e-adf4-9c1d828e428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: global distributed group\n",
    "step 2: parallel groups\n",
    "step 3: set device\n",
    "step 4: seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cf5d6d-b788-45d5-b340-1189fb7c2f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding, linear, attn, layer norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01501b64-23cd-4813-89ec-43eb87ee0876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca46607f-23e1-4356-9a27-11b3e6e4d4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in groups:\n",
    "    dist.barrier()\n",
    "    dist.destroy_process_group(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8ec2c5-7041-491b-a1a4-c0d48204efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: get the input\n",
    "step 2: construct a task\n",
    "step 3: put the task in the correspond in_queues\n",
    "step 4: wait and get the result\n",
    "step 5: put the result in in_queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16125ea-b981-4983-a281-f2289f46b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "- storage\n",
    "- minimize communication\n",
    "- minimize flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d958c8c-acec-49e9-b506-d99def330ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba409d7-cabd-4638-b055-053a632d2301",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelStateHandler:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "        self.saved_model_state = deepcopy(\n",
    "            self.model.\n",
    "        )\n",
    "    \n",
    "    def set_value(self, value):\n",
    "        self.value = value\n",
    "    \n",
    "    def commit(self):\n",
    "        self._saved_model_state = deepcopy(\n",
    "            self.value.load_state_dict()\n",
    "        )\n",
    "    \n",
    "    def restore(self):\n",
    "        self.value.load_state_dict(self._saved_model_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42402b40-639b-4f9d-bf38-4c9063961cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_model(model, balances, devices):\n",
    "    partitions = []\n",
    "    partition_idx = 0\n",
    "    layers = {}\n",
    "    \n",
    "    for name, module in model.named_children():\n",
    "        layers[name] = module\n",
    "        \n",
    "        if len(layers) == balances[partition_idx]:\n",
    "            partition = nn.Sequential(**layers)\n",
    "            device = devices[partition_idx]\n",
    "            partition.to(device)\n",
    "            partitions.append(partition)\n",
    "            partition_idx += 1\n",
    "    \n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df66d88b-98b3-4386-bf57-12aa2607bb6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor_model_parallel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "325809b8-518b-4fa4-b12f-5a8463a0f2e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_model_parallel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "649beb5c-48a9-49b1-a341-2c454bb2728c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_pipeline_model_parallel_groups = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b64e520a-fd16-4122-8089-707bfbe3dc0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_parallel_groups = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17ba7d80-6261-4964-a721-2371dae12533",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2]\n",
      "[1, 3]\n",
      "[4, 6]\n",
      "[5, 7]\n",
      "[8, 10]\n",
      "[9, 11]\n",
      "[12, 14]\n",
      "[13, 15]\n"
     ]
    }
   ],
   "source": [
    "for i in range(pipeline_model_parallel_size):\n",
    "    start_rank = i*num_pipeline_model_parallel_groups\n",
    "    end_rank = (i+1)*num_pipeline_model_parallel_groups\n",
    "    \n",
    "    for j in range(tensor_model_parallel_size):\n",
    "        ranks = list(range(\n",
    "            start_rank+j,\n",
    "            end_rank,\n",
    "            tensor_model_parallel_size\n",
    "        ))\n",
    "        \n",
    "        print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20a6a9b0-f6d4-409a-83b0-6becd5ab19a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da2bba6-079d-4ef2-be60-4fabe089fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in groups:\n",
    "    dist.barrier()\n",
    "    dist.destroy_process_group(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b634007a-acea-424b-96da-0540f3016226",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    for p in param_group[\"params\"]:\n",
    "        print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44ccc7aa-2ac7-450f-bbe6-7f9d521d91df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c295380-9075-4d62-abc1-7f65c3e96ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = random_split(dataset, lengths=[6, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c41d5fc-07be-442b-8193-fd78207c1df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=2)\n",
    "test_loader = DataLoader(test_set, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c994cf3-6e95-43c6-bdba-6ff14533ad12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.profiler import profile, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36e5a19-9548-4bbc-a3b0-48dd6f1c44d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ac54937-ccf4-4fe2-927c-4e2a2a33a431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b9e612-e6f8-4599-b181-3d5d96495713",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv(Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.observation_space = Discrete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
