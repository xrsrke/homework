{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e0e871e-c6ef-4592-a09c-a58a8146500e",
   "metadata": {},
   "source": [
    "### MechInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f0884ef-1b03-47a2-a23e-af6356c29512",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfa5958-0172-474b-9815-487598b368fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "name mover head, duplication head, s-inhibition head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dbf104-d41f-4071-8022-853424b475f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: s2 attend to s1, copy duplicate information\n",
    "step 2: s-inhibition, end attend to s1, move the duplication information to end\n",
    "step 3: name mover head attend from end to io "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e395c-f975-4409-9c62-e7d2cf197319",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[\"hook_embed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d7549d-4aa7-4ad8-a582-f9b4a1da9b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(out1 + out2 + out3) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407cab83-645a-4093-a257-40fd04d07b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8edc2279-e907-4615-b62b-6be18dd8e66c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23910212-d44a-40eb-9246-a36eeb5d9789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_name = get_act_name(\"resid_post\", 2)\n",
    "output_name = get_act_name(\"normalzied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1f0ecb-fb99-4479-91a4-392c67c437d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_acts = cache[input_name]\n",
    "output_acts = cache[output_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ede291-e953-46e1-9101-57c4def60f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = LinearRegression().fit(input_acts, output_acts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eeefc4-f0bc-45bd-b409-e7848198dbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = model.to_tokens(clean_prompt)\n",
    "corrupted_tokens = model.to_tokens(corrupted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10bdddc-455a-4d5f-89a3-ce564b5b3181",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_token = model.to_single_token(\" John\")\n",
    "incorrect_token = model.to_single_token(\" Mary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd842d7c-2d6f-4266-8c94-86b4f88d5a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_cache = model.run_with_cache(\n",
    "    clean_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e77bcf2-8a9f-48c8-943d-63cbf385ffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, corrupted_cache = model.run_with_cache(corrupted_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f66b72-32da-4d69-bc29-08ba55575fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = clean_tokens.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38e11655-326c-4651-942f-183381524d41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a5a41fb-eac6-4078-b26a-9d9f2435b1b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_resid(resid, hook, clean_cache, position_idx):\n",
    "    resid[:, position_idx, :] = clean_cache[hook.name][:, position_idx, :]\n",
    "    return resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c026cfe-22e4-431f-87c4-f24c8b80fc69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_logit_diff(logits, correct_token, incorrect_token):\n",
    "    final_logits = logits[:, -1, :]\n",
    "    return final_logits[:, correct_token] - final_logits[:, incorrect_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fdb82d-13c1-4a63-9934-bd4cad5cc301",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.zeros(n_layers, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efcba13-18d7-45e8-9b9e-29d5eb9328b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(n_layers):\n",
    "    hook_name = get_act_name(\"resid_pre\", layer_idx)\n",
    "    for position_idx in range(seq_len):\n",
    "        hook_func = partial(\n",
    "            patch_resid,\n",
    "            clean_cache=clean_cache,\n",
    "            position_idx=position_idx\n",
    "        )\n",
    "        \n",
    "        patched_logits = model.run_with_cache(\n",
    "            corrupted_tokens,\n",
    "            fwd_hooks=[(hook_name, hook_func)]\n",
    "        )\n",
    "        \n",
    "        logit_diff = compute_logit_diff(patched_logits, correct_token, incorrect_token)\n",
    "        results[layer_idx, position_idx] = logit_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab407385-f040-4f7e-8670-c0616ce077bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: q = x @ W_Q, k = x @ W_K\n",
    "step 2: x = embed + pos_embed + sum(12 heads)\n",
    "step 3: [embed + pos_embed + sum(12 heads)] @ W_Q = q\n",
    "[embed + pos_embed + sum(12 heads)] @ W_K = q\n",
    "step 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed09b381-ca3b-41d9-8489-1db2cb3d89e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef840f7-8607-4b08-b23b-7970b45ca5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "resid = cache[final_residual_name]\n",
    "final_resid = resid[:, -1, :]\n",
    "scaled_final_resid = model.apply_ln_to_stack(\n",
    "    final_resid,\n",
    "    layer=-1,\n",
    "    pos_slice=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413ec284-be04-4166-855c-fd059e6de9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U\n",
    "logit_diff_direction = W_U[:, correct_token] - W_U[:, incorrect_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52b51912-dac0-4981-bce7-10230039408b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94eb8a2-7247-409d-91c8-24b821d52337",
   "metadata": {},
   "outputs": [],
   "source": [
    "einsum(\n",
    "    scaled_final_resid,\n",
    "    logit_diff_direction\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7b936f-cead-4f58-b75a-aecbb8ad69af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mine = linear_probe[..., 2]\n",
    "theirs = linear_probe[..., 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1bf8c3-1aea-4518-b330-45ef30eadff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mine_vs_theirs = mine - theirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32188125-6075-4556-a084-489d915eca6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attn_contributions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc55b0cd-504d-4e05-b0e6-2e6804dcf68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(6):\n",
    "    hook_name = get_act_name(\"attn_out\", layer_idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33456e84-36b7-4b0b-a6dc-8390e375530f",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: prob[0] = sigmoid(logit0 - logit1)\n",
    "step 2: logit0 = resid2 @ W_U[0], logit1 = resid2 @ W_U[1]\n",
    "step 3: logit0 - logit1 = resid2 @ (W_U[0] - W_U[1])\n",
    "step 4: resid2 = resid1 @ ln2 @ W_OV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b52ab83-5657-4173-bd7b-0044d1adad89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParameterSharding:\n",
    "    def __init__(self, param_groups, parallel_context):\n",
    "        self.param_groups = param_groups\n",
    "        self.parallel_context = parallel_context\n",
    "    \n",
    "    def shard(self):\n",
    "        world_size = self.parallel_context.get_world_size()\n",
    "        partioned_params = [[] for _ in range(world_size)]\n",
    "        sizes = [0 for _ in range(world_size)]\n",
    "        \n",
    "        for param_group in self.param_groups:\n",
    "            param_list = [[] for _ in range(world_size)]\n",
    "            \n",
    "            for p in param_group[\"params\"]:\n",
    "                rank_to_go = sizes.index(min(sizes))\n",
    "                param_list[rank_to_go].append(p)\n",
    "                sizes[rank_to_go] += p.numel()\n",
    "            \n",
    "            for rank, params in enumerate(param_list):\n",
    "                temp = copy.copy(param_group)\n",
    "                temp[\"params\"] = params\n",
    "                partioned_params[rank] = temp\n",
    "        \n",
    "        return partioned_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee25f37c-b66b-431e-a866-43b6492466f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tokens = tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f1b73-cfaf-4634-b3d2-82f3ba3af6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ad426-4b9d-46c7-8fcf-e94ddf9820c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = cache[\"embed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b089e2-b908-4e8f-bc21-ab3240136033",
   "metadata": {},
   "outputs": [],
   "source": [
    "einsum(\n",
    "    embed[:-1],\n",
    "    W_U[:, target_tokens]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c58cbd0-c5d3-4f5b-810e-4b443804d4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: ln1 = ln1(resid_pre)\n",
    "step 2: attn_out = [attn1(ln1) + attn2(ln2)...]\n",
    "step 3: resid_mid = resid_pre + attn_out\n",
    "step 4: ln2 = ln2(resid_mid)\n",
    "step 5: mlp = mlp(ln2)\n",
    "step 6: resid_final = resid_mid + mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4eb11cf-dee9-43e6-bef0-326f7415ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.W_in[layer_idx, :, neuron_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd0d6cf-56b9-454d-bfe3-ec1095cea731",
   "metadata": {},
   "outputs": [],
   "source": [
    "A^1 @ x @ W_OV^{1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad688d3-684f-477b-9caf-b1ae4e236f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a56f5d6-edb0-499f-b468-c3785ef2113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_preds = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd26604e-09d8-4372-94f5-e81b49d805ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack([a, b], dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3701559f-16ac-49c1-8df7-f7b93c3c2dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b41068-4ae2-4786-8005-2f4a4d6ca47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pack(\n",
    "    image_rgp, image_depth,\n",
    "    \"h w *\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f6ff579-0906-421f-87ef-4301ac92539c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dafe7e4-5467-49ed-9b36-4bc3ad92417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = reduce(images, \"b c h w -> b h w\", reduction=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6817d807-25bf-4ee9-9112-7e3223f8271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_rref.rpc()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544a3681-ef6f-42ac-9283-ce2547d75934",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: prob[0] = sigmoid(logit0 - logit1)\n",
    "step 2: logit0 = final_resid @ W_U[0], logit1 = final_resid @ W_U[1]\n",
    "step 3: logit0 - logit1 = final_resid @ (W_U[0] - W_U[1])\n",
    "step 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4fbbc0-49a6-4025-b7d5-76eefc0e19a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: head1_output = L0H00(pre_resid)\n",
    "step 2: resid0 = pre_resid + head1_output\n",
    "step 3: mlp0 = MLP0(resid0)\n",
    "step 4: resid0 = resid0 + mlp0\n",
    "step 5: mlp1 = MLP1(resid0)\n",
    "step 6: resid1 = resid1 + mlp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132cd3dd-5a3d-4593-aef1-3a0eb3757d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "A @ x @ W_OV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bc1fbe-9635-4bf4-970a-5f353c685e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: head0_output = L0H00(x)\n",
    "step 2: resid1 = x + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dedb53-d4e4-4d00-905a-6c398475ce4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A^1 @ x @ W_OV^{1} @ W_V @ W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5421eb-5556-4b6b-81ca-c718bd9f3b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU > CPU > PCI-E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28274b9c-bb79-4b03-bf67-556e05c333ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: register pre backward hook\n",
    "step 2: gather\n",
    "step 3: do the forward\n",
    "step 4: register post backward hook\n",
    "step 5: release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ab812-10dd-4231-82c2-05f8b4a78e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: epoch, num of processed data\n",
    "step 2: get unprocessed data\n",
    "step 3: num of workers\n",
    "step 4: partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275805fa-0079-4bbd-9dbf-22af20e083c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: fp32, fp16 of the weights\n",
    "step 2: do forward and backward in fp16\n",
    "step 3: case fp16 to fp32\n",
    "step 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1635b39-323b-4cc3-8929-3e5cdb18a3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 0: create\n",
    "step 1: bind\n",
    "step 2: accept\n",
    "step 3: communicate\n",
    "step 4: close connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41700b65-5c1a-4d8a-851c-9f8ee821eaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.storage()._resize(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56873899-0793-41b8-b52a-741ded94ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: split a mini-batch into micro-batches\n",
    "step 2: forward\n",
    "step 3: backward\n",
    "step 4: reduce-scatter\n",
    "step 5: ipdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b50ba21b-2a53-4a34-b003-55879dcc0035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ranks = [0, 1, 3, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687f06b8-8804-4c67-a9be-0fdf42d4fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = torch.distributed.get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd23cd37-5928-486f-9346-1c79f28d4d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "group = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b868cd-0871-4f52-b72f-5221200a560e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rank in ranks:\n",
    "    group = torch.distributed.new_group(ranks=ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d06c4dc-952b-4edf-9d71-e1d02f1590c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if group is not None:\n",
    "    torch.distributed.broadcast(x, src=0, group=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "673d275d-8710-4e13-877f-4d22f2133115",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Copy(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, prev_stream, next_stream, input):\n",
    "        ctx.prev_stream = prev_stream\n",
    "        ctx.next_stream = next_stream\n",
    "        \n",
    "        compute_stream = torch.cuda.default_stream(\n",
    "            next_stream.device\n",
    "        )\n",
    "        \n",
    "        with torch.cuda.stream(prev_stream), torch.cuda.stream(next_stream):\n",
    "            moved_input = input.to(next_stream.device)\n",
    "            \n",
    "            input.record_stream(prev_stream)\n",
    "            moved_input.record_stream(compute_stream)\n",
    "        \n",
    "        return moved_input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        prev_stream = ctx.prev_stream\n",
    "        next_stream = ctx.next_stream\n",
    "        \n",
    "        compute_stream = torch.cuda.default_stream(prev_stream.device)\n",
    "        \n",
    "        with torch.cuda.stream(prev_stream), torch.cuda.stream(next_stream):\n",
    "            moved_grad_input = grad_input.to(prev_stream.device)\n",
    "            \n",
    "            grad_input.record_stream(next_stream)\n",
    "            moved_grad_input.record_stream(prev_stream)\n",
    "        \n",
    "        return moved_grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6917acad-bd30-491c-9c07-8c8c0f7dfd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "- \n",
    "- F(m, n) before F(m+1, n)\n",
    "- B(m, n) before B(m-1, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70d26bce-cdf6-48da-91c6-beda4752a2fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestFruit:\n",
    "    def setup_method(self):\n",
    "        self.fruit = Fruit(\"x\")\n",
    "    \n",
    "    def test_fruit(self):\n",
    "        assert self.fruit.name == \"x\"\n",
    "    \n",
    "    def teardown_method(self):\n",
    "        del self.fruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f685e9c5-dcba-4c27-a3f1-14239c5a987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast, scatter, reduce, gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e6a376-a21d-4c8c-82a8-4de18bacd968",
   "metadata": {},
   "outputs": [],
   "source": [
    "data pretetching, memory mapping, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2583eb-35f1-4b58-8f04-abd6ad379b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast, scatter, reduce, gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47216fc5-3e7f-49f4-b68c-733976b0f658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, n, d_model):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.d_model = d_model\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        seq_len = len(tokens)\n",
    "        embeddings = torch.zeros(seq_len, d_model)\n",
    "        \n",
    "        for p in range(seq_len):\n",
    "            for i in range(self.d_model):\n",
    "                denominator = torch.pow(self.n, (2*i)/self.d_model)\n",
    "                embeddings[p][i] = torch.sin(p/denominator) if p%2!=0 else torch.cos(p/denominator)\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8563b077-1882-4e96-b0d8-d45172c25bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: get input data\n",
    "step 2: wait for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3f5d86-6f08-4def-8dc8-558a819c3606",
   "metadata": {},
   "outputs": [],
   "source": [
    "1:9:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda1ff71-73c0-4a7f-843d-b99d17cf8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy loading, data prefetching, memory mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f80a6-2092-4f78-a3ed-88ed395b993b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: wait for data\n",
    "step 2: get the input data\n",
    "step 3: construct a task\n",
    "step 4: put the task into the correspond's in_queues\n",
    "step 5: wait the output\n",
    "step 6: put the output to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73576c2-951f-4eff-b1ef-134707dbc423",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition2(microbatch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c3d8a3-a839-499e-b154-5d2288b0a426",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock cycle 0: F(0, 0)\n",
    "clock cycle 1: F(1, 0), F(0, 1)\n",
    "clock cycle 2: F(2, 0), F(1, 1)\n",
    "clock cycle 3: F(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cf1be7-f931-486d-b63e-1cbcb12ffd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space().sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c61c098-282b-4caa-9872-9be9964082dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    action = env.action_space.sample()\n",
    "    env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2af47d82-7a58-45af-a2f1-4ead1b65a9aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Discrete, Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "685d9056-0436-4c66-8b83-502d0102879e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f44fc2-0b6d-4181-9103-6e9dbe870bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv(Env):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.observation_space = Box(\n",
    "            low=np.array(37),\n",
    "            high=np.array(39)\n",
    "        )\n",
    "        self.action_space = Discrete(2)\n",
    "    \n",
    "    def step(self):\n",
    "        \n",
    "    \n",
    "    def reset(self):\n",
    "        self.temperature = 20\n",
    "        self.shower_length = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69214a90-e60c-46db-894a-764b792997eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training task: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46472db3-1cb4-433f-a9d8-547279792f04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "191ea07e-b520-48f3-841c-8b26b67a5111",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NutritionInformation:\n",
    "    value: int\n",
    "    unit: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8db01dab-c821-4286-a087-054966088521",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RecipeNutritionInformation:\n",
    "    recipes_used: int\n",
    "    calories: NutritionInformation\n",
    "    carbs: NutritionInformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "455c66e4-efba-441e-a512-e1d4fd7f25a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab2d1c-1aa2-4c77-9371-5bdbf6936bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER_PWD: Final = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98a3d652-f86d-4bf5-a5cb-6d6600104ec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6c3ca87-df9f-45bb-bc73-fc23d4e4dd81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"bigscience/bloom-560m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfadda71-c2fe-4674-8bf6-6ec3161117df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BloomModel(\n",
       "  (word_embeddings): Embedding(250880, 1024)\n",
       "  (word_embeddings_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (h): ModuleList(\n",
       "    (0-23): 24 x BloomBlock(\n",
       "      (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (self_attention): BloomAttention(\n",
       "        (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): BloomMLP(\n",
       "        (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (gelu_impl): BloomGelu()\n",
       "        (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d131b4f-c817-4d43-8615-23ea34ca5e78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74ca425f-aba5-4004-94a6-1de0b4fcce0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47c900bb-5cfa-4c2a-aed5-ff17aacde2d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linear.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062a8794-b1d7-43e2-8aba-2ae7b635a042",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
