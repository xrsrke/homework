{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58f47eec-fd64-4acf-b5dc-7d4e30da3b49",
   "metadata": {},
   "source": [
    "### MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50049ca1-d1fc-405d-851c-c39f46896fd7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from airflow.decorators import dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23039f9-e09a-4115-842e-d9dd37bbcd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dag(dag_id=dag_id, start_date=start_date)\n",
    "def example():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7523f4f3-9211-4c3a-88fc-f717b39194cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from airflow.decorators import dag, task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1502cea6-08c7-4729-a40f-4bc71ef453e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dag(dag_id=dag_id, start_date=start_date)\n",
    "def example():\n",
    "    @task\n",
    "    def get_name():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eb7c7a0-a0a3-4d6a-87fd-906eea17c1dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97db0013-ba87-4c0c-a177-59881970004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        output_size_per_partition = output // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.randn(\n",
    "            output_size_per_partition,\n",
    "            self.input_size\n",
    "        ))\n",
    "        \n",
    "        self.bias = nn.Parameter(torch.randn(\n",
    "            output_size_per_partition\n",
    "        ))\n",
    "    \n",
    "    def forward(self, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e71f0a-000c-467a-ab08-3f4ed2796dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(A^2 @ A^1)()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700981c2-af6b-410c-a1ca-8f4ab98f9d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 @ W_E @ W_Q @ [v1, v2] @ W_E @ W_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8924063-9723-4de9-9fde-65a5209a36a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP > Residual stream > attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d703de7-8abb-4dd4-b9e3-508c9be56bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_OV^{0, 7} @ W_WK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42f252a3-d9ab-4aa5-b07f-ecb9fa896fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ea232c7-9c64-47dc-9d17-1c2e8b3957ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"bigscience/bloom-560m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd79a428-beeb-411a-8aa6-12345ed7402f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BloomModel(\n",
       "  (word_embeddings): Embedding(250880, 1024)\n",
       "  (word_embeddings_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (h): ModuleList(\n",
       "    (0-23): 24 x BloomBlock(\n",
       "      (input_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (self_attention): BloomAttention(\n",
       "        (query_key_value): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (attention_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (post_attention_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): BloomMLP(\n",
       "        (dense_h_to_4h): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (gelu_impl): BloomGelu()\n",
       "        (dense_4h_to_h): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "495e2efb-6523-4e52-a83a-eaeb0079b921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Albert is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:259\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 259\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/Albert/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/transformers/utils/hub.py:417\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 417\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/huggingface_hub/file_download.py:1195\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;66;03m# Cache the non-existence of the file and raise\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/huggingface_hub/file_download.py:1541\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[1;32m   1532\u001b[0m r \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[1;32m   1533\u001b[0m     method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1534\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1539\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m   1540\u001b[0m )\n\u001b[0;32m-> 1541\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;66;03m# Return\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:291\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    283\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    290\u001b[0m     )\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[0;31mRepositoryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-64dae861-28b7b9e3239340296dd86284)\n\nRepository Not Found for url: https://huggingface.co/Albert/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model2 \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAlbert\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py:444\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs_copy\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    442\u001b[0m         _ \u001b[38;5;241m=\u001b[39m kwargs_copy\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch_dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 444\u001b[0m     config, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_unused_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs_copy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map:\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/transformers/models/auto/configuration_auto.py:928\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    926\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname_or_path\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pretrained_model_name_or_path\n\u001b[1;32m    927\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 928\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m trust_remote_code:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/transformers/configuration_utils.py:574\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    573\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 574\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[1;32m    576\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/transformers/configuration_utils.py:629\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME)\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 629\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    643\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    645\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/transformers/utils/hub.py:433\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    417\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m    418\u001b[0m         path_or_repo_id,\n\u001b[1;32m    419\u001b[0m         filename,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    429\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    430\u001b[0m     )\n\u001b[1;32m    432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[0;32m--> 433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    436\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    438\u001b[0m     )\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError:\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    443\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    444\u001b[0m     )\n",
      "\u001b[0;31mOSError\u001b[0m: Albert is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`."
     ]
    }
   ],
   "source": [
    "model2 = AutoModel.from_pretrained(\"Albert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48fd0ffc-ade4-459d-b6e4-512da4dccef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5968d73-19f6-4d85-aee1-56ab7f5f5430",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input = torch.randn(10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3b0a19e-e081-4bdf-99f0-b75d6229349c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6417, -0.1661, -0.0222, -0.4692, -0.7832],\n",
       "        [ 0.8348, -0.4903, -0.0359, -0.2169,  0.8685],\n",
       "        [ 0.7439,  0.8626,  0.8403,  1.6685, -0.9894],\n",
       "        [ 0.0306, -2.7734, -1.6663, -0.2720, -0.0711],\n",
       "        [ 0.5266,  0.3457, -0.2163, -0.0487, -0.4683],\n",
       "        [-0.3293,  0.7775,  0.3178, -0.1967,  0.3104],\n",
       "        [-0.0103,  0.3835, -0.2067,  1.8071,  0.7385],\n",
       "        [-0.7402,  1.4468, -1.7868,  0.2571,  0.4012],\n",
       "        [-0.5330,  0.4477,  1.3730,  0.7652,  1.3986],\n",
       "        [-0.3887,  0.0406,  1.3223, -1.4569, -0.0809]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bffa038-5f51-4a00-9ecd-f1a5fd419125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weight = torch.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "212f4dcd-23c8-4cc9-91fb-fce7372210bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalized_input = F.layer_norm(input, normalized_shape=(5,), weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0103b589-4e64-4d84-93f4-d34b18fabe26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6743, -0.0131,  0.2875, -0.6464, -1.3023],\n",
       "        [ 1.1524, -1.2232, -0.4087, -0.7332,  1.2128],\n",
       "        [ 0.1360,  0.2719,  0.2464,  1.1949, -1.8491],\n",
       "        [ 0.8932, -1.6597, -0.6518,  0.6177,  0.8006],\n",
       "        [ 1.3714,  0.8740, -0.6712, -0.2104, -1.3639],\n",
       "        [-1.2676,  1.5094,  0.3558, -0.9349,  0.3373],\n",
       "        [-0.7771, -0.2234, -1.0531,  1.7779,  0.2757],\n",
       "        [-0.5974,  1.3948, -1.5508,  0.3111,  0.4424],\n",
       "        [-1.7201, -0.3412,  0.9600,  0.1054,  0.9959],\n",
       "        [-0.3098,  0.1721,  1.6111, -1.5091,  0.0357]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c1de61-4fc9-4bd6-a93e-016ce03dd554",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "81d12a5c-4823-4eba-95d7-546e35bfb5ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input = torch.randn(10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "bacb706e-65cc-465a-86e9-44094e7084d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "223f8a53-e73b-4732-a171-ef98c467de9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 5]), torch.Size([5]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape, weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a277ed-0de4-4e9d-abbc-15bbd5dca765",
   "metadata": {},
   "source": [
    "Normalize each feature in the `input` across the 10 samples, where each sample contains 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "17b7f338-ae10-42ee-8577-47615e22d258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalized_input = F.layer_norm(input, normalized_shape=(5,), weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8520c3fe-01d2-4812-86c9-ae87eab62663",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3fe5c9b9-ac28-41d0-be73-d1b75e1d9a4d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7518), tensor(0.6328))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_input[:, 0].mean(), normalized_input[:, 0].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2870c818-9e85-4551-a518-d744c289fddc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b88a01-32df-4fd1-becf-e417feed3481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a908c2cf-e3c7-4dbf-b928-838d4d1b349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "getattr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778c5d60-73d0-45b3-bea8-7502e47cee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158332b7-5c61-47db-94e3-b736a51752f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "int* ptr = (int*)malloc(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68c546c-92d0-4e8c-95b8-7600b522dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include iostrea m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b4f63-ca78-40c8-a9c0-eb759da2a523",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer states, model params, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d0140657-58fd-47f8-b7cc-1764f3f374ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_decorator(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(\"x\")\n",
    "        func(*args, **kwargs)\n",
    "    \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d66f9f-3549-43b9-ba97-e4e2fbb33094",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: fp32, fp16 of weights\n",
    "step 2: do forward and backward pass in fp16\n",
    "step 3: cast fp16 gradients to fp32\n",
    "step 4: update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4f58441a-1c1c-4bbb-88cb-a7cadc36501c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Copy(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, prev_stream, next_stream, input):\n",
    "        ctx.prev_stream = prev_stream\n",
    "        ctx.next_stream = next_stream\n",
    "        \n",
    "        compute_stream = torch.cuda.default_stream(\n",
    "            next_stream.device\n",
    "        )\n",
    "        \n",
    "        with torch.cuda.stream(prev_stream), torch.cuda.stream(next_stream):\n",
    "            moved_input = input.to(next_stream.device)\n",
    "            input.record_stream(prev_stream)\n",
    "            moved_input.record_stream(next_stream)\n",
    "        \n",
    "        return moved_input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        prev_stream = ctx.prev_stream\n",
    "        next_stream = ctx.next_stream\n",
    "        \n",
    "        compute_stream = torch.cuda.default_stream(prev_stream.device)\n",
    "        \n",
    "        with torch.cuda.stream(prev_stream, next_stream):\n",
    "            moved_grad_input = grad_input.to(compute_stream)\n",
    "            grad_input.record_stream(next_stream)\n",
    "            moved_grad_input.record_stream(prev_stream)\n",
    "        \n",
    "        return moved_grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9862d0-3d9f-4b7a-943f-fae246c9b457",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock_idx+1-n_microbatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f467931a-1b1a-4827-90e8-56c3ff6cb705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0232d4ce-a682-4366-9499-7fb4ecb835c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorParallelGroupInitializer(ProcessGroupInitializer):\n",
    "    def init_dist_group(self):\n",
    "        self.num_tensor_parallel_groups = self.world_size // tensor_parallel_size\n",
    "        \n",
    "        group = None\n",
    "        ranks_in_group = None\n",
    "        local_rank = None\n",
    "        local_world_size = None\n",
    "        \n",
    "        for i in range(tensor_parallel_size):\n",
    "            start_rank = i*num_tensor_parallel_groups\n",
    "            end_rank = (i+1)*num_tensor_parallel_groups\n",
    "            \n",
    "            for j in range(start_rank, end_rank):\n",
    "                ranks = list(range(\n",
    "                    start_rank+j,\n",
    "                    end_rank,\n",
    "                    tensor_parallel_size\n",
    "                ))\n",
    "                \n",
    "                group = dist.new_group(ranks=ranks)\n",
    "                if self.rank in ranks:\n",
    "                    local_rank = ranks.index(self.rank)\n",
    "                    local_world_size = len(ranks)\n",
    "        \n",
    "        return {\n",
    "            \"\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2c1e7a-45a1-45a7-8e7e-da203b527a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E@W_OV^{0, 7}@W_QK@W_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc3dc70-7434-4c72-8512-d8b9be05dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_pos = model.W_pos\n",
    "W_Q = model.W_Q[layer_idx, head_idx]\n",
    "W_K = model.W_K[layer_idx, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae8bfd0-e969-47ff-a489-bfa489cabd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_by_pos_scores = W_pos @ W_Q @ W_K @ W_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6612ee08-467f-4b4f-bcba-0daee95dfa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_scores(scores):\n",
    "    masks = torch.triu(torch.ones(scores))\n",
    "    return torch.where(masks==True, scores, -1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6caa90-6498-4bd9-bb12-26b50ba7730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_pos_by_pos_scores = mask_scores(pos_by_pos_scores/(d_head**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8302d7b6-6572-4323-bb03-16f1760f6501",
   "metadata": {},
   "outputs": [],
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2faa923-5c8b-4dc1-9246-29fc7857088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8529d07-3292-4b8e-9e44-545a1637de9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E\n",
    "W_Q = model.W_Q[1, 4]\n",
    "W_K = model.W_K[1, 4]\n",
    "W_O = model.W_O[0, 7]\n",
    "W_V = model.W_V[0, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c18b2fc-26cd-4d4a-81ca-552ac023c15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = W_E @ W_Q\n",
    "K = W_E @ W_V @ W_O @ W_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa88b9b8-9bb6-4d23-a0f4-bdd0e420de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad221fa7-6f06-4b76-89d5-eba318a30347",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(\n",
    "    tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993957f0-0aa8-4b6e-ba88-d4ca6bb9d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_components = torch.tensor([\n",
    "    cache[\"embed\"],\n",
    "    cache[\"pos_embed\"],\n",
    "    cache[\"result\", layer_idx-1]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "19a93d8d-6fea-4ef2-b1bf-ecc71c90b98b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a32551-6e4c-4693-8e7d-a679a357de5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Q = model.W_Q[layer_idx, head_idx]\n",
    "query_components = einsum(\n",
    "    input_components,\n",
    "    W_Q\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4c56e-bf5f-4cc2-8813-791db84a9158",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_K = model.W_K[layer_idx, head_idx]\n",
    "key_components = einsum(\n",
    "    input_components,\n",
    "    W_K\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e72727-dfe7-4aee-bece-f1a60a80a453",
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_scores = einsum(\n",
    "    query_components,\n",
    "    key_components\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2674b719-2e4e-43a7-8ed1-2838d678ca00",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "131c564c-bbb3-4146-bd3d-a0d60b1103dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, head_idx = 2, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6946e4-a8a9-46ca-9a22-b1a17d6ea964",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_outputs = cache[\"z\", layer_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c678493-d78e-4d2f-877a-ab532d96177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output = attn_outputs[:, :, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459518d2-a4c9-4ebd-8a56-cca2ec04c577",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5636d8e4-2747-4433-84bc-a6d73643ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(Attn(x@W_E))@W_Ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9844c47a-9c67-425b-854a-42256ad575e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a184b9-37dd-4803-beed-14e8aa2e6a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "dc92a456-a44b-48fe-99b7-c5d105c82af6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, head_idx = 9, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2e8290-6f66-4244-895b-db78ad2c88bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_prob = cache[\"attn_prob\", layer_idx][:, :, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f9b09c-e98f-46e8-9c34-8c9e5748f8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_idx = tokens.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901f05fd-a077-4919-b482-c2611383b4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_prob[:, query_idx, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fef9f28b-d28f-4d8d-9dd4-5e9735a96a67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, neuron_idx = 5, 1393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ed44ca-d42a-4f7a-b8e0-c5f80ca45b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_direction = model.W_in[layer_idx, :, neuron_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1294a22b-8d7a-4847-b015-d1183a0351bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_consine_similarity(input_direction, feature):\n",
    "    input_direction /= input_direction.norm(dim=-1)\n",
    "    feature /= feature.norm(dim=-1)\n",
    "    \n",
    "    return einsum(\n",
    "        input_direction,\n",
    "        feature,\n",
    "        \"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ace34db3-7e75-421b-84cf-35021a800efb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4cd22-c88b-41bc-8588-741864a799c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "induction_score = reduce(\n",
    "    induction_stripe,\n",
    "    \"head_idx seq_len -> head_idx\",\n",
    "    reduction=\"mean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a44a736-4f3f-434b-9143-c87c5894be3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: head0_output = L0H00(pre_resid)\n",
    "step 2: resid = pre_resid + head0_output\n",
    "step 3: mlp0_output = MLP0(resid)\n",
    "step 4: resid0 = resid + mlp0_output\n",
    "step 5: mlp1_output = MLP1(resid0)\n",
    "step 6: resid1 = resid0 + mlp1_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed77cda-56f5-4433-a363-cf0d9657455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e44fd7be-5343-4364-8b39-0a246d6f57ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, head_idx = 9, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc96c99-ed49-4f20-8fb9-ae536e864d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_output = cache[\"z\", layer_idx][:, :, head_idx]\n",
    "output = head_output @ model.W_O[layer_idx, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6142fb-46e2-49cf-9af6-045e1e0c550f",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U\n",
    "io_direction = W_U[:, io_tokens]\n",
    "s_direction = W_U[:, s_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bd15ae-aa44-4527-937c-78ce931489e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_in_io_dir = output @ io_direction\n",
    "projection_in_s_dir = output @ s_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e129a9-8709-4b15-9dc3-1d0431e5fbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_patterns = cache[\"attn_pattern\", layer_idx][:, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85afcf92-3c1b-4290-8532-bc3971fe2b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_pattern_from_end_to_io = attn_patterns[:, 0, io_tokens]\n",
    "attn_pattern_from_end_to_s = attn_patterns[:, 0, s_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bb53b7-5850-4547-af09-793979786565",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce, scatter, gather, broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb16ca6-62fe-43d3-9d68-b385f2cc0ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock cycle 1: F(0, 0) \n",
    "clock cycle 2: F(1, 0), F(0, 1)\n",
    "clock cycle 3: F(2, 0), F(1, 1)\n",
    "clock cycle 4: F(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d27691-d2d1-4871-a776-6bdc4f2ad0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: wait for data\n",
    "step 2: get data\n",
    "step 3: construct a task\n",
    "step 4: put the task into ___\n",
    "step 5: wait\n",
    "step 6: get\n",
    "step 7: put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a99b6f-425a-47cd-bd6e-c72db4a86916",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E\n",
    "W_Q = model.W_Q[1, 4]\n",
    "W_K = model.W_K[1, 4]\n",
    "W_O = model.W_O[0, 7]\n",
    "W_V = model.W_V[0, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ca5ddd-3689-425a-a8bb-2b4f29f20eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = W_E @ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cb0a6f4d-9201-4766-8869-d3dcb0696015",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, head_idx = 0, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad0cdb-cfd7-48ff-b74f-5c8765594bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e742779-5516-4c18-90b9-bb3726823adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_output = cache[\"z\", layer_idx][:, :, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3ab7a3-ff23-4a80-b405-3f0bcf768794",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = head_output @ model.W_O[layer_idx, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42066cea-9043-4d7b-8a9c-6e9be60f6b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = torch.cuda.Stream(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa7cd4-97eb-409c-82ae-24e170b75a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.device(device):\n",
    "    with torch.cuda.stream(stream):\n",
    "        mean = xs.mean(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "35e6145f-953a-4c50-ae7a-71b1074be54f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5be3172d-dcbd-4967-ad66-bd55e658c8c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Gather(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb52422-be46-40d1-91eb-c4489bd04bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gather(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        world_size = dist.get_world_size()\n",
    "        rank = dist.get_rank()\n",
    "        input_chunks = torch.split(input, input.shape[-1] // world_size)\n",
    "        return input_chunks[rank]\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9db9f213-846d-4bd2-abea-3ee2af509d6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ColumnParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        world_size = dist.get_world_size()\n",
    "        \n",
    "        out_per_partition = output_size // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.randn(\n",
    "            out_per_partition, input_size\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.randn(\n",
    "            out_per_partition\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_parallel = Broadcast.apply(input)\n",
    "        output_parallel = F.linear(input_parallel, self.weight, self.bias)\n",
    "        outputs = Gather.apply(output_parallel)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e66748e-6f99-4028-8283-4738979a2b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Broadcast > Gather > Scatter > Allreduce "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01abaf0f-853b-4e4b-86fd-166b82b34ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E\n",
    "W_Q = model.W_Q[1, 4]\n",
    "W_K = model.W_K[1, 4]\n",
    "W_O = model.W_O[0, 7]\n",
    "W_V = model.W_V[0, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c09a269-9a69-4e20-8e90-b9fa7dbab4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = W_E @ W_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199870ee-7821-4fb4-b764-02a5d92ab7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = W_E @ W_V @ W_O @ W_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3213c497-cdeb-4c16-a573-cdf21539a804",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params:\n",
    "                p.data -= p.data * self.lr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e56243f-5e5d-40fa-a248-6daeb976ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "Broadcast > Gather > Scatter > All-reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb12aae-e856-403e-a4ba-ebaf4b291f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scatter, Reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971886e1-8a1a-4536-831c-63c2109d12b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scatter > Reduce > "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6226cda4-b12a-411c-8498-c521978c6c56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Broadcast(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2ff2b4c0-6380-4590-9770-da9e19551e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Gather(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        inputs = [torch.zeros_like(input) for _ in range(world_size)]\n",
    "        torch.distributed.all_gather(inputs, input)\n",
    "        inputs = torch.cat(inputs)\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        world_size = dist.get_world_size()\n",
    "        rank = dist.get_rank()\n",
    "        \n",
    "        grad_input_chunks = torch.split(\n",
    "            grad_input,\n",
    "            split_size_or_sections=grad_input.shape[-1] // world_size\n",
    "        )\n",
    "        \n",
    "        return grad_input_chunks[rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "39ac847d-9892-4979-abe3-2ae060bcf310",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ColumnParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        world_size = dist.get_world_size()\n",
    "        \n",
    "        out_per_partition = output_size // world_size\n",
    "        self.weight = nn.Parameter(torch.randn(\n",
    "            out_per_partition, input_size\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.randn(\n",
    "            out_per_partition\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_parallel = Broadcast.apply(input)\n",
    "        output_parallel = F.linear(input_parallel, self.weight, self.bias)\n",
    "        outputs = Gather.apply(output_parallel)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e2230e-735b-4eb7-890a-3069991a5c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss_of_soft_v(states, actions, action_probs):\n",
    "    q_preds = q_function(states, actions)\n",
    "    entropy = -action_probs.log()\n",
    "    \n",
    "    target = v_function(states)\n",
    "    return target-(q_preds+entropy).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
