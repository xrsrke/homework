{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "421ca77e-4a98-4718-ae8b-08a583bd1ab7",
   "metadata": {},
   "source": [
    "### MechInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f4828b2-fef5-4577-8d96-0d3f414b235b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8154b7b-6ef7-4480-a5e1-47715ea93efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = interference.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eeb6d7-b938-4a6a-ab80-1d1caf9f9dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "interference[torch.arange(n_features), torch.arange(n_features)] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf16d1c-2b99-4f21-8172-6ea68e290c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "polysemanticity = interference.pow(2).sum(dim=-1).sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb551c81-df35-4678-8988-462c31044091",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce366d9-ba63-40b7-9faf-1ad62885da6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(\n",
    "    tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb95645f-8e78-430a-ae83-d36b78d5d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_name = f\"blocks.{layer_idx}.mlp.hook_post\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3232bfef-7749-491a-86f8-0d3e77829365",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = cache[hook_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331459ff-e67a-40a5-8f0f-87c3fddd6388",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_idx = torch.argmax(activations[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432bc3ba-52e2-4a8a-8e27-7c9739137c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: prob[0] = sigmoid(logit0 - logit1)\n",
    "step 2: logit0 - logit1 = final_ln @ W_U[0] - final_ln @ W_U[1]\n",
    "= final_ln @ (W_U[0] - W_U[1])\n",
    "step 3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff11a59-4691-46d7-8225-ad6c110835e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: cell f1\n",
    "step 2: past moves\n",
    "step 3: run\n",
    "step 4: patch\n",
    "step 5: continue the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9090a04-65f2-4b69-b3e6-61a04f9125f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ab133-c491-48b2-9e2b-38e95215011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "induction_score = reduce(\n",
    "    induction_stripe,\n",
    "    pattern=\"head_idx seq_len -> head_idx\",\n",
    "    reduction=\"mean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc926ab9-1c43-40ff-a767-bd86ca1e7b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intervene_resid(resid, hook):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37e4426f-a1b2-409a-bd67-de1bdfb47566",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16c5dedf-0fa0-4b9c-b9fb-87f15f344d98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def intervene_resid(resid, hook, scale, feature):\n",
    "    normalized_feature = feature / feature.norm()\n",
    "    feature_projection = resid[0, position] @ normalized_feature\n",
    "    resid[0, position] -= scale * feature_projection * normalized_feature\n",
    "    return resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e337a0-f45c-4c87-8e2d-36c6c998a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_name = get_act_name(\"resid_post\", layer_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f8254cd-7ca7-416b-87fa-6b435c901f3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e18ce1-18bf-455d-b8f4-a076e7879463",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_func = partial(\n",
    "    intervene_resid,\n",
    "    scale=scale_factor,\n",
    "    feature=target_feature\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b664bd9-2a7d-4741-acf3-a5fd286465e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervened_logits = model.run_with_hooks(\n",
    "    past_moves, fwd_hooks=[(hook_name, hook_func)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64568bf0-b1d3-42bf-849e-cb5676a2420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_name = get_act_name(\"pattern\", layer_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69caf929-7bc2-478a-aaf3-e39779356d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(\n",
    "    tokens,\n",
    "    names_filter=lambda x: x == hook_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e7e5d9-22f1-4ea2-97f0-6299daf49ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = cache[hook_name][:, :, target_query_position]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9170ddff-e697-40d1-b434-af4dd04466f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_pattern = pattern.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32e23c2-d0f3-4ff1-bb92-3658516efef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "directly or indirectly contribute to the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a9d52-b990-4c9c-9624-de1049a800b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1 & 2: not_empty = (theirs+mine) / 2\n",
    "step 3: blank - not_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4610b84b-3b1e-4e57-b6d2-ac009fb68a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: prob(0) = sigmoid(logit0 - logit1)\n",
    "step 2:\n",
    "logit0 = final_ln @ W_U[0]\n",
    "logit1 = final_ln @ W_U[1]\n",
    "logit0 - logit1 = resid2 @ (W_U[0] - W_U[1])\n",
    "step 3:\n",
    "resid2 = resid1 @ ln2 @ W_OV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6470f6-7645-4925-9ac3-2a5c12710e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74161dee-684e-470f-9500-0d3453b28aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53288e-30d4-4594-8ccc-2094544ded4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_name = get_act_name(\"out\", layer_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb8a3a4-ced6-4c62-ad3e-fed8325d3693",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cache[hook_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f4dd76-61b4-41c6-863c-9543fb2083fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_out = model.W_out[layer_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6a3d39-975b-42b1-805d-9d91bc407d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = einsum(\n",
    "    x, W_out,\n",
    "    \"... neuro\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "909de66c-73e6-4175-99fa-a7b27ed43e17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_shape(module, inp):\n",
    "    print(inp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149d4768-58d7-49b7-a14a-6d3404e57b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.blocks[1].register_forward_pre_hook(print_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233423fd-753e-4936-97f0-1949b41bc20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(past_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4c9229-2138-4509-adf4-45794da5b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = F.log_softmax(logits[0, -1], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4cfdac-ed59-4e18-a85a-a214e292f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "board_states = torch.zeros(board_size*board_size)\n",
    "board_state[next_possible_moves] = log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a755e4a3-6637-43e4-9340-7a278f6d9eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: diverse\n",
    "step 2: record the attention pattern of the target head\n",
    "step 3: extract the attention pattern of the target quer\n",
    "step 4: average across batch\n",
    "step 5: plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2f8306-80c0-4515-b9e4-4612cff1bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "game rules\n",
    "attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b6fdbd-72ef-4b1b-9cac-73c4673f7d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_name = f\"blocks.{layer_idx}.mlp.hook_post\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb986512-7896-465f-9996-5adcd03ba788",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c42d92-3e16-4be3-85bb-8e4ef4662535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_neuron_activations(activations, hook):\n",
    "    data = activations[hook_name][:, :, neuron_idx]\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2985fff-e8aa-4c97-9bde-1d49b336a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c13d71-54df-4db5-9f00-be069f3b8e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.argmax(data, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3b8d51-718a-4d97-9ecf-55220d268aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: approximate layer norm using linear function\n",
    "step 2: reverse transformation => pre layer norm\n",
    "step 3: logit difference direction: logit_diff_dir = W_U[0] - W_U[1]\n",
    "step 4: project pre_ln to logit_diff_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8963b887-b342-4716-ba05-f925316311c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "direct path, head "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c40652-1587-446e-b0f3-3f7df9094bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E@W_Q@ W_OV^{0, 7}@W_K@W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346eb9d9-b8e2-4c1e-92a3-b6b71759ec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: determine a list of global ranks in that parallel group\n",
    "step 2: check whether the process's global rank in that list\n",
    "step 3: if yes, init a process group\n",
    "step 4: determine its local rank\n",
    "step 5: save "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ef30d2-b661-4fb3-9554-dcd785bfe825",
   "metadata": {},
   "outputs": [],
   "source": [
    "api server, ectd, control manager, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c964d3f2-eebb-431b-85e3-917978787a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0f05da-a92c-4a2a-bc07-638812f3578a",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int a = 69;\n",
    "    int* b{&a};\n",
    "    \n",
    "    std::cout << *b;\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138c6d96-6d36-4eb5-80a9-74e62abc17d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "host discovery, 3 notif, torchstate, elastic driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285242b1-36e0-4c2f-92f4-2c4db9d9c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding, layer norm, linear, attentb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec63fbd4-1940-4f3a-a386-2d9cfa6e4fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: normalize the loss\n",
    "step 2: calculate the grads with respect to the loss\n",
    "step 3: accu\n",
    "step 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c7f44b-2030-48d4-9673-452a5162b7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bb5cca-5d50-46c0-8d6f-ebab5026de42",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor\n",
    "leave, reassign\n",
    "join, rebuild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6201bd5c-a77d-4092-ad7f-5765a748eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, padding_idx, d_model):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size,\n",
    "            embedding_dim=d_model,\n",
    "            padding_idx=padding_idx\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757d0bd2-5fd1-437f-9f7a-5d0234de0579",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: ReLU(x@W_in)@W_out\n",
    "step 2: sum over d_mlp neurons(ReLU(x@W_in[:, i])@W_out[i, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "635b2fa6-323c-4bbd-ade3-267f1304582a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def intervene_resid(resid, hook, scale, position, feature):\n",
    "    normalized_feature = feature / feature.norm()\n",
    "    projection = resid[0, position] @ normalized_feature\n",
    "    resid[0, position] -= scale * projection * normalized_feature\n",
    "    return resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44318987-7fbd-43ca-8967-5648225a4203",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc8baf7-1661-43a9-b80a-a2727c594189",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_func = partial(\n",
    "    intervene_resid,\n",
    "    scale=scale_factor,\n",
    "    position=position,\n",
    "    feature=target_feature\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e0f1be-37a8-490f-bc0c-2323fb7bf61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_name = get_act_name(\"resid_post\", layer_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03f7838-8954-4faa-a76d-b6cd4929b33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "intervened_logits = model.run_with_hooks(\n",
    "    past_moves,\n",
    "    fwd_hooks=[(hook_name, hook_func)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb4258-cd46-46fb-bcb4-499653f7e211",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = F.log_softmax(intervened_logits[0, position], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbd8ad2-f5d7-423e-b0c6-8233cc993b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in params:\n",
    "                p.data -= p.grad * self.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7afb51-4ce9-46b0-b165-636d7951d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_name = get_act_name(\"out\", layer_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a86a0-2741-4297-81a5-087336d7cbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c5a77d-00e9-489c-90cf-2793051d6641",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_W_in = cache[hook_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252eec62-25d5-4cb9-85f3-4dd7f20c79d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_out = model.W_out[layer_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dc2901-264b-47ef-a939-e4f2bf683a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = einsum(\n",
    "    out_W_in,\n",
    "    W_out,\n",
    "    \"... neuron, ... neuron d_model -> ... neuron d_model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba90d245-de6e-468d-bf55-2e3f1784a824",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b6a9fcd-420e-456f-a1ce-9dd3a78e6c7b",
   "metadata": {},
   "source": [
    "It's important to frame this discussion in the context of the paper's exploration of the Softmax Linear Unit (SoLU) activation function, and its interaction with Layer Normalization (LayerNorm). The paper suggests that SoLU helps to promote more interpretable neurons, but when used alone it led to a significant decrease in model performance. To mitigate this, an extra LayerNorm step was added after the SoLU activation function, which substantially improved the model performance.\n",
    "\n",
    "The SoLU activation function, when used alone, suppresses small activation values. This can be seen in the equation for SoLU:\n",
    "\n",
    "[\n",
    "\\operatorname{SoLU}(x)=x * \\operatorname{softmax}(x)\n",
    "]\n",
    "\n",
    "The softmax function will assign smaller fractions to smaller input values, so the product of (x) and (\\operatorname{softmax}(x)) will be even smaller if (x) is small to begin with.\n",
    "\n",
    "To understand why this might be problematic, let's consider a simple example. Suppose we have a single-layer neural network with two neurons, (n_1) and (n_2), and two input features, (x_1) and (x_2). The output of this network is given by:\n",
    "\n",
    "[\n",
    "y = w_1 * \\operatorname{SoLU}(x_1) + w_2 * \\operatorname{SoLU}(x_2)\n",
    "]\n",
    "\n",
    "where (w_1) and (w_2) are the weights associated with (n_1) and (n_2) respectively.\n",
    "\n",
    "If (\\operatorname{SoLU}(x_1)) and (\\operatorname{SoLU}(x_2)) produce very small activations, the output (y) will also be small, regardless of the values of (w_1) and (w_2). This means that even small changes in the input features (x_1) and (x_2) could have a significant impact on the output (y), making the learning process unstable and potentially leading to poor model performance.\n",
    "\n",
    "Moreover, small activations can make it hard for the gradient descent optimization algorithm to effectively update the model's weights. The gradients used to update the weights in gradient descent are calculated based on the activations of the neurons. If these activations are very small, the gradients might also be very small, leading to very slow learning or, in the worst case, causing the learning process to get stuck if the gradients become too close to zero (a problem known as vanishing gradients).\n",
    "\n",
    "To mitigate these issues, the authors of the paper introduced an extra LayerNorm step after the SoLU activation function. LayerNorm scales the activations so that they have a mean of 0 and a standard deviation of 1, effectively preventing the activations from becoming too small and helping to ensure more stable and effective learning. However, as the authors point out, this also introduces a complication, as the extra LayerNorm step might allow the model to \"smuggle\" non-neuron-aligned features through as small activations that are rescaled to be larger, potentially complicating the interpretation of the neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1d97c93-6c05-44cb-880e-6e399d2ef3a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fb394b2-829d-41bc-af70-d2f611bac1bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Module.__init__() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m linear \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/torch/nn/modules/module.py:449\u001b[0m, in \u001b[0;36mModule.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.__init__() got an unexpected keyword argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_super_init \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(args):\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.__init__() takes 1 positional argument but \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m were\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m given\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    452\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;124;03mCalls super().__setattr__('a', a) instead of the typical self.a = a\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03mto avoid Module.__setattr__ overhead. Module's __setattr__ has special\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;124;03mhandling for parameters, submodules, and buffers but simply calls into\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;124;03msuper().__setattr__ for all other attributes.\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Module.__init__() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "linear = nn.Module(10, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428ae5a9-eabb-43aa-9a8c-d6e211afca0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
