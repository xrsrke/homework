{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "380ac073-f734-4e32-b91c-fed0e118c593",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea9b947-6b8f-4712-be7c-463192f778cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e581cf02-ae49-48b6-8fff-26f3443e5ca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cffadf8-afd6-4d7b-b909-990ff95d284b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: loss / (current_epoch / n_epoch)\n",
    "step 2: calculate the gradients with respect to the normalized loss\n",
    "step 3: accumulate the gradients\n",
    "step 4: if current_epoch == n_epoch, update, otherwise, repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdedef0-290c-4b44-8b17-5aaf85400201",
   "metadata": {},
   "outputs": [],
   "source": [
    "message passing, sharded memory, file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b57a0a3-e89f-41cd-93ba-0a337e5e24c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(local_rank + 1)%local_world_Sizec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e20e3e12-1c0c-448e-89bc-4f42381ae0c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ecc64d2-d6ef-46c9-b785-33bbb00e5158",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Broadcast(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        dist.all_reduce(grad_input)\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9c4a84a-d057-4f20-900e-b66e42f3408e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Gather(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        world_size = dist.get_world_size()\n",
    "        inputs = [torch.zeros_like(input) for _ in range(world_size)]\n",
    "        dist.all_gather(inputs, input)\n",
    "        inputs = torch.cat(inputs)\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        world_size = dist.get_world_size()\n",
    "        rank = dist.get_rank()\n",
    "        chunks = torch.split(\n",
    "            grad_input,\n",
    "            split_size_or_sections=grad_input.shape[-1]//world_size\n",
    "        )\n",
    "        return chunks[rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2664ce7a-ef5a-4e7b-a5d3-2a893d9c7446",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ColumnParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size, world_size):\n",
    "        super().__init__()\n",
    "        out_per_partition = world_size // output_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.randn(\n",
    "            out_per_partition,\n",
    "            input_size\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.randn(\n",
    "            out_per_partition\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_parallel = Broadcast.apply(input)\n",
    "        output_parallel = F.linear(input_parallel, self.weight, self.bias)\n",
    "        outputs = Gather.apply(output_parallel)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a782ec7-360a-4403-9f4f-d6d40686113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RowParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        world_size = dist.get_world_size()\n",
    "        input_per_partrition = input_size // world_size\n",
    "        self.weight = nn.Parameter(torch.randn(\n",
    "            output_size,\n",
    "            input_per_partrition\n",
    "        ))\n",
    "        \n",
    "        self.bias = nn.Parameter(torch.randn(\n",
    "            output_size\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_parallel = Scatter.apply(input)\n",
    "        output_parallel = F.linear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ef3925-aec8-41c3-8cf9-e6c46c060afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e46b137-886d-4a75-a176-a2adabe62590",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Scatter(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx: Any, input: torch.Tensor, dim: int, parallel_context: ParallelContext) -> torch.Tensor:\n",
    "        ctx.dim = dim\n",
    "        ctx.parallel_context = parallel_context\n",
    "        \n",
    "        world_size = parallel_context.get_world_size(parallel_mode)\n",
    "        rank = parallel_context.get_local_rank(parallel_mode)\n",
    "\n",
    "        if world_size == 1:\n",
    "            return tensor\n",
    "\n",
    "        assert tensor.size(dim) % world_size == 0\n",
    "\n",
    "        tensor_list = torch.chunk(tensor, world_size, dim=dim)\n",
    "        return tensor_list[rank]\n",
    "\n",
    "        \n",
    "        return scatter(input, dim=dim, parallel_context=parallel_context, parallel_mode=ParallelMode.TENSOR)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx: Any, grad_output: torch.Tensor) -> Tuple[torch.Tensor, None, None]:\n",
    "        dim = ctx.dim\n",
    "        parallel_context = ctx.parallel_context\n",
    "\n",
    "        return (\n",
    "            all_gather(\n",
    "                grad_output, dim=dim, async_op=False, parallel_context=parallel_context, parallel_mode=ParallelMode.TENSOR\n",
    "            ),\n",
    "            None,\n",
    "            None,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af42fc65-e9e2-465c-90f7-4c179c351391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RowParallelLinear(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        out_features,\n",
    "        parallel_context,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        in_per_partition = self._get_input_per_partition(in_features, parallel_context)\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.parallel_context = parallel_context\n",
    "\n",
    "        self.weight = nn.Parameter(torch.randn(out_features, in_per_partition))\n",
    "\n",
    "        self.bias = nn.Parameter(torch.randn(out_features))\n",
    "\n",
    "    def _get_input_per_partition(self, in_features, parallel_context):\n",
    "        local_world_size = parallel_context.get_world_size(ParallelMode.TENSOR)\n",
    "        return in_features // local_world_size\n",
    "\n",
    "    def forward(self, input):\n",
    "        input_parallel = scatter_tensor_1d(input, dim=-1, parallel_context=self.parallel_context)\n",
    "        output_parallel = F.linear(input_parallel, self.weight)\n",
    "        outputs = reduce_tensor_1d(output_parallel, parallel_context=self.parallel_context)\n",
    "\n",
    "        return outputs + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5707f403-1493-42a8-a095-e16f7ab65592",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestFruit:\n",
    "    def setup_method(self):\n",
    "        self.fruit = Fruit(\"x\")\n",
    "    \n",
    "    def test_fruit(self):\n",
    "        assert self.fruit == \"x\"\n",
    "        \n",
    "    def teardown_method(self):\n",
    "        del self.fruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c107b6f3-74c7-458a-9a77-6ed4decd73a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "world_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afbefac1-44f9-4a65-8113-c71f98ccb103",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor_model_parallel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eebc11cc-c929-415d-aded-deb06cf85a58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_model_parallel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a68ba0b-10f7-4d61-9d28-cc58999fe9d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_parallel_groups = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d7396bb-e454-4fdd-991d-2367e48816b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_pipeline_model_parallel_groups = world_size // pipeline_model_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fa20785-5e83-404b-804f-33d6262f4aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2]\n",
      "[1, 3]\n",
      "[4, 6]\n",
      "[5, 7]\n",
      "[8, 10]\n",
      "[9, 11]\n",
      "[12, 14]\n",
      "[13, 15]\n"
     ]
    }
   ],
   "source": [
    "for i in range(pipeline_model_parallel_size):\n",
    "    start_rank = i*num_pipeline_model_parallel_groups\n",
    "    end_rank = (i+1)*num_pipeline_model_parallel_groups\n",
    "    \n",
    "    for j in range(tensor_model_parallel_size):\n",
    "        ranks = list(range(\n",
    "            start_rank+j,\n",
    "            end_rank,\n",
    "            tensor_model_parallel_size\n",
    "        ))\n",
    "        \n",
    "        print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f27c0c-1bb5-474a-9afa-9f73653e790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hostdiscovery, torchstate, 3 notif, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bedf1f-9fe2-4f01-bee9-6c3c0d30236f",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: var\n",
    "step 2: global\n",
    "step 3: parallel groups\n",
    "step 4: set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8aedad-b2e0-4f5a-a500-1ffb78c91f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scatter > All reduce > Identity > All-gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a8f7bc-1ca0-4aec-8355-d132af9b3ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ab0670-be3b-489a-a8a1-cd717758fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[\"out\", 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02df098c-f0a8-49fd-8cf4-e2c43580e5d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_len, d_model = 4, 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4843c538-7168-4710-b985-193146d2269c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W_in = torch.zeros(d_model, seq_len)\n",
    "W_in[0:4, :] = torch.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0ea1bd8-6f71-43e9-b111-0d6ab772a41e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b933e0f5-aebb-4b86-a17c-56501ec5ac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: prob[0] = sigmoid(logit0 - logit1)\n",
    "step 2: logit0 = resid @ W_U[0], logit1 = resid @ W_U[1]\n",
    "step 3: resid @ (W_U[0] - W_U[1])\n",
    "step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1cc2bf1-146a-4d62-8540-66627ef0dde6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_model = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c4c1e0c-076b-471a-87ff-dea0c1bd2c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq_len = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da732adc-da71-4493-9c38-d828900c2a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W_V = torch.zeros(seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6564be12-2661-4b05-94a1-b35dd706ee85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W_V[torch.arange(4), torch.arange(4)] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "632f2a70-d980-44fc-af1a-e958e6ece8ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94d29487-73c8-465c-9368-c54ffb1723db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W_O = torch.zeros(d_model, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0651a923-891e-486f-b5c4-bc652ee39ed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W_O[8:11, :] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c9cbc4e-09b5-4360-9d70-6d33ad28b53b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5526b56c-efc2-49e9-8d39-f649c3718291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_head = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "63c52039-ff79-4490-b087-e4ab7ff821b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b91a1800-a491-4f8d-86a0-bd91a804bfca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model, d_head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4ff331-c519-4f19-a2dd-7502e5b8e3bf",
   "metadata": {},
   "source": [
    "Write down $W_V^1$ and $W_{\\text {out }}^1$ for head 1 , such that the head copies dimensions 0-3 of its input to 8-11 in its output + there are four input tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "46c9cc44-826a-4fad-9e16-4d54e7b40031",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W_V = torch.zeros(d_head, d_model)\n",
    "W_V[torch.arange(4), torch.arange(4)] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dea4a07d-210a-43fb-abb0-43da62c0b6ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W_O = torch.zeros(d_model, d_head)\n",
    "W_O[7:11, :] = torch.eye(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "17dce060-be56-4a1d-bbcb-77730d977c89",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "57199278-9edf-4037-9ba2-8f0119927c82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bcc12e21-45bb-428d-afc2-60ef906d163f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 16]), torch.Size([16, 4]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_V.shape, W_O.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad9396d-c248-4e34-bb7e-4aa688d34484",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[\"attn\", 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef84bc10-e3b8-45c6-810a-7b7f39b69f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "A@ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433e33f8-d6ed-4ab9-b310-be24dc772832",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_activations = model.run_with_cache(clean_tokens)\n",
    "_, corrupted_activations = model.run_with_cache(corrupted_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9ca5d69e-f368-4f0f-bcc5-eae30f1b3342",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d5b7dc3f-a409-43b7-9cf9-c9ea5bbbb7e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_layers = 12\n",
    "n_heads = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "afef0d52-c210-43cb-9281-b9f18e60d367",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combinations = product(range(n_layers), range(n_heads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "62a4ef39-31e4-41ca-b3f5-444b99458b59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_head(\n",
    "    activations,\n",
    "    hook,\n",
    "    clean_activations,\n",
    "    corrupted_activations,\n",
    "    target_head\n",
    "):\n",
    "    target_layer_idx, target_head_idx = target_head\n",
    "    if hook.layer() == target_layer_idx:\n",
    "        activations[:, head_idx] = corrupted_activations[hook.name][:, head_idx]\n",
    "    else:\n",
    "        activations = clean_activations[hook.name][:, head_idx]\n",
    "    \n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1cd75ac7-0946-4cbe-aff0-b2473cd35936",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aa7f62-534a-4149-ace0-15aaad2a8a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.zeros(n_layers, n_heads)\n",
    "\n",
    "for layer_idx, head_idx in combinations:\n",
    "    model.reset_hooks()\n",
    "    \n",
    "    hook_name = get_act_name(\"z\", layer_idx)\n",
    "    hook_func = partial(\n",
    "        patch_head,\n",
    "        clean_activations=clean_activations,\n",
    "        corrupted_activations=corrupted_activations,\n",
    "        target_head=(layer_idx, head_idx)\n",
    "    )\n",
    "    \n",
    "    patched_logits = model.run_with_hooks(clean_tokens)\n",
    "    logit_diff = compute_ioi_metric(patched_logits)\n",
    "    results[layer_idx, head_idx] = logit_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1a66e1-5f1d-449b-b650-43f54287c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7de2342-8cef-4768-b0ac-d3f6bdeb330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_in_acts = cache[\"post\", layer_idx]\n",
    "W_out = model.W_out[layer_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2cb0174b-cc99-46f1-8d9d-7d554b6f9d8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996860b3-bc1d-4f5e-8a60-6d046adb96cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "einsum(W_in_acts, W_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cae7554-631d-47c1-9774-fd95024c85e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "A@W_OV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafe1519-60d9-4a10-adf2-ef71419f1ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(board_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ac8012-0297-48a0-aaa7-ade8be97877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be23dd0-22fc-4355-93ba-cf9a44df5be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9d686e56-2a0d-4e7c-a4b3-2aa108eea0af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, head_idx = 9, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc220a5-2f83-4b61-88a7-ab8ae3b7489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_out = cache[\"z\", layer_idx][:, :, head_idx]\n",
    "\n",
    "W_U = model.W_U\n",
    "io_dir = W_U[:, io_tokens]\n",
    "s_dir = W_U[:, s_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed095bdf-774a-4f32-9029-a427ecb20884",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_in_io_dir = (attn_out * io_dir).sum()\n",
    "projection_in_s_dir = (attn_out * s_dir).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559d0979-3eae-4094-ad6f-56bfd82bd40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_pattern = cache[\"pattern\", layer_idx][:, head_idx]\n",
    "attn_from_end_to_io = attn_pattern[:, end_idxs, io_idxs]\n",
    "attn_from_end_to_s = attn_pattern[:, end_idxs, s_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189859e7-35c5-4a98-967e-fdeeb663d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(past_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abce8abe-ce8e-4925-9b04-69836ee4b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_neurons = cache[\"post\", 2].std(dim=[0, 1]).argsort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266f0f66-0ed1-4938-b69d-3e8d6584a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_out = model.W_out[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12fa6da-e475-4f35-94cd-04cbfd75e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_V = torxh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89f5343-f6ff-4bd0-8c65-2eb4f57d1270",
   "metadata": {},
   "outputs": [],
   "source": [
    "A@x@W_OV@W_OV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "52de237f-1f2a-474c-bf18-bcab07f17a18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Scatter(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        world_size = dist.get_world_size()\n",
    "        rank = dist.get_rank()\n",
    "        chunks = torch.split(\n",
    "            inputs,\n",
    "            split_size_or_sections=input.shape[0] // world_size\n",
    "        )\n",
    "        return chunks[rank]\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        world_size = dist.get_world_size()\n",
    "        grads = [torch.zeros_like(grad_input) for _ in range(world_size)]\n",
    "        dist.all_gather(grads, grad_input)\n",
    "        grads = torch.cat(grads)\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "97ca4164-8e48-42db-b9e4-1a9a19c941ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Reduce(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        dist.all_reduce(input)\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "22b53526-20fb-4ad4-a173-a0c36bca85b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RowParallelLinear(torch.autograd.Function):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        world_size = dist.get_world_size()\n",
    "        self.weight = nn.Parameter(torch.randn(\n",
    "            output_size,\n",
    "            input_size//world_size\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.randn(\n",
    "            output_size\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_parallel = Scatter.apply(input)\n",
    "        output_parallel = F.linear(input_parallel, self.weight)\n",
    "        outputs = Reduce.apply(output_parallel)\n",
    "        return outputs + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275cb58e-d3b7-41a0-803c-72ffe4b666ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter > all-reduce > identity > all-gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61a7d5c-55c7-4a50-83d8-9456942c12ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast > gather > scatter > all-reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00cfab7-9762-45fa-884e-54e615ed995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter > all-reduce > identty > all gather "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "08d9d33f-7bc7-4d3b-920e-4e1f251be0b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "33e6660e-b0b7-47e6-bf62-2892616cc0d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e712a2b0-0578-4307-8825-9bcb59f85e12",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(4, 2)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "da4865bb-e80d-4d05-ac03-5ccd50239577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input = torch.tensor([[55]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3d5735ac-5783-4903-a767-400241d820d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 // 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cebe31da-113f-41df-a4ce-e18002ccf537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weight = torch.randn(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2a378243-3898-46ec-a577-83d2629aabe7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunks = torch.split(weight, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1a3c3ae2-8a18-44b7-8956-7b6f510f59a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2077, -1.2928],\n",
       "        [ 0.4192, -0.6931]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "45b154ad-eb09-4b32-bcf4-832f86e3ceaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5300,  0.5838],\n",
       "        [-1.2980,  0.2849]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7e4df3ab-ea42-4e51-a152-aad62efce798",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2077, -1.2928],\n",
       "        [ 0.4192, -0.6931],\n",
       "        [ 0.5300,  0.5838],\n",
       "        [-1.2980,  0.2849]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02465066-efc5-4c5d-8f96-769d2dfafd12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
