{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d470ff7-7751-4cdb-be30-89423d0137a2",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acbfef87-fb97-422c-aae0-4f9ef065f6df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e89d223-08d0-40fa-96cb-f53bf2397ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding, linear layer, attention, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fe0780-dd88-4c53-bfff-41a14e558f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: get the global rank\n",
    "step 2: resize the embedding vocab size\n",
    "step 3: parallelize embeddng layer, linear layer, layer norm, attn\n",
    "step 4: resize the output size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f142fdd-7644-468f-ba07-b38c14d13caf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2190ef7-229b-4e5c-86ab-d445dfb6dca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParallelContext:\n",
    "    def init_rpc_workers(self, host, port):\n",
    "        if self.tensor_parallel_size > 1:\n",
    "            rank = self.get_global_rank()\n",
    "            world_size = self.get_world_size(ParallelMode.GLOBAL)\n",
    "            options = rpc.TensorPipeRpcBackendOptions(\n",
    "                init_method=f\"tcp://{host}:{port}\"\n",
    "            )\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                ranks = self.get_ranks_in_group(ParallelMode.GLOBAL)\n",
    "                rpc_mappings = {\n",
    "                    rank: WORKER_NAME.format(rank)\n",
    "                    for rank in ranks\n",
    "                }\n",
    "                \n",
    "                for other in ranks:\n",
    "                    if other == rank:\n",
    "                        continue\n",
    "                    \n",
    "                    options.set_device_map(\n",
    "                        rpc_mappings[other], {rank: other}\n",
    "                    )\n",
    "            \n",
    "            rpc.init_rpc(\n",
    "                name=WORKER_NAME.format(rank),\n",
    "                world_size=world_size,\n",
    "                options=options\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5059ec69-8ae3-4f86-a94f-8e635f7e506f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _P2P:\n",
    "    def _send_metadata(self, data, dst_rank, parallel_context, parallel_mode):\n",
    "        group = parallel_context.get_group(parallel_mode)\n",
    "        \n",
    "        dtype = torch.tensor(DTYPE_TO_ID[data.dtype])\n",
    "        dist.send(dtype, dst=dst_rank, group=group)\n",
    "        \n",
    "        shape = torch.tensor(data.shape)\n",
    "        dist.send(shape, dst=dst_rank, group=group)\n",
    "        \n",
    "        requires_grad = torch.tensor(1 if data.requires_grad else 0)\n",
    "        dist.send(requires_grad, dst=dst_rank, group=group)\n",
    "    \n",
    "    def send(self, data, src_rank, dst_rank, parallel_context, parallel_mode=ParallelMode.PIPELINE):\n",
    "        group = parallel_context.get_group(parallel_mode)\n",
    "        self._send_metadata(data, dst_rank, parallel_context, parallel_mode)\n",
    "        dist.send(data, dst=dst_rank, group=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f336c95f-0bcb-43f3-8219-24ca5d909812",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def send(data, src_rank, dst_rank, parallel_context):\n",
    "    rank = parallel_context.get_rank()\n",
    "    \n",
    "    if rank == src_rank:\n",
    "        _P2P.send(data, src_rank, dst_rank, parallel_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9651170c-ca32-4351-b141-b97acfb9f58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: get global rank\n",
    "step 2: resize embedding\n",
    "step 3: parallelize embedding, linear, attention, layer norm\n",
    "step 4: resize lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c8e019a-e4c4-47c7-9385-f25a6fe455c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5ff0104-b135-429e-a48b-bec8965bb575",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SERVER_PWD: Final = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14d57f5-71bc-4189-8529-63bd93961773",
   "metadata": {},
   "outputs": [],
   "source": [
    "based on microbatch_idx, partition_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eac331-f028-42ac-a282-062993c6525c",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize communication\n",
    "maximize storage\n",
    "minimie flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e50f80-3322-4231-afeb-26eeed9ab37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.recv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ba645b-70a3-471d-a6f1-0dd9d947fe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _P2P:\n",
    "    def _recv_metadata(self, src_rank, parallel_context, parallel_mode):\n",
    "        group = parallel_context.get_group(parallel_mode)\n",
    "        \n",
    "        dtype = torch.tensor(0)\n",
    "        dist.recv(dtype, src_rank, group=group)\n",
    "        dtype = ID_TO_DTYPE(dtype)\n",
    "        \n",
    "        shape = torch.tensor()\n",
    "        dist.recv(shape, src_rank, group)\n",
    "        \n",
    "        requires_grad = torch.tensor(0)\n",
    "        dist.recv(requires_grad, src_rank, group=group)\n",
    "        requires_grad = True if requires_grad == 1 else False\n",
    "        \n",
    "        return dtype, shape, requires_grad\n",
    "        \n",
    "    \n",
    "    def recv(self, src_rank, dst_rank, parallel_context, parallel_mode: ParallelMode.GLOBAL):\n",
    "        group = parallel_context.get_group(ParallelMode)\n",
    "        dtype, shape, requires_grad = self._recv_metadata(src_rank, parallel_context, parallel_mode)\n",
    "        \n",
    "        data = torch.zeros_like(shape, dtype=dtype, requires_grad=requires_grad)\n",
    "        dist.recv(data, src=src_rank, group=group)\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d29bb97-298c-4f9e-a91e-558c33ed86cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recv(src_rank, dst_rank, parallel_context):\n",
    "    rank = parallel_context.get_global_rank()\n",
    "    if rank == dst_rank:\n",
    "        return _P2P.recv(src_rank, dst_rank, parallel_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb085b0-809d-4bd1-8ab0-2522ffac06ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximize storage\n",
    "minimize flops\n",
    "minimize communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45db022e-6e79-412a-ae0d-3b88223a5788",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: determine local maximum\n",
    "step 2: determine global maximum\n",
    "step 3: normalize the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4a17182-65ea-44c5-ac43-b655105c19df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def by_row_parallelism(inputs, weights):\n",
    "    inp_per_partition = inputs.shape[-1] // 2\n",
    "    w_per_partition = weights.shape[0] // 2\n",
    "    \n",
    "    inp1, inp2 = inputs[:, :inp_per_partition], inputs[:, inp_per_partition:]\n",
    "    w1, w2 = weights[:w_per_partition, :], weights[w_per_partition:, :]\n",
    "    \n",
    "    out1 = inp1 @ w1\n",
    "    out2 = inp2 @ w2\n",
    "    \n",
    "    return out1 + out2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cdc7b3-24d0-4530-b044-b648e684da7e",
   "metadata": {},
   "source": [
    "step 1: record all the interdimate activations\n",
    "step 2: analyze the attention pattern\n",
    "step 3: spot induction heads\n",
    "step 4: decompose attention scores\n",
    "step 5: trace back which pair of q-k contribute to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18411792-6231-40f0-9cb0-64466e608d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A^T W_E W_QK^{h} W_E^{B} = A^T W_E W_Q^{h} (W_Q^{h})^T W_E^{T} B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c545410-0600-4db2-a901-12ca15e0680c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ad68007-9d99-43c9-8e2a-452e85f3793d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Sauce(Enum):\n",
    "    BECHAMEL = \"Bechamel\"\n",
    "    VELOUTE = \"Veloute\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4680d46e-ddcb-47bc-b41f-e0b4ec714991",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: define a mapping\n",
    "step 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27234061-b524-4a8d-a24e-e76d22440d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980c25b6-7f7b-4705-a23a-79a846ff2220",
   "metadata": {},
   "outputs": [],
   "source": [
    "A @ W_E @ W_QK^{h} @ W_E @ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbda40d-56f5-4daf-8b56-3819adacd2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[\"result\", 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9413500b-495b-4e10-b290-bb03b712498d",
   "metadata": {},
   "source": [
    "step 1: output = pos_embed + embed + layer0 + layer1\n",
    "step 2:\n",
    "    - layer0 = head00 + head01 + mlp0\n",
    "    - layer1 = head10 + head11 + mlp1\n",
    "step 3:\n",
    "    output = embed + pos_embed + head00 + head01 + mlp0 + head10 + head11 + mlp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add3fde4-75a7-40d4-981c-4b6d7c2389f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: prob[0] = sigmoid(logit0 - logit1)\n",
    "step 2: logit0 = resid2 @ W_U[0], logit1 = final_resid @ W_U[1]\n",
    "step 3: logit0 - logit1 = resid2 @ (W_U[0] - W_U[1])\n",
    "step 4: final_resid = resid1 @ ln1 @ W_OV^{1}\n",
    "step 5: resid1 @ ln1 @ W_OV^{1} @ (W_U[0] - W_U[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99010b70-3f92-4b18-97a9-86e603a3304b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ede6bd-8c15-4369-bb8b-6d14ebe0bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "[embed + pos_embed + sum(12 heads)] @ W_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e1baa1-3337-4622-9c70-8eeed5256233",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_head[:, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159f9866-7623-4d5f-baaf-9487ae5fb629",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e82847-aac0-4ad5-b19c-1650155b7fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_pattern = cache[\"attn_pattern\", layer_idx][:, : head_idx][:, query_position].float().mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b918123a-e5b5-480a-8524-3fd0cb920472",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_logit_diff - corrupted_logit_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150d0ba0-d502-4c4e-ac62-d5ea93d78a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "v @ fourier_basis.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da04f2c-8b7a-4b17-bfc8-c3dfe79cbd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_O = model.W_O[0, 1]\n",
    "W_V = model.W_V[0, 1]\n",
    "W_Q = model.W_Q[1, 2]\n",
    "W_K = model.W_K[1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1532dc07-c0ca-40be-8ac9-b00fda5bdc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "OV_circuit = W_V @ W_O\n",
    "QK_circuit = W_Q @ W_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296e62f7-1ab7-4693-b186-7994623928fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_weight = OV_circuit @ QK_circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59abdd0-7585-4237-ad1c-1c52907b5867",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_cache = model.run_with_cache(clean_tokens)\n",
    "_, corrupted_cache = model.run_with_cache(corrupted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41baaa1d-a547-495c-bcfc-2df57ad9fa4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3fafe0-c5fe-45ec-b69f-af674a2c7c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = product(range(n_layers), range(n_heads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd3de7da-301b-4034-83be-8badcbb84bbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcc1f692-1bf6-4b9b-a41d-1416ff82d9ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_head(\n",
    "    head_acts, hook,\n",
    "    clean_cache, corrupted_cache,\n",
    "    target_head\n",
    "):\n",
    "    trg_layer_idx, trg_head_idx = target_head\n",
    "    if trg_layer_idx == hook.layer():\n",
    "        head_acts[:, head_idx] = corrupted_cache[hook.name][:, head_idx]\n",
    "    else:\n",
    "        head_acts = clean_cache\n",
    "    return head_acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d149fa-c695-474e-a89b-c49b96815d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.zeros(n_layers, n_heads)\n",
    "\n",
    "for layer_idx, head_idx in combinations:\n",
    "    model.reset_hooks()\n",
    "    hook_name = get_act_name(\"z\", layer_idx)\n",
    "    hook_func = partial(\n",
    "        patch_head,\n",
    "        clean_cache=clean_cache,\n",
    "        corrupted_cache=corrupted_cache,\n",
    "        target_head=(layer_idx, head_idx)\n",
    "    )\n",
    "    model.reset_hook(hook_name, hook_func)\n",
    "    patched_logits, _ = model.run_with_cache(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455bba6c-4ede-47ef-b6d2-bbcdb1485c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: logit_diff = W_U[0] - W_U[1]\n",
    "step 2: approximate layer norm using linearity\n",
    "step 3: extract the approximated coefficients\n",
    "step 4: coeff @ logit_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054fac21-7bd9-48bc-b3e7-5dddf5c38862",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations[1, 2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc349194-7c04-4695-b0b4-222f02c2fb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "(embed + pos_embed + sum(12 heads)) @ W_Q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d296fa76-b0cf-422c-a8a3-22fe3a122499",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_K @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21952fdb-951f-43a5-b87f-76f9666c0dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_idx = start_idx + partition_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4af047-69a8-417b-bd80-77328da26ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfbea0b8-6bbf-4b07-bd26-f75403810ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_microbatches = 4\n",
    "n_partitions = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41c4109b-4c15-48cc-ade9-5632f17c49e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_clock_cycles = n_microbatches+n_partitions - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c894207c-d6e7-4cf1-9583-2800da67ef30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_clock_cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c220de3-a571-4058-9a29-8a097f5c4478",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0)]\n",
      "[(1, 0), (0, 1)]\n",
      "[(2, 0), (1, 1), (0, 2)]\n",
      "[(3, 0), (2, 1), (1, 2)]\n",
      "[(3, 1), (2, 2)]\n",
      "[(3, 2)]\n"
     ]
    }
   ],
   "source": [
    "for clock_idx in range(n_clock_cycles):\n",
    "    start_partition_idx = max(clock_idx+1-n_microbatches, 0)\n",
    "    end_partition_idx = min(clock_idx+1, n_partitions)\n",
    "    \n",
    "    xs = []\n",
    "    for partition_idx in range(start_partition_idx, end_partition_idx):\n",
    "        microbatch_idx = clock_idx - partition_idx\n",
    "        xs.append((microbatch_idx, partition_idx))\n",
    "    \n",
    "    print(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87349a33-b3e0-470f-b6fa-3ac79bb2cac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dbb0f3a1-a178-44bf-9e59-9a5eb41a19ca",
   "metadata": {},
   "source": [
    "- step 1: parittion embedding\n",
    "- step 2: mask\n",
    "- step 3: calculate local embedding\n",
    "- step 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc9295f-a1d8-449c-83f1-81ae28984175",
   "metadata": {},
   "outputs": [],
   "source": [
    "new node enters, new node leaves, no changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8833ac3a-4b2d-427b-89ec-36c347fe5eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Reduce(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, parallel_context):\n",
    "        group = parallel_context.get_group(ParallelMode.TENSOR)\n",
    "        dist.all_reduce(input, group=group)\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        return tuple([grad_input, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfe9934b-4ac8-48cd-9a61-99a6d6c68c99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParalellEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, parallel_context):\n",
    "        super().__init__()\n",
    "        world_size = parallel_context.get_world_size()\n",
    "        per_partition = num_embeddings // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.randn(\n",
    "            per_partition,\n",
    "            embedding_dim\n",
    "        ))\n",
    "        self.vocab_start_idx, self.vocab_end_idx = self._get_vocab_range(\n",
    "            per_partition,\n",
    "            parallel_context\n",
    "        )\n",
    "    \n",
    "    def _get_vocab_range(self, per_partition, parallel_context):\n",
    "        rank = parallel_context.get_local_rank(ParallelMode.TENSOR)\n",
    "        start_idx = per_partition*rank\n",
    "        end_idx = start_idx+per_partition\n",
    "        return start_idx, end_idx\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_mask = (input < self.vocab_start_idx) | (input >= self.vocab_end_idx)\n",
    "        masked_input = input.clone() - self.vocab_start_idx\n",
    "        masked_input[input_mask] = 0\n",
    "        \n",
    "        parallel_embeddings = F.embedding(masked_input, self.weight)\n",
    "        parallel_embeddings[input_mask, :] = 0.\n",
    "        \n",
    "        embeddings = Reduce.apply(parallel_embeddings)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e38535-0df7-4d5c-be2c-9e1fbba7cb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: mask the targets\n",
    "step 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af63c850-62ba-4504-b5d5-5f60c7b86d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(clock_idx+1, n_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db96e5f5-959f-46ba-9e77-b4ca2d69be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = (3, 3)\n",
    "B = (-2, 2)\n",
    "\n",
    "Re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b142aa96-4bd5-4092-9152-8e6706790918",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_K @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e38675-e8f3-44e7-9364-59167b5564f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(board_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "add98de9-9791-42a1-9e34-5352e51a0d6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx = 5\n",
    "neuron_idx = 1393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a4c9d9-42c9-4662-a182-d986de96bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_neurons = cache[hook_name][:, neuron_idx]\n",
    "threashold = mlp_neurons.quantile(0.99)\n",
    "\n",
    "top_neurons = mlp_neurons > threashold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977abb92-3e34-4706-adb8-5fdf0b5d5d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "(board_states == 1)[top_neurons].float().mean(dim=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80deada-9597-4a14-94f0-6f5964b7fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob[0] = sigmoid(logit0 - logit1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2331db8-9b70-4362-818d-7bf2c3361628",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_microbatches = 4\n",
    "n_partitions = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e7f43d5-b596-4812-8176-deeeface7785",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_clock_cycles = n_microbatches+n_partitions-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3330aac2-4cdd-489a-acb2-81af8b8685b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_clock_cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46f55d5c-e4ed-44b4-a9bb-66a4719f1354",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0)]\n",
      "[(1, 0), (0, 1)]\n",
      "[(2, 0), (1, 1), (0, 2)]\n",
      "[(3, 0), (2, 1), (1, 2)]\n",
      "[(3, 1), (2, 2)]\n",
      "[(3, 2)]\n"
     ]
    }
   ],
   "source": [
    "for clock_idx in range(n_clock_cycles):\n",
    "    start_partition_idx = max(clock_idx+1-n_microbatches, 0)\n",
    "    end_partition_idx = min(clock_idx+1, n_partitions)\n",
    "    \n",
    "    schedules = []\n",
    "    for partition_idx in range(start_partition_idx, end_partition_idx):\n",
    "        microbatch_idx = clock_idx - partition_idx\n",
    "        schedules.append((microbatch_idx, partition_idx))\n",
    "    \n",
    "    print(schedules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44bc08e-2094-4639-a178-748a28975441",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: mask targets\n",
    "step 2: calculate local predicted logits\n",
    "step 3: calculate the global logits\n",
    "step 4: calculate log(sum(...))\n",
    "step 5: calculate the loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b475bc7-4a97-441f-b7d9-79cca5e249c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "2*250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99a6d21c-50da-4449-bcb2-7f76e3e56a1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead72f92-eba2-49c5-8ca0-db2e6154876a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def use_stream(stream):\n",
    "    if not isinstance(strea, torch.cuda.Stream):\n",
    "        yield\n",
    "        return\n",
    "    \n",
    "    with torch.cuda.stream(stream):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4b1b69-f47f-4f8e-84bc-88d9b34309e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: partition weights\n",
    "step 2: mask targets\n",
    "step 3: calculate local embeddings\n",
    "step 4: calculate the global embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "059387b5-9a87-4bc0-bd41-b915ea368094",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e841e23-7a89-4f17-9c1f-a1f53ffc5e18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def use_stream(stream):\n",
    "    if not isinstance(stream, torch.cuda.Stream):\n",
    "        yield\n",
    "        return\n",
    "    \n",
    "    with torch.cuda.stream(stream):\n",
    "        yield\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "81bfb3c6-a852-4747-9eda-366d0b6e6660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9084b96-84c5-4ce2-bf62-9977b4da4d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "einsum(\"x y, x y ->\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2ea969-8e3a-4542-8dcb-7056cf09dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "message passing, collective communication, p2p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c3029e-d5b7-42e9-ae41-c1bd691a16e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpc.get_worker_info(wop )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f743ee-0442-4e59-a5c3-a090ff175481",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = embed + pos_embed + x_1 + x_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69591d54-6ebf-4617-a70e-330f5e0902a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c218a-70a0-4e53-8f1a-9f7872e7b53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tokens = tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eddebdf-53f9-4bdd-8c47-74c38addb042",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U\n",
    "W_U[:, target_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e1aa46-094a-42a1-8bf7-db80ce4afa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax(x W_Q W_K.T x.T) x W_V W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13402a13-9c17-419b-9ed0-f5cf1a430796",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d701b025-48de-4c1e-aeba-937a2b55835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = model.embed\n",
    "mlp0 = model.blocks[0].mlp\n",
    "ln01 = model.blocks[0].ln1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc371d74-9454-4999-bd96-899a65454fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln01(mlp0(embed(tokens))) + embed(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2b767f-32fd-4c93-b173-416ac57fbeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x @ W_E @ W_QK @ W_E.T @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6916f39-433f-4148-93ff-fc256c4c92df",
   "metadata": {},
   "outputs": [],
   "source": [
    "[embed + pos_embed + sum(12 heads)] @ W_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f2428c-4784-46be-ba94-46fcf8778431",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu0: [0, 122, 0]\n",
    "gpu1: [567, 0, 888]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d18d16-8ef5-4e4d-aa96-f4ee4499dfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "image encoder, text encoder, constrative loss, projection head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dcf9b3a2-6fa2-4a71-bebc-962be7d4a112",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def probability_scores(image_embedding, text_embedding):\n",
    "    image_norm = image_embedding.norm(dim=-1)\n",
    "    image_embedding /= image_embedding / image_norm\n",
    "    \n",
    "    text_norm = text_embedding.norm(dim=-1)\n",
    "    text_embedding /= text_embedding / text_norm\n",
    "    \n",
    "    similarities = image_embedding @ text_embedding.T\n",
    "    probs = F.softmax(similarities, dim=-1)\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9461f56-e0d4-4b0f-932e-8be8703e9377",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = model.embed\n",
    "mlp0 = model.blocks[0].mlp\n",
    "ln01 = model.blocks[0].ln2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be13ffc-00de-41b1-ab44-5334f2f5f18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)\n",
    "embeddings = embed(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a114048-f14f-43c1-8237-63fc1a276125",
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_after_mlp0 = embeddings + ln01(mlp0(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c30c50-e677-44e2-8a49-873f97e43728",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_rref.rpc_sync().your_mom(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6849d9-82f0-4bfa-9678-46b10666e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = model.embed\n",
    "mlp0 = model.blocks[0].mlp\n",
    "ln0 = model.blocks[0].ln2\n",
    "unembed = model.unembed\n",
    "ln_final = model.ln_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c2158-bdc4-4c54-82da-d73e02d54fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_embeddings = model.embed(name_tokens)\n",
    "name_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f2c13e-18b0-40d9-a73d-6c7692407fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_after_mlp0 = name_embeddings + ln0(mlp0(text_embeddings))\n",
    "W_OV = model.W_V[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "351d799c-0b8d-4972-9ccf-b3a56e6457b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResidualLayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, dropout):\n",
    "        super().__init__()\n",
    "        self.ln = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, residual):\n",
    "        return self.ln(self.dropout(x) + residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84252d-57e4-4565-b5e1-f058636e4c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label[torch.where(dsets.train[0][1] == 1.)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7eee70c6-4be0-4fbe-aace-9acb06ba3b8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def probability_scores(image_embedding, text_embedding):\n",
    "    image_norm = image_embedding.norm(dim=-1)\n",
    "    image_embedding /= image_norm\n",
    "    \n",
    "    text_norm = text_embedding.norm(dim=-1)\n",
    "    text_embedding /= text_norm\n",
    "    \n",
    "    similarities = image_embedding @ text_embedding.T\n",
    "    probs = F.softmax(\n",
    "        similarities,\n",
    "        dim=-1\n",
    "    )\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee7846-38ff-42ab-9036-e68be0e78ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "photoreceptor > biopolar cell > ganglion cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f19ace-0823-46b8-b66b-1c497727ac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "generalization\n",
    "complex reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24289618-c221-4bce-8dac-15b7ac64fe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_policy_probs / prev_policy_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f78ac36-0541-40a9-9847-8ff59eac889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_returns = discount_return_at_each_timestep(rewards)\n",
    "\n",
    "total_loss = 0\n",
    "\n",
    "for discount_return, prob in zip(discount_returns, selected_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36081cf-9f9c-4db8-b20d-e35b973fa237",
   "metadata": {},
   "source": [
    "First, calculate $\\frac{dL}{dg}$ - since $L=g$, this derivative is simply 1.\n",
    "\n",
    "Next, calculate $\\frac{dL}{df}$ using the chain rule: $\\frac{dL}{df}=\\frac{dL}{dg} \\times \\frac{dg}{df}$. We know that $\\frac{dL}{dg}=1$, and $\\frac{dg}{df}=\\frac{1}{f}$ (since $g=\\log(f)$), so $\\frac{dL}{df}=\\frac{1}{f}$.\n",
    "\n",
    "Now, calculate $\\frac{dL}{dd}$ and $\\frac{dL}{de}$ using the chain rule: $\\frac{dL}{dd}=\\frac{dL}{df} \\times \\frac{df}{dd}$ and $\\frac{dL}{de}=\\frac{dL}{df} \\times \\frac{df}{de}$. We know that $\\frac{dL}{df}=\\frac{1}{f}$, and $\\frac{df}{dd}=e$ and $\\frac{df}{de}=d$ (since $f=d \\times e$), so $\\frac{dL}{dd}=\\frac{e}{f}$ and $\\frac{dL}{de}=\\frac{d}{f}$.\n",
    "\n",
    "Finally, calculate $\\frac{dL}{da}$, $\\frac{dL}{db}$, and $\\frac{dL}{dc}$: $\\frac{dL}{da}=\\frac{dL}{dd} \\times \\frac{dd}{da}$, $\\frac{dL}{db}=\\frac{dL}{dd} \\times \\frac{dd}{db}$, and $\\frac{dL}{dc}=\\frac{dL}{de} \\times \\frac{de}{dc}$. We know that $\\frac{dL}{dd}=\\frac{e}{f}$, $\\frac{dL}{de}=\\frac{d}{f}$, $\\frac{dd}{da}=b$, $\\frac{dd}{db}=a$, and $\\frac{de}{dc}=\\frac{1}{c}$ (since $d=a \\times b$ and $e=\\log(c)$), so $\\frac{dL}{da}=\\frac{b \\times e}{f}$, $\\frac{dL}{db}=\\frac{a \\times e}{f}$, and $\\frac{dL}{dc}=\\frac{d}{c \\times f}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d335e485-5849-4164-b1d6-87c84807aeb1",
   "metadata": {},
   "source": [
    "- Step 1: $w_0=x$\n",
    "- Step 2: $w_1=h(x)$\n",
    "- Step 3: $w_2=g\\left(w_1\\right)$\n",
    "- Step 4: $w_3=f\\left(w_2\\right)=y$\n",
    "- Step 5: $\\frac{\\mathrm{d} y}{\\mathrm{~d} x}=\\frac{\\mathrm{d} y}{\\mathrm{~d} w_2} \\frac{\\mathrm{d} w_2}{\\mathrm{~d} w_1} \\frac{\\mathrm{d} w_1}{\\mathrm{~d} x}=\\frac{\\mathrm{d} f\\left(w_2\\right)}{\\mathrm{d} w_2} \\frac{\\mathrm{d} g\\left(w_1\\right)}{\\mathrm{d} w_1} \\frac{\\mathrm{d} h\\left(w_0\\right)}{\\mathrm{d} w_0}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0bc5d0df-aa1b-4a4e-8cd0-63dbe0387baa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logits = torch.randn(3, 5) # Assuming 3 samples, 5 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b58fff82-4478-4354-8a0f-d45ef7e8de74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9688,  0.1355, -0.7155, -0.7923,  0.1033],\n",
       "        [-2.5327, -0.6774, -0.8463,  1.7710, -0.4132],\n",
       "        [ 0.3207,  1.2214,  0.0914, -0.0824, -0.4139]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddfcab5-8162-486e-84d2-abc505267ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
