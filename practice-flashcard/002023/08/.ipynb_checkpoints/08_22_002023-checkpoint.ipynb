{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "906e199d-4d13-4d57-bed4-f9f4cf3bb5c0",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c9ec6d2-2ee1-41e0-a9ed-5b601525c966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfaae0b8-7712-4054-8ff8-6aefe5f4d8d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b9b37b9-1e01-4f11-8754-836b35c609f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WORKER_NAME = \"WORKER_{}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53998c3-2b9a-4905-9d45-b9298733603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelContext:\n",
    "    def init_rpc_workers(self, host, port):\n",
    "        rank = self.get_local_rank(ParallelMode.GLOBAL)\n",
    "        ranks_in_a_group = self.get_ranks_in_a_group(ParallelMode.GLOBAL)\n",
    "        \n",
    "        options = rpc.RpcBackendOptions()\n",
    "        \n",
    "        for _rank in ranks_in_a_group:\n",
    "            if _rank == rank:\n",
    "                continue\n",
    "            options.set_device_map(self.)\n",
    "        \n",
    "        rpc.init_rpc(\n",
    "            WORKER_NAME.format(rnak)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a3ede8-fb3b-4af9-a5ff-42d5331a46d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290277e2-ff7d-47bd-96ba-db5443bb0052",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptr = (int*)malloc(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da854cbe-c7d6-427b-866d-c6979ad3a788",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelContext:\n",
    "    def init_rpc_workers(self, host, port):\n",
    "        if self.pipeline_parallel_size > 1:\n",
    "            rank = self.get_global_rank()\n",
    "            options = rpc.RpcBackendOptions(\n",
    "                init_method= f\"tpc://{host}:{port}\"\n",
    "            )\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                ranks = self.get_ranks_in_group(ParallelMode.GLOBAL)\n",
    "                rpc_worker_map = {\n",
    "                    rank: WORKER_NAME.format(rank)\n",
    "                    for rank in ranks\n",
    "                }\n",
    "                \n",
    "                for _rank in ranks:\n",
    "                    if _rank == rank:\n",
    "                        continue\n",
    "                    options.set_device_map(rpc_worker_map[_rank], {rank: _rank})\n",
    "            \n",
    "            rpc.init_rpc(\n",
    "                name=WORKER_NAME.format(rank),\n",
    "                rank=rank,\n",
    "                world_size,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2342c3e4-7379-4fb0-83cb-669c82106c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recompute(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, phony, recomputed, function, input):\n",
    "        ctx.recomputed = recomputed\n",
    "        ctx.function = function\n",
    "        ctx.input = input\n",
    "        \n",
    "        return phony\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        function = ctx.function\n",
    "        input_leaf = ctx.input.detach().requires_grad_(\n",
    "            ctx.input.requires_grad\n",
    "        )\n",
    "        \n",
    "        with torch.enable_grad():\n",
    "            output = function(input_leaf)\n",
    "        \n",
    "        ctx.recompute.append((output, input_leaf))\n",
    "        return tuple([None, None, None, input_leaf.grad ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e207d43-72a4-4f2f-8224-b3885373e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "m+n-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40eb51a-5145-430d-b5dc-b2658fc27553",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: mapping\n",
    "step 2: extract\n",
    "step 3: create a placeholder tensor with the mapped value\n",
    "step 4: send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a56e90-cd88-45bd-bf58-f2ea48239f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8a58d0d-2732-49c4-9ef7-776c21ce4cbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Checkpoint(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, phony, recomputed, function, input):\n",
    "        ctx.recomputed = recomputed\n",
    "        with torch.no_grad():\n",
    "            output = function(input)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        output, input_leaf = ctx.recompute.pop()\n",
    "        with torch.enable_grad():\n",
    "            torch.autograd.backward(output, grad_input)\n",
    "        \n",
    "        return tuple([None, None, None, input_leaf.grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df8e57b-ba35-4fd4-8842-437e0a42bbec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50e0f60-84ff-4a67-b728-b506267e8284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_row_parallelism(inputs, weights):\n",
    "    inp_per_partition = inputs.shape[-1] // 2\n",
    "    w_per_partition = weights.shape[0] // 2\n",
    "    \n",
    "    x1, x2 = inputs[:, :inp_per_partition], inputs[:, inp_per_partition:]\n",
    "    w1, w2 = weights[:w_per_partition, :], w[w_per_partition:, :]\n",
    "    \n",
    "    out1 = x1 @ w1\n",
    "    out2 = x2 @ w2\n",
    "    \n",
    "    return out1 + out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f7e106-3b1f-4084-85dd-6c3bc0725d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: logit lens across accumulated residual stream\n",
    "step 2: logit lens across decomposed residual stream\n",
    "step 3: logit lens across decomposed attention layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc53e027-535e-48b1-bedb-4493e1e16033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformerConfig, HookedTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92df2622-f2c4-4cdb-80a8-71a7720c67d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = HookedTransformerConfig(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e90bc3-e90d-4f1e-b639-e4b80a626b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HookedTransformer(cfg=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f242cdb4-97f2-4333-8791-7edbeae9102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "handles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7e02ad-d7ab-47f8-8e56-f544943fe939",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hook_func in hooks:\n",
    "    model.ln_f.register_forward_pre_hook(hook_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99a033c-b3ac-45b5-9ecd-8e0592d88e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_func[1].remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc7cbc2-6a28-4160-a6a1-2802b8524473",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_cache = model.run_with_cache(clean_tokens)\n",
    "_, corrupted_cache = model.run_with_cache(corrupted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "648f2507-4990-4a25-8f3e-241456241888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_head(acts, hook, clean_cache, corrupted_cache, target_head):\n",
    "    trg_layer_idx, trg_head_idx = target_head\n",
    "    \n",
    "    if hook.layer() == trg_layer_idx:\n",
    "        acts[:, :, trg_head_idx] = corrupted_cache[hook.name][:, :, trg_head_idx]\n",
    "    else:\n",
    "        acts = corrupted_cache[hook.name]\n",
    "    \n",
    "    return acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06f84813-6213-41b6-9af6-cbd3b0a7eb9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7efd4c8d-380b-40f6-90ec-130039c0bdec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ebde5e-1ff3-4342-81a0-ada08cff013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = list(product(range(n_layers, n_heads)))\n",
    "results = torch.zeros(n_layers, n_heads)\n",
    "\n",
    "for layer_idx, head_idx in combinations:\n",
    "    model.reset_hooks()\n",
    "    hook_name = get_act_name(\"z\", layer_idx)\n",
    "    hook_func = partial(\n",
    "        patch_head,\n",
    "        clean_cache=clean_cache,\n",
    "        corrupted_cache=corrupted_cache,\n",
    "        target_head=(layer_idx, head_idx)\n",
    "    )\n",
    "    model.add_hook(hook_name, hook_func)\n",
    "    \n",
    "    patched_logits, _ = model.run_with_cache(clean_tokens)\n",
    "    results[layer_idx, head_idx] = compute_ioi_metric(patched_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ba376-1e86-4827-a09c-8be09349f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: convert input tokens to fourier basis\n",
    "step 2: do trig \n",
    "step 3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e1fe70-a771-4231-a06a-118ecb6dbdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_pos = model.W_pos\n",
    "\n",
    "torch.cosine_similarity(W_pos[:, 0], W_pos[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54da4d1a-5258-4fba-9d4f-be89ca9525c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "A@x@W_OV^{0}@W_OV^{1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6e8838b-2615-4a82-9a37-9e8cc7cab980",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0c987-5f0f-4707-b461-68789438971a",
   "metadata": {},
   "outputs": [],
   "source": [
    "induction_score = reduce(\n",
    "    induction_stripe,\n",
    "    \"n_heads seq_len -> seq_len\", reduction=\"mean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e25bc71d-7331-422c-b604-82c127af8d47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_model = 16\n",
    "d_head = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9aff5eb6-96b9-4549-987f-97cdb86efd23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W_V = torch.zeros(d_head, d_model)\n",
    "W_V[torch.arange(4), torch.arange(4)] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdbf19a9-d3e2-4958-a6d8-ce6f5d33a2d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ce75d23-6da9-444a-83f0-b91dac6e4379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W_O = torch.zeros(d_model, d_head)\n",
    "W_O[8:12, :] = torch.eye(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67c4d5de-d68b-43fe-a463-ce06ccc8f168",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5518407-e600-45a1-bb67-be96a6e00208",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_heads = 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11efacee-1d91-415e-a15b-213094fdcb1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = {\n",
    "    \"Q\": torch.zeros(n_heads, n_heads),\n",
    "    \"K\": torch.zeros(n_heads, n_heads),\n",
    "    \"V\": torch.zeros(n_heads, n_heads)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f6d0650-0286-45ff-9f75-b9807cadce45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_composition_score(W_A, W_B):\n",
    "    W_AB_norm = (W_A @ W_B).pow(2).sum()\n",
    "    W_A_norm = W_A.pow(2).sum()\n",
    "    W_B_norm = W_B.pow(2).sum()\n",
    "    \n",
    "    return W_AB_norm / (W_A_norm * W_B_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f7dea78-f161-4bb3-96de-626ad59ea87c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7067e78-1c34-416f-9246-4ed428361d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_O = model.W_O\n",
    "W_V = model.W_V\n",
    "\n",
    "W_Q = model.W_Q\n",
    "W_K = model.W_K\n",
    "\n",
    "W_OV = W_V @ W_O\n",
    "W_QK = W_Q @ rea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb2b873-69d2-409c-bc4a-504cb4ca270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_heads):\n",
    "    for j in range(n_heads):\n",
    "        scores[\"Q\"][i, j] = compute_composition_score(\n",
    "            \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14cd7b6-c41d-424b-a0b4-a825d59ab318",
   "metadata": {},
   "source": [
    "step 1: duplication head detects duplicated tokens, and write that information to the duplicated token\n",
    "step 2: s-inhibition head move that information to end token\n",
    "step 3:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1850b665-5ca2-447f-a858-36d4e86a0c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: resid @ W_U\n",
    "step 2: resid = embed + unembed + sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab13133-0ef2-4809-a670-89f3fc633273",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\n",
    "    \"Q\": torch.zeros(n_heads, n_heads),\n",
    "    \"K\": torch.zeros(n_heads, n_heads),\n",
    "    \"V\": torch.zeros(n_heads, n_heads)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "082d6dcf-2e28-4877-913f-5011a7a5299b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_composition_score(W_A, W_B):\n",
    "    W_AB_norm = (W_A @ W_B).pow(2).sum()\n",
    "    W_A_norm = W_A.pow(2).sum()\n",
    "    W_B_norm = W_B.pow(2).sum()\n",
    "    \n",
    "    return W_AB_norm/(W_A_norm*W_B_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9008a8e7-d15b-4c8a-a2f2-44b6c55c29c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a839e8eb-7058-4088-958a-3bb76baa42d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_O = model.W_O\n",
    "W_V = model.W_V\n",
    "W_Q = model.W_Q\n",
    "W_K = model.W_K\n",
    "\n",
    "W_OV = W_V @ W_O\n",
    "W_QK = W_Q @ rearrange(\n",
    "    W_K, \"... d_model d_head -> ... d_head d_model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69887c2-6670-4a10-a641-8d51afb57598",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_heads):\n",
    "    for j in range(n_heads):\n",
    "        scores[\"Q\"][i, j] = compute_composition_score(\n",
    "            W_OV[0, i],\n",
    "            W_QK[1, j]\n",
    "        )\n",
    "        scores[\"K\"][i, j] = compute_composition_score(\n",
    "            W_OV[0, i],\n",
    "            W_QK[1, j].T\n",
    "        )\n",
    "        scores[\"V\"][i, j] = compute_composition_score(\n",
    "            W_OV[0, i],\n",
    "            W_OV[1, j]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c285cc86-064b-4263-b74a-8758164d99e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12a7d71-7077-43fc-86aa-b0dea4003377",
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulated_resid = model.accumulated_resid(layer=-1, pos_slice=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f772820-5835-43de-8c13-ced675fb1c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logit_diff(resid, model, answer_tokens):\n",
    "    W_U = model.W_U\n",
    "    correct_tokens, incorrect_tokens = answer_tokens.unbind(dim=0)\n",
    "    return resid @ (W_U[:, correct_tokens] - W_U[:, incorrect_tokens ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a049c8-16fd-4817-ba93-9c5954fc8044",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E @ W_Q @ W_K @ W_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5a174a-f679-442f-91f1-d01f39aa0468",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(Attn(x @ W_E)) @ W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e36c93-d6c3-4d07-8a48-0eb49c88e806",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_2 @ W_E @ W_Q @ W_K @ W_E @ [v_0, v_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9b3b20-66fe-4842-9ded-13dcce079cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_row_parallelism(inputs, weights):\n",
    "    w_per_partition = weights.shape[0] // 2\n",
    "    inp_per_partition = inputs.shape[-1] // 2\n",
    "    \n",
    "    inp1, inp2 = inputs[:, :inp_per_partition], inputs[:, inp_per_partition:]\n",
    "    w1, w2 = weights[:, :w_per_partition], weights[:, w_per_partition:]\n",
    "    \n",
    "    out1 = inp1 @ w1\n",
    "    out2 = inp2 @ w2\n",
    "    \n",
    "    return out1 + out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f22d31b1-64fd-432c-939d-55a4c4c59065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99061a91-4ac8-441d-b193-0a5acf72a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParallelContext:\n",
    "    def init_rpc_workers(self, host, port):\n",
    "        if self.pipeline_parallel_size > 1:\n",
    "            rank = self.parallel_context.get_global_rank()\n",
    "            ranks = self.parallel_context.get_ranks_in_group(ParallelMode.GLOBAL)\n",
    "            world_size = self.parallel_context.get_local_world_size(ParallelMode.GLOBAL)\n",
    "            \n",
    "            options = rpc.TensorPipeRpcBackendOptions(\n",
    "                init_method=f\"tcp://{host}:{port}\"\n",
    "            )\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                device_maps = {\n",
    "                    rank: WORKER_NAME.format(rank)\n",
    "                    for rank in ranks\n",
    "                }\n",
    "                \n",
    "                for _rank in ranks:\n",
    "                    if _rank == rank:\n",
    "                        continue\n",
    "                    \n",
    "                    options.set_device_map(\n",
    "                        WORKER_NAME.format(_rank), {rank: _rank}\n",
    "                    )\n",
    "            \n",
    "            rpc.init_rpc(\n",
    "                name=WORKER_NAME.format(),\n",
    "                rank=rank,\n",
    "                world_size=world_size,\n",
    "                rpc_backend_options=options\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2893551d-77e8-4de4-9791-80cd0e5ac02e",
   "metadata": {},
   "source": [
    "global distributed group, tensor parallel group, pipeline parallel group, data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd55038-f54e-4a77-b233-7fb32a07e3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "min(clock_idx+1, n_partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a18c8fe-3f6e-4002-8d63-3dae18038067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_column_parallelism(inputs, weights):\n",
    "    per_partition = weights.shape[-1] // 2\n",
    "    w1, w2 = weights[:, :per_partition], weights[:, per_partition:]\n",
    "    out1 = inputs @ w1\n",
    "    out2 = inputs @ w2\n",
    "    \n",
    "    return torch.cat([out1, out2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2974e683-d32c-490d-88e7-9e72775adcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter, all-reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556836e9-65a1-45ff-9f98-9883e3156e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "forward(x) > output = forward(x) -> backward(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50734606-01b7-436e-bc78-52fbe0609b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: determine global rank\n",
    "step 2: initialize global distributed group\n",
    "step 3: initialize parallel groups\n",
    "step 4: set device\n",
    "step 5: set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bba6524-6eff-4ac6-9705-277bdb1a85ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "two uncertainty principles\n",
    "quantization of action, quantization of angular momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cdb40ac-be4e-4694-a36c-d6072586cd15",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.distributed.rpc import RRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e89a5bb-e9b6-44db-838a-bf1581c62196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.id = RRef(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683bd394-5066-4db7-8990-df2c5caab55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_rref.rpc_sync().init() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e423ba06-ce82-4f92-aed0-cbf818098446",
   "metadata": {},
   "outputs": [],
   "source": [
    "neural plasticity, reliable recording, biocompa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e119f1bb-707b-40e8-84a3-80b074f058da",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: record\n",
    "step 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a99b10f-cf0b-4a7a-a6b1-2dba651813b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_reward(states, actions) + gamma*value_function(states+1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb605cc-d912-4879-bd14-54bd2080d120",
   "metadata": {},
   "outputs": [],
   "source": [
    "discover\n",
    "search space\n",
    "inductive bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "790af9c0-2904-4019-bd3e-a71406019a02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compress_gradient(grad, other_tensor_shape):\n",
    "    \"\"\"\n",
    "        Returns the gradient but compressed (needed when gradient shape mismatch during reverse mode).\n",
    "\n",
    "        Paramaters:\n",
    "        - grad: gradient.\n",
    "        - other_tensor_shape: shape of target tensor.\n",
    "    \"\"\"\n",
    "    ndims_added = grad.ndim - len(other_tensor_shape)\n",
    "    for _ in range(ndims_added): \n",
    "        grad = grad.sum(axis=0)         \n",
    "    for i, dim in enumerate(other_tensor_shape):\n",
    "        if dim == 1: \n",
    "            grad = grad.sum(axis=i, keepdims=True) \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eebe7591-4a38-4742-86ee-25fe89e7c5ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "427aa450-3ac5-4215-9c64-2185c5d68045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grad = np.array([[1., 2., 3.], [4., 5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2215d35f-e313-4d1f-993b-0a9b668232d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5., 7., 9.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compress_gradient(grad, (2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24202ce0-85e3-4dd6-8424-647319cce0f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compress_gradient(grad, (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd816258-6989-4de6-b4d9-57b6c9e6d796",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
