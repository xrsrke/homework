{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab3ad91-7760-414a-9705-ea00aaa5b8ab",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28b1658-55b7-44f6-aa01-8554ba0d2af9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d601926-90c0-4372-ad3d-14ac9f7514ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: initialize global dist group\n",
    "step 2: initialize parallel groups\n",
    "ste 3: set device\n",
    "step 4: seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070d7d22-a3b2-4085-9e81-b3b0a7a73639",
   "metadata": {},
   "outputs": [],
   "source": [
    "global, tensor, pipeline, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01b753d-c557-4575-b228-64f0e98decb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_rank, local_world_size, ProcessGroup, ranks_in_a_grouop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5027a271-4cea-4afa-b5fc-a922b57a993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: determine a list of global ranks in that group\n",
    "step 2: if the process's global rank in that list\n",
    "step 3: initialize a parallel group\n",
    "step 4: local rank\n",
    "step 5: save variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4c888d-889e-4cb3-874b-d5a15e776da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding, linear, attention, layer norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce31c500-55ac-4e98-8b3d-af9e89711bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: determine global rank\n",
    "step 2: resize vocab embedding\n",
    "step 3: parallelize linear, attention, layer norm, embedding\n",
    "step 4: resize lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f64110f-36f0-492c-aa77-dad7d0a2e555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include std;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab7a011-f922-4caf-9a88-5d0dc71cc1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "api server, scheduler, ectd, control manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950aafaf-e2a1-45fc-b775-85650d0592aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x@W_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc612773-fc19-4275-a0f6-6ca4f5c6e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "h, range, percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dff7028-5ffc-46aa-8ea4-bcbc36d77306",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: output_layer_2 = (embed + pos_embed) + layer_1 + layer_2\n",
    "step 2: layer_1 = head00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d23e776-16b1-435f-999c-77406622e01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becb0b1b-0825-4d07-8f53-fded73aa5687",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_name = f\"blocks.{layer_idx}.mlp.hook_post\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460bf3c-c1e5-4319-9247-e6735db8494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43511ced-1527-47be-a2c7-b4c5674692c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_activations = cache[hook_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d40dc1-317a-4a75-a57d-efe02946f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_activations = mlp_activations[:, :, neuron_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b4e8a2-e6e8-465b-be95-e7b34a0ff9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.argmax(neuron_activations, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fed9851-3185-462e-8162-015a2796d4f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29ac1ad-3363-44c9-bf32-b3cb70b6b20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "induction_score = reduce(\n",
    "    induction_stripe,\n",
    "    \"head_idx seq_len -> head_idx\",\n",
    "    reduction=\"mean\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4e1b9-5299-4c83-b41e-4f433240e111",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: patch value vector\n",
    "step 2: attention pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4a598a-578d-4adb-9814-91ac0372d877",
   "metadata": {},
   "source": [
    "output_2 = (embed + pos_embed) + output_1 + output_2\n",
    "output1 = head01 + head02 + mlp0\n",
    "output2 = head10 + head12 + mlp1\n",
    "\n",
    "output_2 = embed + pos_embed + head01 + head02 + mlp0 + head10 + head12 + mlp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685f9e0c-d73a-46bb-a454-4e693b51fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_out[i, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93de16b8-3e3f-46f8-a9d1-eeae6f5371f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50b68db7-670c-4cc4-968f-d065d9c3e5b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StartDependency(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        phony = torch.zeros(1)\n",
    "        return input, phony\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input, grad_phony):\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "487dd28c-6fb8-4716-b0c0-d8e512c4585b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EndDependency(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, phony):\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        return grad_input, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd7f17f3-e525-4460-b198-5d5f7bab97da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dependency(start_batch, end_batch):\n",
    "    start_batch, phony = StartDependency.apply(start_batch)\n",
    "    end_batch = EndDependency.apply(start_batch)\n",
    "    return start_batch, end_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600c9265-dcfc-4cc2-87ca-bfe898f87ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Forward(x) > output = Forward(x) > Backward(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f9cb7a-9dcb-4a15-98ef-801195ab5fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model.run_with_logits(past_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40348e2-2b7d-4590-b82d-25b6fbdfcab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = F.log_softmax(logits[:, -1, :], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4767ab-d49d-42bd-b2ff-8cc701cd1792",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(Attn(x@W_E))@W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719822e6-2f57-4e81-a939-355072bf8c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchstate, elasticdriver, 3 notification mechanism, discoveryscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a0b51e-1e55-4ef2-9a4f-616cc8a560f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da8057a-d747-4188-8706-9545092865ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParameterSharding:\n",
    "    def __init__(self, param_groups, parallel_context):\n",
    "        self.param_groups = param_groups\n",
    "        self.parallel_context = parallel_context\n",
    "    \n",
    "    def shard(self):\n",
    "        world_size = self.parallel_context.get_world_size()\n",
    "        sharded_params = [[] for _ in range(world_size)]\n",
    "        sizes = [0 for _ in range(world_size)]\n",
    "        \n",
    "        for param_group in self.param_groups:\n",
    "            param_lists = [[] for _ in range(world_size)]\n",
    "            for param in param_groups[\"params\"]:\n",
    "                next_rank = sizes.index(min(sizes))\n",
    "                param_lists[next_rank].append(next_rank)\n",
    "                sizes[next_rank] += param.numel()\n",
    "            \n",
    "            for rank, params in enumerate(param_lists):\n",
    "                param_group_rank = copy.copy(param_groups)\n",
    "                param_group_rank[\"params\"] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862fdbf2-c62b-42aa-88df-9671e4e7d369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_storage(x):\n",
    "    if x.storage.size() > 0:\n",
    "        x.storage._resize(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111dfa8e-b8a6-43cb-aa89-88f772653dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "void addVector(int* a, int* b, int* c, int total_elements) {\n",
    "    int gid = (blockIdx.x * blockDim.x) + threadIdx.x\n",
    "    \n",
    "    if (gid < total_ele)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e42b7d0-9a7f-4400-9a24-a09f344c342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready > running > blocked > terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577cd492-53f9-4ae6-acaf-964e4326868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: normalize the loss using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da9edcc-199b-4f9c-8469-76553e1c9f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "local v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d326114f-b432-4e4c-888a-9ef0ab9f258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: logit_difference = W_U[0] - W_U[1]\n",
    "step 2: approximate layernorm\n",
    "step 3: backward transformation\n",
    "step 4: project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08de2faa-1980-4df5-878b-c21cd51ea084",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a800cd-5a74-48a7-be05-9fdf678be215",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95cea26-7493-4ae4-a3be-8630af2f63af",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22b5d0c-e197-411e-982d-f7fa343987fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_components = torch.tensor([\n",
    "    cache[\"embed\"],\n",
    "    cache[\"pos_embed\"],\n",
    "    cache[\"result\", prev_layer_idx]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47d3c1b-03ea-470a-a393-bf7af7b0bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Q = model.W_Q[next_layer_idx, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c7f3b26-797a-4f66-856f-6c468a2c1e3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d2a27e-ebb2-4795-a14f-b0d2de31f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_components = einsum(\n",
    "    input_components,\n",
    "    W_Q,\n",
    "    \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d570388-52da-413a-963a-93cb3d806bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_contributions = query_components.pow(2).sum(dim=-1 ).sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f919ab-4ee9-4c20-8e3a-429e8def6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d residual stream = d linearly independent basis vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869dacc5-1c3f-4b8b-a287-7f9c3383293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: record the interdimate activations\n",
    "step 2: spot induction head\n",
    "step 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c2115b-c9b6-4ee6-b684-749fa0dc4b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3029ff-4b76-438a-9a30-960d54b7a004",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = x @ W_Q\n",
    "\n",
    "x = embed + pos_embed + sum(12 heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c1b1cb-7814-4a28-8b80-7c750ebca5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a14e1c2-9314-4c53-a8d6-8ef07c85e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb88cb6-feed-468f-9f68-0673c84510d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_components = torch.tensor([\n",
    "    cache[\"embed\"],\n",
    "    cache[\"pos_emed\"],\n",
    "    cache[\"result\", 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b4de2d-e938-4d63-84cd-065ab507a01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Q = model.W_Q[layer_idx, head_idx]\n",
    "query_components = einsum(\n",
    "    input_components,\n",
    "    W_Q\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7358bd2a-0209-4319-8fba-2b2e4267096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_K = model.W_K[layer_idx, head_idx]\n",
    "key_components = einsum(\n",
    "    input_components,\n",
    "    W_K\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbb38ff-cf13-4088-81ea-accae71b7b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposed_scores = einsum(\n",
    "    query_components,\n",
    "    key_components,\n",
    "    \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d83180f3-acba-4406-b02e-2cc336fa2466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def intervene_resid(resid, hook, feature, scale):\n",
    "    feature /= feature.norm(dim=-1)\n",
    "    projection = resid[:, position] @ feature\n",
    "    resid[:, position] -= scale * projection * feature\n",
    "    return resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc6d7d2-bf1a-42d8-a6c0-565e0e495f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_func = intervene_resid(\n",
    "    feature=target_feature\n",
    "    scale=scale_factor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ccc6e0c-99bb-464e-8909-4ae53de43afe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f3308-9014-4291-9483-e897f250701c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_name = get_act_name(\"resid_pre\", layer_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbadd75-2001-4b4d-89dc-10aa1dcd1f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, patched_logits = model.run_with_hooks(\n",
    "    past_moves,\n",
    "    fwd_hooks=[(hook_name, hook_func)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707d1155-d3e8-45ed-9bcc-0ddbae210e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = F.log_softmax(patched_logits[:, -1, :], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bd76f8-4aba-459e-9d3e-12f4c7d0f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(\n",
    "    board_history\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b4730da-0ab2-4cf6-b2f0-108862183f23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, neuron_idx = 5, 1393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "801cc520-e771-455f-ab05-b33e998e2a3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hook_name = get_act_name(\"mlp_post\", layer_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "614fe914-e44b-40b9-9c25-d94fa0fb2ebc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blocks.5.mlp.hook_post'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hook_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af6cbc1-be43-44a5-8489-4cf5caa70674",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_activations = cache[hook_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e77c4ce-c04c-42f3-86a5-65f51c70b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_activations = mlp_activations[:, neuron_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c92360-f477-44ee-8da4-756296780c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "threashold = neuron_activations.quantile(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0de5df-252c-43e1-9797-70742243f402",
   "metadata": {},
   "outputs": [],
   "source": [
    "move_idxs = neuron_activations > threashold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba06dbd-54b8-451b-a4ec-f494318280cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(board_states == 2)[moves_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e8ae5-d1df-4efd-bf7a-2cb17654047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: record all the interdimate activations\n",
    "step 2: analyze attention patterns\n",
    "step 3: spot induction head patterns, if yes, dig further\n",
    "step 4: decompose the attention scores of the induction heads\n",
    "step 5: identify pair q-k that product the induction charactersitc\n",
    "step 6: trace backward\n",
    "step 7: construct the full circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c74008-b1a6-48b0-bb8b-f76e791a3514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_scores(image_embedding, text_embedding):\n",
    "    image_embedding = image_embedding / image_embedding.norm(dim=-1)\n",
    "    text_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96948f3-660a-439e-a17d-d8e73d4b9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = attn_weights.diagonal(dim1=-2, dim2=-1, offset=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556d227a-8d1e-428a-8ab0-4a51515dacdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParameterSharding:\n",
    "    def __init__(self, param_groups, parallel_context):\n",
    "        self.param_groups = param_groups\n",
    "        self.parallel_context = parallel_context\n",
    "    \n",
    "    def shard(self):\n",
    "        world_size = self.parallel_context.get_world_size()\n",
    "        \n",
    "        sizes = [0 for _ in range(world_size)]\n",
    "        \n",
    "        for param_group in param_groups:\n",
    "            param_lists = [[] for _ in range(world_size)]\n",
    "            \n",
    "            for param in param_group[\"params\"]:\n",
    "                next_rank = sizes.index(min(sizes))\n",
    "                param_lists[next_rank].append(param)\n",
    "                sizes[next_rank] += param.numel()\n",
    "            \n",
    "            for rank, params in enumerate(param_lists):\n",
    "                param_group_rank = copy.copy(param_groups)\n",
    "                param_group_rank[\"params\"] = params\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61d7dd4a-031d-4a2a-bd3c-1d3333727e44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def probability_scores(image_embedding, text_embedding):\n",
    "    image_norm = image_embedding.norm(dim=-1, keepdim=True)\n",
    "    image_embedding /= image_norm\n",
    "    \n",
    "    text_norm = text_embedding.norm(dim=-1, keepdim=True)\n",
    "    text_embedding /= text_embedding\n",
    "    \n",
    "    probs = F.softmax(\n",
    "        image_embedding @ text_embedding.T,\n",
    "        dim=-1\n",
    "    )\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c00d0ce-f2b4-4f05-a5a6-e2bff0c87ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = x.mean(dim=-1, keepdim=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
