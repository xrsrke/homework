{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d9aaf8a-f24e-43b8-89e8-2ee53adbfebb",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "116d7cd4-042e-4e15-a711-47651e0f70ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24de411f-7db0-43d6-9940-f1522e604d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: split a micro-batch\n",
    "step 2: create cuda stream\n",
    "step 3: pipe\n",
    "step 4: gather the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d2d3c5-d658-4d8b-8611-9274b718dc34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a5170c-ed20-4572-99e1-aedc19b65a03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Reduce(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, parallel_context):\n",
    "        group = parallel_context.get_group(ParallelModel.TENSOR)\n",
    "        return dist.all_reduce(input, group=group)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        return (grad_input, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd84c41a-98c1-4843-be05-2d7485c18201",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParallelEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, parallel_context):\n",
    "        super().__init__()\n",
    "        world_size = parallel_context.get_world_size(ParallelMode.TENSOR)\n",
    "        \n",
    "        num_embeddings_per_partition = num_embeddings // world_size\n",
    "        self.vocab_start_idx, self.vocab_end_idx = self._get_vocab_range(\n",
    "            num_embeddings_per_partition,\n",
    "            parallel_context\n",
    "        )\n",
    "        self.weight = nn.Parameter(torch.randn(\n",
    "            num_embeddings_per_partition,\n",
    "            embedding_dim\n",
    "        ))\n",
    "    \n",
    "    def _get_vocab_range(self, num_embeddings_per_partition, parallel_context):\n",
    "        rank = parallel_context.get_local_rank(ParallelMode.TENSOR)\n",
    "        start_idx = rank*num_embeddings_per_partition\n",
    "        end_idx = start_idx+num_embeddings_per_partition\n",
    "        return start_idx, end_idx\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_mask = (input < self.vocab_start_idx) | (input >= self.vocab_end_idx)\n",
    "        masked_input = input.clone() - self.vocab_start_idx\n",
    "        masked_input[input_mask] = 0\n",
    "        \n",
    "        parallel_embedding = F.embedding(masked_input, self.weight)\n",
    "        parallel_embedding[input_mask, :] = 0.\n",
    "        \n",
    "        embeddings = Reduce.apply(parallel_embeddings, parallel_context)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdacc583-8a20-40db-932d-6056261face4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Copy(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, prev_stream, next_stream, input):\n",
    "        ctx.prev_stream = prev_stream\n",
    "        ctx.next_stream = next_stream\n",
    "        \n",
    "        compute_stream = torch.cuda.default_stream(next_stream.device)\n",
    "        \n",
    "        with torch.cuda.stream(prev_stream), torch.cuda.stream(next_stream):\n",
    "            moved_input = input.to(next_stream.device)\n",
    "            input.record_stream(prev_stream)\n",
    "            moved_input.record_stream(next_stream)\n",
    "        \n",
    "        return moved_input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        prev_stream = ctx.prev_stream\n",
    "        next_stream = ctx.next_stream\n",
    "        \n",
    "        compute_stream = torch.cuda.default_stream(prev_stream.device)\n",
    "        \n",
    "        with torch.cuda.stream(prev_stream), torch.cuda.stream(next_stream):\n",
    "            moved_grad = grad_input.to(prev_stream.device)\n",
    "            \n",
    "            grad_input.record_stream(next_stream)\n",
    "            moved_grad.record_stream(prev_stream)\n",
    "        \n",
    "        return moved_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07217bc-dca8-40b7-ad96-98199a4d9832",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4eca096-781a-4325-92b7-5a6b1769f188",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, head_idx = 0, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40620428-3fb5-4284-a718-ffd374e19307",
   "metadata": {},
   "outputs": [],
   "source": [
    "head_output = cache[\"z\", layer_idx][:, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c8f786-a262-44a2-82f9-6a0d5ecb5d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = head_output @ cache.W_O[layer_idx, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db2a538-210c-4ba0-9934-93cf5cab8470",
   "metadata": {},
   "outputs": [],
   "source": [
    "handles = []\n",
    "for hook_func in hooks:\n",
    "    handles.append(model.ln_f.register_forward_pre_hook(hook_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5928e-e201-41dd-ab81-ab2d1820e8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d922453-8573-40e6-87f6-ec4b46bba68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0198cb0a-4b1a-4767-9211-5146ef9c4012",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, neuron_idx = 3, 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28bda980-91bf-4c85-90e9-f6b29dece6d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hook_name = f\"blocks.{layer_idx}.mlp.hook_post\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9afe7b14-e51f-4677-b0f0-39bb62289dbb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blocks.3.mlp.hook_post'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hook_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd5472a-27f7-4fa3-a981-23ec56d60788",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = cache[hook_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b630c3-656c-4b36-8485-194527b5fe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.argmax(neurons, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef297b96-da7e-4002-8826-760c79ef5b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim, shape, dtype, requires_grad, type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d55471-7320-44ca-9a90-ff14368900e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.layer_norm(input, normalized_shape=(5,), weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683319b5-5704-4131-a6f7-2704acce11d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "process,\n",
    "node enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfc9e84-3aca-482e-b4d4-b0ebfb2efa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: mask targets\n",
    "step 2: predicted logits\n",
    "step 3: sum predicted logits\n",
    "step 4: calculate log\n",
    "step 5: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc2a50f-0426-43ac-9bfd-3e4e4b8720fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_cache = model.run_with_cache(clean_tokens)\n",
    "_, corrupted_cache = model.run_with_cache(corrupted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4300114d-928e-46b0-a77d-45c7ef105a09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_head(acts, hook, clean_cache, corrupted_cache, target_head):\n",
    "    target_layer_idx, target_head_idx = target_head\n",
    "    \n",
    "    if target_layer_idx == hook.layer():\n",
    "        acts[:, target_head_idx] = corrupted_cache[hook.name][:, target_head_idx]\n",
    "    else:\n",
    "        acts = clean_cache[hook.name]\n",
    "    return acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ed614ae-6228-4ef7-a7b7-c8ce7dd65d8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5ac0c4-af0f-4908-bbe6-5d0d37272b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = product(range(n_layers), range(n_heads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49b73dd6-0823-4af5-84a1-5556b2defb1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4682ee9-a9fd-422b-aed6-699193a8a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resid2logits(cache):\n",
    "    hook_name = get_act_name(\"resid_post\", -1)\n",
    "    resid = cache[hook_name][:, -1, :]\n",
    "    return model.unembed(model.ln_final(resid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bd42b2-488f-4ba0-ae40-02f8dc5657bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.zeros(n_layers, n_heads)\n",
    "\n",
    "for layer_idx, head_idx in combinations:\n",
    "    hook_name = get_act_name(\"z\", layer_idx)\n",
    "    hook_func = partial(\n",
    "        patch_head,\n",
    "        clean_cache=clean_cache,\n",
    "        corrupted_cache=corrupted_cache,\n",
    "        target_head=(layer_idx, head_idx)\n",
    "    )\n",
    "    \n",
    "    _, cache = model.run_with_cache(\n",
    "        clean_tokens,\n",
    "        fwd_hooks=[(hook_name, hook_func)]\n",
    "    )\n",
    "    patched_logits = resid2logits(cache)\n",
    "    results[layer_idx][head_idx] = compute_ioi_metric(patched_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e031a2-e47e-484a-aa4e-61be60a55b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(board_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92ac44dc-6125-4278-b075-7c56e0ca7b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, head_idx = 5, 1393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7e5421-acc6-47b0-8d80-23a1372486b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_neurons = cache[\"out\", layer_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928ed440-f124-4963-96a7-9375dfde776e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d89a3c-2381-4fa3-9a4a-251315078992",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank*partition_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c201fe92-dca5-4530-91f4-44326471a7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape, dim, requires_grad, dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800da2db-59cc-402a-844c-286ed1969c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock cycle 1: B(m, n)\n",
    "clock cycle 2: B(m-1, n), B(m, n-1)\n",
    "clock cycle 3: B(m-2, n), B(m-1, n-1), B(m, n-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd351f8e-cfb9-487e-814d-48d6dab15c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "{x: y**2 for x, y in simple_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac0b75a-a1ac-4e20-bf91-832f3b5648a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape, dtype, requires_grad, dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed8054c-61df-4b23-ab12-1e80a595f942",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(board_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d8fcce-585e-4502-b384-878a459ce752",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_neurons = cache[hook_name, layer_idx][:, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a73d6-1db2-4d06-9657-aa2480d9dcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "thre = mlp_neurons.quantile(0.99)\n",
    "top_neurons = mlp_neurons > thre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018587cb-d074-4fa1-83cc-2dd757e1f6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "(board_states == 1)[top_neurons].float().mean(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677c644c-ce39-4016-a497-98a66c72c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E\n",
    "W_Q = model.W_Q[1, 4]\n",
    "W_K = model.W_K[1, 4]\n",
    "W_O = model.W_O[0, 7]\n",
    "W_V = model.W_V[0, 7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681355f3-93e2-4878-b0c4-1817c0d3de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = W_E @ W_Q\n",
    "K = W_E @ W_V @ W_O @ W_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11263bae-1651-46cb-b4be-321aed2b3f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)\n",
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca13ce9-6b76-45f0-891f-8bdc67a45934",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_prob = cache[\"attn\", 9][:, 9][:, -1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c492e9-65a8-47cb-80b0-dc5a09bbaebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_pos = model.W_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520e4a5c-4a13-4e75-824c-0a171536a7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cosine_similarity(W_pos[:, 0], W_pos[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bd2551-5543-49cc-8656-68af84d43565",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: convert input tokens to fourier basis\n",
    "step 2: trig identities -> addition\n",
    "step 3: convert the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3addf24b-04a9-4b8f-8475-578394db76c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_O = model.W_Q[0, 1]\n",
    "W_V = model.W_V[0, 1]\n",
    "W_Q = model.W_Q[1, 2]\n",
    "W_K = model.W_K[1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4fc7e2-8715-4fc9-b598-5d9b86991d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_OV = W_O @ W_V\n",
    "W_QK = W_Q @ W_K.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fc55ad-4407-48eb-8a41-ce6266b6e667",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {\n",
    "    \"Q\": torch.zeros(n_heads, n_heads),\n",
    "    \"K\": torch.zeros(n_heads, n_heads),\n",
    "    \"V\": torch.zeros(n_heads, n_heads)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eaea73d5-d09c-46e8-a1e2-c26fb7d0f5ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_composition_score(W_A, W_B):\n",
    "    W_AB_norm = (W_A@W_B).pow(2).sum()\n",
    "    W_A_norm = W_A.pow(2).sum()\n",
    "    W_B_norm = W_B.pow(2).sum()\n",
    "    return W_AB_norm/(W_A_norm*W_B_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "612b73ed-b87c-45a3-9eaa-742e980ee459",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede42c0e-5e54-40a2-ad71-d09839571e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_O = model.W_O\n",
    "W_V = model.W_V\n",
    "W_Q = model.W_Q\n",
    "W_K = model.W_K\n",
    "\n",
    "W_OV = W_V @ W_O\n",
    "W_QK = W_Q @ rearrange(\n",
    "    W_K, \"... d_head d_model -> ... d_model d_head\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81571738-0276-4a27-818c-106c997149c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_heads):\n",
    "    for j in range(n_heads):\n",
    "        scores[\"Q\"] = compute_composition_score(\n",
    "            W_OV[0, i],\n",
    "            W_QK[1, j]\n",
    "        )\n",
    "        scores[\"K\"] = compute_composition_score(W_OV[0, i], W_QK[1, j].T)\n",
    "        scores[\"V\"] = compute_composition_score(W_OV[0, i], W_OV[1, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897ea933-057a-481f-88fc-0291f365f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E@W_OV^{0, 7}@W_QK^{1, 4}@W_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b533011-5dfc-41a1-9edd-53ba23adb9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(past_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe59cd9e-61a9-49de-a242-bb7de268918c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_neurons = cache[hook_name].std(dim=[0, 1]).argsort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dff8fa2a-2f24-4d18-b26a-6ba50b63ab1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "361492cf-e790-4ae2-8124-335feb20978c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_consine_similarity(neuron_idx, feature):\n",
    "    W_out = model.W_out[layer_idx, neuron_idx]\n",
    "    W_out /= W_out.norm(dim=-1)\n",
    "    \n",
    "    feature /= feature.norm(dim=-1)\n",
    "    \n",
    "    return einsum(\n",
    "        W_out, feature\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99be1470-637c-459c-94ee-858c46d3b17b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "heatmap_blank = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ee73dc-75c7-491d-b36e-03659d15082f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for neuron_idx in top_neurons:\n",
    "    heatmap_blank.append(compute_consine_similarity(\n",
    "        neuron_idx, blank_dir\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb19e778-0dbc-4789-bbf1-d15ddb0095ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_O = model.W_O[0, 1]\n",
    "W_V = model.W_V[0, 1]\n",
    "W_Q = model.W_Q[1, 2]\n",
    "W_K = model.W_K[1, 2]\n",
    "\n",
    "W_OV = W_V @ W_O\n",
    "W_QK = W_Q @ W_K.permute(-2, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785949af-d48a-4fdb-9a09-106909463b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_similarities = text_embedding @ text_embedding.T\n",
    "image_similarities = image_embeding @ image_emebdding.T\n",
    "\n",
    "\n",
    "targets = F.softmax(\n",
    "    (text_similarities+image_similarities)/(2*temperature),\n",
    "    dim=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9467538-7c4d-496b-be29-9ea5005c8747",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, mom, eps):\n",
    "        super().__init__()\n",
    "        self.mom, self.eps = eps\n",
    "        self.adds = nn.Parameter(torch.zeros(1))\n",
    "        self.mults = nn.Parameter(torch.ones(1))\n",
    "        self.register_buffer(\"mean\", torch.zeros(1))\n",
    "        self.register_buffer(\"var\", torch.ones(1))\n",
    "    \n",
    "    def update_stats(self, x):\n",
    "        mean = x.mean(dim=0, keepdim=True)\n",
    "        var = x.var(dim=0, keepdim=True)\n",
    "        \n",
    "        self.mean.lerp_(mean, self.mom)\n",
    "        self.var.lerp_(var, self.mom)\n",
    "        return mean, var\n",
    "    \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            mean, var = self.update_stats(x)\n",
    "        \n",
    "        x = (x-mean)/(var+self.eps)\n",
    "        x = self.adds + self.mults*x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455f3325-7e83-42e4-8c18-088d18a52fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74e17da-c1fb-4caa-880f-094bb213d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E\n",
    "W_O = model.W_O[layer_idx, head_idx]\n",
    "W_V = model.W_V[layer_idx, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23a84cc2-b8aa-47eb-9561-5db99832b1b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens import FactoredMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0046356-1eaf-4b4a-bdce-bbeaf15a1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "OV_circuit = FactoredMatrix(W_V, W_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e674f3aa-74f1-475b-bfcf-3777b45d9ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_OV_circuit = W_E @ OV_circuit @ W_E.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf487eb1-52b0-4473-8781-46c7b593c87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualLayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, dropout):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767d1606-cafc-485b-a571-9b85bca1376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: determine global rank\n",
    "step 2: initialize global dist group\n",
    "step 3: initialize parallel groups\n",
    "step 4: set device\n",
    "step 5: set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1d769d-b56f-440e-bb10-c96f6c411ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: mask targets\n",
    "step 2: compute predicted logits\n",
    "step 3: all-reduce\n",
    "step 4: calculate log(sum(exp(logits)))\n",
    "step 5: calculate the loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9eae182a-2d38-4b0e-924a-f4ed929efde4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d_model = 16\n",
    "d_head = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92313e18-2705-40bf-87ef-c14d3e5b6558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W_V = torch.zeros(d_head, d_model)\n",
    "W_V[torch.arange(0, 4), torch.arange(0, 4)] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f64d382-1b70-47de-ae02-4016b6df4cca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c791950-f54d-4cd0-a80f-86de04c9de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_O = torch.zeros(d_model, d_head)\n",
    "W_O[8:11, :] = torch.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faa510b-bc93-4859-9066-688d88c6f6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_rref.rpc_sync().init(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c94d72d1-a703-4d3e-985c-904a5c068ccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        self.attention = attention\n",
    "        self.d_head = d_model // n_heads\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "        self.to_q = nn.Linear(d_model, d_model)\n",
    "        self.to_k = nn.Linear(d_model, d_model)\n",
    "        self.to_v = nn.Linear(d_model, d_model)\n",
    "        self.projection = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def split_heads(self, x):\n",
    "        return rearrange(x, \"batch_size seq_len d_model -> \\\n",
    "            batch_size seq_len n_heads d_head \\\n",
    "        \", d_head=self.d_head)\n",
    "    \n",
    "    def concat_heads(self, x):\n",
    "        return rearrange(x, \"batch_size seq_len n_heads d_head -> \\\n",
    "            batch_size seq_len d_model \\\n",
    "        \", d_model = self.d_model)\n",
    "    \n",
    "    def forward(self, pre_q, pre_k, pre_v):\n",
    "        q = self.to_q(pre_q)\n",
    "        k = self.to_k(pre_k)\n",
    "        v = self.to_v(pre_v)\n",
    "        \n",
    "        q = self.split_heads(q)\n",
    "        k = self.split_heads(k)\n",
    "        v = self.split_heads(v)\n",
    "        \n",
    "        attn_output, attn_weights = self.attention(q, k, v)\n",
    "        output = self.concat_heads(attn_output)\n",
    "        return self.projection(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852a4aaf-6d89-4cd5-8e4f-368d67b4512c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_reward(rewards, discount_factor):\n",
    "    discount_rewards = []\n",
    "    \n",
    "    for reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d17b6-3a1e-4d67-8959-e015d0b7ef9e",
   "metadata": {},
   "source": [
    "First, we need to write out the MLP function, which is $\\operatorname{ReLU}\\left(w^T W{\\text {in }}\\right) W_{\\text {out }}$. Then, we look at the attention function. The attention function, before ReLU, is $\\sum_h\\left(\\alpha^h t_0+\\left(1-\\alpha^h\\right) t_1\\right)^T W_{\\text {neur }}^h$. Here, $W_{\\text {neur }}^h$ is the matrix that determines how to get from a weighted average of initial embeddings to our neuron activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "caa11d11-5650-4a3d-8e67-1d95c16d2b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "244732ee-7cfd-4f8e-abeb-8e354f65c5e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.randn(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6e0fc18-c5f9-4e8c-8ac6-6bc9fc8ba2be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f97bb230-255f-45dd-a5f9-85316eabbfb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "714cec0d-40ed-44df-81ed-e2d0c5016356",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(size=list(x.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e99bcc3-9c1a-4e71-93be-a19f9187daed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
