{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ebbd787-b3a9-44c6-93ed-336039899305",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8a9922b-82f4-499a-b22b-7ba005d49794",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a627198-d7d6-4d04-9264-264e74d8aa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "int *h_a, *h_b, *h_c;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c6de09-87cf-457c-8ce3-b0e64c439d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_t bytes = sizeof(int) * n;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6530693-2374-440b-a4c0-a5156df8eb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_a = (int*)malloc(bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79268f4b-1950-4e7c-9eee-e047792e2a45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.distributed.rpc as rpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03921373-d0d8-41fe-8b19-9ac9e6f5a845",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TensorParallelGroupInitializer(ProcessGroup):\n",
    "    def init_process_group(self):\n",
    "        num_tensor_parallel_groups = self.world_size // self.tensor_parallel_size\n",
    "        \n",
    "        for i in range(num_tensor_parallel_groups):\n",
    "            ranks = list(range(\n",
    "                i*self.tensor_parallel_size,\n",
    "                (i+1)*self.tensor_parallel_size\n",
    "            ))\n",
    "            process_group = dist.new_group(ranks=ranks)\n",
    "            \n",
    "            if self.rank in ranks:\n",
    "                local_rank = ranks.index(self.rank)\n",
    "                local_world_size = len(world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef3a061-9040-4920-b59f-22d950cfdc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_storage(x):\n",
    "    x.storage().resize_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefc41c7-97dd-44ac-a689-67d4cee67108",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: mask targets\n",
    "step 2: calculate local predicted logits\n",
    "step 3: calcualte global predicted logits\n",
    "step 4: calculate log(...)\n",
    "step 5: calculate loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e6983b-5900-49ab-9b93-d5f7c0018db1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_microbatches = 4\n",
    "n_partitions = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa904dae-e929-4268-a7a1-ef4730359632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_clock_cycles = n_microbatches+n_partitions-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "603bc426-17bc-41ad-80f0-5a776eabe45c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0]]\n",
      "[[1, 0], [0, 1]]\n",
      "[[2, 0], [1, 1], [0, 2]]\n",
      "[[3, 0], [2, 1], [1, 2]]\n",
      "[[3, 1], [2, 2]]\n",
      "[[3, 2]]\n"
     ]
    }
   ],
   "source": [
    "for clock_idx in range(n_clock_cycles):\n",
    "    start_partition_idx = max(clock_idx+1-n_microbatches, 0)\n",
    "    end_partition_idx = min(clock_idx+1, n_partitions)\n",
    "    \n",
    "    xs = []\n",
    "    for partition_idx in range(start_partition_idx, end_partition_idx):\n",
    "        microbatch_idx = clock_idx - partition_idx\n",
    "        xs.append([microbatch_idx, partition_idx])\n",
    "        \n",
    "    print(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dd016c-994a-4cf1-9e08-3d35e8068011",
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in groups:\n",
    "    dist.barrier()\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6388532a-03ff-4daa-b07c-910322abfb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: ln1 = ln1(resid_pre)\n",
    "step 2: attn_out = attn1(ln1) + attn2(ln1) + ...\n",
    "step 3: mid_resid = resid_pre + attn_out\n",
    "step 4: ln2 = ln2(mid_resid)\n",
    "step 5: mlp = mlp(ln2)\n",
    "step 6: final_resid = mlp + mid_resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c96d29-daaf-4170-b2b0-53c776818d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aac802-d347-43b4-bd5e-690f302ca0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_pos = model.W_pos\n",
    "\n",
    "similarity = torch.cosine_similarity(W_pos[:, 0], W_pos[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fb54c1-5855-4ff2-9f18-18f279e38ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP(Attn(x @ W_E )) @ W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f25a239-26e0-492c-b75f-24fd26f3de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, _ = model.run_with_cache(past_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b58859f-e728-4d5d-a34a-d82f5ab75604",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = F.log_softmax(logits[:, -1, :], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ebea6b-36a9-4d9f-ba20-2b40f0de5b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "board_state = torch.zeros(board_size, board_size)\n",
    "board_state.view(-1)[:] = log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d104d8fc-40af-4858-8ba7-d721a3f572d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "int *h_a, *h_b, *h_c;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d414b-f845-4f3e-acd1-cb38c2eef5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_t bytes = (int*)sizeof(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7866fc-d9c1-48b5-be79-0e2177df30af",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_a = malloc(bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceda0102-713d-48e3-93a1-2f9a17355e39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "685bfedc-83d6-42e1-89d3-9c5ca9e70837",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class _ParallelCrossEntropy(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, parallel_logits, targets, parallel_context):\n",
    "        # calculate predicted\n",
    "        rank = parallel_context.get_local_rank(ParallelMode.TENSOR)\n",
    "        partition_size = parallel_logits.shape[-1]\n",
    "        vocab_start_idx = partition_size*rank\n",
    "        vocab_end_idx = vocab_start_idx+partition_size\n",
    "        \n",
    "        target_mask = (targets < vocab_start_idx) | (targets >= vocab_end_idx)\n",
    "        masked_targets = targets.clone() - vocab_start_idx\n",
    "        masked_targets[target_mask] = 0.\n",
    "        \n",
    "        parallel_logits = rearrange(\n",
    "            parallel_logits,\n",
    "            \"batch_size seq_len vocab_size -> (batch_size seq_len) vocab_size\"\n",
    "        )\n",
    "        targets_1d = rearrange(\n",
    "            targets,\n",
    "            \"batch_size seq_len -> (batch_size seq_len)\"\n",
    "        )\n",
    "        predicted_logits = parallel_logits[\n",
    "            torch.arange(targets.shape[-1]),\n",
    "            targets_1d\n",
    "        ]\n",
    "        predicted_logits = all_reduce(\n",
    "            predicted_logits,\n",
    "            paralllel_context=parallel_context,\n",
    "            parallel_mode=ParallelMode.TENSOR\n",
    "        )\n",
    "        \n",
    "        exp_logits = torch.exp(parallel_logits)\n",
    "        exp_logits = all_reduce(exp_logits)\n",
    "        loss = exp_logits.sum(dim=-1).log() - predicted_logits\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccafc601-3a4f-43b2-83e0-1f2d24293ed2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParallelCrossEntropy(nn.Module):\n",
    "    def __init__(self, parallel_context):\n",
    "        super().__init__()\n",
    "        self.parallel_context = parallel_context\n",
    "    \n",
    "    def forward(self, logits, targets):\n",
    "        loss = _ParallelCrossEntropy.apply(\n",
    "            logits, targets\n",
    "        )\n",
    "        \n",
    "        loss /= len(targets)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62113da-8c6b-4ee6-adfb-8a85cb0c7171",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready\n",
    "begin forward\n",
    "finished forward\n",
    "finished backward\n",
    "finished batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ec945b-8b10-4d47-bab2-975c4538ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "handshake\n",
    "syncronization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8bbfa-25d5-4c48-b476-f866711bea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "int *h_a, *h_b, *h_c;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7b2f1d-de66-4bfd-9105-e84c6d431fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_t bytes = sizeof(int)*n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec24d42-9945-4276-875e-c7384b32ba57",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_a = (int*)malloc(bytes);\n",
    "h_b = (int*)malloc(bytes);\n",
    "h_c = (int*)malloc(bytes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc356d9-a251-4807-be0f-7551d217564f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_cache = model.run_with_cache(clean_tokens)\n",
    "_, corrupted_cache = model.run_with_cache(corrupted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8db438a-1250-49e1-89ad-42ecde9306ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_head(acts, hook, clean_cache, corrupted_cache, target_head):\n",
    "    target_layer_idx, target_head_idx = target_head\n",
    "    \n",
    "    if hook.layer() == target_layer_idx:\n",
    "        acts[:, :, head_idx] = corrupted_cache[hook.name][:, :, head_idx]\n",
    "    else:\n",
    "        acts = clean_cache[hook.name]\n",
    "    \n",
    "    return acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37262fb3-770c-44b2-bc43-a7b27e901979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb809d80-3952-4fcf-8d58-e5f7460cdff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = torch.zeros(n_layers, n_heads)\n",
    "\n",
    "for layer_idx in range(n_layers):\n",
    "    for head_idx in range(n_heads):\n",
    "        hook_name = get_act_name(\"z\", layer_idx)\n",
    "        hook_func = partial(\n",
    "            patch_head,\n",
    "            clean_cache=clean_cache,\n",
    "            corrupted_cache=corrupted_cache,\n",
    "            target_head=(layer_idx, head_idx)\n",
    "        )\n",
    "        patched_logits, _ = model.run_with_cache(\n",
    "            clean_tokens,\n",
    "            fwd_hooks=[(hook_name, hook_func)]\n",
    "        )\n",
    "        results[layer_idx, head_idx] = compute_ioi_metric(patched_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df4729f0-1f45-4257-8ce8-a2fe6769f91f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255993af-c63d-485c-be8e-713ac964fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(past_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb4f919-bb28-4bae-bf90-af8a6007a3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_neurons = cache[\"post\", layer_idx].std(dim=[0, 1]).argsort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54191f3b-8a72-4fa0-a9cf-9cee79acf91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E\n",
    "W_V = model.W_V[layer_idx, head_idx]\n",
    "W_O = model.W_O[layer_idx, head_idx]\n",
    "W_U = model.W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8b352e-329b-40e9-a80f-79559561a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E @ W_V @ W_O @ W_E.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3933fcab-ed9c-4c78-a8d2-8cf90610621d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = W_A[:, :, 0]\n",
    "ys = W_A[:, :, 1 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f9b2b5c-eb6c-440e-84f8-c57db8e18b35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def intervene_feature(resid, feature, scale):\n",
    "    feature /= feature.norm(dim=-1)\n",
    "    feature_projection = resid[0, position] @ feature\n",
    "    \n",
    "    resid[0, position] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80f4781-7069-4b66-b8e0-bf2ac8154cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b299e7-3aea-48b0-90cc-bce61a76259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache[\"embed\"][:, -1] @ W_U[:, tokens[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f24e53f-2dc8-474c-bfa5-ed6613a7407d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def probabiliy_scores(image_embedding, text_embedding):\n",
    "    image_embedding /= image_embedding.norm(dim=-1)\n",
    "    text_embedding /= text_embedding.norm(dim=-1)\n",
    "    \n",
    "    similarities = image_embedding @ text_embedding.T\n",
    "    probs = F.softmax(similarities, dim=-1)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6fe4d6-f382-413b-85cc-369f772296fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_returns = discounted_return_at_each_step(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217193e5-12dd-4d3d-adfa-641d455d20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0\n",
    "\n",
    "for discount_return, prob in zip(discount_returns, selected_action_probs):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd099077-c6dd-4c21-81ac-c0857f6ec979",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(N_EPISODES):\n",
    "    state, _ = env.reset\n",
    "    state = torch.from_numpy(state) # ignore\n",
    "    done = False\n",
    "    \n",
    "    while done:\n",
    "        predicted_rewards = model(state)\n",
    "        action = torch.argmax(predicted_rewards, dim=-1)\n",
    "        action = action.item() # ignore\n",
    "        \n",
    "        state, reward, done, _, _ = env.step(action)\n",
    "        state = torch.from_numpy(state) # ignore\n",
    "        \n",
    "        if done is True:\n",
    "            target_reward = torch.tensor(reward)\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                predicted_next_rewards = model(state)\n",
    "            \n",
    "            predicted_next_reward = torch.max(\n",
    "                predicted_next_rewards, dim=-1\n",
    "            )\n",
    "            predicted_next_reward = predicted_next_reward[0] # ignore\n",
    "            target_reward = reward + GAMMA * predicted_next_reward\n",
    "        \n",
    "        predicted_reward = predicted_rewards[action]\n",
    "        loss = loss_func(predicted_rewards[action], target_reward)\n",
    "        loss.append(loss.detach().numpy()) # ignore\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de4e97d-faa8-4cdd-bbee-e19809106b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E\n",
    "W_V = model.W_V[layer_idx, head_idx]\n",
    "W_O = model.W_O[layer_idx, head_idx]\n",
    "W_U = model.W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e61dce3-6fc3-4db6-92db-b7b5bba4ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_OV_circuit = W_E @ W_V @ W_O @ W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b222bae7-747d-4d83-8ef4-11b49268af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(past_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cf571f-ac5e-4761-9211-9fda6005909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_neurons = cache[\"post\", layer_idx].std(dim=[0, 1]).argsort(descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4570bbe-960e-41db-bfb8-c11c09fec548",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6ab097-3872-4b0a-986e-33b54a60c538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_consine_similarity(neuron_idx, feature):\n",
    "    feature /= feature.norm(dim=-1)\n",
    "    W_out = model.W_out[layer_idx, neuron_idx]\n",
    "    W_out /= W_out.norm(dim=-1)\n",
    "    \n",
    "    return einsum(\n",
    "        feature,\n",
    "        W_out\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e75b16-1453-4971-962f-bb95ff6734e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)\n",
    "\n",
    "embed = model.embed\n",
    "mlp0 = model.blocks[0].mlp\n",
    "ln1 = model.blocks[0].ln1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f999657f-c14f-4bcd-a227-4338713d4e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embed(tokens)\n",
    "\n",
    "resid_after_mlp0 = embeddings + mlp0(ln1(embeddings) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e93e6a-9219-4faa-91f6-c6c896ea03d8",
   "metadata": {},
   "source": [
    "step 1: a clean prompt, and a corrupted prompt\n",
    "step 2: record all the interdimate activations of the clean prompt, and the corrupted prompt\n",
    "step 3: patch the activations from the corrupted prompt if a component is a part of the direct path, otherwise patch clean activations\n",
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bc4c1c-8c2b-4dbf-aea9-c4df5dc0838e",
   "metadata": {},
   "outputs": [],
   "source": [
    "record, p,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e21ac9ed-cfd5-432f-bb06-83595c164ded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "layer_idx, head_idx = 5, 1393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027fb88e-6127-4e24-a26d-d6a5cf96ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(board_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b828060-0fc8-4e1a-bc72-b7759f6e0736",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_acts = cache[\"post\", layer_idx][:, neuron_idx]\n",
    "threshold = mlp_acts.quantile(0.99)\n",
    "top_neurons = mlp_acts > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8a2a7-04b0-4604-a9e1-e4815367cb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(board_states == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8a3f70-1244-4716-a0e8-9a2e7d822504",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax(x @ W_Q @ W_K.T @ x) @ x @ W_V @W_O "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db7831a0-9310-4a55-aaa4-4db81e91157f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metric(pattern, target_pattern):\n",
    "    return (pattern * target_pattern).sum() / (pattern.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445a6ab3-0b68-4d94-a734-3891208b92fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2e52bb-66ed-4f5c-9ffd-ebd564ba3212",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f959e4-69be-4dda-9ede-30188b827060",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.zeros(n_layers, n_heads)\n",
    "for layer_idx in range(n_layers):\n",
    "    for head_idx in range(n_heads):\n",
    "        hook_name = f\"blocks.{layer_idx}.attn.hook_pattern\"\n",
    "        pattern = cache[hook_name][:, head_idx]\n",
    "        score = compute_metric(pattern, target_pattern)\n",
    "        data[layer_idx, head_idx] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641d5568-a468-4cf9-be66-f175c58e3182",
   "metadata": {},
   "outputs": [],
   "source": [
    "deploy on edge\n",
    "database\n",
    "server\n",
    "service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8041dc-b4dc-4fe4-91c8-b2e29ff2dfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "record, memory, process, send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031bcc2e-bff8-4e86-9b40-819ce4550eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "population activity, motor imagery, stimulus, conditioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923f95ac-17ad-4310-b9a5-d647b0ffe513",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron1 > axon > synapse >  dendiret>   neuron2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1278480-1fd8-455d-899b-30869494c765",
   "metadata": {},
   "source": [
    "- Step 1: The output of head 0.0 is $h(x) = \\frac{1}{n} \\sum_{i=1}^n x_i^T W_{OV}^{0.0}$. This is a weighted average of the input vectors $x_i$ transformed by the OV matrix.\n",
    "\n",
    "- Step 2: We can write each input vector as $x_j = \\text{pos}_j + \\text{tok}_j$. The vector has a positional encoding component and a token embedding component.\n",
    "\n",
    "- Step 3: Plugging this in gives: $h(x) = \\frac{1}{n}(\\sum_{i=1}^n \\text{pos}_i^T W_{OV}^{0.0} + \\sum_{i=1}^n \\text{tok}_i^T W_{OV}^{0.0})$\n",
    "\n",
    "- Step 4: The token embeddings consist of left brackets and right brackets. Let $n_L$ and $n_R$ be the number of each token type.\n",
    "+ $v_L = n_L * tok(\\text{left bracket}) * W_{OV}^{0, 0}$\n",
    "+ $v_R = n_R * tok(\\text{right bracket}) * W_{OV}^{0, 0}$\n",
    "\n",
    "- Step 5: This gives the final formula: $h(x) = \\frac{1}{n}(\\sum_{i=1}^n \\text{pos}_i^T W_{OV}^{0.0} + n_L v_L + n_R v_R)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e103021-0e19-4cd7-a4e8-6595047f6dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs = torch.randn(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "71af97a1-d416-432b-a50e-79992d1c03ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_max = 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "24dae69b-fbca-4cfc-8b18-f53880c387ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2c9ece-b4a3-446b-80ae-0cacc45488ff",
   "metadata": {},
   "source": [
    "Calculate the global maximum value of `xs`, given that `xs` is the current partition on the current GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4980edb7-d5a6-45c5-835b-c95b6664d381",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.8253,  1.3883,  0.7739, -1.5190, -1.1593])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4cd5acdf-15e6-48ff-96e2-2566bb047f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_max = torch.max(xs, dim=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a790f5cd-b123-4487-818b-506964a6926b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3883)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c7606c-4559-4a4f-9c36-195efecf40d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_max = dist.all_reduce(\n",
    "    local_max,\n",
    "    op=dist.ReduceOp.MAX,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c92096d-b6ef-4805-bba5-bda89ac0a2ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalized_xs = xs - global_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a649c7e-956c-4d73-8eef-f192fb6c2dff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.9253, -0.7117, -1.3261, -3.6190, -3.2593])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa042e0-fdeb-40a8-9ad5-d5ad1e1050db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "53172df8-fe44-4eaa-b0fe-52575aef4906",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(0, 6).view((2, 3))\n",
    "y = torch.arange(0, 6).view((3, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "65205d2f-67dc-4c19-84d3-afdd3de2717e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "60456dea-a5cb-484f-9b3e-eb6a9ceb0167",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71351c60-91d6-49ff-8a72-cd380366ea5e",
   "metadata": {},
   "source": [
    "Write the manual version of einsum below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a039ba26-038f-4438-a8ac-9564afe3120a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.zeros(x.shape[0], y.shape[1])\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "900e5e5f-f7c6-45d7-8402-0c54bf136a54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(x.shape[0]):\n",
    "    for j in range(y.shape[1]):\n",
    "        total = 0\n",
    "        for k in range(3):\n",
    "            total += x[i, k] * y[k, j]\n",
    "        \n",
    "        output[i, j] = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "f4a889bf-ba75-4983-92a2-b3d981321c59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 13.],\n",
       "        [28., 40.]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7a0fd49c-48fe-4f55-a530-c48a79df60b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True],\n",
       "        [True, True]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output == torch.einsum(\"ik, kj -> ij\", x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9288f7b2-910e-4e3c-a653-e2e8f80ee784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e30aeac7-d3c6-4e70-b686-e5fb4e13f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_queues = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "12aeb1a3-74d1-4598-a5db-70d821d3bcc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_queues.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d7cd3432-99f2-49af-b18d-1f5defcf05aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1aac58ca-c061-4d04-b5ff-db7d84d121e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_queues.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "138cfc55-3140-49a7-a7b4-ce2663bd9b9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396accef-7452-4598-b879-d40b3526efe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
