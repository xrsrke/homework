{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f82e6b0-2c46-47f2-ae56-1295a6b167b8",
   "metadata": {},
   "source": [
    "### Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977244e0-55cc-4fc2-ade0-c3afed7f384f",
   "metadata": {},
   "source": [
    "conditioned response, population activity, motor imagery, stimulus-evoke activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bed04a-c90a-4d92-8121-cfec3d197c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "am i v_ing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c564be0-25c4-4058-a89a-f5f42b1dab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "had v_ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cae09f3-7e9f-4911-a5be-17b5382305e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "have subject been v_ing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4564e9-3e16-4fb1-b612-4cdeb845875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hadn't past_participle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea20b44c-c21f-4b7b-8e7e-5c827aebb8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "am subject root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9025c769-b654-44dc-b583-9d4a382b6167",
   "metadata": {},
   "outputs": [],
   "source": [
    "was/were"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e78e77-4f0f-45ff-844c-b5997ecaf390",
   "metadata": {},
   "outputs": [],
   "source": [
    "had subject root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdcc6d5-b466-41cc-91d6-581cadf2a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "have been v_ing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9fba12-27b3-45b8-b40d-bea5808d7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "were/was subject v_ing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0350f3e9-2f66-4390-b629-6c9bb83b3ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "will have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9148b8a-2b05-48c9-883f-0d7115ae88ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "will subject have past_participle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4072e606-bbb7-48e5-9c3b-76f567e3588e",
   "metadata": {},
   "source": [
    "### SW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96f7af-abca-4592-8e97-2392dd733115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81826eae-36e8-46f7-83d5-3df411bde773",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sauce(Enum):\n",
    "    BECHAMEL = \"Bechamel\"\n",
    "    VELOUTE = \"Veloute\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1af02b-a508-41bf-9e9c-f3f3d244d224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sauce(sauce: Sauce):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d65e06e-ee78-4ced-acc1-bc8bff7f9d34",
   "metadata": {},
   "source": [
    "### AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca7adf2-5531-4fe5-aaa7-0772c7d383f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3079f32-4e3b-4b7b-8e47-314223e52c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "representation, prediction, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832ba724-cfdc-49cd-91eb-1dba7dd30c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadAttention(d_model, n_heads)\n",
    "        self.position_wise = PositionWiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.norm_1 = ResidualLayerNorm(d_model, dropout)\n",
    "        self.norm_2 = ResidualLayerNorm(d_model, dropout)\n",
    "    \n",
    "    def forward(self, embeddings):\n",
    "        attn_output, attn_weights = self.attention(\n",
    "            pre_q=embeddings, pre_k=embeddings, pre_v=embeddings\n",
    "        )\n",
    "        \n",
    "        out_1 = self.norm_1(x=attn_output, residual=embeddings)\n",
    "        out_2 = self.position_wise(out_1)\n",
    "        out_3 = self.norm_2(x=out_2, residual=out_1)\n",
    "        \n",
    "        return out_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fca3ab-64c0-445d-828c-0d5c54780767",
   "metadata": {},
   "outputs": [],
   "source": [
    "willn't haven past_participle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252d62fc-6059-4274-9946-bed2a6c407c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_return(rewards, discount_factor):\n",
    "    discounted_return = torch.tensor(0.)\n",
    "    for k, reward in enumerate(rewards):\n",
    "        discounted_return += reward * (discount_factor **k)\n",
    "    \n",
    "    return discounted_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be32d23-145d-4149-a53f-df5d58e8ff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = torch.tensor([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8622327f-4d6c-405d-8f37-490790fab9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.4265)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_return(rewards, torch.tensor(0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d76406-906d-400e-aa28-e1eb755aedfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "as service\n",
    "in db\n",
    "in ui\n",
    "edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfb3453-8e37-4d7d-8e74-d066ce516f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c3e02a-109d-4910-acd5-a09304d35c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pf/g3nr86yn4j71vzzmv6knwdhr0000gp/T/ipykernel_1215/1963947385.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  bleu = load_metric(\"bleu\")\n"
     ]
    }
   ],
   "source": [
    "bleu = load_metric(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed8b58c-1c60-4ebb-b547-0ab402740f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = bleu.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b805f97-afad-4a3a-b558-8e5703642035",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = tokenizer(batch[\"text\"], padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74c771-81c2-4ab7-acd5-232b50b6a4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dbd2dd-7448-47ea-8f96-ae0c554fd763",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_head):\n",
    "        super().__init__()\n",
    "        self.d_head = d_head\n",
    "    \n",
    "    def forward(sefl, q, k, v):\n",
    "        qk_matmul = torch.matmul(q, k.permute(3, 2))\n",
    "        scores = qk_matmul / math.sqrt(self.d_head)\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        output = torch.matmul(attn_weights, v)\n",
    "        \n",
    "        return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b224f0ea-d7de-4c52-a06f-236b8a774ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    x = (x-x.mean())/x.std()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9ac37e-0d24-4f0f-855b-90b13a3c5a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShortcutProjection(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, out_channels=out_channels,\n",
    "                kernel_size=1, stride=stride\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1271c281-3098-4221-88fb-22be7a2b2c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(layer, inp, out):\n",
    "    add_log(layer, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cdbe1c-80cf-413c-a1bc-77237690a237",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hook(model):\n",
    "    for layer in model.layers:\n",
    "        layer.register_forward_hook(func)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
