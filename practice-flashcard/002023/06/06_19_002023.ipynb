{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cac7a3c5-3b1a-447e-8846-f6995a4b084f",
   "metadata": {},
   "source": [
    "### MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5da2509-266b-4f5b-a942-0b24c1f2864a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa45a1b-f716-4d51-99b5-4f5934d9961a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raise():\n",
    "    with pytest.raises(ValueError):\n",
    "        raise_exception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29c324a7-7768-4e2a-a922-5beb8e0ca08b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import great_expectations as ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa5552c-0a93-4187-9167-4ea74e90b56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ge.read_table(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2045e1d-d2fe-4a5e-baae-7560eab33c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.exepct_column_values_to_be_unique(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2a7da5-7eeb-4809-a441-c0ca06b5ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestFruit:\n",
    "    def setup_method(self):\n",
    "        self.fruit = Fruit(\"xx\")\n",
    "    \n",
    "    def test_fruit(self):\n",
    "        assert self.fruit.name == \"xx\"\n",
    "    \n",
    "    def teardown_method(self):\n",
    "        del self.fruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abdc7052-d50c-4742-b210-8d8bb0f1141e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84b51363-21ae-4601-84ad-b784c8c84e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NutritionInformation(TypedDict):\n",
    "    value: int\n",
    "    unit: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c61aa9c-f4f9-4b60-a063-28915bb9ee4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RecipeNutritionInformation(TypedDict):\n",
    "    recipes_used: int\n",
    "    calories: NutritionInformation\n",
    "    carbs: NutritionInformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ceaa7c3-c803-4149-ae85-ece90ea68a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp, value, key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e31dfe8-dbe6-404e-a693-2a68e56a2d5c",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44c1cf4c-a59a-4cd3-b4f8-a654634a0123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359cc5c9-0090-4779-89ef-14ee80d0a71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091f1316-cfc2-4784-885c-549e2da06b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int i = 0;\n",
    "    \n",
    "    while (i <= 5) {\n",
    "        std::cout << i;\n",
    "        i++;\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d28c196-800e-40e9-b01a-daae54a562bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid > thread block > thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fd41be-6835-48e3-86a2-7969fc08afde",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int a = 69;\n",
    "    int* b = &a;\n",
    "    \n",
    "    std::cout << *b;\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbae4c35-28c1-4097-a1de-b8bb8620773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api server, scheduler, ectd, control manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd970fc2-edc6-4ac5-a291-1661f13bb709",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Monster() {\n",
    "    public:\n",
    "        Monster() {\n",
    "            std::cout << \"fuck yea\";\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6cd13c-68c9-4041-88ab-199bfe5c9f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "send sync, receiv sync\n",
    "send sync, receiv async\n",
    "send async, receive sync\n",
    "send async, receiv async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8702c302-7200-44bc-8e2d-7ee1eb01b0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157c89f1-7aca-4731-b535-0a8facca66dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def forward(self, x, labels):\n",
    "        outputs = self.net(x)\n",
    "        losses = loss_func(outputs, labels)\n",
    "        return losses, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce173fe-6229-42e2-957d-eb8b81279327",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, data in enumerate(data_loader):\n",
    "    outputs, losses = model(x)\n",
    "    loss = loss.mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b477c727-864e-4997-b992-9b4e5f8c14a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model parameters, gradients, optimiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a40d1ff-5587-4e15-b7ab-5402ee019b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: model partritioning\n",
    "step 2: move to rank\n",
    "step 2.1: move to device\n",
    "step 3: init local optimizer\n",
    "step 4: step\n",
    "step 5: broadcast\n",
    "step 7: sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a6fa8-f377-427a-9201-99abef523daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabParallelEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim_per_partrition = embedding_dim // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.num_embeddings,\n",
    "            self.embedding_dim_per_partrition\n",
    "        ))\n",
    "        self.vocab_start_idx, self.vocab_end_idx = self.get_vocab_range(\n",
    "            self.embedding_dim_per_partrition\n",
    "        )\n",
    "    \n",
    "    def get_vocab_range(self, embedding_dim_per_partrition):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        start_idx = rank*embedding_dim_per_partrition\n",
    "        end_idx = start_idx + embedding_dim_per_partrition\n",
    "        return start_idx, end_idx\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        mask = (self.vocab_start_idx > tokens) || (self.vocab_end_idx < tokens)\n",
    "        tokens = tokens - self.vocab_start_idx\n",
    "        tokens[mask] = 0.\n",
    "        \n",
    "        embeddings = F.embedding(tokens, self.weight)\n",
    "        mask_idxs = torch.where(mask==False)[1]\n",
    "        embeddings[mask_idxs] = 0.\n",
    "        \n",
    "        torch.distributed.all_reduce(embeddings)\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b702fa-c9fb-4428-bde2-42b9861ad575",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: partrition the parameters\n",
    "step 2: to rank\n",
    "step 3: init local optimizer\n",
    "step 4: sync the optimizer's states\n",
    "step 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f038dd9e-5fca-4115-85f1-bfbcbe067d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock cycle 1: backward(m, n)\n",
    "clock cycle 2: backward(m, n-1), backward(m-1, n)\n",
    "clock cycle 3: backward(m, n-2), backward(m-1, n-1), backward(m-2, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0763b5a2-77fc-47dd-899c-32f5a7179e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb22c708-ef81-462b-b418-89ff27a3d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "start.record()\n",
    "\n",
    "hardshit()\n",
    "\n",
    "end.record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcdc99d-382e-47ca-b6d3-5a2c55c641d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "start.time_elapsed(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c917bf3-cab5-4e5e-a860-261880b4db64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StartDependency(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        phony = torch.empty(1, requires_grad=False, device=input.device)\n",
    "        return input, phony\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input, grad_phony):\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7f73cd6-5006-41fb-af05-9d12533b694d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EndDependency(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, phony):\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        return grad_input, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d3d3447-a7c4-4a43-8484-edba280443e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dependency(start_batch, end_batch):\n",
    "    start_batch, phony = StartDependency.apply(start_batch)\n",
    "    end_batch = EndDependency.apply(start_batch, phony)\n",
    "    return start_batch, end_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d862bb63-810c-470c-9a51-f2b61a9d7089",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: partrition\n",
    "step 2: rank\n",
    "step 3: init local\n",
    "step 4: sync optimizer's states\n",
    "step 5: move local params to buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86bd156c-c188-4c55-a00a-b01cb2660836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StartDependency(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        phony = torch.empty(\n",
    "            0,\n",
    "            requires_grad=False,\n",
    "            device=input.device\n",
    "        )\n",
    "        \n",
    "        return input, phony\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input, grad_putput):\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c47f31-e45b-4aff-b1f8-0524774cb117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EndDependency(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, phony):\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        return input, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ced85c2-b969-48f4-8aba-2c3b39681060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dependency(start_batch, end_batch):\n",
    "    start_batch, phony = StartDependency.apply(start_batch)\n",
    "    end_batch = EndDependency.apply(start_batch, phony)\n",
    "    return start_batch, end_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fceb3a1-93d9-43c7-89ec-62155bbd8c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock cycle 1: backward(m, n)\n",
    "clock cycle 2: backward(m, n-1), backward(m-1, n)\n",
    "clock cycle 3: backward(m, n-2), backward(m-1, n-1), backward(m-2, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6dcc12-9c25-4127-88c2-391e945e92a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = interference.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a62b7aa-d017-4a5b-a14e-2514102b8dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "interference[torch.arange(n_features), torch.arange(n_features)] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c67326fd-051e-4d96-a6e0-cc9683e49750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, n, d_model):\n",
    "        super().__init__()\n",
    "        self.n, self.d_model = n, d_model\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        n_tokens = len(tokens)\n",
    "        embeddings = torch.zeros((n_tokens, self.d_model))\n",
    "        \n",
    "        for p in range(n_words):\n",
    "            for i in range(self.d_model):\n",
    "                denominator = torch.pow(self.n, (2*i/self.d_model))\n",
    "                embeddings[p][i] = torch.sin(p/denominator) if i%2==0 else torch.cos(p/denominator)\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6260a644-672f-4525-a77d-4cd4f54daea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [\n",
    "            nn.Linear(n_in, nh),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nh, n_out)\n",
    "        ]\n",
    "        \n",
    "        for l in self.layers:\n",
    "            self.add_module(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892c9183-2b7e-45dd-b9d6-810f369d4a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97244e6f-e64f-422a-91cf-a5e8384be5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = interference.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5523339-bf34-4c48-a881-9c95af917d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "interference[torch.arange(n_features), torch.arange(n_features)] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5519116f-254d-4568-9dcc-80349a9697b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf80867-f66c-4be0-9949-1a36f74bbdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "polysemanticity = inteference.pow(2).sum(dim=-1).sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fb994f3-b177-4dda-b411-8958ec58a2f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a171125-cc82-4040-accb-431639ec666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = repeat(x, \"h w -> h w n\", n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "940f125a-3c42-47c3-9bd6-16d1056e7e42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        self.attention = attention\n",
    "        self.d_model, self.n_heads = d_model, n_heads\n",
    "        self.d_head = d_model // n_heads\n",
    "    \n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.proj = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_len, d_model = x.size()\n",
    "        return x.view(batch_size, self.n_heads, seq_len, self.d_head)\n",
    "    \n",
    "    def concat_heads(self, x):\n",
    "        batch_size, n_heads, seq_len, d_head = x.size()\n",
    "        return x.view(batch_size, seq_len, self.d_model)\n",
    "    \n",
    "    def forward(self, pre_q, prev_k, prev_v):\n",
    "        q = self.w_q(pre_q)\n",
    "        k = self.w_k(pre_k)\n",
    "        v = self.w_v(pre_v)\n",
    "        \n",
    "        q = self.split_heads(q)\n",
    "        k = self.split_heads(k)\n",
    "        v = self.split_heads(v)\n",
    "        \n",
    "        attn_output, attn_weights = self.mha(q, k, v)\n",
    "        \n",
    "        output = self.concat_heads(attn_output)\n",
    "        output = self.proj(output)\n",
    "        \n",
    "        return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a038b1-c956-42d5-80eb-16cdb0c72161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hook(model):\n",
    "    for layer in model:\n",
    "        layer.register_forward_hook(add_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e73303bc-a355-4839-855f-5426e380e4f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_one_hot(idx, dim):\n",
    "    x = torch.zeros(dim)\n",
    "    x[idx] = 1.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6aff2a7e-10e9-4cc6-a731-4b8f791175ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_one_hot(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b830f8dc-6cdb-4f7d-bc0b-50cbe10e8d9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, n, d_model):\n",
    "        super().__init__()\n",
    "        self.n, self.d_model = n, d_model\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        seq_len = len(tokens)\n",
    "        embeddings = torch.zeros(seq_len, d_model)\n",
    "        \n",
    "        for p in range(seq_len):\n",
    "            for i in range(self.d_model):\n",
    "                denominator = torch.pow(self.n, 2*i/self.d_model)\n",
    "                embeddings[p][i] = torch.sin(p/denominator) if i%2==0 else torch.cos(p/denominator)\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc4ff22-7cbf-46d9-b3ef-195b02392fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = interference.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457bff7f-f271-454b-bbca-e5f9336f4a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "interference[torch.arange(n_features), torch.arange(n_features)] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0ef186-ee9a-4cbe-9849-50fa3de37718",
   "metadata": {},
   "outputs": [],
   "source": [
    "polysemanticity = interference.pow(2).sqrt().sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c3f3c2-4d45-4d31-b0c6-4ed971874592",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: two prompts\n",
    "step 2: choose a component\n",
    "step 3: record all inter activations\n",
    "step 4: extract the activations of the prompt 1, patch\n",
    "step 5: logit diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f551ad-f095-4905-afc7-4c9632a9c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward = get_reward(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a14334-8bca-445e-88d0-88cbdc5deec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(ratio, epsilon):\n",
    "    return torch.clamp(ratio, min=1-epsilon, max=1+epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f85dcf5-61e0-4602-b62c-8a85a30c0168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss_of_soft_v(states, actions, action_probs):\n",
    "    q_preds = q_function(states, actions)\n",
    "    entropy = -action_probs.log()\n",
    "    \n",
    "    v_values = v_function(states)\n",
    "    \n",
    "    return (v_values - (q_preds + entropy).mean()).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f37c448-c9cb-45aa-adb7-4164911a9605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bd72efc-5be2-4697-9564-1fe15cf29c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune.callback import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c20655d-9196-4492-b592-a36f7a305187",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PrintCallback(Callback):\n",
    "    def on_trial_result(self, iteration, trials, trial, result, **info):\n",
    "        print(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff064ab-2cf1-4144-9601-82bc8eec0143",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune.run(\n",
    "    objective,\n",
    "    config=search_space,\n",
    "    callbacks=[PrintCallback()]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
