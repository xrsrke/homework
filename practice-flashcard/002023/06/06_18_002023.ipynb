{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c48c4e75-482e-4b74-abca-ef7cf3ebf8df",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04f3dfbd-3fee-4c37-a38b-1ad4e34ede4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1300c54e-fcee-4be0-8a42-b20e85105a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_grad_enabled(input):\n",
    "    return torch.is_grad_enabled and input.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "120a5594-0ae2-4f3d-a749-bb8646a2d891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _broadcast(input):\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97ca4bcb-844e-468c-9407-c224a1578b54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _reduce(input):\n",
    "    world_size = torch.distributed.get_world_size(group=parallel_group)\n",
    "    \n",
    "    if world_size == 1:\n",
    "        return input\n",
    "    \n",
    "    torch.distributed.all_reduce(input, group=parallel_group)\n",
    "    \n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e1909e-68fb-4e4d-a0a6-498f9f01b944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Broadcast(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return _broadcast(input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        return _reduce(grad_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eed0d1b3-96bc-4626-b266-4ac9245bf1b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def broadcast_with_forward_and_backward(input):\n",
    "    if is_grad_enabled(input):\n",
    "        output = Broadcast.apply(input)\n",
    "    else:\n",
    "        output = _broadcast(input)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee9b27b5-3b55-4024-85b0-ca79528f92b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class f(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        torch.distributed.all_reduce(grad_input)\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e421b6d0-de82-4239-a022-bfb70ed086cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class g(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        world_size = torch.distributed.get_world_size()        \n",
    "        inputs = [torch.empty_like(input) for _ in range(world_size)]\n",
    "        torch.distributed.all_gather(inputs, input)\n",
    "        inputs = torch.cat(inputs, dim=-1)\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        rank = torch.distributed.get_rank()\n",
    "        \n",
    "        dim_size = grad_input.shape[-1]\n",
    "        dim_size_per_partrition = dim_size // world_size\n",
    "        \n",
    "        grads = torch.split(grad_input, dim_size_per_partrition, dim=-1)\n",
    "        return grads[rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46c9f4e0-63db-4d29-a3d1-90790d1f31fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ColumnParallellLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output_size_per_partrition = output_size // world_size\n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_partrition,\n",
    "            self.input_size\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_partrition\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_parallel = f.apply(input)\n",
    "        output_paralell = F.linear(input, self.weight, self.bias)\n",
    "        outputs = g.apply(output_paralell)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018b6049-11e6-425a-87ea-9d6945c4d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = torch.cuda.Event(enable_timing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2f55f4-bb5e-4a25-99bd-bc8c7bba3a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "end = torch.cuda.Event(enable_timing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e1f69b-0762-4aaa-9163-a12dbda8a800",
   "metadata": {},
   "outputs": [],
   "source": [
    "start.record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70945043-753c-4485-bc11-7e86b084ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "hardshit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7176b4-2554-49cd-b9f2-b686465216f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "end.record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c505d1-6a6a-451b-b386-1babfd955f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f17e4-6f73-433c-956d-35f40b04f8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time = start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337fe70-586f-40c1-bacf-6055a2b00837",
   "metadata": {},
   "outputs": [],
   "source": [
    "file system, memory sharing, message passing, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62f08c62-ddc5-4c1a-8a68-72377ac6ae85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StartDependency(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        phony = torch.zeros(1, requires_grad=False, device=input.device)\n",
    "        return input, phony\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input, grad_phony):\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cc22ca9-e5e1-4a9f-b354-fae7043fdd2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EndDependency(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, phony):\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20116601-79a3-4327-b2e7-67ae5b025dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dependency(start_batch, end_batch):\n",
    "    start_batch, phony = StartDependency.apply(start_batch)\n",
    "    end_batch = EndDependency.apply(end_batch, phony)\n",
    "    return start_batch, end_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc501ce-69e8-49cb-a946-d7da96f58afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int i = 0;\n",
    "    \n",
    "    while (i <= 5) {\n",
    "        std::cout << i;\n",
    "        i++;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8edf778f-f887-4b2b-9c63-a9da163ae8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "316a913d-433f-4151-bda1-0687323b257e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_forward_pass_using_data_parallelism(model, input, device_ids, output_id):\n",
    "    models = nn.parallel.replicate(model, device_ids)\n",
    "    inputs = nn.parallel.scatter(input, device_ids)\n",
    "    \n",
    "    logit = nn.parallel.parallel_apply(models, inputs)\n",
    "    logits = nn.parallel.gather(logit, output_id)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d68c2e75-53bf-47af-aaca-8f11c5835051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35730798-cd10-4127-8d62-28f058363cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachedDataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        super().__init__()\n",
    "        self.filename = filename\n",
    "        self.data = None\n",
    "    \n",
    "    def prefetch(self, idxs):\n",
    "        if all([i in self.cached_index for i in idxs]):\n",
    "            return\n",
    "        \n",
    "        if not self.data:\n",
    "            self.data = torch.load(filename)\n",
    "        \n",
    "        total_elements = sum([self.data[i].numel() for i in idxs])\n",
    "        self.cache = torch.zeros(total_elements, dtype=self.data.dtype)\n",
    "        \n",
    "        offset = 0\n",
    "        for i in ixs:\n",
    "            n_elements = self.data[i]\n",
    "            self.cache[offset:offset+n_elements] = self.data[i].view(-1)\n",
    "            offset += n_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff88f631-7f6a-4bb9-ba71-bbe1560cc689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from contextlib import contextmanager\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d813f445-f495-4d7c-916c-73da8ad3c695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wait_and_execute(device, in_queue, out_queue):\n",
    "    while True:\n",
    "        task = in_queue.get()\n",
    "        \n",
    "        try:\n",
    "            output = task()\n",
    "        except:\n",
    "            out_queue.put((None, False))\n",
    "            continue\n",
    "        \n",
    "        out_queue.put((output, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947da881-28de-4afe-8595-7529a1ebc8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def spawn_workers(devices):\n",
    "    in_queues = []\n",
    "    out_queues = []\n",
    "    workers = {}\n",
    "    \n",
    "    for device in devices:\n",
    "        try:\n",
    "            in_queues, out_queues = workers[device]\n",
    "        except Exception:\n",
    "            in_queue = Queue()\n",
    "            out_queue = Queue()\n",
    "            workers[device] = (in_queue, out_queue)\n",
    "            \n",
    "            thread = Thread(\n",
    "                target=wait_and_execute,\n",
    "                args=(device, in_queue, out_queue),\n",
    "                daemon=True\n",
    "            )\n",
    "            thread.start()\n",
    "        \n",
    "        in_queues.append(in_queue)\n",
    "        out_queues.append(out_queue)\n",
    "    \n",
    "    yield (in_queues, out_queues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b0bbed-9d5a-4793-bd9a-690233b4f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast, scatter, reduce, gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256f68c7-541b-4960-a273-41b9993cceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock cycle 1: backward(m, n)\n",
    "clock cycle 2: backward(m, n-1), backward(m-1, n)\n",
    "clock cycle 3: backward(m, n-2), backward(m-1, n-1), backward(m-2, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b6653a4-e7a4-416d-8c81-afdb07963e32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33794255-0ee9-4c6c-923a-ae72fca269da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationTrainer(Trainer):\n",
    "    def __init__(self, teacher_model):\n",
    "        super().__init__()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a1f125-044d-4004-ac8d-875a7db3032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, n, i, d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
