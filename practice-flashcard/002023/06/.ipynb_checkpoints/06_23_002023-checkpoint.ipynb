{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7567dcfe-7c01-49ab-afc1-4f7651c575ed",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "495cebcf-d993-41d5-ba93-27b19d51197c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2560e2-337c-4880-9cc8-c01dda1ccca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_stream(source_stream, target_stream):\n",
    "    if isinstance(target_stream, torch.cuda.Stream):\n",
    "        if isinstance(source_stream, torch.cuda.Stream):\n",
    "            # GPU waits for GPU\n",
    "            source_stream.wait_stream(target_stream)\n",
    "        else:\n",
    "            # CPU waits for GPU\n",
    "            target_stream.syncronous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "325c2f79-c5a7-4ab9-8d3b-c4f389b90f16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Wait(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, prev_stream, next_stream, input):\n",
    "        ctx.prev_stream = prev_stream\n",
    "        ctx.next_stream = next_stream\n",
    "        \n",
    "        wait_stream(\n",
    "            source_stream=next_stream,\n",
    "            target_stream=prev_stream\n",
    "        )\n",
    "        \n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        prev_stream = ctx.prev_stream\n",
    "        next_stream = ctx.next_stream\n",
    "        \n",
    "        wait_stream(\n",
    "            source_stream=prev_stream,\n",
    "            target_stream=next_stream\n",
    "        )\n",
    "        \n",
    "        grad_stream = [None, None]\n",
    "        \n",
    "        return grad_stream + grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af09957-e7f6-4a81-9b7c-f501c8a8d468",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock cycle 1: backward(m, n)\n",
    "clock cycle 2: backward(m, n-1), backward(m-1, n)\n",
    "clock cycle 3: backward(m, n-2), backward(m-1, n-1), backward(m-2, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4071f126-a6a6-41a8-b007-da3f4ca57b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "node > pod > continer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1c680d-8e02-49fd-b971-ccf2e194151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: scale the loss using the scaling factor\n",
    "step 2: calculate the gradient using the scaled loss\n",
    "step 3: unscale the gradient using the scaling factor\n",
    "step 4: update the model's parameters with respect to unscaled gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db3d22b-1d94-4abf-bd82-24c742c8962e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VocabParallelEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        self.num_embeddings_per_partrition = num_embeddings // world_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.num_embeddings_per_partrition,\n",
    "            self.embedding_dim\n",
    "        ))\n",
    "        self.vocab_start_idx, self.vocab_end_idx = self.get_vocab_range(\n",
    "            self.num_embeddings_per_partrition\n",
    "        )\n",
    "    \n",
    "    def get_vocab_range(self, num_embeddings_per_partrition):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        start_idx = rank*num_embeddings_per_partrition\n",
    "        end_idx = rank*num_embeddings_per_partrition\n",
    "        return start_idx, end_idx\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        mask = (tokens < self.vocab_start_idx) | (tokens > self.vocab_end_idx)\n",
    "        tokens = tokens - self.vocab_start_idx\n",
    "        tokens[mask] = 0.\n",
    "        \n",
    "        embeddings = F.embedding(tokens, self.weight)\n",
    "        mask_idxs = torch.where(mask == False)[1]\n",
    "        embeddings[:, mask_idxs, :] = 0.\n",
    "        \n",
    "        torch.distributed.all_reduce(embeddings)\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c27aa62-17b2-4336-a0dc-bdc4507fa1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: partrition\n",
    "step 2: rank\n",
    "step 3: init local\n",
    "step 4: sync\n",
    "step 5: move to buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990b0d5c-4b83-43ab-ab17-99d57d46c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cb7bab-cd9a-43c9-83cf-9e7e1d22a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start.record()\n",
    "\n",
    "hardshit()\n",
    "\n",
    "end.record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a646f22b-4767-4b8b-8ef7-7244808ad7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed_time_ms = start.elapsed_time(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c64431-3704-49d3-8568-52a7860dab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "new > running > blocked > terminate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "216ceb47-0031-46dc-86b2-65ea1cefce8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RowParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        world_size = torch.distributed.get_world_Size\n",
    "        self.input_size_per_partrition = input_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.output_size,\n",
    "            self.input_size_per_partrition\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.empty(\n",
    "            self.output_size\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        last_dim_size = input.shape[-1]\n",
    "        last_dim_size_per_partrition = last_dim_size // world_size\n",
    "        input_chunks = torch.split(\n",
    "            input,\n",
    "            last_dim_size_per_partrition,\n",
    "            dim=-1\n",
    "        )\n",
    "        \n",
    "        input_parallel = input_chunks[rank]\n",
    "        output_parallel = F.linear(input_parallel, self.weight, self.bias)\n",
    "        torch.distributed.all_reduce(output_parallel)\n",
    "        return output_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d0665dd-7faf-422f-9193-d747573bc960",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "world_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7768297-ff0c-442a-b8ed-f90352fd10ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tensor_model_parallel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fa3cda8-3295-4c7f-a6cb-a12047255b34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_model_parallel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5af601f6-c027-4a5c-b6bc-b527ebf6caac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_pipeline_model_parallel_groups = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02d915e2-341f-4771-94fb-16010cdecbad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2]\n",
      "[1, 3]\n",
      "[4, 6]\n",
      "[5, 7]\n",
      "[8, 10]\n",
      "[9, 11]\n",
      "[12, 14]\n",
      "[13, 15]\n"
     ]
    }
   ],
   "source": [
    "for i in range(pipeline_model_parallel_size):\n",
    "    start_rank = i*num_pipeline_model_parallel_groups\n",
    "    end_rank = (i+1)*num_pipeline_model_parallel_groups\n",
    "    \n",
    "    for j in range(tensor_model_parallel_size):\n",
    "        ranks = list(range(\n",
    "            start_rank+j,\n",
    "            end_rank,\n",
    "            tensor_model_parallel_size\n",
    "        ))\n",
    "        \n",
    "        print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3f6136-f683-49a4-8ab2-afe7aef8c2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = torch.distributed.get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f34b3b-4897-47d3-baeb-b71098ed3b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rank == 69:\n",
    "    torch.distributed.isend(x, dest=42)\n",
    "elif rank == 42:\n",
    "    torch.distributed.irecv(tensor_will_be_received_data, src=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e13aa5d-d140-4a5b-890d-6d49cfc34d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "Forward(x) -> output = Forward(x) -> Backward(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2048f893-2662-4652-ad43-bd992635821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment, configmap, services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2635ca53-7a2a-4f3b-bf14-834cdf104b3c",
   "metadata": {},
   "source": [
    "### MechInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ff15638-9838-43e7-bcc8-d34b7bc1132c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "induction_heads = [(6, 9), (4, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549d3cc6-68be-4c4f-b46f-afcc81299a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(repeated_text, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a0135-84f8-4416-b32d-9486b0f1fe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b721fa97-c2da-4e9c-8a33-df80c8b56461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c212c517-6c04-4a07-be8f-81eb8eb853b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for head_idx, layer_idx in induction_heads:\n",
    "    hook_name = get_act_name(\"attn\", layer_idx)\n",
    "    attention_pattern = cache[hook_name][0, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2801b680-2007-4f43-9ce3-3543535bc45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = interference.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383090c2-0969-455b-a6e6-2e8a32e31188",
   "metadata": {},
   "outputs": [],
   "source": [
    "polysemanticity = interference.pow(2).sqrt().sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5994468c-865b-4daa-83d1-7168b4c9851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.device(device):\n",
    "    total = x.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56a083f6-d931-4b46-9429-befefff0bc70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f008edd9-7b6f-4a0f-9a53-b44537f0b96d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def first_context():\n",
    "    print(\"entering the context\")\n",
    "    yield\n",
    "    print(\"leaving the context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d0e2b1-e44f-48dd-a509-a73f0ec8385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if some_number > 6\n",
    "    println(\"yes\")\n",
    "endif "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66956bc1-71fa-4bf1-a6ae-90080aa33f4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiplyConstant(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.input = input\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx):\n",
    "        return ctx.input + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "86c2e3df-fc1c-4ee6-a161-f42a07cbaaf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def use_stream(stream):\n",
    "    if not isinstance(stream, torch.cuda.Stream):\n",
    "        yield\n",
    "        return\n",
    "        \n",
    "    with torch.cuda.stream(stream):\n",
    "        yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23339890-9703-4652-bf33-8e53d1bfd611",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributed.get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51069099-ccd9-4c4f-be67-25810a7dfd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.parallel.scatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce90f58-6ffd-43dc-b8dc-3b9d677880bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c368408a-3034-4e9a-af4d-81168e44a541",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075f3d70-33e5-4f9a-8826-711071746f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.setAppName(app_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50af970a-8433-4826-944f-b6937f3339a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c8d199-7abe-421e-be3c-5f7c1d055e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c4d0844-6118-4de2-9c08-d47dfe82fb3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RowParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        self.input_size_per_partrition = input_size // world_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.output_size,\n",
    "            self.input_size_per_partrition\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.empty(\n",
    "            self.output_size\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        dim_size = input.shape[-1]\n",
    "        dim_size_per_partrition = dim_size // world_size\n",
    "        input_chunks = torch.split(\n",
    "            input,\n",
    "            dim_size_per_partrition,\n",
    "            dim=-1\n",
    "        )\n",
    "        input_parallel = input_chunks[rank]\n",
    "        output_parallel = F.linear(input_parallel, self.weight, self.bias)\n",
    "        \n",
    "        torch.distributed.all_reduce(output_parallel)\n",
    "        \n",
    "        return output_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdd1d5f-caaf-48f8-9dbf-45e3a2a0e021",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_partrition\n",
    "split\n",
    "process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac4ff13c-e5b2-4385-934f-0e785d2736ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f981f-7781-4cd4-997b-3e14365e8f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\n",
    "    (\"input\", \"output\"),\n",
    "    [(1, 1), (2, 4)]\n",
    ")\n",
    "def test_square(input, output):\n",
    "    assert square(input) == output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "465aaf12-27bf-461f-96ce-a177a15783cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractclassmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9774a450-b3ed-45af-ba23-3cab7441bbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Switchable(ABC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "680ed63d-d6d0-4704-9123-326b4810a3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, n, d_model):\n",
    "        super().__init__()\n",
    "        self.n, self.d_model = n, d_model\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        seq_len = len(tokens)\n",
    "        embeddings = torch.zeros(seq_len, self.d_model)\n",
    "        \n",
    "        for p in range(seq_len):\n",
    "            for i in range(self.d_model):\n",
    "                denominator = torch.pow(self.n, 2*i*self.d_model)\n",
    "                embeddings[p][i] = torch.cos(p/denominator) if i%2==0 else torch.sin(p/denominator)\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eda49e0c-8fda-42cb-9877-9ac9f6217552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_one_hot(idx, size):\n",
    "    xs = torch.zeros(size)\n",
    "    xs[idx] = 1\n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6459b674-9462-4780-bced-4a94dc50ea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_one_hot(3, 5).T @ user_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd50d7e1-8956-4e92-af01-60a9c7dc0549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_x(layer, inp, out):\n",
    "    add_log(layer, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ee6a84-f5bb-499a-b245-cc648d95b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_hook(model):\n",
    "    for layer in model:\n",
    "        layer.register_forward_hook(add_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4fe6d4-6adf-4059-b910-8e7e5868a352",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer:\n",
    "    def __init__(self, params, lr):\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        for p in params:\n",
    "            if p.requires_grad:\n",
    "                p -= p.grad * self.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862fe325-45a0-4e08-a9ef-282b9e70a2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.parallel.gather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a380d3-ed28-4aac-9444-546d48b39409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    return tokenizer(x[\"se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37706761-78df-47a6-9dbe-2ecc69e2257e",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset[\"sentence1\"].map(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2771805-6010-437a-9fc4-43a8ad289d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = RLTrainer(\n",
    "    \"PPO\",\n",
    "    config=ScalingConfig(num_workers=3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d01a2997-673c-46c3-8e3e-12df8a97632d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ray import tune\n",
    "from ray.tune.callback import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bfb07fd0-7d25-457a-98f1-db8afd190e56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PrintCallback(Callback):\n",
    "    def on_trial_result(self, iteration, trials, trial, result, **info):\n",
    "        print(\"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfd79e1-6e34-415a-9927-37a0f9cf8ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune.run(\n",
    "    objective,\n",
    "    config=search_space,\n",
    "    callbacks=PrintCallback()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c4f5c6-3fb1-41d1-8902-73a85fb6a1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(10):\n",
    "    action = env.action_space.sample()\n",
    "    env.step(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21a9fab-7d44-41c5-95a0-7dcac43bea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(ratio, epsilon):\n",
    "    return torch.clamp(ratio, min=1-epsilon, max=1+epsilon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
