{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e9fbb92-8e03-409f-9078-e48533b2e183",
   "metadata": {},
   "source": [
    "### MLE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5073ebee-799f-405b-9285-f828077fcbad",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b67a251-8b14-415b-9583-7d7923e6c210",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2616e5b2-aa6c-45c4-986a-d1db1331f721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f73953c8-abc7-4d6d-a8d0-d4da7d9853e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_communication(rank, world_size, config):\n",
    "    torch.distributed.init_process_group(\n",
    "        *config,\n",
    "        rank=rank,\n",
    "        world_size=world_size,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0dddb8-e0b0-4f44-8d6f-05a6281af5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rank in range(4):\n",
    "    process = Process(\n",
    "        target=init_communication,\n",
    "        args=(rank, world_size, config)\n",
    "    )\n",
    "    process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db213ed0-a9c2-4325-b32b-28bdcf9362ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9e1446-f73c-4a94-b691-3658a1bec631",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int x = 1;\n",
    "    std::cout << &x;\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f4efd1-8728-4968-b1c6-d46eab3d8dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    const float pi = 3.14;\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ccb8e1-2fa9-4e27-90eb-4dcf998bea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int file_size = 100;\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2185796-ca39-4ebf-8d50-ccea11576fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    std::cout << \"hello\" << std::endl;\n",
    "    std::cout << \"world\";\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c99a74-2ff3-4d76-8cb0-a557049aafac",
   "metadata": {},
   "outputs": [],
   "source": [
    "typedef int age_type;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1884d4a-c6da-4d02-be57-f4fc74b71238",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_microbatches = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6b76b7f-6074-416b-87c9-5b1eb0dae08d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_partritions = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87eee431-32f9-4f85-ac82-4638ac58cc67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_clock_cycles = n_microbatches + n_partritions - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37d88858-f23e-4f33-9690-e17bd9511d9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0)]\n",
      "[(1, 0), (0, 1)]\n",
      "[(2, 0), (1, 1), (0, 2)]\n",
      "[(3, 0), (2, 1), (1, 2)]\n",
      "[(3, 1), (2, 2)]\n",
      "[(3, 2)]\n"
     ]
    }
   ],
   "source": [
    "for clock_idx in range(n_clock_cycles):\n",
    "    start_partrition = max(clock_idx+1-n_microbatches, 0)\n",
    "    end_partrition = min(clock_idx+1, n_partritions)\n",
    "    \n",
    "    tasks = []\n",
    "    for partrition_idx in range(start_partrition, end_partrition):\n",
    "        microbatch_idx = clock_idx - partrition_idx\n",
    "        tasks.append((microbatch_idx, partrition_idx))\n",
    "    \n",
    "    print(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddcae15-81bd-4ef0-91f1-4ef62bfccc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "main thread > worker thread > task > cuda stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea175c3f-fe00-4e41-a4f7-accfe59828b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_grad_enabled(input):\n",
    "    return torch.is_grad_enabled() and input.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88e8a39e-1203-4a69-94eb-66538820269a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _broadcast(input):\n",
    "    world_size = torch.distributed.get_world_size()\n",
    "    if world_size == 1:\n",
    "        return input\n",
    "\n",
    "    torch.distributed.broadcast(input, group=parallel_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae281cba-2bff-4e41-83a4-cf5585aee1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reduce(input):\n",
    "    world_size = torch.distributed.get_world_size()\n",
    "    if world_size == 1:\n",
    "        return input\n",
    "    \n",
    "    torch.distributed.all_reduce(input, group=parallel_group)\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9a5f478-61dd-4c25-9470-334754117c64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Broadcast(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return _broadcast(input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        return _reduce(grad_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "209c257c-4a7e-4b65-a8f7-e17d0975f0b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def broadcast_with_forward_and_backward(input):\n",
    "    if is_grad_enabled(input):\n",
    "        output = Broadcast.apply(input)\n",
    "    else:\n",
    "        output = _broadcast(input)\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1d07089-c03a-494d-a15e-9c23fd4d3d19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class StartDependency(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        device = input.device\n",
    "        phony = torch.randn(1, requires_grad=False, device=device)\n",
    "        return input, phony\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input, grad_phony):\n",
    "        return grad_input, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b9d68fa-36e7-41c5-b3e0-2e9f364b5d90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EndDependency(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, phony):\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7258c631-f97a-4b72-a7fd-fc29f7c6cbe2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dependency(start_batch, end_batch):\n",
    "    start_batch, phony = StartDependency(start_batch)\n",
    "    end_batch = EndDependency(start_batch, phony)\n",
    "    return start_batch, end_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43fc17f-b187-473e-b642-dd1a1864b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock cycle 1: B_{m, n}\n",
    "clock cycle 2: B_{m-1, n}\n",
    "clock cycle 3: B_{m-2, n}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf66f28-106e-41b1-9f5f-c2e000170d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "typedef int age;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cd62e9-82f5-4ec8-b257-41b62b7a1558",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock cycle 1: Backward(4, 3), Recompute(3, 3)\n",
    "clock cycle 2: Backward(3, 3), Recompute(2, 3)\n",
    "clock cycle 3: Backward(2, 3), Recompute(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06ef08c1-6496-4709-989a-17f20ec01f39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36a932b-2515-46d0-9f6b-74efafc53e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachedDataset(DataLoader):\n",
    "    def __init__(self, filename):\n",
    "        super().__init__()\n",
    "        self.filename = filename\n",
    "        self.cached_idxs = {}\n",
    "        self.data = None\n",
    "    \n",
    "    def prefetch(self, idxs):\n",
    "        if all([idx in self.cached_idxs for idx in idxs]):\n",
    "            return\n",
    "        \n",
    "        if not self.data:\n",
    "            self.data = torch.load(self.filename)\n",
    "        \n",
    "        self.total_elements = sum([self.data[i].numel() for i in ixs])\n",
    "        self.cache = torch.zeros(total_elements, dtype=self.data.dtype)\n",
    "        self.cache_index.clear()\n",
    "        \n",
    "        offset = 0\n",
    "        for i in idxs:\n",
    "            n_elements = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210caae4-7b6a-4e75-8fe5-18bc2c59168a",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast, scatter, reduce, gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03104da7-e178-42dc-b5b0-2dd4b546a897",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "from queue import Queue\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000f705b-7831-4ae5-8c36-fca1368c81db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_and_execute(device, in_queue, out_queue):\n",
    "    while True:\n",
    "        task = in_queue.get()\n",
    "        \n",
    "        try:\n",
    "            output = task()\n",
    "        except Exception:\n",
    "            out_queue.put([None, False])\n",
    "            continue\n",
    "        \n",
    "        out_queue.put([output, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99412683-38e4-4dc7-809b-bfa29ef63dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def spawn_workers(devices):\n",
    "    in_queues = []\n",
    "    out_queues = []\n",
    "    workers = {}\n",
    "    \n",
    "    for device in devies:\n",
    "        try:\n",
    "            in_queue, out_queue = workers[device]\n",
    "        except Exception:\n",
    "            in_queue = Queue()\n",
    "            out_queue = Queue()\n",
    "            workers[device] = in_queue, out_queue\n",
    "            \n",
    "            thread = Thread(target=)\n",
    "        \n",
    "        in_queues.append(in_queue)\n",
    "        out_queues.append(out_queue)\n",
    "    \n",
    "    yield (in_queues, out_queues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a14561a-eb4d-4539-98e0-704626e94dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast, scatter, reduce, gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb768de5-e9fd-429a-b18e-e22c6d972124",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7d2fa6-7b9b-4d29-a9a4-9ce9b06ee68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachedDataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        super().__init__()\n",
    "        self.filename = filename\n",
    "        self.cached_index = {}\n",
    "        self.data = None\n",
    "        self.cache = {}\n",
    "    \n",
    "    def prefetch(self, idxs):\n",
    "        if all([i in self.cached_index for i in idxs]):\n",
    "            return\n",
    "        \n",
    "        if not self.data:\n",
    "            self.data = torch.load(filename)\n",
    "        \n",
    "        n_elements = sum([self.data[i].numel() for i in idxs])\n",
    "        self.cache = torch.zeros(n_elements, dtype=self.data.dtype)\n",
    "        \n",
    "        offset = 0\n",
    "        for i in idxs:\n",
    "            length = self.data[i].numel()\n",
    "            self.cache[offset:offset+length] = self.data[i]\n",
    "            offset += length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e1fb3-17cf-4de9-8c58-84c60078af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock cycle 1: backward(m, n)\n",
    "clock cycle 2: backward(m, n-1), backward(m-1, n)\n",
    "clock cycle 3: backward(m, n-2), backward(m-1, n-1), backward(m-2, n-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca57a9f-5089-46d4-ada4-f68a064eee2b",
   "metadata": {},
   "source": [
    "### AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae320f6-93ef-46c0-9ecd-c2166658ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0192e2ad-731f-44ef-98fe-4a0ec13a9a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.roll(x, shifts=1, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b36c694-f975-49de-9184-4dccc0f7b4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributed.recv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168b5745-7112-4884-921f-0b91066ce75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Function(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.input = input\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        return ctx.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672884f2-9b67-4643-a89f-043b71a9a041",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba77228-6473-4a4d-81b9-25f78a75dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_prompt = \"A told B: 'Persistence is all you need.' C replied back to \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123842a3-d700-4180-b903-baa8ef89fc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_tokens = model.to_tokens(corrupted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a79a8e-63b2-40f3-a6c8-04a2f25b6bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_token = model.to_single_token(\"John\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6b2a43-f673-44d8-9aef-0963e6303ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_activations = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e726bf1d-b856-45f6-85d3-2f682ff4fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, corrupted_activations = model.run_with_cache(corrupted_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43c77eb5-dfe4-41b8-8836-a5bfbd7e0ccd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec68fc96-83d6-47c8-830e-31f750d673e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "head_idx, layer_idx = 6, 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ee8d3c7-9477-4edb-b444-d010ac8b1206",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hook_name = utils.get_act_name(\"attn\", layer_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd919bb-1d2d-4e3e-91f7-5678521f8e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_head_activations = corrupted_activations[hook_name][:, head_idx, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b92e1db6-e1ce-4ba9-b4bc-1443372dd3ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_corrupted_head_activation(activations, hook):\n",
    "    activations[:, head_idx, :, :] = corrupted_head_activations\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0960620-6e35-45db-a878-ae8f81338bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    ", patched_activations = model.run_with_hooks(\n",
    "    tokens,\n",
    "    fwd_hooks=([hook_name, patch_corrupted_head_activation])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f11929-0dcc-45de-add7-5427a551c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_receiver_activations = patched_activations[receiver_hook_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78400c81-263b-41ca-8dcc-26a36b83cf80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_corrupted_receiver_activations(activations, hook):\n",
    "    return corrupted_receiver_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c9e64-4138-40ee-ab66-48dae9e06ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_hook(patch_corrupted_receiver_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064bad9b-c1d5-48e1-8ab9-49f4031692fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, patched_logits = model(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05219d82-fffd-4831-96d8-05669ccca29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_hooks()\n",
    "_, clean_logits = model(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5018e2-a8ba-4dac-b624-a14ff35d4d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logit_difference(clean_logits, corrupted_logits, target_token):\n",
    "    return corrupted_logits[:, -1, :][target_token] - clean_logits[:, -1, :][target_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442c818a-5c68-4708-904f-ab05467d66e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShortcutProjection(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "99f6c23f-39f7-4c21-8b2e-9f0a5bfe06ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_discounted_return_an_episode(rewards, discount_factor):\n",
    "    total = 0\n",
    "    \n",
    "    for k, reward in enumerate(rewards):\n",
    "        total += (discount_factor**k)*reward\n",
    "    \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5720d304-a7f3-4d50-9413-0c86197f82f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
