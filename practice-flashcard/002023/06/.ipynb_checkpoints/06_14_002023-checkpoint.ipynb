{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b86a3ba-4c62-4dd7-9e14-dd646c76061e",
   "metadata": {},
   "source": [
    "##### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab022c7-78dd-4586-9606-0290180ae019",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: load the full training data into disk\n",
    "step 2: idxs\n",
    "step 3: size(idxs)\n",
    "step 4: create a chunk in memory\n",
    "step 5: load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8214b03-2ad3-447d-b072-1b21fd3ab6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "int i = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457ec1b9-bcab-44c8-ac09-c95b582989e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a0bb24-3aa7-424a-a0e8-1c0051386442",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (; i < 10; i++) {\n",
    "    std::cout << i << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc87ffc-a8ba-4668-adcf-8bce960e868d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (auto x: xs) {\n",
    "    std::cout << x << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba28d67d-9815-459d-96c8-26c73e8bf6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment, configmap, service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3612afc-b96f-4449-bd4e-7f6989830051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6629f058-f725-497b-9add-687e755a798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_forward_pass_using_data_paralell(\n",
    "    model,\n",
    "    input,\n",
    "    device_ids,\n",
    "    output_id\n",
    "):\n",
    "    models = nn.parallel.replicate(model, device_ids=device_ids)\n",
    "    inputs = nn.parallel.scatter(input, device_ids)\n",
    "    \n",
    "    logit = nn.parallel.parallel_apply(models, inputs, device_ids)\n",
    "    logit = nn.parallel.gather(logit, output_id)\n",
    "    \n",
    "    return logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31ebb9bf-b5f8-4064-98e2-acf450e3e4a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_microbatches = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "558d4db5-1ac3-49e4-9400-6ca623131b40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_partritions = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6c51fc7-4534-4aea-92b1-35efe277caf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_clock_cycles = n_microbatches + n_partritions - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8576ae6e-e234-42b4-8e39-7f47110f6f7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0)]\n",
      "[(1, 0), (0, 1)]\n",
      "[(2, 0), (1, 1), (0, 2)]\n",
      "[(3, 0), (2, 1), (1, 2)]\n",
      "[(3, 1), (2, 2)]\n",
      "[(3, 2)]\n"
     ]
    }
   ],
   "source": [
    "for clock_idx in range(n_clock_cycles):\n",
    "    start_partrition = max(clock_idx+1-n_microbatches, 0)\n",
    "    end_partrition = min(clock_idx+1, n_partritions)\n",
    "    \n",
    "    results = []\n",
    "    for partrition_idx in range(start_partrition, end_partrition):\n",
    "        microbatch_idx = clock_idx - partrition_idx\n",
    "        # print((microbatch_idx, partrition_idx))\n",
    "        results.append((microbatch_idx, partrition_idx))\n",
    "    \n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6251db31-5aa7-40bc-81ae-a9f167e53e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread-based\n",
    "process-based\n",
    "vectorization\n",
    "stream processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0069b3ba-be37-4f34-b0a3-0fd1137fd9a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class f(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        torch.distributed.all_reduce(grad_output)\n",
    "        return grad_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2da4bef6-631b-42ef-96d2-da4db459ca37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class g(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        inputs = [torch.empty_like(input) for _ in world_size]\n",
    "        torch.distributed.all_gather(inputs, input)\n",
    "        inputs = torch.cat(inputs, dim=-1)\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        dim_size = grad_input.shape[-1]\n",
    "        dim_size_per_partrition = dim_size // world_size\n",
    "        \n",
    "        grad_chunks = torch.split(\n",
    "            grad_input,\n",
    "            dim_size_per_partrition,\n",
    "            dim=-1\n",
    "        )\n",
    "        \n",
    "        return grad_chunks[rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd2df550-a465-448c-86a8-7d5338a912ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ColumnParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size, world_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size_per_partrition = output_size // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_partrition,\n",
    "            self.input_size\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.empty(\n",
    "            self.output_size\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_parallel = f.apply(input)\n",
    "        output_parallel = F.linear(\n",
    "            input_parallel,\n",
    "            self.weight,\n",
    "            self.bias\n",
    "        )\n",
    "        outputs = g.apply(output_parallel)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf78687d-008a-4ac1-bc35-540c4a16660d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_forward_pass_using_data_parallel(\n",
    "    model, input,\n",
    "    device_ids, output_id\n",
    "):\n",
    "    models = nn.parallel.replicate(model, device_ids)\n",
    "    inputs = nn.parallel.scatter(input, device_ids)\n",
    "    \n",
    "    logit = nn.parallel.parallel_apply(models, inputs)\n",
    "    logits = nn.parallel.gather(logit, output_id)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50991a3-9c3b-4a3f-b5b9-3e234b5bac44",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast, reduce, scatter, gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22c7ccc-0080-4764-bc68-f8991d73eb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy loading, data-pretching, memory mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ab95d-caa8-436c-b1ca-b3bea17f1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "data parallel, tensor parallel, pipeline parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde91300-2899-47c1-8b00-428274ca391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "std::size(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843c316d-5c29-44f5-a68f-010603ba5177",
   "metadata": {},
   "outputs": [],
   "source": [
    "register > cache > ram > hard disk > external"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde15741-a636-45fb-b913-31d643d6dd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock cycle 1: Backward(4, 3), Recompute(3, 3)\n",
    "clock cycle 2: Backward(3, 3), Recompute(2, 3)\n",
    "clock cycle 3: Backward(2, 3), Recompute(1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc60304-93d8-4909-aed8-dff65b6a00f2",
   "metadata": {},
   "source": [
    "### MechInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0b3ac7e-f3d2-4fc3-adfc-9a02fe3f3f03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "components = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e483904f-56c5-4ce7-8218-a206b584bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "components.append(cache[\"embed\"])\n",
    "components.append"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fda1d1b-f0f9-460f-a075-f6ab46379b86",
   "metadata": {},
   "source": [
    "### AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c53f2e38-629f-4de2-9e93-ed3fd264c5e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4943926a-c802-4e7f-9801-20ca55d06180",
   "metadata": {},
   "outputs": [],
   "source": [
    "einsum(x, y, \"b d, b d -> \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d185f145-60fb-4e09-8a45-f2ef7a34f3a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class f(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        torch.distributed.all_reduce(grad_input)\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b08b19a1-1f10-499d-ae1b-6faed6b3639c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class g(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        inputs = [torch.empty(inputs) for _ in world_size]\n",
    "        torch.distributed.all_gather(inputs, input)\n",
    "        inputs = torch.cat(inputs, dim=-1)\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        world_size= torch.distributed.get_world_size()\n",
    "        dim_size = grad_input.shape[-1]\n",
    "        dim_size_per_partrition = dim_size // world_size\n",
    "        \n",
    "        grad_chunks = torch.split(\n",
    "            grad_input,\n",
    "            dim_size_per_partrition,\n",
    "            dim=-1\n",
    "        )\n",
    "        \n",
    "        return grad_chunks[rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f9740f9-4f94-4080-ad63-3180e1d8b53c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ColumnParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size, world_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output_size_per_partrition = output_size // world_size\n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_partrition,\n",
    "            self.input_size\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_partrition\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_parallel = f.apply(input)\n",
    "        output_parallel = F.linear(\n",
    "            input_parallel, self.weight, self.bias\n",
    "        )\n",
    "        outputs = g.apply(output_parallel)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c0895b9-0628-4c19-a512-e99bee645a55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_func = nn.KLDivLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c34eb82-c692-49dc-924d-3ff511c7154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = loss_func(\n",
    "    input=F.log_softmax(student_logits),\n",
    "    target=F.softmax(teacher_logits)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d82a481-11b8-4bf0-b117-8f69780c86ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
