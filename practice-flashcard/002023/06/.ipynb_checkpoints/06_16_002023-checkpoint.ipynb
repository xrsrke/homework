{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "007c8339-4f95-4366-a0e8-48d4e760a004",
   "metadata": {},
   "source": [
    "### MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f6b5ee6-790d-4eaa-b08e-a3af904168c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sqlalchemy.orm import sessionmaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247f29d4-b523-4f44-ac94-c5ccf675fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80488782-a95d-4995-9dce-fa2d87ceaf73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eecfa50f-2f7d-43fe-b834-c3948476a441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class XX(BaseModel):\n",
    "    secret: int\n",
    "    unv: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e12786-71b3-4cdd-956d-aa7797f606e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/secret\")\n",
    "def index():\n",
    "    return 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7fa2cdc-9abc-4e6b-80c6-6627fee24e95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "121ae0ca-dc3d-4e32-8a0d-e3c84c1148b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_raise():\n",
    "    with pytest.raises(ValueError) as err:\n",
    "        raise_exception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec91240c-c12c-42f4-95d7-233d63a907c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c508a6-ace9-4747-bca8-99b1b0796dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce(lambda x, y: x + y, numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba4bb10f-6ca3-4979-9bfb-1e67d1526ae7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f3123fc-6abf-4390-95d0-463f4c4cce32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NutritionInformation(TypedDict):\n",
    "    value: int\n",
    "    unit:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1f4953e-a4b7-4af2-9601-8e1cb3db1ef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RecipeNutritionInformation(TypedDict):\n",
    "    recipes_used: int\n",
    "    calories: NutritionInformation\n",
    "    carbs: NutritionInformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e138c093-6326-4161-8f59-2f12f402b9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "population, motor, conditioned, stimus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21baaed4-9ebc-4e5e-98c0-61f20b654a87",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c7461a3-5444-4ef4-8077-5bd420e7be0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92236a8-def6-4af1-bfe7-8d79bff27514",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5915f90a-f3e5-4b42-b953-eb04f7911b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    std::cout << \"hello world\";\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a33d148-3ad1-44f8-8237-291ce31199aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "from contextlib import contextmanager\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a882f8a3-a27c-48de-9579-d76dfdaaf319",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wait_and_execute(in_queue, out_queue):\n",
    "    while True:\n",
    "        task = in_queue.get()\n",
    "        \n",
    "        try:\n",
    "            output = task()\n",
    "        except:\n",
    "            output = False\n",
    "        \n",
    "        out_queue.put(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b39bdeb-4342-407d-b9fb-f1335b3ee7ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def spawn_worker(devices):\n",
    "    in_queues = []\n",
    "    out_queues = []\n",
    "    workers = {}\n",
    "    \n",
    "    for device in devices:\n",
    "        try:\n",
    "            in_queue, out_queue = workers[device]\n",
    "        except KeyError:\n",
    "            in_queue = Queue()\n",
    "            out_queue = Queue()\n",
    "            workers[device] = in_queue, out_queue\n",
    "            \n",
    "            t = Thread(\n",
    "                target=wait_and_execute,\n",
    "                args=(in_queue, out_queue, device),\n",
    "                daemon=True\n",
    "            )\n",
    "            t.start()\n",
    "        \n",
    "        in_queues.append(in_queue)\n",
    "        out_queues.append(out_queue)\n",
    "    \n",
    "    yield in_queues, out_queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17973588-cbae-48c4-b080-81a07b4b9c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "using namespace std;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4e08ea-6f8a-44b8-8ac8-7280ff7bdf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Book() {\n",
    "    public:\n",
    "        string title;\n",
    "        string author;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4efb0a-96e4-4ffe-a1b6-eb88a62f6639",
   "metadata": {},
   "outputs": [],
   "source": [
    "int zero() {\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20cb368-f8a5-4269-a0c8-10294c00fbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "api server, control manager, ectd, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f880fdc-1253-499f-82a3-ec5f1e9170fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f458398-bc13-4fc2-97bb-88efcbeabcec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def profile_times(model, batch):\n",
    "    records = [[] for _ in model]\n",
    "    \n",
    "    for idx, layer in enumerate(model):\n",
    "        start_time = time.time()\n",
    "        outputs = [layer(x) for x in batch]\n",
    "        \n",
    "        output_with_grad = [x for x in outputs if x.grad]\n",
    "        if output_with_grad > 0:\n",
    "            torch.autograd.backward(output_with_grad, output_with_grad)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        records[idx].append(end_time-start_time)\n",
    "\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2743da8-08b1-4ba6-b82a-d8f49515f955",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VocabParallelEmbedding(nn.Module):\n",
    "    def __init__(self, num_embedding, embedding_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        self.num_embedding_per_partrition = num_embedding // world_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.num_embedding_per_partrition,\n",
    "            self.embedding_dim\n",
    "        ), requires_grad=True)\n",
    "        self.start_vocab_idx, self.vocab_end_idx = self.get_vocab_range(\n",
    "            self.num_embedding_per_partrition\n",
    "        )\n",
    "    \n",
    "    def get_vocab_range(self, num_embedding_per_partrition):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        start_idx = rank * num_embedding_per_partrition\n",
    "        end_idx = start_idx + num_embedding_per_partrition\n",
    "        return start_idx, end_idx\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        mask = (tokens > self.vocab_start_idx) | (tokens < self.vocab_end_idx)\n",
    "        tokens = tokens - self.vocab_start_idx\n",
    "        tokens[mask] = 0.\n",
    "        \n",
    "        embeddings = F.embedding(tokens, self.weight)\n",
    "        mask_idxs = torch.where(mask == True)[1]\n",
    "        embeddings[mask_idxs] = 0.\n",
    "        \n",
    "        torch.distributed.all_reduce(embeddings)\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9fddda-3a27-46fb-8308-d05e99908b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: partrition\n",
    "step 2: rank\n",
    "step 3: device\n",
    "step 4: init local optimizer\n",
    "step 5: step\n",
    "step 6: broadcast\n",
    "step 7: sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c7657c1-b286-41b0-b347-502948a913dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_microbatches = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6faae2ce-3611-46c7-beaa-2637fcd0fc2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_partritions = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b57d8c1-83bf-4281-b665-90dfd35ef923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_clock_cycles = n_microbatches + n_partritions -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2339259-69bf-4a0c-8b24-ecf810ff1e90",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0)]\n",
      "[(1, 0), (0, 1)]\n",
      "[(2, 0), (1, 1), (0, 2)]\n",
      "[(3, 0), (2, 1), (1, 2)]\n",
      "[(3, 1), (2, 2)]\n",
      "[(3, 2)]\n"
     ]
    }
   ],
   "source": [
    "for clock_idx in range(n_clock_cycles):\n",
    "    start_partrition = max(clock_idx+1-n_microbatches, 0)\n",
    "    end_partrition = min(clock_idx+1, n_partritions)\n",
    "    \n",
    "    results = []\n",
    "    for partrition_idx in range(start_partrition, end_partrition):\n",
    "        microbatch_idx = clock_idx - partrition_idx\n",
    "        results.append((microbatch_idx, partrition_idx))\n",
    "    \n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1469cb2c-f1df-4511-adad-27505825bea9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_grad_enabled(input):\n",
    "    return torch.is_grad_enabled and input.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c18096f2-b0a9-4293-ac63-f6320994a3a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _broadcast(input):\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2664fd7a-2653-460b-a7db-22bd359774c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Broadcast(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        world_size = torch.distributed.get_world_size(\n",
    "            group=parallel_group\n",
    "        )\n",
    "        grads = [torch.empty_like(grad_input) for _ in range(world_size)]\n",
    "        torch.distributed.all_gather(grads, grad_input)\n",
    "        grads = torch.cat(grads, dim=-1)\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e5717b2-8da5-4258-bfb4-ba7bc4c1b021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def broadcast_with_forward_and_backward(input):\n",
    "    if is_grad_enabled(input):\n",
    "        output = Broadcast.apply(input)\n",
    "    else:\n",
    "        output = _broadcast.apply(input)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98e0a78-94f7-42f4-a3e5-049a212ea01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment, configmap, services"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23c3750-adaa-4b1e-9378-510662807816",
   "metadata": {},
   "source": [
    "### AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2bcb6e45-8458-461b-bf0a-5e90b8315398",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff2397a-093d-4843-ad36-3eace2191a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiplyConstant(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.input = input\n",
    "        return input\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        return ctx.input + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae93c157-27f0-487a-aa89-cf937ec8687b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualLayerNorm(nn.Module):\n",
    "    def __init__(self, d_model, dropout):\n",
    "        super().__init__()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8799861-d55c-4be0-ae05-d0264a74e360",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e96c378-a517-48dd-be00-bb67b487bd6e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_head):\n",
    "        super().__init__()\n",
    "        self.d_head = d_head\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        k = k.transpose(3, 2)\n",
    "        qk = torch.matmul(q, k)\n",
    "        scores = qk / math.sqrt(self.d_head)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scores = scores.mask_fill(mask==True, 1e-9)\n",
    "        \n",
    "        attn_weights = F.softmax(scores)\n",
    "        output = torch.matmul(attn_weights, v)\n",
    "        return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef85758-310a-479a-b7c0-1bf582d10984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
