{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd12e56a-b9bd-47e8-bb13-9446dbb69c96",
   "metadata": {},
   "source": [
    "### ML Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dccc3a-f898-48ae-ac9c-04c03943db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9499c5-201f-4eec-b4e0-a9d740ac5449",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e703639c-5c4f-49e0-a082-17c07cc06532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.decorators import dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f3d64d-691f-4609-954e-ed31d721b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dag\n",
    "def example(\n",
    "    dag_id=dag_id,\n",
    "    start_date=start_date\n",
    "):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0894988d-7240-4ddf-83a7-ca12e8f5d048",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.bash import BashOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2027ab-6eb3-44b4-9ed3-4bdec7189a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with DAG(\n",
    "    task_id=task_id\n",
    ") as dag:\n",
    "    task = BashOperator(\n",
    "        task_id=\"x\",\n",
    "        bash_command=\"echo hello world\"\n",
    "    )\n",
    "    \n",
    "    task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3511d67-c21b-4cc1-aec5-85ac4fb467a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.operators.python import PythonOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ff8e55-928a-4c38-9087-97dda3134b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_1(ti):\n",
    "    ti.xcom_push(\"x\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95fefad-0f67-4b8d-9774-5406642f57eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_2(ti):\n",
    "    x = ti.xcom_pull(\"x\", task_id=\"task_1\")[0]\n",
    "    y = x + 3\n",
    "    ti.xcom_push(\"y\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b421713b-eb9b-4702-87fc-7e76347823d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with DAG(\n",
    "    dag_id=dag_id,\n",
    "    start_date=start_date\n",
    ") as dag:\n",
    "    task_1 = PythonOperator(\"task_1\", python_callable=task_1)\n",
    "    task_2 = PythonOperator(\"task_2\", python_callable=task_2)\n",
    "    \n",
    "    task_1 >> task_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be2ef99-014a-4dad-809c-b97934e6aae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c9cdc-4e54-4060-890c-cad80054181b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with DAG(dag_id=\"nnn\", start_date=datetime(2023, 5, 31)) as dag:\n",
    "    task = PythonOperator(\"task\", python_callable=say_hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ed1f3b-1222-4a57-b2e9-eeca3210e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.decorators import dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2394397-771f-459d-87f5-5bbf93d7095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dag(start_date=start_date)\n",
    "def fck():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d594f6eb-f801-4e3f-a9e0-d6ef3b460758",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.decorators import dag, task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290cb75-f8fb-46b6-8889-464c47dab8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dag(dag_id=dag_id, start_date=start_date)\n",
    "def example():\n",
    "    @task\n",
    "    def get_name(): pass\n",
    "\n",
    "    @task\n",
    "    def get_age(): pass\n",
    "\n",
    "    @task\n",
    "    def greet(name, age):\n",
    "        pass\n",
    "    \n",
    "    name = get_name()\n",
    "    age = get_age()\n",
    "    \n",
    "    greet(name, age )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e712b3-44c8-4d8f-a157-94df80fae284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import FlowSpec, step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0f839f-a7f8-488e-bd77-79f7dae3f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountFlow(FlowSpec):\n",
    "    @step\n",
    "    def start(self):\n",
    "        self.words = words\n",
    "        self.next(self.count, foreach=\"words\")\n",
    "    \n",
    "    @step\n",
    "    def count(self):\n",
    "        self.length = len(self.input)\n",
    "        self.next(self.join)\n",
    "    \n",
    "    @step\n",
    "    def join(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125886ae-9a58-495b-ac4c-7fcad4c220a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075c0f31-ab26-4b46-b9a7-48689e635511",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\n",
    "    \"input, output\",\n",
    "    ([1, 1], [2, 4])\n",
    ")\n",
    "def test_square(input, output):\n",
    "    assert square(input) == output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0293fafa-9197-4618-922c-e85ba228a46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "[task_3, task_2] >> task_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cbcce2-69fd-4cc5-a33c-d87ef04758cf",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3e9e8a-9304-4d79-9d42-83752a1d3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: create the data on cpu\n",
    "step 2: reserve a portion in memory in gpu\n",
    "step 3: copy the data from cpu to gpu\n",
    "step 4: determine ___\n",
    "step 5: launch a new kernel\n",
    "step 6: execute\n",
    "step 7: copy the results from gpu to cpu\n",
    "step 8: memory dealocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dce451d-9798-45e0-8792-3e3e3c8248ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid > thread block > thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ffa35b-1301-4988-8972-cdcf01bfdaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "global memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f33341-a8af-440d-906c-c3a51e0b6c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: replicate the model\n",
    "step 2: mini-batch -> micro-batch\n",
    "step 3: do forward and backward\n",
    "step 4: average the gradient\n",
    "step 5: update according to the average gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68e313b-d28b-4309-a0a7-9d5ac415e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b0ac11-4c0e-4dee-a0fc-1b16d198c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabParallelEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim_per_partrition = embedding_dim // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.num_embeddings,\n",
    "            self.embedding_dim_per_partrition\n",
    "        ))\n",
    "        self.vocab_start_idx, self.vocab_end_idx = self.get_vocab_range(\n",
    "            self.embedding_dim_per_partrition\n",
    "        )\n",
    "    \n",
    "    def get_vocab_range(self, embedding_dim_per_partrition):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        start_idx = rank*embedding_dim_per_partrition\n",
    "        end_idx = start_idx+embedding_dim_per_partrition\n",
    "        return start_idx, end_idx\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        mask = (tokens < self.vocab_start_idx) | (tokens > self.vocab_end_idx)\n",
    "        masked_tokens = tokens - self.vocab_start_idx # why?\n",
    "        masked_tokens[mask] = 0.\n",
    "        \n",
    "        embeddings = F.embedding(masked_tokens, weight=self.weight)\n",
    "        mask_idxs = torch.where(mask==False)[1]\n",
    "        embeddings[mask_idxs] = 0.\n",
    "        \n",
    "        torch.distributed.all_reduce(embeddings)\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91caa4d-2ae3-4125-a759-7ee0e887353e",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: copy fp16 and fp32 of weight\n",
    "step 2: do forward pass in fp16\n",
    "step 3: update "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303c897-ab82-4c44-80fc-ee8776af7dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4e2262-16d3-4146-b35c-16c1004ae1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MPU:\n",
    "    def __init__(self, master_addr, master_port, backend):\n",
    "        if not torch.distributed.is_initialized():\n",
    "            rank = os.getenv(\"RANK\")\n",
    "            world_size = os.getenv(\"WORLD_SIZE\")\n",
    "            os.environ[\"MASTER_ADDR\"] = master_addr\n",
    "            os.environ[\"MASTER_PORT\"] = master_port\n",
    "            \n",
    "            torch.distributed.init_process_group(\n",
    "                rank=rank,\n",
    "                world_size=world_size,\n",
    "                backend=backend\n",
    "            )\n",
    "            \n",
    "            device_count = torch.distributed.device_count()\n",
    "            if device_count > 0:\n",
    "                device = rank % device\n",
    "                torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa1e59f-c0c7-41e8-b35e-dd20445a91f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a16eef-7fa5-473e-b673-0604c8286922",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachedDataset:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.data = None\n",
    "        self.cache_index = {}\n",
    "    \n",
    "    def prefetch(self, idxs):\n",
    "        if all(i in self.cache_index for i in idxs):\n",
    "            return\n",
    "        \n",
    "        if not self.data:\n",
    "            self.data = torch.load(self.filename)\n",
    "        \n",
    "        total_elements = [self.data[i] for i in idxs]\n",
    "        self.cache = torch.empty(total_elements, dtype=self.data.dtype)\n",
    "        self.cache_index.clear()\n",
    "        \n",
    "        offset = 0\n",
    "        for i in idxs:\n",
    "            n_elements = self.data[i].numel()\n",
    "            self.cache[offset:offset+n_elements] = self.data[i]\n",
    "            self.cache_index[i] = offset\n",
    "            offset += n_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19069c0-ca15-4b68-a805-e6afc3d273f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import ProfilerActivity, profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe01efe-9385-4e35-b62d-f55da8e0690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer.param_groups:\n",
    "    for param in param_group[\"params\"]:\n",
    "        print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eff9d3-1158-4fdb-b409-b4aac4ef1085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b73b57e-c974-4628-a514-d9938e06fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(repeated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01327e8f-b7ac-4e63-8ef1-aa467aad0185",
   "metadata": {},
   "outputs": [],
   "source": [
    ", cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a44d9a-9fab-4797-866b-251d5cf1e355",
   "metadata": {},
   "outputs": [],
   "source": [
    "induction_heads = [(6, 9), (4, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea29ffb-f19e-405c-9328-d94248e761ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_patterns = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd068d85-4ab5-4cfc-aaec-3acbb3521b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "for head_idx, layer_idx in induction_heads:\n",
    "    layer_attention_pattern = cache[\"attn\", layer_idx]\n",
    "    attention_pattern = layer_attention_pattern[0, head_idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
