{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cc40ff6-6a0a-4db9-bed3-875a5003073f",
   "metadata": {},
   "source": [
    "### ML Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bfa71e6-8012-4c38-877a-2c442ebdf4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import great_expectations as ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2438f513-b487-4263-a002-56c9c8b1b2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ge.dataset.PandasDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9061fe-f429-425c-b4f2-244dee3c649d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.expect_table_column_to_match_ordered_list(ordered_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16779e12-4fd3-4ee2-9753-645bc5b67234",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ge.dataset.PandasDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6948c72-9faa-4af6-92b1-3d7b42fb8daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.expect_column_values_to_be_unique(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b301d69-9366-45b8-9e09-1ece4ce78791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd6438c-bd1e-403a-9e7f-2e1e6f8d634f",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int a = 69;\n",
    "    int* p = &a;\n",
    "    \n",
    "    std::cout << *p;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790900fc-09d3-4b59-87a6-cf22aa8fb0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Monster() {\n",
    "    public:\n",
    "        Monster() {\n",
    "            std::cout << \"Creating a monster!!\";\n",
    "        }\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bd0db4-a725-406e-9e60-2cc8bd98aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Number() {\n",
    "    public:\n",
    "        int value;\n",
    "        \n",
    "        int isLargerThanZero() {\n",
    "            if (value > 0) {\n",
    "                return 1;\n",
    "            } else {\n",
    "                return 0;\n",
    "            }\n",
    "        };\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47ca367-38e8-4f78-9de3-33df384142f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestFruit:\n",
    "    def setup_method(self):\n",
    "        self.fruit = Fruit(\"banana\")\n",
    "    \n",
    "    def test_fruit(self):\n",
    "        assert self.fruit.name == \"banana\"\n",
    "    \n",
    "    def teardown_method(self):\n",
    "        del self.fruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aa4674-cc51-454e-ae1d-1cd8f6a9533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Deployment > Ingress > Service > Pod > Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c644315-b077-4f0a-9c1e-a6fa6b122860",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: create a chunk in memory\n",
    "step 2: load the file to that chunk\n",
    "step 3: read and write\n",
    "step 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d6a91b-df15-4324-b134-b8587349a713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "using namespace std;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4bcab8-a369-4676-a01f-d4ee8c010bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Book() {\n",
    "    string title;\n",
    "    string author;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a54ed53-7bba-48f0-9a98-2d957b8c5bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Book() {\n",
    "    public:\n",
    "        string title;\n",
    "    \n",
    "        Book(string aTitle) {\n",
    "            title = aTitle;\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3b58f2-cceb-4be6-bf99-5765e7b96dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: load the dataset\n",
    "step 2: add exepctations\n",
    "step 3: suit\n",
    "step 4: validate the suit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2346d6b-f0ba-4dca-b09b-cc0688b13bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: split mini-batch into micro-batches\n",
    "step 2: generate a new cuda stream for each micro-batch on each device\n",
    "step 3: generate a pipline and run it\n",
    "stpe 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99406778-083e-4c5b-94ea-1b2a049ab257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebf97bb-6a02-49e4-8781-5b27e370a803",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.mark.parametrize(\n",
    "    \"input, output\",\n",
    "    ([1, 1], (2, 4))\n",
    ")\n",
    "def test_square(input, output):\n",
    "    assert square(input) == output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54cdaa9-a008-405d-a228-6e5ebf412a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.query(User).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837357df-0898-49d5-832e-501bb682e6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ge.dataset.PandasDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60d47e6-9729-4bd9-bd76-df46067aa02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df.expect_column_values_to_be_unique(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd19e548-69d1-4f51-a10e-7aec900c47a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.expect_table_columns_to_match_ordered_list(\n",
    "    ordered_columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4392e63f-b03d-4926-8fbd-6588f7d111df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ge.dataset.PandasDataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e38ca28e-5a89-447f-88b2-b75cb63804ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ad2e62e-0e08-44c4-8bec-dfb70451eda8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32094182-d8a5-49ab-bb9f-dec83c07a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pq.read_table(PARQUET_URL )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966184f0-54b2-47c5-a915-379b0377880a",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2986ad15-f9bc-4c10-a9e6-99ceaabcb00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03126e75-ab66-4f4d-b7f4-e7e61d0354b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int value;\n",
    "    std::cout << \"enter a number\";\n",
    "    std::cin >> value;\n",
    "    std::cout << \"you entered: \" << value;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f7bd6b-81d7-49ba-b0fe-031c978ef2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: split a mini-batch into mirco-batches\n",
    "step 2: create a new cuda stream for each mini-batches on each device\n",
    "step 3: create and run pipeline\n",
    "step 4: gather micro-batches into a mini-batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c04be5e8-8962-483c-9187-0b7c0c982663",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "world_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20e20c01-bd87-4e49-8cac-5602da6dd2fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numel_per_rank = [0 for _ in range(world_size)]\n",
    "param_per_rank = [[] for _ in range(world_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d2bd14-13ac-46cd-ac90-06a91c537c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_param = sorted(param_list, key=lambda x: x.numel(), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560abacc-e042-470c-b20f-0e6007ff3e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in sorted_param:\n",
    "    next_device = numel_per_rank.index(min(numel_per_rank))\n",
    "    \n",
    "    param_per_rank[next_device].append(param)\n",
    "    numel_per_rank[next_device] += param.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66965208-e905-4d06-a2b7-7a757e7b5e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int numbers[] = {1, 2, 3, 4, 5};\n",
    "    \n",
    "    for (int i=0; i < 3; i++) {\n",
    "        std::cout << numbers[i];\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db17e57-10d8-46a0-899f-b3de10cb0fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int i = 0;\n",
    "    while (i <= 5) {\n",
    "        std::cout << i;\n",
    "        i++;\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645064f5-4f55-4b5f-bac8-1fafa8b05436",
   "metadata": {},
   "outputs": [],
   "source": [
    "void say_hello() {\n",
    "    std::cout << \"hello\";\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d785ec-80bd-4a59-844c-8a5ec7b85727",
   "metadata": {},
   "outputs": [],
   "source": [
    "void getMax(int x1, int x2) {\n",
    "    int result;\n",
    "    \n",
    "    if (x1 > x2) {\n",
    "        result = x1;\n",
    "    } else {\n",
    "        result = x2;\n",
    "    }\n",
    "    \n",
    "    std::cout << result;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a59c5b-22aa-434a-8ea2-1f235a69588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int x = 1;\n",
    "    std::cout << &x;\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9646fc-b4c3-4f04-95a0-bf1040a643a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid > thread block > thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdf04d8-0dc9-497a-928f-01d9e32e8f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "using namespace std;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b28ac59-0a44-4fca-96ba-806bdc21b6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "void say_name(string name) {\n",
    "    cout << name;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee10f4-625b-4ee1-a848-04f01f0c8ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    std::cout << \"hello\" << std::endl;\n",
    "    std::cout << \"world\";\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11235ab-6454-4765-b2f7-14842b9cac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    for (int i = 1; i <= 5; i++) {\n",
    "        std::cout << i;\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e22a0403-5c73-4e63-a078-67ecf1c9a96b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b57e9976-3052-4e43-8404-7fc5042d2b5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_model(model, balances, devices):\n",
    "    partritions = OrderedDict()\n",
    "    layers = []\n",
    "    index = 0\n",
    "    \n",
    "    for layer in model:\n",
    "        layers.append(layer)\n",
    "        \n",
    "        if len(layers) == balances[index]:\n",
    "            partritions[device[index]] = layers\n",
    "            layers.clear()\n",
    "        \n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22f4ba7-267c-4668-aeb2-b82206d41198",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: partrition params\n",
    "step 2: move partrition to rank\n",
    "step 3: move to device\n",
    "step 4: init local optimizer\n",
    "step 5: step\n",
    "step 6: broadcast\n",
    "step 7: sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d558ccc7-ab8a-474e-9846-9da1d7c6a157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bb1cb7-344c-49ac-ba19-d7cdda2de519",
   "metadata": {},
   "outputs": [],
   "source": [
    "void plus_one(int number) {\n",
    "    return number + 1; \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd19024-87f2-4a1b-9d2f-725e8e00e195",
   "metadata": {},
   "outputs": [],
   "source": [
    "using namespace std;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133c8d79-5bb4-4530-9844-c6dd16e9272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    cout << \"hello\";\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c4f8a1-906f-44c8-ae37-22ecf3580955",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Number() {\n",
    "    public:\n",
    "        int value;\n",
    "    \n",
    "        int isLargerThanZero() {\n",
    "            if (value > 0) {\n",
    "                return 1;\n",
    "            } else {\n",
    "                return 0;\n",
    "            }\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bf660d-4d65-4a19-abca-1534ed96d795",
   "metadata": {},
   "outputs": [],
   "source": [
    "void numberToColor(int number) {\n",
    "    std::string color;\n",
    "    \n",
    "    switch\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa32ffe9-a16e-4f17-bad7-f5c5fcd72dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int tensor[3][2] = {\n",
    "        {1, 2},\n",
    "        {3, 4},\n",
    "        {5, 6}\n",
    "    };\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6334737a-584e-4a20-9eba-850bbf5d764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Monster() {\n",
    "    public:\n",
    "        Monster() {\n",
    "            std::cout << \"creating a monster\";\n",
    "        }\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e087e7-ca1e-4ba7-9d23-ebeb725cb820",
   "metadata": {},
   "outputs": [],
   "source": [
    "global memory > shared memory > register memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fb6c57-b77b-4df7-b164-eb7583740633",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = [0, 1, 3, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe336ad6-0102-4170-a09c-65ddf1ecc193",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f62f1b9-0259-4637-831b-f6cca020f0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = torch.distributed.ProcessGroup(ranks=ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4094f00e-d598-46c6-a9b6-9440f9e7239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = torch.distributed.get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5859a7d3-b67d-469f-b0bc-110468b67d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rank == 0:\n",
    "    torch.distributed.broadcast(x, src=0, group=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80952e4-8b86-4c88-970f-016ee85a49ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int numbers[] = {1, 2, 3, 4};\n",
    "    return numbers[0];\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d461d5-e509-43e4-93db-f75b62f0035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Book() {\n",
    "    public:\n",
    "        std::string title;\n",
    "    \n",
    "        Book(std::string aTitle) {\n",
    "            title = aTitle;\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00afa6be-2012-48f2-aac6-12ea193359be",
   "metadata": {},
   "outputs": [],
   "source": [
    "string numberToColor(int number) {\n",
    "    string color;\n",
    "    \n",
    "    switch (number) {\n",
    "        case 1:\n",
    "            color = \"red\";\n",
    "            break;\n",
    "        case 2:\n",
    "            color = \"blue\";\n",
    "            break;\n",
    "    }\n",
    "    \n",
    "    return color;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cdf837-e4b5-4842-ab6c-2f4c90e5ebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int a = 69;\n",
    "    int* p = &a;\n",
    "    \n",
    "    std::cout << *p;\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533248bc-8969-4a22-a0a8-6129221bd96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: partrition the params\n",
    "step 2: extract the partirtion to rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc2dc280-3de0-448e-a2d3-cc6eeed85a41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db14b9e0-e9d1-404a-8beb-d932361325f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ParallelMLP(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.dense_h_to_4h = ColumnParallelLinear(\n",
    "            input_size=hidden_size,\n",
    "            output_size=hidden_size*4\n",
    "        )\n",
    "        self.gelu = nn.GELU()\n",
    "        self.dense_4h_to_h = RowParallelLinear(\n",
    "            input_size=hidden_size*4,\n",
    "            output_size=hidden_size\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        intermediate_output = self.dense_h_to_4h(x)\n",
    "        intermediate_output = self.gelu(intermediate_output)\n",
    "        output = self.dense_4h_to_h(intermediate_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e000603b-421f-4ba5-ac45-521fce5332bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "new > ready > running > x > terminated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b263eb-b431-4925-9a04-7f406c87278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_tokens = model.to_tokens(repeated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7823cb8a-ec28-4697-898e-8867336fa1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "induction_heads = [(6, 9), (4, 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e044d3-a57c-4e24-9c9c-c1a96d1f9162",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(repeated_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6aabd3e2-3a19-4011-a235-b1dca823cf35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformer_lens import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f262ddda-d174-48ce-a866-f8dd5e5cdcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48626d41-1544-4c9a-858c-0cfe4e157fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for head_idx, layer_idx in induction_heads:\n",
    "    hook_name = utils.get_act_name(\"attn\", layer_idx)\n",
    "    layer_attn_pattern = cache[hook_name]\n",
    "    attn_pattern = layer_attn_pattern[0, head_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d5f303-71c3-4e71-ae05-494baf95688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: compute activations of part 1\n",
    "step 2: compute the activation of part 2 using part 1\n",
    "step 3: remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5a24d2b-f663-4bb7-8098-3cefd5f79b16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6658a5-47d6-48e6-a3b0-33ab27291e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.data[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0966992-4045-4d8a-9bf8-40c8e5a9b2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(0, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b75891cf-41d0-447c-97cc-9fed4e98fcfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa36bd7-78de-4995-b237-7ab43722487e",
   "metadata": {},
   "outputs": [],
   "source": [
    "einops_output = einsum(x, y, \"b c, b c ->\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9665852a-bc1a-44b3-a78a-497751e9c160",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: load data to disk\n",
    "step 2: idxs\n",
    "step 3: total size\n",
    "step 4: create a chunk memory\n",
    "step 5: load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6c97bb-2f64-4584-91cc-533b29eb7c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: record the elapsed time\n",
    "step 2: determine the number of layers per partrition\n",
    "step 3: split\n",
    "step 4: move to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1397ac45-9580-4cfa-8de2-e5d4d6d13735",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "components = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91392728-e6bb-4885-9427-011e707dceea",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_embeddings = cache[\"embed\"]\n",
    "pos_embeddings = cache[\"pos_embed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba45bb1b-b24e-45ff-9e48-b25ec97e838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = text_embeddings + pos_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be49555-2ed6-4aff-b73b-513ee4b0a708",
   "metadata": {},
   "outputs": [],
   "source": [
    "components.append(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589ca5b2-3786-4bbb-9914-c0cdc7d7c9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: identify a specific head\n",
    "step 2: generate two different prompts\n",
    "step 3: record all the activations of the two prompts\n",
    "step 4: replace the activation of the head h in prompt 1 to the corresponds x_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a688cf8-896d-487a-b4a5-78baa2785805",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer(nn.Module):\n",
    "    def __init__(self, params, lr):\n",
    "        super().__init__()\n",
    "        self.params = params\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for param in self.params:\n",
    "                if param.requires_grad:\n",
    "                    param -= param.grad * self.lr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
