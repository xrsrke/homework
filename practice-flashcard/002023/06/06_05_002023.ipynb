{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eaec66-547f-47b6-8446-2494dc682380",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8713f-5948-417f-9b55-d4a673611205",
   "metadata": {},
   "outputs": [],
   "source": [
    "with DAG(\n",
    "    dag_id=dag_id,\n",
    "    start_date=datetime(2023, 5, 31)\n",
    ") as dag:\n",
    "    task = PythonOperator(\n",
    "        python_callable=say_hello\n",
    "    )\n",
    "    \n",
    "    task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aa501f-8153-4c3c-a31f-b92ed5635c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.operators.bash import BashOperator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd8f02f-cd25-4ff6-9b9c-4251b9e3c1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = BashOperator(\n",
    "    task_id=\"hello_world\",\n",
    "    bash_command=\"echo hello world\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cb7f5e-6ac5-4ead-87c4-23123eeaa5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow import DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf19055b-1699-47cf-bcf8-57a4a2d8d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_1(ti):\n",
    "    ti.push(\"x\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d5d1a2-4137-41f2-9f6d-f0598d95d7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_2(ti):\n",
    "    x = ti.pull(\"x\", task=[\"task_1\"])\n",
    "    y = x + 3\n",
    "    ti.push(\"y\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9634f0-11f7-4a45-9914-540e169ad4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with DAG(\n",
    "    dag_id=dag_id,\n",
    "    start_date=start_date\n",
    "):\n",
    "    task_1 = PythonOperator(\n",
    "        \"task_1\",\n",
    "        python_callable=task_1\n",
    "    )\n",
    "    \n",
    "    task_2 = PythonOperator(\n",
    "        \"task_2\",\n",
    "        python_callable=task_@\n",
    "    )\n",
    "    \n",
    "    task_1 >> task_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d11ebe-a250-4a97-8546-c80d6110ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.decorators import dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c9e5b4-cdbd-470a-b157-1ab7804df742",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dag(dag_id=dag_id, start_date=start_date)\n",
    "def example():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afe5c2d-0c3b-44df-bc5c-629039173863",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: nat\n",
    "step 2: attach nat to vpc\n",
    "step 3: route table in subnet\n",
    "step 4: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08830417-097c-48f1-b003-48633f97e148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import cast, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58088562-73cb-4b4d-b7b6-e284efb43850",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = cast(List[int], numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d449a74-0cd0-4b3e-8370-d236816e36a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from airflow.decorators import task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5505dee-489d-4aba-a3e2-b5b03e328434",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dag(dag_id=dag_id, start_date=start_date)\n",
    "def example():\n",
    "    @task\n",
    "    def get_name(): pass\n",
    "\n",
    "    @task\n",
    "    def get_age(): pass\n",
    "\n",
    "    @task\n",
    "    def greet(name, age): pass\n",
    "\n",
    "    name = get_name()\n",
    "    age = get_age()\n",
    "    \n",
    "    greet(name, age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7004f1-c3e2-41f6-9b62-51c20129b5d5",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2efa2e2-db70-4a37-9d57-d6e86dc27eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: partrition params\n",
    "step 2: move to rank\n",
    "step 3: move device\n",
    "step 4: init local optimizer\n",
    "step 5: step\n",
    "step 6: broadcast\n",
    "step 7: sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b194d7e2-6af2-48e0-b5a2-630f4c89bfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e188a01b-5215-4642-b0a5-fe12b46971b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def forward(self, x, labels):\n",
    "        outputs = self.net(x)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        return outputs, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e7fcb-c738-49e4-9af4-887954a4acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid > thread block > thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9663abff-05ca-47a0-9784-2b410dbec0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_model_parallel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9702186a-0a03-4890-bc58-28b2d285e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tensor_model_parallel_groups = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc1b295-36e1-4f44-812b-5037dfaf1e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[2, 3]\n",
      "[4, 5]\n",
      "[6, 7]\n",
      "[8, 9]\n",
      "[10, 11]\n",
      "[12, 13]\n",
      "[14, 15]\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_tensor_model_parallel_groups):\n",
    "    ranks = list(range(\n",
    "        tensor_model_parallel_size*i,\n",
    "        (i+1)*tensor_model_parallel_size\n",
    "    ))\n",
    "    \n",
    "    print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2682f62-c1f3-4289-ae10-14e17a6665cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c3f08f-b9d9-4d30-bdab-dbd5cd927b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream1 = torch.cuda.Stream()\n",
    "stream2 = torch.cuda.Stream()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.cuda.stream(stream1):\n",
    "    operation_a()\n",
    "\n",
    "with torch.cuda.stream(stream2):\n",
    "    operation_b()\n",
    "    \n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302cae8a-22c9-4a70-b076-b3981bea0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_grad_enabled(x):\n",
    "    return torch.is_grad_enabled() and x.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bddd176-2d84-4176-86f1-f9d7257c1760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _broadcast(x):\n",
    "    return x.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2039490-56ea-408c-a685-307eb7b389a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reduce(x):\n",
    "    world_size = torch.distributed.get_world_size(group=parallel_group)\n",
    "    \n",
    "    if world_size == 1:\n",
    "        return x\n",
    "    \n",
    "    torch.distributed.all_reduce(x, group=parallel_group)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cddc88d-adb9-4c8f-832a-3888856ac123",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Broadcast(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return _broadcast(input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return _reduce(grad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede0aba1-e64a-48ee-9950-30aed2585a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_with_forward_and_backward(x):\n",
    "    if is_grad_enabled(x):\n",
    "        outputs = Broadcast.apply(x)\n",
    "    else:\n",
    "        outputs = _broadcast(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd39a3f7-6cb5-4a15-af6b-a6f2786751c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabParallelEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim_per_partrition = embedding_dim // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.zeros(\n",
    "            self.num_embeddings,\n",
    "            self.embedding_dim_per_partrition\n",
    "        ))\n",
    "        self.vocab_start_idx, self.vocab_end_idx = self.get_vocab_range(\n",
    "            self.embedding_dim_per_partrition\n",
    "        )\n",
    "    \n",
    "    def get_vocab_range(self, embedding_dim_per_partrition):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        start_idx = embedding_dim_per_partrition*rank\n",
    "        end_idx = start_idx+embedding_dim_per_partrition\n",
    "        return start_idx, end_idx\n",
    "\n",
    "    def forward(self, input):\n",
    "        mask = (self.vocab_start_idx > x) | (self.vocab_end_idx < x)\n",
    "        masked_input = input - self.vocab_start_idx\n",
    "        masked_input[mask] = 0.\n",
    "        \n",
    "        embeddings = F.embedding(masked_input, self.weight)\n",
    "        mask_idxs = torch.where(mask == 0.)[1]\n",
    "        embeddings[mask_idxs] = 0.\n",
    "        \n",
    "        torch.distributed.all_reduce(embeddings)\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ed530-388b-45b7-985b-c1baa7124096",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: fp16, fp32 of weight\n",
    "step 2: forward and backward using fp16\n",
    "step 3: cast the grad to fp32\n",
    "step 4: update "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ebdbdd-1dc6-42fe-a316-ac0cd70b9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_token = model.to_single_token(\" John\")\n",
    "incorrect_token = model.to_single_token(\" Mary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4261a501-2ead-4a1b-80d0-aeb2de26f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tokens = model.to_tokens(clean_prompt)\n",
    "corrupted_tokens = model.to_tokens(corrupted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3954ed1b-58d1-43f6-a061-dcba71dadd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clean_activations = model.run_with_cache(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751524b5-9670-4211-bc20-0a03561b66ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_logit(\n",
    "    corrupted_activations,\n",
    "    hook,\n",
    "    position,\n",
    "    clean_activations\n",
    "):\n",
    "    extracted_activations = clean_activations[hook.name][0, position, :]\n",
    "    corrupted_activations[0, position, :] = extracted_activations\n",
    "    return corrupted_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a80937a-7a23-4307-b40e-310e86bbeeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tokens = clean_tokens.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394492f5-ad8c-45c9-ac5a-aa4ca37342d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b3ba51-b578-45a4-a284-a8aaabba4a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84825f73-90b8-44d4-892f-5bcc191deea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.zeros(n_layers, n_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79380124-9a0f-4d15-8e6b-aac6a66fd649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_logit_difference(logits, correct_token, incorrect_token):\n",
    "    correct_logit = logits[:, -1, correct_token]\n",
    "    incorrect_logit = logits[:, -1, incorrect_token]\n",
    "    return correct_logit-incorrect_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2bca70-05b2-4aa4-b47c-39b8f66e4900",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_idx in range(n_layers):\n",
    "    for position in range(n_tokens):\n",
    "        hook_func = partial(patch_logit, position=position, clean_activations=clean_activations)\n",
    "        hook_name = get_act_name(\"resid_pre\", layer_idx)\n",
    "        patched_logits = model.run_with_hooks(\n",
    "            corrupted_tokens\n",
    "            fwd_hooks=([hook_name, hook_func])\n",
    "        )\n",
    "        logit_difference = compute_logit_difference(\n",
    "            patched_logits,\n",
    "            correct_token,\n",
    "            incorrect_token\n",
    "        )\n",
    "        data[layer_idx][position] = logit_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111a5059-be48-4a21-8f97-e4c556cfc00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, schedule, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32701b82-49ee-4432-b864-66ebdf271e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU]):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb13749-c807-4bfd-937f-0d1005674ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5151a1-1742-4e69-b028-c0880777baf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "interference[torch.arange(n_features, torch.arange(n_feature))] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47f3f6e-43be-4898-a958-38eef1ae1277",
   "metadata": {},
   "outputs": [],
   "source": [
    "polysemanticity = interference.pow(2).sum(dim=-1).sqrt()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
