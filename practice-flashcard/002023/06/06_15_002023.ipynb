{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a47216d-102b-4bda-a8ad-85efa0990dec",
   "metadata": {
    "tags": []
   },
   "source": [
    "### MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef805c9e-5953-48ce-ae49-ece337c48de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c9a29c-f069-4504-b7f0-2ef8683af4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raise():\n",
    "    with pytest.raises(ValueError) as e:\n",
    "        raise_exception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f5a2b-bdd8-4b0e-88d0-1651172a8840",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = {**d1, **d2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea63107-48ed-4131-b293-1f589c6ef146",
   "metadata": {},
   "outputs": [],
   "source": [
    "RecipeNutritionInformation = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f92a3e3f-c75e-445c-97af-884744ee1b6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8f86a90-bfea-43e0-ba74-90d15a8d6102",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NutritionInformation(TypedDict):\n",
    "    value: int\n",
    "    unit: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34b5b7fa-443f-4d84-8e2f-65005c0fee05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RecipeNutritionInformation(TypedDict):\n",
    "    recipes_used: int\n",
    "    calories: NutritionInformation\n",
    "    carbs: NutritionInformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59991256-3b23-43c8-bbad-e1a6da1ab6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7b66b4-12ec-41a3-bcce-e1989aa2bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_raise():\n",
    "    with pytest.raises(ValueError) as e:\n",
    "        raise_exception()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c438af00-02a9-43fa-9821-67c4819be21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: number of partrition\n",
    "step 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd214f0-3b1e-415c-95fa-c3123d363175",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker pull redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5daf79f4-a6f4-438a-a828-f5e87a73041d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1e6d435-d53a-42d4-8dd3-d3a643fddfdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NutritionInformation(TypedDict):\n",
    "    value: int\n",
    "    unit: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3bcb789-5371-498a-b938-b6173689da39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RecipeNutritionInformation(TypedDict):\n",
    "    recipes_used: int\n",
    "    calories: NutritionInformation\n",
    "    carbs: NutritionInformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7cc7d1-0f9c-4ee5-be0e-d91f9af13b48",
   "metadata": {},
   "source": [
    "### Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10bb326-6ed1-4953-9f09-b832904a6daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "int i = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed945a2-fb84-4dca-90b3-da73499e4807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb8984-205a-40c5-beda-77bcf5e6b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (; i < 10; i++) {\n",
    "    std::cout << \"i: \" < i;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e82106-aac0-418e-8291-0ce8c810fee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "int main() {\n",
    "    int numbers[] = {1, 2, 3, 4, 5};\n",
    "    \n",
    "    for (int i; i <= 3; i++) {\n",
    "        std::cout << numbers[i];\n",
    "    }\n",
    "    \n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86da14c9-d6f9-42a3-b9b0-ffc8737fb407",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (int x: xs) {\n",
    "    std::cout << \"value: \" << x << std::endl;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7824172d-d4a4-4d2c-9490-d78c56b56e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "api server, control manager, ectd, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a044b4e8-5a9f-4938-a0d9-51d026f32bb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81ea6393-cb50-446a-adf2-5d743a746086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_forward_pass_using_data_parallelism(\n",
    "    model, input,\n",
    "    device_ids, output_id):\n",
    "    models = nn.parallel.replicate(model, device_id)\n",
    "    inputs = nn.parallel.scatter(input, device_id)\n",
    "    \n",
    "    logit = nn.parallel.parallel_apply(model, input)\n",
    "    logits = nn.parallel.gather(logit, output_id)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c38ef2b6-b0ba-476b-ac81-853fc0939df1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_microbatches = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f55bee4-0417-46d4-9c0b-ec979d616217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_partritions = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24994eaf-0b4d-45ee-9bc6-e32cd6f41bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_clock_cycles = n_microbatches + n_partritions - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cbbbd7d-04ca-4de2-b01a-10d529640365",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0)]\n",
      "[(1, 1), (0, 1)]\n",
      "[(2, 2), (1, 2), (0, 2)]\n",
      "[(3, 3), (2, 3), (1, 3)]\n",
      "[(3, 4), (2, 4)]\n",
      "[(3, 5)]\n"
     ]
    }
   ],
   "source": [
    "for clock_idx in range(n_clock_cycles):\n",
    "    start_partrition = max(clock_idx+1-n_microbatches, 0)\n",
    "    end_partrition = min(clock_idx+1, n_partritions)\n",
    "    \n",
    "    results = []\n",
    "    for partrition_idx in range(start_partrition, end_partrition):\n",
    "        microbatch_idx = clock_idx-partrition_idx\n",
    "        results.append((microbatch_idx, clock_idx))\n",
    "    \n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315662bb-1127-4bec-9377-87e5d5536352",
   "metadata": {},
   "outputs": [],
   "source": [
    "api server, control manager, ectd, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a1d4f3-9a76-4ad0-9418-b004e7834a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid > thread block > thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6615e454-87e6-4b6c-a2f1-ec8626967a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "global memory > shared memory > register memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defb73b8-d547-4994-94ce-37a1e59d7a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "step 1: cpu memory\n",
    "step 2: gpu memory\n",
    "step 3: copy from cpu to gpu\n",
    "step 4: do the compuatation\n",
    "step 5: copy the result back to cpu\n",
    "step 6: dellocate GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811fc0f0-c6b1-4a44-8556-461f493b1c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabParallelEmbedding(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim):\n",
    "        super().__init__()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.embedding_dim_per_partrition = embedding_dim // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.num_embeddings,\n",
    "            self.embedding_dim_per_partrition\n",
    "        ))\n",
    "        self.vocab_start_idx, self.vocab_end_idx = self.get_vocab_range(\n",
    "            self.embedding_dim_per_partrition\n",
    "        )\n",
    "    \n",
    "    def get_vocab_range(self, embedding_dim_per_partrition):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        start_idx = rank*embedding_dim_per_partrition\n",
    "        end_idx = start_idx + embedding_dim_per_partrition\n",
    "        return start_idx, end_idx\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        masked = (self.vocab_start_idx > tokens) || (self.vocab_end_idx < tokens)\n",
    "        tokens = tokens - self.vocab_start_idx\n",
    "        tokens[masked] = 0.\n",
    "        \n",
    "        embeddings = F.embedding(tokens, self.weight)\n",
    "        masked_idxs =\n",
    "        embeddings[masked_idxs] = 0.\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9b46bc2-ab32-48d7-90ff-d973768158b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def wait_stream(source_stream, target_stream):\n",
    "    # ___ waits GPU\n",
    "    if isinstance(target_stream, torch.cuda.Stream):\n",
    "        if isinstance(source_stream, torch.cuda.Stream):\n",
    "            # GPU waits for GPU\n",
    "            source_stream.wait_stream(target_stream)\n",
    "        else:\n",
    "            # CPU waits for GPU\n",
    "            target_stream.syncronous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "baf37e8e-aae3-40ee-b073-8bb014519b14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Wait(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, prev_stream, next_stream, input):\n",
    "        ctx.prev_stream = prev_stream\n",
    "        ctx.next_stream = next_stream\n",
    "        \n",
    "        wait_stream(\n",
    "            source_stream=next_stream,\n",
    "            target_stream=prev_stream\n",
    "        )\n",
    "        \n",
    "        return input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        prev_stream = ctx.prev_stream\n",
    "        next_stream = ctx.next_stream\n",
    "        \n",
    "        wait_stream(\n",
    "            source_stream=prev_stream,\n",
    "            target_stream=next_stream\n",
    "        )\n",
    "        \n",
    "        grad_stream = (None, None)\n",
    "        \n",
    "        return grad_stream + grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6817ef90-0054-4d48-ba7a-8cc237f88b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "partritioning\n",
    "rank\n",
    "device\n",
    "local optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b093e38f-c288-4001-b510-315711fd7805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e56ea89-6d7f-4b52-b021-12c3dd003981",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MPU:\n",
    "    def __init__(master_addr, master_port, backend):\n",
    "        if not torch.distributed.is_initialized():\n",
    "            rank = os.getenv(\"RANK\")\n",
    "            os.environ[\"MASTER_ADDR\"] = str(master_addr)\n",
    "            os.environ[\"MASTER_PORT\"] = str(master_port)\n",
    "            \n",
    "            self.set_device(rank)\n",
    "            \n",
    "            torch.distributed.init_process_group(\n",
    "                master_addr=master_addr,\n",
    "                master_port=master_port,\n",
    "                backend=backend\n",
    "            )\n",
    "    \n",
    "    def set_device(self, rank):\n",
    "        n_devices = torch.cuda.device_count()\n",
    "        \n",
    "        if n_devices > 0:\n",
    "            device = rank % n_devices\n",
    "            torch.distributed.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3e7051e5-b133-46ba-98bc-c76b19dfc6ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class f(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        torch.distributed.all_reduce(grad_input)\n",
    "        return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d218aebf-a794-4319-a18d-9d229d8d088a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class g(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        inputs = [torch.empty_like(input) for _ in range(world_size)]\n",
    "        torch.distributed.all_gather(inputs, input)\n",
    "        inputs = torch.cat(inputs, dim=-1)\n",
    "        return inputs\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_input):\n",
    "        rank = torch.distributed.get_rank()\n",
    "        world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        dim_size = grad_input.shape[-1]\n",
    "        dim_size_per_partrition = dim_size // world_size\n",
    "        \n",
    "        grad_chunks = torch.split(grad_input, dim_size_per_partrition, dim=-1)\n",
    "        return grad_chunks[rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c4bbec3-145c-4af0-9fac-72a59bbb3fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ColumnParallelLinear(nn.Module):\n",
    "    def __init__(self, input_size, output_size, world_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size_per_partrition = output_size // world_size\n",
    "        \n",
    "        self.weight = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_partrition,\n",
    "            self.input_size\n",
    "        ))\n",
    "        self.bias = nn.Parameter(torch.empty(\n",
    "            self.output_size_per_partrition\n",
    "        ))\n",
    "    \n",
    "    def forward(self, input):\n",
    "        input_parallel = f.apply(input)\n",
    "        output_parallel = F.linear(\n",
    "            input_parallel,\n",
    "            self.weight,\n",
    "            self.bias\n",
    "        )\n",
    "        outputs = g.apply(output_parallel)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e7483b-9d8b-4354-b2e7-761513762073",
   "metadata": {},
   "outputs": [],
   "source": [
    "int* p_number{};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa9e2d4-8708-4a41-aecb-37500b5c3bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_continuous_memory(memory_size):\n",
    "    n_elements = memory_size // 4\n",
    "    return torch.randn(n_elements, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3781e49-e238-4934-8a8b-0b3fba3e5652",
   "metadata": {},
   "outputs": [],
   "source": [
    "int x = y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d887cd5c-7d91-46be-9bde-4c49b1bab7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "int* p_x{&y};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caedfa7e-874b-44ca-8f24-fa4fb2fd1c1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from einops import pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18115ed-de6a-42ff-9864-e12c07826099",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_images = pack(image_rgb, image_depth, \"b c *\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785fc275-8ccb-4a78-bbba-e8dafb855a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9c3cf2-d272-4a6c-aca0-921195c32105",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7436c72-1fbb-4a7b-a6e4-0a850f700545",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = F.log_softmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4804f9-aa73-46c2-8806-21ea3591495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tokens = tokens[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909832fc-c1e5-4ba1-9985-dcea01946989",
   "metadata": {},
   "outputs": [],
   "source": [
    "-log_probs[target_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0e6546-e45f-4e19-ac4f-e2a690a8f3b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
