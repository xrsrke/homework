{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7987f37-b4f7-4852-a010-39d1979dbcfd",
   "metadata": {},
   "source": [
    "### SWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a35a26f-f8a7-4627-a732-54fddfcb13df",
   "metadata": {},
   "outputs": [],
   "source": [
    "F && K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b813cdf5-8dac-474a-8681-896e7f392ed3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name: integration test\n",
    "\n",
    "jobs:\n",
    "    check-version:\n",
    "        runs-on: ubuntu-latest\n",
    "        x:\n",
    "            - name: echo a string\n",
    "              run: echo \"hello world\"\n",
    "            - name: check python version\n",
    "              run: python3 --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705f988f-6c40-44b6-a815-e19d9c052d47",
   "metadata": {},
   "source": [
    "### NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4079c59-b21b-43f2-be8c-5b8f229b9a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_batch(article_batches, max_context_length):\n",
    "    for  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2989ca88-ce75-4d46-993e-50f1e973a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization - preprocess - tokenize -> post-process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fea350a8-57f8-4748-89cd-3b5d6246965a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aac32d-3f5b-4673-ae4e-b0050b24412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pack([img_rgb, img_depth], 'h w *')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf4e5b9-009a-4c85-afac-61430d9af829",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory, latency, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6200ef-6b8d-4075-8423-7b8599040d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][\"article\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3dc74d-11aa-40e3-b1c1-56f0ffe3b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu, rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1885ce2f-61b2-4804-87f2-dbde61c1c4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.from_ids_to_tokens(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572ea5f8-6b59-4c59-807d-f009a5ba848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer.from_tokens_to_string(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acb7f5ab-b623-4126-b4c8-45e802330195",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db110f4a-e94d-4180-8624-0bb1aa31af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb96aa6-da83-4074-b031-f5ff021fbbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = tokenizer(\"ersi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0751b94-95d7-437b-b5c9-98ab3f89ccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceBenchmark:\n",
    "    def __init__(self, pipe, dataset):\n",
    "        self.pipe = pipe\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def compute_memory(self):\n",
    "        pass\n",
    "    \n",
    "    def compute_latency(self):\n",
    "        pass\n",
    "    \n",
    "    def compute_accuracy(self):\n",
    "        pass\n",
    "    \n",
    "    def run_benchmark(self):\n",
    "        results = {}\n",
    "        results[\"memory\"] = self.compute_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f35c7fdf-0219-435d-bc80-040d8804cb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a619ffeb-45c4-47c9-ae6b-e85b2fbd961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd67317d-ce2c-4d69-b908-1ee17897db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationTrainer(Trainer):\n",
    "    def __init__(self, *args, teacher_model, **kwargs):\n",
    "        super().__init__()\n",
    "        self.teacher_model = teacher_model\n",
    "        self.loss_func = nn.KLDivLoss()\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        output_student = model(inputs)\n",
    "        logits_student = output_student.logits\n",
    "        loss_ce = output_student.loss\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output_teacher = self.teacher_model(inputs)\n",
    "            logits_teacher = output_teacher.logits\n",
    "        \n",
    "        temperature = self.args.temperature\n",
    "        alpha = self.args.alpha\n",
    "        \n",
    "        loss_kd = temperature**2 * self.loss_func(\n",
    "            F.log_softmax(logits_student / temperature),\n",
    "            F.softmax(logits_teacher / temperature)\n",
    "        )\n",
    "        \n",
    "        loss = alpha * loss_ce + (1-alpha) * loss_kd\n",
    "        \n",
    "        return (loss, output_student) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4662f5d-bc1f-4cef-be70-83f38810bac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_loss = nn.KLDivLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6112ba22-8f09-43e7-9dbc-00042dfc621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = kl_loss(\n",
    "    F.log_softmax(student_logits),\n",
    "    F.softmax(teacher_logits)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163375a8-0ba7-4947-a791-b12564863f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ratio(current, prev):\n",
    "    return (current - prev).exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20320199-5517-4528-9047-3e8a54c41b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_batch(article_batches, max_context_length):\n",
    "    arr_summaries = []\n",
    "    \n",
    "    for article in article_batches:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a16c31fe-860b-4119-acf0-13b3947e4257",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136ffc80-8123-4059-b595-1220f151c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = rearrange(images, 'b c h w -> b c w h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3bce8d-d923-4f7b-ae4c-5295c398ca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "entropyloss: maximize -> substract, smaller overall loss\n",
    "`value_loss`: minimize -> add, smaller value loss, smaller overall loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7651c5-f4da-49e8-9a9e-c696e1815867",
   "metadata": {},
   "outputs": [],
   "source": [
    "rearrange(images, 'b c h w -> b c (h w)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4adcee-83fd-4c55-976c-9cbceda032d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rearrange(images, 'b c h w -> (b c h w)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b97771-d441-48a4-8021-b804241350dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = compute_returns(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c1ba01-0de7-4cb1-9ff8-0c7f62b7c271",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4b932c-f875-4845-9677-03d836da627e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for return_, prob in zip(returns, selected_action_probs):\n",
    "    total_loss += return_ * -prob.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263637d9-69e6-4094-918d-1bf5fdf25b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = total_loss / len(selected_action_probs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d947d7-6597-455e-8b8c-3487530f64b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p: seq_len\n",
    "i: index of dim\n",
    "n: user define\n",
    "d_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e34697-9a24-42ba-ab6c-ecfbbaf0fe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_batch(article_batches, max_context_length):\n",
    "    arr_summaries = []\n",
    "    \n",
    "    for article_batch in article_batches:\n",
    "        tokenized_article = tokenizer(\n",
    "            article_batch,\n",
    "            max_context_length=max_context_length,\n",
    "            truncate=True,\n",
    "            return_tensors=\"pt\"\n",
    "            **tokenizer_params\n",
    "        )\n",
    "        \n",
    "        summaries = model.generate(\n",
    "            tokenized_article,\n",
    "            attention_mask=tokenized_article[\"attention_mask\"],\n",
    "            **model_params\n",
    "        )\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f99c2ee3-6c3e-4349-b3c8-9b5b8ec0180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_hidden):\n",
    "        super().__init__()\n",
    "        self.i_h = nn.Embedding(vocab_size, n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.i_h(x[0, :]))\n",
    "        h = F.relu(self.i_h(x[1, :])) + F.relu(self.h_h(h))\n",
    "        h = F.relu(self.i_h(x[2, :])) + F.relu(self.h_h(h))\n",
    "        \n",
    "        return self.h_o(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5951d9d-8635-41d4-a07e-f8e75357f1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_hidden):\n",
    "        super().__init__()\n",
    "        self.i_h = nn.Embedding(vocab_size, n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_size)\n",
    "        self.h = 0.\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(3):\n",
    "            self.h = self.h + F.relu(self.i_h(x[i, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b24407e-7c75-4314-8ea8-c67f748519ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_values = q_network(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be8077e-c302-4b5a-b88e-e41c29edaeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_target = get_reward(states, actions) + gamma * value_network(states + 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc25be24-a157-40a7-9ee8-471299c53d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (q_values - q_target).pow(2) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceecd8d1-2ec3-47f1-97f0-b2c5252a87e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b8e16f-48c1-4ca9-b4bc-f789cfcb3b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Linear(12, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3, 12)\n",
    "        )\n",
    "        self.act_means = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        self.act_means.append(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbed3d31-f60b-4426-8711-55aa32fa0f36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_abosolute_error(preds, targs):\n",
    "    return (preds-targs).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7bfd95-fe3b-4b66-a040-47550ac46185",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
