{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77617179-774e-4b20-be14-6856715d9c90",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73ddc17a-f104-4dfd-9082-0416539eb591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f35aaf8-7edb-43a9-8fea-51a73ee3d1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(collections: Sequence[str]):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4d09767-847f-4100-bf80-42e8a88b5d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a703a3a5-d357-46be-ae11-79ab516005e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "031691c5-1bb7-4e52-8457-226ca0aa5fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bb6310d-7f35-4ddd-b4eb-65c97af62202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest import TestCase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4c521f-1247-42dd-b0dc-ba599e08024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestFeature(TestCase):\n",
    "    def test_eq(self, a, b):\n",
    "        self.assertEqual(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e0e222a-2b3b-47f1-a0a0-31ec5628bc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91695a72-e5bb-47b3-bd50-001d3277b2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Foo:\n",
    "    def __init__(self, a, b):\n",
    "        self.a, self.b = a, b\n",
    "    \n",
    "    _repr = basic_repr('a, b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c81521-5130-464e-a083-8091f87d0b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = partial(my_func, a=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9de525ad-af47-444c-858b-a2568e9b8910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.meta import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcfd48a-96bc-4496-bd15-79c21dca816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_kwargs_dict(b: int = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4898f509-9438-4f6a-bf97-03abdc5ef11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "setattr(m2, 'color', 'less reddish')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b59e1e4-f5f9-4b8d-951e-49761bf8b6eb",
   "metadata": {},
   "source": [
    "### NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d95f887d-1935-47fe-a076-c409b66366d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc67cee-5779-41f8-967a-4ab0ebb4bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token = output.logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd084b74-d50e-4c2f-9e76-3f2ac8df22cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_probs = F.softmax(next_token, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3471a64b-f45d-4af3-84d3-d727c228837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ids = torch.argmax(next_token_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3cb842-906e-4c73-bb9d-a8d809e1e150",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dd22c6-3053-44fc-85f7-fd162494571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac05cbd-e148-44d9-88e2-d28b30838757",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe0b837-b0e8-4515-8d64-83be15bc4a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "064ebb04-9775-4af0-ab6e-68f56252695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddac131b-8157-4d41-b63e-2c00a43b1554",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = Categorical(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876811ca-c813-49c5-9788-d97fb693eea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = dist.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d176bc96-c700-4743-8139-61f70f595aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.log_pro(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0a9db5-0488-4672-a8bb-50a2a23e81d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image encoder, text encoder, constrative loss, projection head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7574fa90-51f4-47ab-abb8-a157bccc127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e485be-9dbd-4e60-b5ac-0db73df70027",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_text = tokenizer.decode(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f34f161f-78c9-493b-88d7-4b1e9d5c568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31da757-15e4-4f5e-a825-f54ca494286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenClassifier(nn.Module):\n",
    "    def __init__(self, checkpoint, n_labels, dropout):\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(checkpoint)\n",
    "        \n",
    "        # custom head\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.reward_head = nn.Linear(768, n_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.model(input_ids, attention_mask)\n",
    "        last_hidden_state = output.last_hidden_state\n",
    "        \n",
    "        outpout = self.dropout(last_hidden_state)\n",
    "        output = self.reward_head(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a764bd-2794-4587-b0fd-3836ad884e0c",
   "metadata": {},
   "source": [
    "mimize the loss_vf => if substract, the smaller loss_vf => the larger the overall loss => aligns with objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be40bf3e-dadc-4fc6-9893-877e640a48e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a function describes physical properties of a quantum object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7308fb55-2feb-4d99-ba3d-4dcac5f37db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(pred, targ):\n",
    "    idx_preds = torch.argmax(pred, dim=1)\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a312f0a-b36c-4a76-aea8-ccaf3d495ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = embedding.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe0d55f-0acb-45c8-8dc8-d9873f3dfddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_norm = nn.LayerNorm(n_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cac6863-213f-4730-9824-ba6e569de418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, n_layers, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.text_embedding = TextEmbedding(\n",
    "            vocab_size=1000, d_model=d_model, padding_idx=0\n",
    "        )\n",
    "        self.positional_encoding = PositonalEncoding(d_model)\n",
    "        \n",
    "        self.encoder_layers = [\n",
    "            EncoderLayer(\n",
    "                d_model, n_heads, d_ff, dropout\n",
    "            ) for _ in range(n_layers)\n",
    "        ]\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        embeddings = self.text_embedding(tokens)\n",
    "        positional_encoding = self.positional_encoding(embeddings)\n",
    "        \n",
    "        output = positional_encoding\n",
    "        \n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            output, output_attn = encoder_layer(output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bbc4dd-b9cb-4f72-aad1-1a3ef3886975",
   "metadata": {},
   "outputs": [],
   "source": [
    "did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bc3396-3624-4877-9269-944a248a8062",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.mean(x, dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428aee1e-b1d7-44dd-b35b-b962e89c4c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(sm_pred, targ):\n",
    "    pred_idx = torch.argmax(sm_pred, dim=-1)\n",
    "    \n",
    "    return (pred_idx == targ).sum().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2b2c3-859f-44f9-a878-08c814963eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return torch.clamp_min(x, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fea247-1bb5-4622-86e5-716470949d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.argmax(dsets.train[0][1] == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b78023-a6ef-48a7-8979-f806e2ad32b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = vocab[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6540a05a-700e-438a-9a13-41f9bc64a2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModel3(nn.Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        super().__init__()\n",
    "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
    "        self.h = 0.\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(3):\n",
    "            self.h = F.relu(self.i_h(x[i, :]))\n",
    "            self.h = self.h + F.relu(self.h_h(x[i, :]))\n",
    "        \n",
    "        return self.h_o(self.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8c7e60-56a4-4128-94ef-06bca24fd87f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
