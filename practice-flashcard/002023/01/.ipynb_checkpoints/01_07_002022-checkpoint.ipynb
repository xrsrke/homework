{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccdfbacc-817d-47cf-957c-effa8a7bb179",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735d3e5a-b191-425b-a61d-5584e5edcbe5",
   "metadata": {},
   "source": [
    "quantum state: describe physical properties of a system at quantum scale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c255860-433f-4b9e-8e91-421cad3310fc",
   "metadata": {},
   "source": [
    "### Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47730f8a-f234-47e0-861e-17ab3a1790ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fb3bdd-b327-43a0-8d99-bba9f8c3f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.init.kaiming_normal_(layer1.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2a7e91-c41e-47d8-b85b-6d9e6707a8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sequence longer than max context length of the model => truncate it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77222225-811a-4536-adb4-45f444afaa6e",
   "metadata": {},
   "source": [
    "model may attention to parts of tokens that it should not pay attention to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995591c8-992d-42bf-b0c6-f781ced351ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "high temperature => low prob -> high prob -> low accuracy\n",
    "low temperature => flatten -> only pick high -> high accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c88ea5e-cc94-4959-b327-72c3b3dea794",
   "metadata": {},
   "source": [
    "### RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da7b8b-26ce-4ab0-9e5f-877e9f8f76f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "the goal is minimize the loss\n",
    "-> increase entropy -> substract, higher entropy => smaller loss\n",
    "-> minimize the value_loss -> add, smaller value_loss -> smaller_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadccecb-0fd5-4403-b5bf-33aab6d4bf9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d2d48e-1e03-4117-add5-1db4b414a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired return, past states, past actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c609e8e-ccc8-41f1-9b4d-35dda9551c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47669226-6afc-43f3-b3e9-e8a9ffd741f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(nn.Module):\n",
    "    def __init__(self, n_observations, n_actions, n_hidden):\n",
    "        super().__init__()\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(n_observations, n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, n_actions),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(n_observations, n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_hidden, 1)\n",
    "        )\n",
    "    \n",
    "    def get_action_and_value(self, state):\n",
    "        critic_value = self.critic(state)\n",
    "        \n",
    "        probs = self.actor(state)\n",
    "        dist = Categorical(probs)\n",
    "        action = dist.sample()\n",
    "        log_prob = dist.log_prob(action)\n",
    "        entropy = dist.entropy()\n",
    "        \n",
    "        return action, log_prob, entropy, critic_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f43d0ee-b090-4114-a1d3-99462e2fd076",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit the policy in certain range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a3225-fcba-4198-bb23-65d9870213ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if the gradient exceeds a threadshold, then scale it to the allowed range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab1ee46-3da6-446f-a919-f0c967fa7bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool, filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d3b7acd-82f1-415d-a037-4ae575c51a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(size):\n",
    "    return torch.ones((1, size, size)).triu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24eb3ab0-59d7-4170-96af-3e613a713bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1., 1.],\n",
       "         [0., 1., 1., 1.],\n",
       "         [0., 0., 1., 1.],\n",
       "         [0., 0., 0., 1.]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_mask(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5a6dbb6-dcc3-49b0-8f10-39707b2e4f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc3f92b-fd0e-4aac-8461-3924a0aa0719",
   "metadata": {},
   "outputs": [],
   "source": [
    "with multiprocessing.Pool(8) as pool:\n",
    "    pool.map(sum, numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36dc0d3f-8312-4b18-bc6f-2d604867afd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ratio(current, prev):\n",
    "    return (current - prev).exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7deb4be-db17-46e5-b1b8-ed7fedb178f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts the policy and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a0591-7f5d-4cf7-8faf-b584ab13ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "higher r_t => the ratio between current policy and old policy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183dff78-c53b-4768-904d-ebad37fe9e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "the goal is to maximize the loss function\n",
    "\n",
    "maximize entropy => add entropy => larger loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8ca236-a05e-4c42-9080-997a08f5f464",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit the policy update in a small range, not too far deviate from the old policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b800db73-335b-4c78-88a7-e2590bc1574d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nope. collected data by other agents, or by human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad7d6e1-6d91-428b-9401-8c7da24f0e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_reshaped = tensor.view(2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8833a497-8dab-4c69-b699-32b802fce51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip connection, conv, batch norm, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f39ccc-76b0-4a1a-8547-f6b6c14c6860",
   "metadata": {},
   "outputs": [],
   "source": [
    "current env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9d1d13-60e2-4f6d-8cf2-acc68ff23e0a",
   "metadata": {},
   "source": [
    "### NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd40ae53-d52c-4888-a6e2-6283f0e1fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbe050b-771e-42ab-a5e2-6c20294170e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_logits = output.logits[0, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c617fb8-6bb6-4eb4-85e2-bac1ff3df2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_logit_probs = F.softmax(next_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22789e3-d0e5-48ea-b910-511522745b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = torch.argmax(next_logit_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d80b14-17d6-4cea-a5a8-81abc2b79590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332051da-0707-42a0-9ae9-af6e1137052f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660933e1-1e43-4f01-a9c0-fec5f2713c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_logits = output.logits[0, -1, :][4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4201d037-8835-4e79-9f04-d7457d682f8b",
   "metadata": {},
   "source": [
    "different patterns in text => split words different => not accurate for dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54ae9d0-c0a4-4044-abca-f4592ee642bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute attention weights between words only count the preceding words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23985700-0d0a-42dd-9259-fc646a1eaa59",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model % n_head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eda98fb-e6a6-4465-9f1a-3bd61135e46d",
   "metadata": {},
   "source": [
    "a function describe the probability of observing an object at a specific location in quantum scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9b4961-912b-4ffb-97ef-150374d02b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][\"article\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b301d2-a1a4-4e4f-a0ec-c314013c4798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a279084c-3211-4bbe-992f-bc4cfa2855e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pf/g3nr86yn4j71vzzmv6knwdhr0000gp/T/ipykernel_32876/1963947385.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  bleu = load_metric(\"bleu\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a46a04e036e40f0a96acc1760cf2567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a885bc0d58241d9a86d0514360667f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bleu = load_metric(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113a03f5-4e13-48be-ad6e-41306a96d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = bleu.compute(predictions, references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82439a00-223a-4059-8f7e-d196c3118085",
   "metadata": {},
   "source": [
    "predict first token -> append to the input -> predict the 2th token based on the new appened input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ee532d-944d-4381-a4cd-0b111120a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.gather(x, dim=1, index=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c465321-2e45-42d5-8f90-86c813904875",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ea7ffa5-3cde-44f1-bd5b-d520ebe3c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76285c35-7ee7-4190-afb2-97ca7fc32450",
   "metadata": {},
   "outputs": [],
   "source": [
    "pack([image_rgb, image_depth], pattern=\"h w *\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8323cb96-cab4-4553-aca3-bbbef8496dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b436362-a687-4561-b577-3e77b36c0cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat(x, \"h w -> h w n\", n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e509d394-0841-4f84-be27-6ba06c0c60d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b7a53-b780-48d5-b2b1-4d6ed550ae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb691d4-21e7-404c-9edf-70a628b94d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e78f7de-74ab-48ca-8c24-29edf7765b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability_scores(image_embedding, text_embedding):\n",
    "    image_embedding_norm = image_embedding.norm()\n",
    "    text_embedding_norm = text_embedding.norm()\n",
    "    \n",
    "    image_embedding = image_embedding / image_embedding_norm\n",
    "    text_embedding = text_embedding / text_embedding_norm\n",
    "    \n",
    "    scores = image_embedding @ text_embedding.T\n",
    "    \n",
    "    probs = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49334c9-0dc3-4579-9cdf-0ce89de4c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "adds, mults, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4080c8e7-b7cc-496c-9810-40cd32658ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat(x, \"h w -> h w n\", n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b572a69-f2ae-4159-8d2f-05a6ef764204",
   "metadata": {},
   "outputs": [],
   "source": [
    "pack([image_rgb, image_depth], \"h w *\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f4d557-506b-4d6b-8bf9-99c9a5d52281",
   "metadata": {},
   "outputs": [],
   "source": [
    "self normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9794100d-9016-469b-8c0d-21177b3e0ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5044c1b1-22f2-4f71-b93a-0a0eaca85596",
   "metadata": {},
   "outputs": [],
   "source": [
    "onpolicy action, value functionb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b558250-7fba-4338-91c3-51c07c6e43b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a transfer learning technique uses in RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7745ac-fc25-4b15-9b1a-bb9ef932c8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "two "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804f7080-54ff-4f51-bc36-ddb1da75a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall points in more important in summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f4c7c6-f8e8-4c65-a8f4-465a8e400cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "max length, special token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8fb310-6343-47c1-a52e-cad9c366315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller loss -> larger loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d55147-ae0d-4e00-ba20-f162dc64ae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(x, y):\n",
    "    return covar(x, y) / (std(x)*std(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c12d3f43-ea3c-428c-8f9a-f33f3f92b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss_of_soft_v(states, actions, action_probs):\n",
    "    v_values = v_function(states)\n",
    "    \n",
    "    q_values = q_function(states, actions)\n",
    "    log_probs = action_probs.log()\n",
    "    \n",
    "    target_v = (q_values - log_probs).mean()\n",
    "    \n",
    "    error = (v_values - target_v).pow(2) * 0.5\n",
    "    return error.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dad9b4b9-7f3b-4cfa-9092-4907daef85b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frobenius_norm(x):\n",
    "    return x.pow(2).sum().sqrt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564116c7-4a94-4fe9-8476-9b5252cdbe34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
