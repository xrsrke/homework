{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "850a40cd-125c-422a-92a6-9e79746aa741",
   "metadata": {},
   "source": [
    "### Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfde5ec-a05e-4684-9c71-e6b5fdabf41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "- two uncertainty principles\n",
    "- conservation of angular momentum\n",
    "- conservation of action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe998b6f-a933-43b4-b8cf-4c43f34dd0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "charge of the field, and charge of the proton, the velocity of the proton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4348cc-152b-4a58-a141-cbead6fcebf1",
   "metadata": {},
   "source": [
    "### SW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83f7f2a4-621d-4f8f-8618-9b11abd1388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f92589-9d95-4644-9fad-8eaae6debc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MediumTestCase(unittest.TestCase):\n",
    "    def test_avg(self):\n",
    "        with self.assertRaises(TypeError) as err:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab95a8b-fd84-4a86-8c0f-37c2a471d06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(func):\n",
    "    def wrapper():\n",
    "        # time\n",
    "        func()\n",
    "        # time\n",
    "        \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc39701-8a8a-4d42-a52b-95ba133d8949",
   "metadata": {},
   "outputs": [],
   "source": [
    "docker-compose -f mongo.yaml up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05be0db-1993-44a7-aaf6-6f450d05853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35043648-348b-4b8c-88e6-43d55e4a75af",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def num_items(self: Learner):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12927bff-424e-4328-80ce-3f69b6c14baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8958416-2d36-4e51-a635-ccbc3e499ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = smp.symbols('x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "061510ae-5879-48a2-9a92-325500bbb45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, g = smp.symbols('f, g', cls=smp.Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "776db078-3a52-48dd-a0a2-add6e8aea276",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = g(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1b02e90-97b4-4b20-8d3d-d4cb46d32ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle g{\\left(x \\right)}$"
      ],
      "text/plain": [
       "g(x)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1672a989-aa89-4109-bfba-da7c81b1d203",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = x + g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d196767-eb71-45ea-af32-789f14ccf6ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Add' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mg\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Add' object is not callable"
     ]
    }
   ],
   "source": [
    "f = f()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b9c302-0722-4549-bf35-988193fb4e47",
   "metadata": {},
   "source": [
    "### AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ea9c0c6-5e55-45fc-a651-bbd09aa3e6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c2a16cc-1e1d-45d1-b86b-90588cd36c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_head):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_head = d_model // n_head\n",
    "        \n",
    "        self.attention = attention\n",
    "        self.d_model, self.n_head = self.d_model, self.n_head\n",
    "        \n",
    "        self.to_q = nn.Linear(d_model, d_model)\n",
    "        self.to_k = nn.Linear(d_model, d_model)\n",
    "        self.to_v = nn.Linear(d_model, d_model)\n",
    "        self.mha_linear = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_len, d_model = x.size()\n",
    "        return x.view(batch_size, self.n_head, seq_len, self.d_head)\n",
    "    \n",
    "    def concat(self, x):\n",
    "        batch_size, n_head, seq_len, d_head = x.size()\n",
    "        return x.view(batch_size, seq_len, n_head*d_head)\n",
    "    \n",
    "    def forward(self, pre_q, pre_k, pre_v):\n",
    "        q, k, v = self.to_q(pre_q), self.to_k(pre_k), self.to_v(pre_v)\n",
    "        q, k, v = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
    "        \n",
    "        attn_output, attn_weights = self.attention(q, k, v)\n",
    "        \n",
    "        output = self.concat(attn_output)\n",
    "        output = self.mha_linear(output)\n",
    "        return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26f5191e-2040-43e6-92fd-0734a262da2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms as tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd0f4536-c2b1-4134-a444-0e280970f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = tfms.Compose([\n",
    "    tfms.ToTensor(),\n",
    "    tfms.Normalize(0.3, 0.9)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9da34ea3-3d22-43fd-b3f8-20c82ea82ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22e2b9a-6187-4a1d-a7b5-2fdba3084840",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShowerEnv(Env):\n",
    "    def __init__(self):\n",
    "        self.action_space = Discrete(3)\n",
    "        self.observation_space = Box(\n",
    "            low=np.array(0), high=np.array(100)\n",
    "        )\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.state -= action\n",
    "        \n",
    "        reward = 1 if self.state >= 37 and self.state <= 39 else 0\n",
    "        done = True if self.shower_length == 0 else 0\n",
    "        info = {}\n",
    "        \n",
    "        return self.state, reward, done, info\n",
    "    \n",
    "    def reset(self):\n",
    "        self.state = 20\n",
    "        self.shower_length = 60\n",
    "        \n",
    "        return self.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb342f87-91ae-4f26-bebe-d4f8737ed1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_logits = output.start_logits\n",
    "end_logits = output.end_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7fb6e1-2a2d-40de-8ba5-7fdd77bd9b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_idx = torch.argmax(start_logits, dim=-1)\n",
    "end_idx = torch.argmax(end_logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64f9fdab-54a6-4958-a28b-7024bb7de224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cross_entropy(logits, targets):\n",
    "    log_probs = torch.log_softmax(logits, dim=-1)\n",
    "    loss = -log_probs[targets.shape[-1], targets].mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22050fe2-803a-4f20-84f7-ad29276e8b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "1, 3 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef526ea-87c8-4458-b5fd-c45662fda591",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clipped_surrogate_objective(ratio, advantage_estimate, epsilon):\n",
    "    x = ratio * advantage_estimate\n",
    "    clipped_ratio = torch.clamp(ratio, 1-epsilon, 1+epsilon)\n",
    "    loss = torch.min(x, clipped_ratio*advantage_estimate).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e47d3aa-1578-4d6f-80a9-8e75d16da3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(size):\n",
    "    return torch.ones((1, size, size)).triu(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82f6d237-cf63-497d-809c-7cdeb02bc9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 1., 1.],\n",
       "         [0., 0., 1., 1.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_mask(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51c843c0-0637-45e7-a44e-d42507455836",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb22c1-7f74-49e4-9796-8f56feddcc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "|rearrange(images, 'b c h w 1 -> b c h w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b04dcb6-aeb4-4026-8451-88e46040fec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bf1ca4f-905a-4d20-b03a-3d52a2112921",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_head):\n",
    "        super().__init__()\n",
    "        self.d_head = d_head\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        k_tranposed = k.transpose(3, 2)\n",
    "        qk_matmul = torch.matmul(q, k_tranposed)\n",
    "        \n",
    "        if mask is not None:\n",
    "            qk_matmul = qk_matmul.fill_mask(mask == 1, 1e-9)\n",
    "        \n",
    "        scores = qk_matmul / math.sqrt(self.d_head)\n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "        output = torch.matmul(v, attention_weights)\n",
    "        \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2661329-0692-48e6-a9a7-b541c171586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(2, 3, latent_height, latent_weight) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea573bb-d989-49d8-8e44-44fec2ced2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "end of token, reach maximum tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de73bf9-ea3e-4ea8-8e33-7d5db4679fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncation, spliding window, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2b99fe-401a-463c-bf2f-3567f73e81e2",
   "metadata": {},
   "source": [
    "multi-head attention, masked multi-head attention, batch norm, linear, residual connection, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab884a2-e19b-4db1-bb2d-18299da2a4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncation, sliding window, split sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb21fb1-36df-4dd6-b4ad-5a86858bfe4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
