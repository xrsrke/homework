{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3012ee20-d422-4053-acde-0492bbf3546c",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5dd8fa7-5cae-4cc5-bb60-f9112120c1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.meta import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b896e09-d66b-4822-a2f4-943f3a7e1722",
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_kwargs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fc827a-06b1-4eec-a8fe-0ff86e0b9584",
   "metadata": {},
   "source": [
    "### Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53d9d4dc-02eb-41a3-8de6-f5233e5f83db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ba17a2e-861d-4cb5-bec7-d9dfd74a54c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c713aac9-38d5-4d9c-9996-0677da98405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset, valid_dset = random_split(datasets, lengths=[6, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c04162-427a-454d-b77d-04ab39fe5ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dset, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adec9b33-929a-4222-986c-f4940b38d48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_return(rewards, discount_factor):\n",
    "    total_return = 0\n",
    "    \n",
    "    for k, reward in enumerate(rewards):\n",
    "        total_return += discount_factor**k * reward\n",
    "    \n",
    "    return total_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08923dda-cd86-450f-8e8b-039d6a229e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = torch.tensor([10, 20, 30, 40, 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3e65f2d-2fd0-4de1-bc21-df079a864577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(114.2650)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_return(rewards, 0.900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230713fb-2833-4fd6-be5b-b5b1aac7b976",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0501b3a0-52b4-4cb7-a71d-d52a1b0d6cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.clamp_max_(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc215f0c-87b7-4336-83f8-75b2f218a5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len / n_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d10fae1e-4dab-4d38-a3d0-1bd66e372f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig, RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fba14db-3ba1-4110-a62b-bd5f0c446f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RobertaConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a178589-6732-428c-8e89-617a3aac0750",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaModel(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9bba30-5aa9-4703-beac-445e6363daa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.gather(x, dim=1, index=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65aed7f-e3b7-4ef9-a466-932ddfae74e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaModel.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29fd529c-d6a5-45fb-b7a6-b3e02ab90b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6c7c7c-cd4d-4c4c-ac63-0b259ceb24c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTokenClassifier(nn.Module):\n",
    "    def __init__(self, checkpoint, n_labels, dropout):\n",
    "        super().__init__()\n",
    "        self.model = AutoModel.from_pretrained(checkpoint)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.classifier = nn.Linear(768, 1)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.model(\n",
    "            input_ids, attention_mask\n",
    "        )\n",
    "        \n",
    "        out = self.dropout(output.last_hidden_state)\n",
    "        out = self.classifier(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b80d7ac-7ffb-4bdc-b708-4acbb2b75e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_loss = nn.KLDivLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017cb864-f18f-465c-8823-7de694e98715",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = kl_loss(\n",
    "    F.log_softmax(student_logits),\n",
    "    F.softmax(teacher_logits)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df9b1c8-032b-41e2-a61a-5d385c17a11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "high temp => flat => low -> hgher\n",
    "low temp => peak -> high -> higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cb10448-2d8d-4a99-8ca3-7db96c75f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7afe9c27-445a-44d6-ad1d-1cd4faffca2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, d_k):\n",
    "    qk_matmul = torch.matmul(q, k.T)\n",
    "    scores = qk_matmul / math.sqrt(d_k)\n",
    "    attention_weights = F.softmax(scores, dim=-1)\n",
    "    output = torch.matmul(attention_weights, v)\n",
    "    \n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b33f748-5745-4a56-b504-667597f157ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean, z_log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd54cba7-7897-4448-8f3e-6c37a4c4e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceBenchmark:\n",
    "    def __init__(self, pipe, dataset):\n",
    "        self.pipe = pipe\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def compute_accuracy(self): pass\n",
    "\n",
    "    def compute_memory(self): pass\n",
    "    \n",
    "    def compute_latency(self): pass\n",
    "\n",
    "    def run_benchmark(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b778055d-9fa3-471d-a6ed-d6d42b7fd691",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.logits[0, -1, :][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa40759-70b0-4cf6-aa78-d7f798eae70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_prob = F.softmax(output.logits[0, -1, :], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd0bbfd-bac3-4a93-b65c-00c66cf2bb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.argmax(next_token_prob, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484e8ec0-451f-457e-8060-37417c7bb8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(size):\n",
    "    return torch.ones((1, size, size)).triu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3702d8ec-5be0-4f85-95a4-ba6a65a1080c",
   "metadata": {},
   "source": [
    "entropy_loss: the goal is increase -> substract, the larger the smaller the loss\n",
    "\n",
    "value_loss: the goal is decrease -> add, the smaller the smaller the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2f33c3-3c3a-4b00-a1ca-acebba0e61a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d388b1e-08a6-4705-8bfa-5d61676a7e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[0].requires_grad = True\n",
    "model.classifier[3].requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac449bdc-6c30-459b-826c-9b2713763061",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier[6] = nn.Linear(4095, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30ad3211-075d-4361-9cab-8f8d00e504c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f436cf-179b-49d4-95c9-cbaaedc82b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with multiprocess.Pool(4) as pool:\n",
    "    result = pool.map(sum, numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8c316f-1386-4a76-b497-a12ee03dc5bf",
   "metadata": {},
   "source": [
    "prefered summary > non-prefered summary -> larger than zero -> sigmoid -> large\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffb27df-48f1-49f0-af23-da46fdf92d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_layers, n_heads, n_layers, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attention = MultiHeadAttention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff343af-1d9b-4734-9d66-783a9709167d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embeddings = embedding.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbef4ee-f724-4c91-8eee-d649d6258138",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_norm = nn.LayerNorm(n_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "695acc39-38de-4e3c-aaf8-77fb659e490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3409e43-922f-4bbf-a865-bddb6ac17cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dblock = DataBlock(blocks=[ImageBlock, MultiCategoryBlock],\n",
    "                   get_x=get_x,\n",
    "                   get_y=get_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a94a0-f01f-4fce-82a3-b38f76c1cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = dblock.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9f4caa-1a7b-4a58-89bb-f8a4452002a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token = outputs.logits[0, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed0b0aa-147e-4ff5-b09c-cc6c5aacf4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_probs = F.softmax(next_token, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebedae1f-de4c-4b10-a6b8-6a1307592cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = torch.argmax(next_token_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f686bb80-7424-4f0c-9857-96b68063ca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModel(nn.Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        super().__init__()\n",
    "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
    "        self.h = 0.\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(3):\n",
    "            self.h = F.relu(self.i_h(x[i, :]))\n",
    "            out = self.h + F.relu(self.h_h(x[i, :]))\n",
    "        \n",
    "        return self.h_o(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b53333-dab8-4e0c-9d51-24eda84d0f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, n_layers, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.text_embedding = TextEmbedding(\n",
    "            vocab_size, d_model, padding_idx=0\n",
    "        )\n",
    "        self.positional_encoding = PositionEncoding(d_model)\n",
    "        \n",
    "        self.encoder_layers = [\n",
    "            EncoderLayer(\n",
    "                d_model, n_heads, d_ff\n",
    "            ) for _ in range(n_layers)\n",
    "        ]\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        text_embeddings = self.text_embedding(tokens)\n",
    "        embeddings = self.positional_encoding(text_embeddings)\n",
    "        \n",
    "        encoder_out = embeddings\n",
    "        for encoder_layer for self.encoder_layers:\n",
    "            encoder_out, encoder_weights = encoder_layer(encoder_out)\n",
    "        \n",
    "        return encoder_out, encoder_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9aa8bd-ace6-45b6-9c95-8d2c42e310fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.permute(3, 1, 2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb4f99b3-f848-4f42-9cd5-0fb986adbdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, features, eps):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.adds = nn.Parameter(torch.zeros(features))\n",
    "        self.mults = nn.Parameter(torch.ones(features))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True)\n",
    "        \n",
    "        # normalize\n",
    "        x = (x-mean) / (var + self.eps).sqrt()\n",
    "        \n",
    "        # scale and shift\n",
    "        x = self.mults * x + self.adds\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e078b7db-148d-41f7-bed6-9abf20e9f0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.where(dsets.train[0][1] == 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1d5125-cdb5-46cb-b8c2-2434ac491d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b723e7e0-d2a6-47ce-a8e2-1d2d1905aa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMModel(nn.Module):\n",
    "    def __init__(self, vocab_sz, n_hidden):\n",
    "        super().__init__()\n",
    "        self.i_h = nn.Embedding(vocab_sz, n_hidden)\n",
    "        self.h_h = nn.Linear(n_hidden, n_hidden)\n",
    "        self.h_o = nn.Linear(n_hidden, vocab_sz)\n",
    "        self.h = 0.\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for i in range(3):\n",
    "            self.h = self.h + F.relu(self.i_h(x[i, :]))\n",
    "            self.h = F.relu(self.h_h(x[i, :]))\n",
    "        \n",
    "        return self.h_o(self.h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7793625-c378-40c5-a939-7c63d30f6915",
   "metadata": {},
   "outputs": [],
   "source": [
    "l1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08420d9-94f9-483a-8cb1-1a8a288262b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "latency, memory, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be291603-88ed-4f90-bf84-97efef775918",
   "metadata": {},
   "outputs": [],
   "source": [
    "it helps the model learn out-of-vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d227e0e-7a8f-4b54-a75b-f68cd7d336de",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.clamp(min=-3, max=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1253088-5b2b-4cac-992f-ed243a85c485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "259da536-4cfe-4d5d-ae31-cd0c3e2f2546",
   "metadata": {},
   "source": [
    "The equation \"a^k=\\arg \\max _a\\left[Q(s, a)+P(s, a) \\cdot \\frac{\\sqrt{\\sum_b N(s, b)}}{1+N(s, a)}\\left(c_1+\\log \\left(\\frac{\\sum_b N(s, b)+c_2+1}{c_2}\\right)\\right)\\right]\" is used in the selection stage of the MCTS algorithm to select an action $a^k$ at each hypothetical time-step $k=1 \\ldots l$ of the simulation. It's an extension of the standard UCB1 formula and it's used to balance exploration and exploitation in the search tree.\n",
    "\n",
    "Let's break it down:\n",
    "\n",
    "$\\arg \\max _a$: This notation means \"argmax over a\", it's used to find the action $a$ that maximizes the expression inside the brackets. So, the action $a^k$ that is selected by the algorithm is the one that maximizes the value of the expression inside the brackets.\n",
    "$Q(s, a)$: This notation represents the mean value of the action $a$ from state $s$, it's an estimate of how good the action is. It's calculated as the average value of all the simulations that have been run from this state-action pair.\n",
    "$P(s, a)$: This notation represents the policy for the action $a$ from state $s$, it's a probability that indicates how likely the action is to be taken from this state.\n",
    "$\\frac{\\sqrt{\\sum_b N(s, b)}}{1+N(s, a)}$: This term is an exploration bonus, it encourages the algorithm to explore actions that have been visited less often. The $\\sqrt{\\sum_b N(s, b)}$ is the square root of the sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6411b6f8-313f-44a7-bf7b-312f5a4a4efa",
   "metadata": {},
   "source": [
    "of the visit counts for all actions from state $s$, it's a measure of how often the state has been visited. The $1+N(s, a)$ is the number of times the action $a$ has been visited. So this term is the ratio of the square root of the sum of all the visit counts for all actions over the number of times the action $a$ has been visited.\n",
    "\n",
    "$(c_1+\\log \\left(\\frac{\\sum_b N(s, b)+c_2+1}{c_2}\\right))$ : This term is used to control the influence of the prior $P(s, a)$ relative to the value $Q(s, a)$ as nodes are visited more often. The $\\log \\left(\\frac{\\sum_b N(s, b)+c_2+1}{c_2}\\right)$ is the logarithm of the ratio between the total number of visits and a constant $c_2$ . The $c_1$ is an additional constant.\n",
    "So, in summary, the equation is using the UCB formula to select the action that maximizes the sum of the mean value of the action $Q(s, a)$ and the exploration bonus weighted by the policy $P(s, a)$ and a term that control the influence of the prior relative to the value as nodes are visited more often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25238fd-d89f-4dca-9b6b-26e09f2c71be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb01cd12-1e68-4f4c-884d-2b4fca02176d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b7a88-8cf6-425c-a178-5d4d8e122dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3bf20ce-7f81-4229-b6ee-1781180dc576",
   "metadata": {},
   "source": [
    "This passage is describing the expansion stage of the MCTS algorithm, which happens when the simulation reaches a leaf node in the search tree. In this stage, the algorithm performs the following steps:\n",
    "\n",
    "At the final time-step $l$ of the simulation, the reward $r^l$ and next state $s^l$ are computed by the dynamics function $g_\\theta\\left(s^{l-1}, a^l\\right)$. This function uses the current state-action pair $(s^{l-1}, a^l)$ and the neural network parameters $\\theta$ to predict the reward and next state that result from taking action $a^l$ in state $s^{l-1}$.\n",
    "The reward and next state are stored in the corresponding tables: $R\\left(s^{l-1}, a^l\\right)=r^l$ and $S\\left(s^{l-1}, a^l\\right)=s^l$\n",
    "The policy and value are computed by the prediction function $f_\\theta\\left(s^l\\right)$. This function uses the next state $s^l$ and the neural network parameters $\\theta$ to predict the policy and value of the next state.\n",
    "A new node is added to the search tree, corresponding to the next state $s^l$.\n",
    "For each possible action $a$ from the next state $s^l$, a new edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c57b83a-4fd8-438d-bca0-e4d1e33f5c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2008373-4918-4b29-a5e0-9a701c972858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e33529-00f5-473e-b381-afe34846f998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "92c94204-5d2f-4555-a8f6-d086fe0ceb35",
   "metadata": {},
   "source": [
    "The $R\\left(s^{l-1}, a^l\\right)$ and the $S\\left(s^{l-1}, a^l\\right)$ tables in MuZero are data structures that are used to store the outcome of the simulations performed by the MCTS algorithm.\n",
    "\n",
    "The $R\\left(s^{l-1}, a^l\\right)$ table is used to store the rewards associated with each state-action pair $(s^{l-1}, a^l)$. Specifically, the algorithm stores the reward $r^l$ that results from taking action $a^l$ in state $s^{l-1}$ in the R table. This information can be used to update the statistics of the current node and its children nodes, such as mean value, and also it can be used during the training phase to improve the estimates of the rewards provided by the neural network.\n",
    "\n",
    "The $S\\left(s^{l-1}, a^l\\right)$ table is used to store the next state associated with each state-action pair $(s^{l-1}, a^l)$. Specifically, the algorithm stores the next state $s^l$ that results from taking action $a^l$ in state $s^{l-1}$ in the S table. This information can be used to update the statistics of the current node and its children nodes, such as visit count, and also it can be used during the training phase to improve the estimates of the next state provided by the neural network.\n",
    "\n",
    "It's worth noting that these tables are not an explicit data structure, they are represented implicitly in the MCTS algorithm, which helps to save the memory space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ddcc36-571f-451d-a9e0-c15e6238febb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdccb7d-daef-4432-9f54-7d7d4c1c3e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fb7bec1-279d-48cd-991b-bfa295a40d11",
   "metadata": {},
   "source": [
    "The Backup stage of the MCTS algorithm is used to update the statistics of the current node and its children nodes in the search tree.\n",
    "\n",
    "In this passage, the algorithm uses the stored rewards and the value prediction to compute an estimate of the cumulative discounted reward for each node on the search path.\n",
    "\n",
    "The algorithm starts at the final time-step $l$ of the simulation and works backwards to the root node. For each time-step $k=l \\ldots 0$, the algorithm forms an $l-k$-step estimate of the cumulative discounted reward, bootstrapping from the value function $v^l$. The cumulative discounted reward is calculated using the following equation:\n",
    "\n",
    "$$\n",
    "G^k=\\sum_{\\tau=0}^{l-1-k} \\gamma^\\tau r_{k+1+\\tau}+\\gamma^{l-k} v^l\n",
    "$$\n",
    "\n",
    "The $\\gamma$ term is the discount factor and is used to weigh the importance of future rewards. The $r_{k+1+\\tau}$ term is the intermediate reward that is stored in the R table for each node in the search path.\n",
    "\n",
    "Once the cumulative discounted reward is calculated, the algorithm updates the statistics for each edge $(s^{k-1}, a^k)$ in the simulation path. The mean value of the current state-action pair is updated using the following equation:\n",
    "\n",
    "$$\n",
    "Q\\left(s^{k-1}, a^k\\right):=\\frac{N\\left(s^{k-1}, a^k\\right) \\cdot Q\\left(s^{k-1}, a^k\\right)+G^k}{N\\left(s^{k-1}, a^k\\right)+1}\n",
    "$$\n",
    "\n",
    "The visit count is incremented by 1 using the following equation:\n",
    "\n",
    "$$\n",
    "N\\left(s^{k-1}, a^k\\right):=N\\left(s^{k-1}, a^k\\right)+1\n",
    "$$\n",
    "\n",
    "The algorithm uses the minimum-maximum values observed in the search tree up to that point to compute the normalized Q value estimates $\\bar{Q}$ to be used in the pUCT rule, this is done by the following equation:\n",
    "$$\n",
    "\\bar{Q}\\left(s^{k-1}, a^k\\right)=\\frac{Q\\left(s^{k-1}, a^k\\right)-\\min _{s, a \\in \\text { Tree }} Q(s, a)}{\\max _{s, a \\in \\text { Tree }} Q(s, a)-\\min _{s, a \\in \\text { Tree }} Q(s, a)}\n",
    "$$\n",
    "\n",
    "This normalization step is done to ensure that the Q-values are within the range of $[0,1]$ which is necessary for the pUCT rule (Eqn 2) and to avoid adding prior knowledge to the MuZero algorithm. This allows the algorithm to work in environments where the value is unbounded and is not dependent on game specific knowledge.\n",
    "\n",
    "In summary, the Backup stage uses the cumulative discounted reward, computed using the stored rewards and value prediction, to update the statistics of the current node and its children nodes in the search tree. The statistics are updated for each edge $(s^{k-1}, a^k)$ in the simulation path. The mean value of the current state-action pair is updated and the visit count is incremented. The algorithm also normalizes the Q-values to ensure that they are within the range of $[0,1]$ to be used in the pUCT rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c05294b-a5a3-4b2b-ba64-64cb4bc8c0ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
