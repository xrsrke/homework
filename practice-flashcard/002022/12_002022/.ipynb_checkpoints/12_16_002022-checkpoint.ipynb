{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f6a9ec-224d-4291-981d-60d8751f50e4",
   "metadata": {},
   "source": [
    "### Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a9b230a-d9ff-456d-a7eb-ca085db07335",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a27c1a-73ad-4390-bd2e-cd33a714077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding.masked_fill(mask == False, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04a315a-92d3-4303-bbd5-f9be2f175ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_norm = nn.LayerNorm(embedding.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c71c0793-13fb-4507-932d-d4ad2d7282e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23c42496-5a0f-4de6-b8ad-d1376f0cb9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63bdc099-6242-416e-9610-925123053d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08736f3d-4255-439f-a25f-d9942e1f84c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_head):\n",
    "        super().__init__()\n",
    "        self.d_head = d_head\n",
    "    \n",
    "    def forward(self, q, k, v):\n",
    "        \n",
    "        permuted_k = k.permute(3, 2)\n",
    "        scores = torch.matmul(q, permuted_k)\n",
    "        scaled_scores = scores / math.sqrt(self.d_head)\n",
    "        attention_weights = F.softmax(scaled_scores, dim=-1)\n",
    "        output = torch.matmul(attention_weights, v)\n",
    "        \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f0487ce-8d91-4913-8099-9a43c25b7fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, attention, d_model, n_heads):\n",
    "        super().__init__()\n",
    "        self.attention = attention\n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.d_head = d_model // n_heads\n",
    "        \n",
    "        self.to_q = nn.Linear(d_model, n_heads * self.d_head)\n",
    "        self.to_k = nn.Linear(d_model, n_heads * self.d_head)\n",
    "        self.to_v = nn.Linear(d_model, n_heads * self.d_head)\n",
    "        self.linear = nn.Linear(n_heads * self.d_head, d_model)\n",
    "    \n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_len, d_model = x.size()\n",
    "        return x.view(batch_size, self.n_heads, seq_len, self.d_head)\n",
    "    \n",
    "    def concat(self, x):\n",
    "        batch_size, n_heads, seq_len, d_head = x.size()\n",
    "        return x.view(batch_size, seq_len, n_heads * d_head)\n",
    "    \n",
    "    def forward(self, pre_q, pre_k, pre_v):\n",
    "        \n",
    "        q, k, v = self.to_q(pre_q), self.to_k(pre_k), self.to_v(pre_v)\n",
    "        \n",
    "        q, k, v = self.split_heads(q), self.split_heads(k), self.split_heads(v)\n",
    "        \n",
    "        output, attention_weights = self.attention(q, k, v)\n",
    "        \n",
    "        output = self.concat(x)\n",
    "        \n",
    "        projection = self.linear(output)\n",
    "        return projection, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99a7b8ed-a590-473f-8054-4b1db7cde6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, n, d_model):\n",
    "        self.n, self.d_model = n, d_model\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        seq_len = len(tokens)\n",
    "        embeddings = torch.zeros(seq_len, self.d_model)\n",
    "        \n",
    "        for p in range(seq_len):\n",
    "            for i in range(self.d_model):\n",
    "                denominator = torch.pow(self.n, (2*i)/self.d_model)\n",
    "                embeddings[p][i] = torch.sin(p, denominator) if i % 2 == 0 else torch.cos(p, denominator)\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113efcd2-8eeb-4947-8a59-e2a6c494f82d",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93fea98f-c790-4d55-80be-3d7879eb3b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5acca97-b2da-4626-8db2-3bb5a20e3c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "T =  TypeVar(\"T\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08c3f2b5-f02c-4fe1-8c31-2ebbb55b78cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import field, dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3f83557-caae-49cb-b812-bdf37bec80b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Camera:\n",
    "    resolution: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae4a80e6-2490-4c29-8566-47c0cac98d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d2d4f3-cf31-461f-aac7-a31b5ea12f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MediumTestCase(unittest.TestCase):\n",
    "    def test_avg(self):\n",
    "        with self.assertRaises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6579bb3c-a3a7-4243-808c-5189fcf6f043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractclassmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d35bdfd6-bf4e-4903-b38c-cf1596a9d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(ABC):\n",
    "    def __init__(self, order):\n",
    "        self.order = order\n",
    "    \n",
    "    @abstractclassmethod\n",
    "    def receive_payment(self): pass\n",
    "\n",
    "    @abstractclassmethod\n",
    "    def ship(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d84282a3-f1b3-4aca-a81b-febc8cd95f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnpaidOrder(State):\n",
    "    def receive_payment(self):\n",
    "        self.order.set_state(self.order.paid_state)\n",
    "        print(\"Ypur payment has been accepeted\")\n",
    "    \n",
    "    def ship(self):\n",
    "        print(\"Can't ship unpaid orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55037465-d1bd-4ee0-828c-b1551a27ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Order:\n",
    "    def __init__(self):\n",
    "        self.unpaid_state = UnpaidOrder(order=self)\n",
    "        \n",
    "        self.state = self.unpaid_state\n",
    "    \n",
    "    def set_state(self, state):\n",
    "        self.state = state\n",
    "    \n",
    "    def receive_payment(self):\n",
    "        return self.state.receive_payment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccf5a3a-e332-4a6e-bdb5-58bc3e7364df",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin.bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "112bf94a-2200-4336-b473-0142ca85d421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ecc6693-841f-4cf1-9855-f8ceac5d01d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b11a9f4a-9b3e-4ff6-8ee2-c2cee42cc54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "75e8a645-5f9d-41e5-9473-9e7a6592fa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout_layer(activations, dropout):\n",
    "    assert 0 <= dropout <= 1\n",
    "    if dropout == 0: return torch.zeros_like(activations)\n",
    "    \n",
    "    mask = torch.randn(activations.shape)\n",
    "    mask = mask > dropout\n",
    "    return (mask*activations) / (1 - dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1028762-7ce0-47d0-a1e9-2f2a7a4ee387",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(16).reshape((4, 4)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cca48e8d-c097-4076-bf26-ec8029ca959c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "61c176d3-1bf4-4ea8-b5dc-b0d7a337a60a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\"normal_kernel_cpu\" not implemented for 'Long'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"normal_kernel_cpu\" not implemented for 'Long'"
     ]
    }
   ],
   "source": [
    "torch.randn_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c3368169-7a31-440e-a1b8-7d05ff512b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  2.5000,  0.0000,  7.5000],\n",
       "        [ 0.0000, 12.5000, 15.0000,  0.0000],\n",
       "        [ 0.0000, 22.5000,  0.0000, 27.5000],\n",
       "        [ 0.0000,  0.0000,  0.0000, 37.5000]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout_layer(x, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd64ac2d-39a4-404a-9e2d-87f12366e30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss(D(x), 1) + Loss(D(G(z)), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6317bd35-c36e-4e71-a6e9-a95374ae23b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = torch.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ecd31517-f2cf-4e88-bd15-2d3af8171218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x):\n",
    "    softmax = x.exp() / x.exp().sum()\n",
    "    return softmax.log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "390bcd1d-b39b-46a5-969b-f2033f02fb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary(x):\n",
    "    return x.exp() / 1 + x.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8a14ad83-0e41-4bae-8311-d966cf165a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, mom, eps):\n",
    "        super().__init__()\n",
    "        self.mom, self.eps = mom, eps\n",
    "        self.mults = nn.Parameter(torch.ones(1))\n",
    "        self.adds = nn.Parameter(torch.zeros(1))\n",
    "        self.register_buffer('vars', torch.ones(1))\n",
    "        self.register_buffer('means', torch.zeros(1))\n",
    "    \n",
    "    def update_stats(self, x):\n",
    "        mean, var = x.mean(dim=-1), x.var(dim=-1)\n",
    "        self.vars.lerp_(mean, self.mom)\n",
    "        self.means.lerp_(var, self.mom)\n",
    "        return mean, var\n",
    "    \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            mean, var = self.update_stats(x)\n",
    "        \n",
    "        # normalized\n",
    "        x = (x - mean) / (var + self.eps).sqrt()\n",
    "        \n",
    "        # shift\n",
    "        x = self.mults * x + self.adds\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afefd87b-819b-4613-b07c-4539137cba0c",
   "metadata": {},
   "source": [
    "### Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c90ccb7d-4160-46e8-9d19-8e74e3cd53bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N_EPISODES' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mN_EPISODES\u001b[49m):\n\u001b[1;32m      2\u001b[0m     observation, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m      3\u001b[0m     in_progress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'N_EPISODES' is not defined"
     ]
    }
   ],
   "source": [
    "for episode in range(N_EPISODES):\n",
    "    observation, _ = env.reset()\n",
    "    in_progress = False\n",
    "    \n",
    "    while in_progress:\n",
    "        predicted_reward = model(torch.from_numpy(observation))\n",
    "        action_idx = torch.argmax(predicted_reward, dim=-1)\n",
    "        \n",
    "        new_observation, reward, done, truncated, info = env.step(action_idx)\n",
    "        \n",
    "        if not done:\n",
    "            predicted_next_reward = model(torch.from_numpy(new_observation))\n",
    "            max_predicted_next_reward = torch.max(predicted_reward)\n",
    "            target_reward = reward + GAMMA * max_predicted_next_reward\n",
    "            \n",
    "            loss = loss_func(target_reward, predicted_next_reward)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            observation = torch.from_numpy(new_observation)\n",
    "        else:\n",
    "            in_progress = False\n",
    "            observation, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "957d475a-ac69-4962-bcce-bc67a2f1dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQNetwork(nn.Module):\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(n_observations, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_actions)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "54bcb601-1a73-4533-9d28-37f4c8db685a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_reward(rewards, discount_factor):\n",
    "    n_rewards = len(rewards)\n",
    "    discount = discount_factor ** torch.arange(n_rewards)\n",
    "    return discount * rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ccc698-bbc5-4ce0-a43f-b07ed8758d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state, reward, truncated, info, done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
