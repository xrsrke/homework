{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "427fc5ab-9ed8-4f6a-963f-92c171e62d6e",
   "metadata": {},
   "source": [
    "### Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f60bc3-f28c-4b40-8868-03605b630fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e08fa5d-f86b-4818-8baf-0e0a4df73d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, padding_idx):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.embed = nn.Embedding(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=d_model,\n",
    "            padding_idx=padding_idx\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embed = self.embed(x)\n",
    "        return embed * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c282ecba-541a-4aef-be80-c4e73878d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6869d10e-9901-4c18-b151-8af65c990416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(x, w, b):\n",
    "    return x @ w + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509e7761-8675-40ea-8d93-d1031aba2da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _ListContainer:\n",
    "    def __init__(self, items):\n",
    "        self.items = items\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx[0], int):\n",
    "            return self.items[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60043d0f-7723-4043-bf1e-f274a1ed51ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09b8e1d-b851-439e-b874-70b4d4793414",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.init(l1.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f13b8c2-e0cd-4b39-b823-d1e4bff35d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, n_input, n_hidden):\n",
    "        super().__init__()\n",
    "        self.forget_gate = nn.Linear(n_input + n_hidden, n_hidden)\n",
    "        self.input_gate = nn.Linear(n_input + n_hidden, n_hidden)\n",
    "        self.cell_gate = nn.Linear(n_input + n_hidden, n_hidden)\n",
    "        self.output_gate = nn.Linear(n_input + n_hidden, n_hidden)\n",
    "    \n",
    "    def forward(self, inp, states):\n",
    "        cell, hidden = states\n",
    "        \n",
    "        stacked_hidden = torch.stack([inp, hidden], dim=1)\n",
    "        \n",
    "        out_of_forget_gate = F.sigmoid(self.forget_gate(stacked_hidden))\n",
    "        out_of_input_gate = F.sigmoid(self.input_gate(stacked_hidden))\n",
    "        out_of_cell_gate = F.tanh(self.cell_gate(stacked_hidden))\n",
    "        out_of_output_fate = F.sigmoid(self.output_gate(stacked_hidden))\n",
    "        \n",
    "        new_cell = cell * out_of_forget_gate + out_of_input_gate * out_of_cell_gate\n",
    "        new_h = F.tanh(new_cell) * out_of_output_fate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019572af-7651-4062-a9fe-0e88c08e458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pooling(x):\n",
    "    return F."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28af668-a90b-485c-8150-7cc55e04ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "7, 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee993ac-f7a5-439e-9045-0e25cb754943",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual block, conv2d, batch norm, linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4c29dc-c5bc-4793-a59c-bb90128d9eb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
