{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c20c28-66a2-44e1-8a05-9ae0dab9a666",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27d01822-9c9b-45fa-9b4c-4cd15d969c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19c71dc0-30bc-4812-9369-85efe52b8d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "NumberOfServing = int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0b24a2d-3712-4ddc-8f06-c5803ad02fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ingredient = Tuple[str, int, str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33ae8e4e-99cf-4500-a8f1-2fc83ce2adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = List[Union[NumberOfServing, Ingredient]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18718305-6f12-4b03-a627-26456b1e0f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "326d2034-b90a-4701-b937-0d0dd0120e4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1391157165.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def test_avg(self)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class MediumTestCase(unittest.TestCase):\n",
    "    def test_avg(self):\n",
    "        with self.assertRaises(TypeError):\n",
    "            self.assert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d4418-5685-442d-afbe-1afeb4cf6e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vehicle:\n",
    "    color = property(fget=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0411aff-fee3-4d24-a3c5-0bef72df2071",
   "metadata": {},
   "outputs": [],
   "source": [
    "arange > act > assert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bfc375-96a3-41d1-915d-e13fb57dd4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(func=func_sum, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6012cdb-0991-48d8-8489-2d9419aa682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MercedezBenz:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4743bc34-8b4c-46ff-b0e3-22ed7beb12da",
   "metadata": {},
   "source": [
    "### Design Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22e5cbbd-38ee-45f9-a960-127935a8cd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyBitmap:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.bitmap = None\n",
    "    \n",
    "    def draw(self):\n",
    "        if self.bitmap is None:\n",
    "            self.bitmap = Bitmap(self.filename)\n",
    "        \n",
    "        return self.bitmap.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c2cbbb-1a0d-4298-8c64-b95d67934019",
   "metadata": {},
   "source": [
    "### fastcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7046834-169b-4e63-99f2-cb7d346067ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.meta import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2299dbb-ac49-46a2-af03-6e6e381bb868",
   "metadata": {},
   "outputs": [],
   "source": [
    "@use_kwargs_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dabd3fa-83d8-4a49-bdef-0ac4108d7163",
   "metadata": {},
   "source": [
    "### Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e8cce30-46c1-4518-9347-c909f82ab09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82715486-01ab-4580-8eb1-3a19ee212f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformersTokenizer(Transform):\n",
    "    def encodes(self, x): return encode_text(x)\n",
    "\n",
    "    def decodes(self, x): return decode_text(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45288a71-07e1-4f89-9ee0-63232217d168",
   "metadata": {},
   "source": [
    "### Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd0434d-64f7-42aa-b2b0-176c0cef25e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_observations = env.observation_space.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81332a9c-1460-4f34-b9ea-90cb66129cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_actions = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f9c1d36-cc93-4f7c-81ba-b9127891c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3987e38e-bb6e-4456-8c88-4cfdb811b6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQ(nn.Module):\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(n_observations, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, n_actions)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5fba1c-1f59-421f-abc9-908bb9b8a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(Callback):\n",
    "    def __init__(self):\n",
    "        self.preds = []\n",
    "        \n",
    "    def after_batch(self):\n",
    "        self.preds.append(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a1c594-67a1-48d8-a879-ae84ff1a1cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "1, 2, 3, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a782a0b-4fa6-4b67-a70d-6f7887a9a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "import open_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb65ba4e-6d38-422a-9df1-37a7b49e5c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_batch = open_clip.tokenize([sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06df0966-5ee8-44e6-a41e-c85b1b6a9655",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image_batch)\n",
    "    text_features = model.encode_text(text_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dee81a7-b7fc-4ab3-b2ba-74b5ae1e2f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f461260d-ba09-470e-ac84-dfcec87ff237",
   "metadata": {},
   "outputs": [],
   "source": [
    "envs = gym.vector.SyncVectorEnv(\n",
    "    lambda: env.make(\"CartPole-v1\"),\n",
    "    lambda: env.make(\"CartPole-v1\"),\n",
    "    lambda: env.make(\"CartPole-v1\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e2e6a17-1785-4fd7-9443-6c68b72f31d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41bf5465-b660-4964-8fec-1478627b12b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m torch\u001b[38;5;241m.\u001b[39mmultinomial(\u001b[43mpreds\u001b[49m, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "torch.multinomial(preds, num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b446e87-5819-445a-b4af-8b4892cf2cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39e8e9c4-ee26-4825-8156-13c8bedb28dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02fc11b2-f65d-49d4-bad8-f364e7ec87ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m     text_embedding_norm \u001b[38;5;241m=\u001b[39m \u001b[43mtext_embedding\u001b[49m\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m     image_embedding_norm \u001b[38;5;241m=\u001b[39m image_embedding\u001b[38;5;241m.\u001b[39mnorm(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m     text_embedding \u001b[38;5;241m=\u001b[39m text_embedding \u001b[38;5;241m/\u001b[39m text_embedding_norm\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_embedding' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    text_embedding_norm = text_embedding.norm(dim=-1, keepdim=True)\n",
    "    image_embedding_norm = image_embedding.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    text_embedding = text_embedding / text_embedding_norm\n",
    "    image_embedding = image_embedding / image_embedding_norm\n",
    "    \n",
    "    scores = text_embedding @ image_embedding.T\n",
    "    probs = F.softmax(scores, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c47d2b3-c2d0-4e11-8102-fa6d6cf140b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for episode in range(N_EPISODE):\n",
    "    state, _ = env.reset()\n",
    "    state = torch.from_numpy(state)\n",
    "    \n",
    "    in_progress = False\n",
    "    \n",
    "    while in_progress:\n",
    "        predicted_reward = model(state)\n",
    "        action = torch.argmax(predicted_reward, dim=-1)\n",
    "        \n",
    "        next_state, reward, done, truncated, info = env.step(action)\n",
    "        next_state = torch.from_numpy(next_state)\n",
    "        \n",
    "        predicted_next_reward = model(next_state)\n",
    "        max_predicted_next_reward = torch.max(predicted_next_reward, dim=-1) if done else\n",
    "        \n",
    "        target_reward = reward + GAMMA * max_predicted_next_reward\n",
    "        \n",
    "        loss = loss_func(predicted_reward, target_reward)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "        if done: break\n",
    "        \n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a79aea9-71fb-4958-8de5-2ac0195ecd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_discounted_return_an_episode(rewards, discount_factor):\n",
    "    total_return = torch.zeros(1)\n",
    "    \n",
    "    for k, reward in enumerate(rewards):\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "        total_return += (discount_factor**k) * reward\n",
    "    \n",
    "    return total_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a2c500c-9cf4-4bb3-b4a3-cb45c1582c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = torch.tensor([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5c3e1120-6fca-4f43-8931-953ab151431f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14.6045])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_discounted_return_an_episode(rewards, discount_factor=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb904448-149b-4d70-a20a-80b6a8778dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential([\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "            nn.ReLU(),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2403f285-f274-4091-8086-78c84e9ca081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transitions(model, env):\n",
    "    transitions = []\n",
    "    state, _ = env.reset()\n",
    "    state = torch.from_numpy(state)\n",
    "    \n",
    "    while True:\n",
    "        predicted_action = model(state)\n",
    "        action = torch.argmax(predicted_action)\n",
    "        \n",
    "        next_state, reward, done, truncated, info = env.step(action)\n",
    "        \n",
    "        transitions.append([\n",
    "            state, action, reward, next_state\n",
    "        ])\n",
    "        \n",
    "        if done: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eeef8f59-5905-4c62-83cb-57e5a5f9689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_discounted_return_time_step(rewards, timestep, discount_factor):\n",
    "    total_return = torch.zeros(1)\n",
    "    rewards = rewards[timestep:]\n",
    "    \n",
    "    for k, reward in enumerate(rewards):\n",
    "        total_return += (discount_factor**k) * reward\n",
    "    \n",
    "    return total_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f24dc9a-13e1-439c-ada5-5dbc1434ecf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(\n",
    "            d_model, n_heads\n",
    "        )\n",
    "        self.norm_1 = ResidualLayerNorm(d_model, dropout)\n",
    "        self.position_wise = PositionWiseFeedForward(d_model, d_ff, dropout)\n",
    "        self.norm_2 = ResidualLayerNorm(d_model, dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mha_out, mha_attention_weights = self.mha(x, x, x)\n",
    "        norm_1 = norm_1(mha_out, residual=x)\n",
    "        position_wise = self.position_wise(norm_1)\n",
    "        \n",
    "        return self.norm_2(position_wise, norm_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "150dab0f-a9d3-4c76-a224-ab47348b750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, n_layers, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.text_embedding = TextEmbedding(vocab_size=1000, d_model=d_model, padding_idx=0)\n",
    "        self.position_encoding = PositionEncoding(d_model)\n",
    "        self.encoder_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, tokens):\n",
    "        text_embedding = self.text_embedding(tokens)\n",
    "        text_embedding = self.position_encoding(text_embedding)\n",
    "        \n",
    "        encoder_output = text_embedding\n",
    "        \n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            encoder_output, encoder_attention_weights = encoder_layer(encoder_output)\n",
    "        \n",
    "        return encoder_layer, encoder_attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "edea38a1-35f0-4503-8255-26255f830f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProduct(nn.Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors):\n",
    "        super().__init__()\n",
    "        self.user_factors = nn.Embedding(n_users, n_factors)\n",
    "        self.movie_factors = nn.Embedding(n_movies, n_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "952b57de-eaca-4c75-8298-531d7bef2a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, mom, eps):\n",
    "        self.mom, self.eps = mom, eps\n",
    "        self.adds = nn.Parameter(torch.zeros(1))\n",
    "        self.mults = nn.Parameter(torch.ones(1))\n",
    "        self.register_buffer('means', torch.zeros(1))\n",
    "        self.register_buffer('vars', torch.ones(1))\n",
    "    \n",
    "    def update_stats(self, x):\n",
    "        mean, var = x.mean(dim=-1), x.var(dim=-1)\n",
    "        self.means.lerp_(mean, self.mom)\n",
    "        self.vars.lerp_(var, self.mom)\n",
    "        return mean, var\n",
    "    \n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            mean, var = self.update_stats(x)\n",
    "        \n",
    "        # normalized\n",
    "        x = (x - mean) / (var + self.eps)\n",
    "        \n",
    "        # scaled and shift\n",
    "        x = self.mults * x + self.adds\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89201e48-711a-440c-9faa-6dd48f3d6766",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(\n",
    "    in_channels=3,\n",
    "    out_channels=5,\n",
    "    kernel_size=64,\n",
    "    padding=1 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b29535a-2718-4f8c-b8b1-36454f4aeff6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
