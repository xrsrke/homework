{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0089601-81e4-4cbf-a3c8-6d94434fc09c",
   "metadata": {},
   "source": [
    "Pipeline parallelism is a parallelization strategy that distributes the execution of a neural network's forward and backward passes across multiple devices. It does this by dividing the network into smaller subnetworks or partitions and assigning each partition to a different device. This way, the workload is evenly distributed and allows for improved training efficiency.\n",
    "\n",
    "In pipeline parallelism, the forward and backward passes are decomposed into smaller tasks based on the micro-batches and partitions of the network. Let's break down how the forward and backward passes are decomposed.\n",
    "\n",
    "Forward Pass Decomposition:\n",
    "\n",
    "Divide the input batch into micro-batches, e.g., $x_1, \\cdots, x_m$.\n",
    "Sequentially execute the partitions $f^j$ on each micro-batch $x_i$. This results in tasks $F_{i, j}$, where $x_i^0 = x_i$ and $x_i^j = f^j(x_i^{j-1})$ for $i = 1, \\cdots, m$ and $j = 1, \\cdots, n$.\n",
    "Compute the output $f(x)$ by aggregating the results from each device, $x_i^n = f(x_i)$.\n",
    "Backward Pass Decomposition:\n",
    "\n",
    "Compute the gradient of the loss with respect to each output, $dx_i^n$.\n",
    "Sequentially execute the backward pass through the partitions $f^j$ on each gradient $dx_i^j$. This results in tasks $B_{i, j}$, where $dx_i^{j-1} = \\partial_x f^j(dx_i^j)$ and $g_i^j = \\partial_{\\theta^j} f^j(dx_i^j)$ for $i = 1, \\cdots, m$ and $j = 1, \\cdots, n$.\n",
    "Compute the gradient of the loss with respect to the network parameters, $g^j = \\sum_{i=1}^m g_i^j$.\n",
    "Pipeline parallelism takes advantage of the sequential nature of the tasks in the forward and backward passes. By assigning tasks with different micro-batch indices to different devices, the network can be trained efficiently using data parallelism. Note that there are data dependencies between tasks, so they must be executed in a specific order to ensure that the required data is available when needed.\n",
    "\n",
    "In summary, pipeline parallelism decomposes the forward and backward passes into smaller tasks based on micro-batches and partitions, assigning each task to a different device for parallel execution. This enables efficient training of large neural networks across multiple devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd0115dd-1161-4b42-bc46-cb06f2e652de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for clock_idx in range(n_microbatches+n-1):\n",
    "#     from_partrition = max(1+clock_idx-n_microbatches, 0)\n",
    "#     to_partrition = min(1+clock_idx, n_partritions)\n",
    "    \n",
    "#     # print(f\"from_partrition={from_partrition}\")\n",
    "#     # print(f\"to_partrition={to_partrition}\")\n",
    "    \n",
    "# #     for j in range(max_val, min_val):\n",
    "# #         microbatch_idx = clock_idx-j\n",
    "# #         partrition_idx = j+1\n",
    "        \n",
    "# #         print((microbatch_idx, partrition_idx))\n",
    "    \n",
    "#     results = []\n",
    "#     for j in range(from_partrition, to_partrition):\n",
    "#         result = (clock_idx-j, j)\n",
    "#         results.append(result)\n",
    "#     print(results)\n",
    "\n",
    "#     print([(clock_idx-j, j) for j in range(from_partrition, to_partrition)] )\n",
    "    \n",
    "    \n",
    "#     print(\"---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da36f923-63a0-447a-a240-9ca1787d63a5",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d32b4bd-ac5f-4051-87ee-b643e8b348ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clock_cycle(m, n):\n",
    "    for k in range(m+n-1):\n",
    "        yield [(k-j, j) for j in range(max(1+k-m, 0), min(1+k), n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88fabf88-c0d4-443b-a45f-9160461a4c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 4\n",
    "n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9b4b32b-7676-4b15-9755-0c572d3adf92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_microbatches = m = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d4917088-fff0-4e22-b391-22e8b63a156b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_partritions = n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e99dc06e-ecf9-49e6-b16c-91f6541c9089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from_partrition=0\n",
      "to_partrition=1\n",
      "partrition_idx = 0\n",
      "[(1, 1)]\n",
      "---------\n",
      "from_partrition=0\n",
      "to_partrition=2\n",
      "partrition_idx = 0\n",
      "partrition_idx = 1\n",
      "[(2, 1), (1, 2)]\n",
      "---------\n",
      "from_partrition=0\n",
      "to_partrition=3\n",
      "partrition_idx = 0\n",
      "partrition_idx = 1\n",
      "partrition_idx = 2\n",
      "[(3, 1), (2, 2), (1, 3)]\n",
      "---------\n",
      "from_partrition=0\n",
      "to_partrition=3\n",
      "partrition_idx = 0\n",
      "partrition_idx = 1\n",
      "partrition_idx = 2\n",
      "[(4, 1), (3, 2), (2, 3)]\n",
      "---------\n",
      "from_partrition=1\n",
      "to_partrition=3\n",
      "partrition_idx = 1\n",
      "partrition_idx = 2\n",
      "[(4, 2), (3, 3)]\n",
      "---------\n",
      "from_partrition=2\n",
      "to_partrition=3\n",
      "partrition_idx = 2\n",
      "[(4, 3)]\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "for clock_idx in range(n_microbatches+n_partritions-1):\n",
    "    from_partrition = max(clock_idx+1-n_microbatches, 0)\n",
    "    to_partrition = min(clock_idx+1, n_partritions)\n",
    "    \n",
    "    print(f\"from_partrition={from_partrition}\") # ignore\n",
    "    print(f\"to_partrition={to_partrition}\") # ignore\n",
    "\n",
    "    results = []\n",
    "    for partrition_idx in range(from_partrition, to_partrition):\n",
    "        print(f\"partrition_idx = {partrition_idx}\") # ignore\n",
    "        microbatch_idx = clock_idx-partrition_idx\n",
    "        result = (microbatch_idx+1, partrition_idx+1)\n",
    "        results.append(result)\n",
    "    \n",
    "    print(results)\n",
    "    \n",
    "    print(\"---------\") # ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9d14dd-fd5a-431a-b3c4-6d93437852fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "- `from_partrition`: represent the earliest possible partition index that can be activated in clock cycle `clock_idx`, while ensuring we don't start too early\n",
    "    - `1+clock_idx` means we can start as early as partition 1\n",
    "    - `-n_microbatches` means we have to offset by the number of microbatches that have already entered the pipeline\n",
    "    - `min(x, 0)`: We take the max with 0 because we can never start earlier than partition 0.\n",
    "\n",
    "- `to_partrition`: represents the latest partition we can start a microbatch on for clock cycle `clock_idx`.\n",
    "    - `clock_idx+1`: means we can go as late as k partitions into the pipeline. The reason the next partrition we can go is `1+clock_idx` because if we go to `n` clock cycles in the pipeline, we already processed `n` micro-batches, so the next one will be `clock_idx+1`\n",
    "    - `min(x, n_partritions)`: take the min with n (total # of partitions) because we can never go past the last partition.\n",
    "\n",
    "\n",
    "The range from `from_partrition` to `to_partrition` then iterates over all the possible partitions we could start a microbatch on for clock cycle `clock_idx`\n",
    "\n",
    "\n",
    "\n",
    "- `(clock_idx-j, j)`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a548a6d6-504a-4042-918d-a622b887f599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c76208b-69c2-45b2-b0c1-c90afb07a63c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0)]\n",
      "[(1, 0), (0, 1)]\n",
      "[(2, 0), (1, 1)]\n",
      "[(3, 0), (2, 1)]\n",
      "[(3, 1)]\n"
     ]
    }
   ],
   "source": [
    "for k in range(m+n-1):\n",
    "    print([(k-j, j) for j in range(max(1+k-m, 0), min(1+k, n))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77961f9-fafb-48e8-bbd3-3bae2e0b00b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5d2a6e-9942-42f2-91ae-c6f4989f400a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b5e04d7-e2cc-4f61-a1d9-69dbe0c15f47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 4):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d27d0c-2839-41b6-a596-b9b9852afb9e",
   "metadata": {},
   "source": [
    "##### Draft 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec4089-3f4a-4f87-b680-ff06a1199d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6a4da1-481f-4eec-a70c-ea4162c106f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
