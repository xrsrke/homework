{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a907c847-76dd-4c06-a191-2244fbdb6d39",
   "metadata": {},
   "source": [
    "Source: https://www.cnblogs.com/rossiXYZ/p/15339953.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682636fb-9c52-48bb-8049-8434cabaff74",
   "metadata": {},
   "source": [
    "### 3. Splitting Data and Runtime System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65cb405-72bf-4089-bca4-89f2332634ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f57c0a-f2d0-40f1-836a-84c4fb5365e9",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7619b8f-fea9-404e-974e-36912fedecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2)\n",
    "y = torch.randn(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e680857d-f02c-48e7-aa08-f77806898902",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7687136d-5291-4a7a-8743-1a23c3612420",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73930519-7e7b-40c4-8745-012e7991eae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62742a40-271e-4121-9966-dc36d5a1fa1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2]), torch.Size([22]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8cef0c-411f-4839-b934-94e618c172e5",
   "metadata": {},
   "source": [
    "Compute the mean of `x` and `y` in parallel using CUDA stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c279d6b-d97a-4d14-b3bf-bbfcc3619403",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream1 = torch.cuda.Stream()\n",
    "stream2 = torch.cuda.Stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616edb60-c781-4b01-8092-d63948a3a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.stream(stream1):\n",
    "    x_mean = x.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8906e631-2c1a-45d0-bb0f-fb809c728296",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.stream(stream1):\n",
    "    y_mean = y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150661e5-48bc-406f-b6ed-e8ac0f1917eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.4989), tensor(-0.3499))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_mean, y_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaeafa5-798c-4b9b-a9ff-1e4bdb64324f",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ca3a33-c139-4d80-a776-a48b47758718",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59738dcc-ee30-4345-abf6-324329f02cf4",
   "metadata": {},
   "source": [
    "Write context managers that work as bellow and explain it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeff967-43bb-48bd-b19b-a80655ff3d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def first_context():\n",
    "    # Code to be executed before the context\n",
    "    print(\"Entering the context\")\n",
    "    \n",
    "    # Yield the value to be used in the context\n",
    "    yield\n",
    "    \n",
    "    # Code to be executed after the context\n",
    "    print(\"Leaving the context\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbad61a-1fd8-4316-a5f1-a7e5ee378888",
   "metadata": {},
   "source": [
    "**Explain**\n",
    "\n",
    "`yield` is used to indicate the boundary between the setup (enter) and the cleanup (exit) phases of the context.\n",
    "\n",
    "Since there is no value being yielded, the variable that is assigned the result of calling the function will be `None`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c2b76-ad51-43f9-970c-8175ca632077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering the context\n",
      "None\n",
      "3\n",
      "Leaving the context\n"
     ]
    }
   ],
   "source": [
    "with first_context() as x:\n",
    "    print(x)\n",
    "    print(1 + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399b73eb-621e-4f85-8bf2-dc8d4366b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def second_context():\n",
    "    print(\"Entering the context\")\n",
    "    # Yield the value to be used in the context\n",
    "    yield \"Hello, World!\"\n",
    "    print(\"Leaving the context\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8856c097-04f2-4892-9ab0-eb5aabc59bf1",
   "metadata": {},
   "source": [
    "**Explain**\n",
    "\n",
    "Because the `yield` statement returns the string \"Hello, World!\", so when the context is used, the value \"Hello, World!\" is available to the code that called the context manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde152ef-7841-4a0d-969f-d17f7ae5e9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering the context\n",
      "Hello, World!\n",
      "3\n",
      "Leaving the context\n"
     ]
    }
   ],
   "source": [
    "with second_context() as x:\n",
    "    print(x)\n",
    "    print(1 + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d736f24-5b88-439f-a063-199b9f194999",
   "metadata": {},
   "source": [
    "##### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289ba1fa-08f3-4bfb-9b4c-3528dca5a2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([69, 69, 69])\n",
    "b = torch.tensor([420, 420, 420])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a5249d-ba11-494d-bc5d-2b7a896e1d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327704c0-0323-4016-b8b5-0fd0375096d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e31424-dff5-4807-a8b4-1c123d8c8954",
   "metadata": {},
   "source": [
    "Write a context manager that takes a stream and executes a block of code either on a CUDA stream or a CPU stream. Explain the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5dd01e-2320-43a1-990d-6221636ba69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def use_stream(stream):\n",
    "    if not isinstance(stream, torch.cuda.Stream):\n",
    "        yield\n",
    "        return # stop the function's execution\n",
    "    \n",
    "    with torch.cuda.stream(stream):\n",
    "        yield"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd29ec77-962e-4e6e-bd29-4f2592d3795e",
   "metadata": {},
   "source": [
    "**Explain**\n",
    "\n",
    "- `@contextmanager`: This is a decorator that turns the use_stream function into a context manager. It allows the function to be used in a with statement.\n",
    "\n",
    "- `def use_stream(stream)`: This defines the use_stream function that takes a single argument called stream. This can be a CPU or CUDA stream.\n",
    "\n",
    "- `if not isinstance(stream, torch.cuda.Stream):`: This line checks if the provided stream is a CPU stream. If the stream is not an instance of torch.cuda.Stream, it means it's a CPU stream.\n",
    "\n",
    "- `yield`: This is the point in the context manager where the code inside the with block will be executed. If the stream is a CPU stream, the yield statement allows the code within the with block to execute without any additional setup.\n",
    "\n",
    "- `return`: This line stops the execution of the function early when the stream is a CPU stream. This ensures that the code following the return statement, which sets up a CUDA stream context, is not executed.\n",
    "\n",
    "- `with torch.cuda.stream(stream):`: This line is only executed if the stream is a CUDA stream. It creates a new context for the provided CUDA stream, ensuring that any code executed within this context will use the specified CUDA stream.\n",
    "\n",
    "- `yield`: This yield statement is used when the stream is a CUDA stream. It allows the code within the with block to execute using the set up CUDA stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be5beaa-cbee-47e1-b9db-d75eb103fdc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([69, 69, 69]), tensor([420, 420, 420]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caec9856-026b-49fa-952d-50e4ecf0a820",
   "metadata": {},
   "outputs": [],
   "source": [
    "with use_stream(stream):\n",
    "    x = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab62e40c-2b4f-46d9-af8f-c99c22c1ff80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([489, 489, 489])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e0dbbc-6320-4f9a-99a6-d8def0e69e2c",
   "metadata": {},
   "source": [
    "##### Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e6a15f-c410-435a-9b2e-7479789244f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd182b-ddd7-4784-8db1-1ad1469e68f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33ca904-eeb5-423c-9a88-63c85a077ace",
   "metadata": {},
   "source": [
    "Implement a queue data structure using Python's built-in module that stores all values in `xs` and works as bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b852ccf3-96e9-41e5-8ab3-fb29c4d33374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b967d52f-b2f8-4943-8ca9-6408c493ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Queue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad6ff6f-e0a0-4248-bb39-ff8ffac43211",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in xs:\n",
    "    q.put(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29305a0c-df11-4179-ba10-03a52b00ea22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6e764f-c042-439d-a65c-e43cc1fca00f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9018e2f3-7cc1-4c54-b12f-7bd39f66e014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a1e250-4a17-482a-8e65-1c64928b5ee8",
   "metadata": {},
   "source": [
    "##### Example 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafaa06b-5c78-488b-b7c7-767d5fa86596",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e548e-c85b-4abf-9f36-5d37d1922ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([69, 69, 69])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35ca68f-8545-4692-91ff-e78e7dc3bb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129ee3ae-ec17-4a19-9a2e-5a11e39a8122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3749be69-0b74-4059-a0f4-58afca128a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([69, 69, 69])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936b2253-4155-4c17-8f47-b078dae65d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6336b732-77be-4412-9f30-3b6b4f9aa381",
   "metadata": {},
   "source": [
    "Compute the sum of all elements in `x` on `device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b64a4b-adf7-4f6f-b19a-0978ef658724",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.device(device):\n",
    "    total = x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ee03f6-a783-4a10-8635-a9d20a499a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(207)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21abbb85-d2aa-4067-8451-588be1443751",
   "metadata": {},
   "source": [
    "##### Example 5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c5288-108d-4908-bb4e-883b310c88eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c3c1ae-3d9e-46e3-9535-bda3097c0662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_numbers():\n",
    "    for i in range(5):\n",
    "        print(i)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b16b40-e208-4a6c-b2f3-ab882719b586",
   "metadata": {},
   "source": [
    "Run the function `print_numbers` on a new thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f161189-d973-441b-9ffb-d9fca766b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbb8e6e-2a20-421c-afba-4a9bed758a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = threading.Thread(target=print_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4adce7d-ab8b-4172-8bdd-ff7756e8e8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919112ad-5ec7-4d5d-b2e7-ad2c2dfb9722",
   "metadata": {},
   "source": [
    "##### Example 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8838770-0b43-472c-8021-e46a61873937",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.tensor([69, 69, 69]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3926c6c2-24b6-4b6d-876b-40146af7a699",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd2e1b1-a5ad-4531-82e1-be07ea488636",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = xs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8435965-3748-4d96-933c-1ebe0eea2f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc0725f-908b-49e4-b435-e1bc725f6d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([69., 69., 69.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37799224-670e-4f2b-a321-c2e6a51504b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d575b99-a05d-462f-8787-70837c348b0f",
   "metadata": {},
   "source": [
    "Create a new CUDA stream on the device, and then calculate the average of `xs` using that CUDA stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a00b880-7feb-4b36-b605-438482020946",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = torch.cuda.Stream(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b823a8da-26cd-468e-bb3d-400232666ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.device(device):\n",
    "    with torch.cuda.stream(stream):\n",
    "        mean = xs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b06b30f-88c8-4700-b4fa-3c8ed879a0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(69.)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceed99f4-a270-4e4a-8ba5-8440cf3acb73",
   "metadata": {},
   "source": [
    "##### Example 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa03b1d9-7fb2-4967-a29f-c89161a4763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3895dbf-6f02-4524-a660-335bd8a99987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.exc_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea33a24c-4208-4bf8-9b2a-16ffde4586b1",
   "metadata": {},
   "source": [
    "### Spawn Workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab2c6ddb-4236-4167-bbe6-97223c62095c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clock_cycles(m: int, n: int):\n",
    "    \"\"\"Generates schedules for each clock cycle.\"\"\"\n",
    "    # m: number of micro-batches\n",
    "    # n: number of partitions\n",
    "    # i: index of micro-batch\n",
    "    # j: index of partition\n",
    "    # k: clock number\n",
    "    #\n",
    "    # k (i,j) (i,j) (i,j)\n",
    "    # - ----- ----- -----\n",
    "    # 0 (0,0)\n",
    "    # 1 (1,0) (0,1)\n",
    "    # 2 (2,0) (1,1) (0,2)\n",
    "    # 3       (2,1) (1,2)\n",
    "    # 4             (2,2)\n",
    "    for k in range(m+n-1):\n",
    "        yield [(k-j, j) for j in range(max(1+k-m, 0), min(1+k, n))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ace7b44-e253-4e5b-bfa4-a14e54af78ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a09775e3-ba96-4dd5-b1c8-bc38263c1620",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from queue import Queue\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b21b74c-3a59-44b8-9ddd-52edea8d2b02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def worker(in_queue, out_queue, device):\n",
    "    with torch.cuda.device(device):\n",
    "        while True:\n",
    "            task = in_queue.get()\n",
    "            \n",
    "            try:\n",
    "                output = task()\n",
    "            except Exception:\n",
    "                out_queue.put(False)\n",
    "                continue\n",
    "            \n",
    "            out_queue.put((True, output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "88b4abc7-c409-4ab5-9fd4-d0c20fe56a02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hello():\n",
    "    print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d8315c8-0501-47f6-8cc8-2289a6d5c558",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def spawn_workers(devices):\n",
    "    in_queues = []\n",
    "    out_queues = []\n",
    "    \n",
    "    workers = {}\n",
    "    \n",
    "    for device in devices:\n",
    "        in_queue = Queue()\n",
    "        out_queue = Queue()\n",
    "        workers[device] = (in_queue, out_queue)\n",
    "        \n",
    "        t = Thread(\n",
    "            target=worker,\n",
    "            args=(in_queue, out_queue, device),\n",
    "            daemon=True\n",
    "        )\n",
    "        t.start()\n",
    "        \n",
    "        in_queues.append(in_queue)\n",
    "        out_queues.append(out_queue)\n",
    "    \n",
    "    yield (in_queue, out_queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1756c70d-9a92-480b-b41f-328ff1491e31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "devices = [\n",
    "    torch.device(\"cuda:0\"),\n",
    "    torch.device(\"cuda:1\"),\n",
    "    torch.device(\"cuda:2\"),\n",
    "    torch.device(\"cuda:3\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c52bc75-01bc-4bee-9c0b-930f6a477193",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[device(type='cuda', index=0),\n",
       " device(type='cuda', index=1),\n",
       " device(type='cuda', index=2),\n",
       " device(type='cuda', index=3)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba0e803f-9f76-4fc3-bbd6-edc8ebc482bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_microbatches = 4\n",
    "n_partritions = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3755d986-7aa4-4ca2-84f6-38f3e763dbbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hello():\n",
    "    print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed6ebbf2-34d2-40bf-b831-360b8dc38893",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Exception in thread Thread-21:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/education/opt/anaconda3/envs/ml_engineering/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "Exception in thread Thread-23:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/education/opt/anaconda3/envs/ml_engineering/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "Thread-22:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/education/opt/anaconda3/envs/ml_engineering/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "Exception in thread Thread-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/education/opt/anaconda3/envs/ml_engineering/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/education/opt/anaconda3/envs/ml_engineering/lib/python3.8/threading.py\", line 870, in run\n",
      "    self.run()\n",
      "  File \"/Users/education/opt/anaconda3/envs/ml_engineering/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/pf/g3nr86yn4j71vzzmv6knwdhr0000gp/T/ipykernel_2702/2507933274.py\", line 2, in worker\n",
      "    self.run()\n",
      "  File \"/Users/education/opt/anaconda3/envs/ml_engineering/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/pf/g3nr86yn4j71vzzmv6knwdhr0000gp/T/ipykernel_2702/2507933274.py\", line 2, in worker\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/pf/g3nr86yn4j71vzzmv6knwdhr0000gp/T/ipykernel_2702/2507933274.py\", line 2, in worker\n",
      "    self.run()\n",
      "  File \"/Users/education/opt/anaconda3/envs/ml_engineering/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/var/folders/pf/g3nr86yn4j71vzzmv6knwdhr0000gp/T/ipykernel_2702/2507933274.py\", line 2, in worker\n",
      "  File \"/Users/education/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 316, in __enter__\n",
      "  File \"/Users/education/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 316, in __enter__\n",
      "  File \"/Users/education/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 316, in __enter__\n",
      "  File \"/Users/education/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 316, in __enter__\n",
      "    self.prev_idx = torch.cuda._exchange_device(self.idx)\n",
      "  File \"/Users/education/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 79, in _exchange_device\n",
      "    self.prev_idx = torch.cuda._exchange_device(self.idx)\n",
      "  File \"/Users/education/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 79, in _exchange_device\n",
      "    self.prev_idx = torch.cuda._exchange_device(self.idx)\n",
      "  File \"/Users/education/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 79, in _exchange_device\n",
      "    self.prev_idx = torch.cuda._exchange_device(self.idx)\n",
      "  File \"/Users/education/opt/anaconda3/envs/ml_engineering/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 79, in _exchange_device\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Queue' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m spawn_workers(devices) \u001b[38;5;28;01mas\u001b[39;00m (in_queues, out_queues):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m in_queue \u001b[38;5;129;01min\u001b[39;00m in_queues:\n\u001b[1;32m      4\u001b[0m             in_queue\u001b[38;5;241m.\u001b[39mput(hello)\n\u001b[1;32m      5\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Queue' object is not iterable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        raise RuntimeError(\"PyTorch was compiled without CUDA support\")\n",
      "RuntimeError: PyTorch was compiled without CUDA support\n",
      "    raise RuntimeError(\"PyTorch was compiled without CUDA support\")\n",
      "RuntimeError: PyTorch was compiled without CUDA support\n",
      "raise RuntimeError(\"PyTorch was compiled without CUDA support\")\n",
      "RuntimeError: PyTorch was compiled without CUDA support\n",
      "    raise RuntimeError(\"PyTorch was compiled without CUDA support\")\n",
      "RuntimeError: PyTorch was compiled without CUDA support\n"
     ]
    }
   ],
   "source": [
    "with spawn_workers(devices) as (in_queues, out_queues):\n",
    "    while True:\n",
    "        for in_queue in in_queues:\n",
    "            in_queue.put(hello)\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad364df8-0137-49d3-98e9-b8b4c57c3fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
