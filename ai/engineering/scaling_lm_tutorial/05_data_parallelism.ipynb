{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c05a5ae-cebf-4d0b-b569-af27c5a24f9d",
   "metadata": {},
   "source": [
    "Source: https://nbviewer.org/github/tunib-ai/large-scale-lm-tutorials/blob/main/notebooks/05_data_parallelism.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3050a9a4-6c19-47dd-a2a1-a7433b1fd7cd",
   "metadata": {},
   "source": [
    "### Data Parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e810ff47-fdc2-400a-a71b-145d0b6b0ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede93e40-2c31-4ab6-999f-62aefd82e9bf",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eaafdf-f96d-4a0d-b5e1-3d2390ca789f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(10, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c8922-0a39-4e19-876e-76c2ed1d9023",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48ea50e-37da-46d9-94ce-5dccea899527",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760397f1-1e82-40bf-b8a7-7e7c7b692c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=20, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=20, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8e9c2a-4ba2-4a26-a749-5f4f606aca1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6d6742-9099-49e0-8c5b-d3b76366ceea",
   "metadata": {},
   "source": [
    "Write the forward pass for data parallelism. The `input_ids` variable holds the IDs of all the devices, while `output_id` is the ID of the main device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5430fe-7f96-404f-b0fa-5f974ce23bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6686fb-1ad2-4cda-9f6b-de811f04f0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_forwward_pass_using_data_parallelism(model, input, device_ids, output_id):\n",
    "    # Distribute the inputs to all `device_ids`.\n",
    "    inputs = nn.parallel.scatter(input, device_ids)\n",
    "    \n",
    "    # Replicate the model to all `device_ids`.\n",
    "    models = nn.parallel.replicate(model, device_ids)\n",
    "    \n",
    "    # Compute the logits of each micro-batch with respect to each replicated model\n",
    "    # on each device.\n",
    "    logit = nn.parallel.parallel_apply(models, inputs)\n",
    "    \n",
    "    # Gathers the logits from all devices and sends them to `output_device`.\n",
    "    logits = nn.parallel.gather(logit, output_id)\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83b3d86-5b86-4d0b-9010-3d79c41d165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = compute_forwward_pass_using_data_parallelism(model, input, device_ids, output_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80eda86-bc54-4d35-8cfa-5ea5c65eae41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ab4de3-e037-4f57-8000-0d16b5c87892",
   "metadata": {},
   "source": [
    "##### Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a9ff91-aea6-4540-a81a-2ce163a302b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ids = torch.tensor([0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b96052-05dc-4750-b3ca-5419008f5179",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_id = torch.tensor(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ffffab-75a4-4ba2-90b7-32ad7e8ef237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=10, out_features=20, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=20, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0c6a02-960d-4f3d-a14e-07e19be5c7ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 1, 2, 3, 4]), tensor(0))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_ids, output_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606830de-9176-4035-9095-529aae3346ab",
   "metadata": {},
   "source": [
    "Write a function that utilizes PyTorch's built-in module for performing Data Parallelism.\n",
    "\n",
    "**Hint**: both forward and backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d9c246-7e4b-4d58-9e55-fe507b743ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e6de58-0ba2-4c98-875a-9ac1fe74791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_iter(inp, targ, model, loss_func, optimizer, device_ids, output_ids):\n",
    "    optimizer.zero_grad()\n",
    "    model = nn.DataParallel(model, device_ids=device_ids, output_device=output_ids)\n",
    "    \n",
    "    logits = model(inp)\n",
    "    loss = loss_func(logits, targ)\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e869c0c-9498-4af4-b612-b934cfab99e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_iter(inp, targ, model, loss_func, optimizer, device_ids, output_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c581a8e4-313e-4396-8ab2-038cdfcb1cf2",
   "metadata": {},
   "source": [
    "##### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fcb7af-5400-49ec-a650-5e353f08b533",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def forward(self, x): return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583d564e-9e1a-432e-b405-465a420e14f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.DataParallel(\n",
    "    model,\n",
    "    device_ids=[0, 1, 2, 3],\n",
    "    output_device=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb999dd-339e-47cf-a7fe-6559fc1a3388",
   "metadata": {},
   "source": [
    "Explain how this code causes memory imbalance across all GPUs.\n",
    "\n",
    "How to utilize all the GPUs's memory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b03e56-cec3-4ae2-bd87-4cb0e142ee09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, data in enumerate(data_loader):    \n",
    "    ### ....\n",
    "    outputs = model(x) \n",
    "    loss = loss_fn(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c485124e-1662-472a-bdb6-caafaf380128",
   "metadata": {},
   "source": [
    "**Explain**\n",
    "\n",
    "`nn.DataParallel` splits the input data to the model and distributes it to all available devices (GPUs). After processing the data on each device, the final logits are concatenated and sent back to device `0` for further processing. \n",
    "\n",
    "The memory imbalance arises because only one GPU (device `0`) is responsible for collecting the outputs from all other devices and computing the loss function. This aggregation of outputs and loss computation on a single GPU increases the memory usage on device `0`, while the other devices do not experience the same memory consumption.\n",
    "\n",
    "We can utilize all GPUs by distributing the loss computation across all GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8b1ecf-ffdf-4df0-a46b-6fad27c29913",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, data in enumerate(data_loader):    \n",
    "    ### ....\n",
    "    _, losses = model(x)    \n",
    "    # because the final `loss` is\n",
    "    # the loss from all devices\n",
    "    loss = losses.mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d9ff0b-9154-4fc7-896f-2ba284796ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2cc736-9ae9-4e7f-a01f-b3fbe1d9f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def forward(self, x, labels):\n",
    "        output = self.net(x)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0867ff-beba-41a0-a51f-6d8079e101c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
