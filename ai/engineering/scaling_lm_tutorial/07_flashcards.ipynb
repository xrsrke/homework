{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a81609c-321c-4f83-8843-67bb2d803157",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd61dddc-2457-47fc-a439-100deed9d44e",
   "metadata": {},
   "source": [
    "##### Examle 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad288aa6-ebed-439c-ad42-cfe3e51ee682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87cb142-6be2-4e1f-80b0-8714447967a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"./persistence.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e51354-6038-4f72-90fd-382b70a3f841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('persistence.txt')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511b16ae-3b3f-4b67-a305-701a41c3c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open(path, \"rb\", buffering=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc2ee49-3d20-4516-b606-a3ebc0f32e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.FileIO name='persistence.txt' mode='rb' closefd=True>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9a26af-ae29-4721-9f0e-be3033305345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'persis'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file.read(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9db5cd6-0fbc-4d08-9a10-2e0e347db74f",
   "metadata": {},
   "source": [
    "Bring the file cursor back to the beginning of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ca6634-9a56-4ec4-b5b5-6865cd3a0ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b782c8-5a9a-4b8a-bc09-33e01cfa1821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'persis'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file.read(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2146dccb-0ffe-4c37-971d-92011bf71b72",
   "metadata": {},
   "source": [
    "##### Example 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf0af9a-129f-4f22-9860-08898089cf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ffdd3f-0d44-4af5-9513-d6267e4d4a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "number = torch.tensor(6.9, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0fe6d7-82e7-4d02-92b9-60e3e810b621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number.numel() * number.element_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa7893b-a395-4dbc-94fd-0ac784c4e357",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_size = 100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ad0619-bcb1-44ca-a43a-b5725d05bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98e75a0-0dfa-48aa-a7cd-71b8a13ba0a4",
   "metadata": {},
   "source": [
    "Create a function that creates a placeholder tensor for a continuous memory block as shown below.\n",
    "\n",
    "**Hint**: Each number in FP32 format takes up 4 bytes in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a3f3ec-4a1a-4285-8eb0-bf91485e85cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_continuous_memory(size):\n",
    "    FP32_SIZE = 4\n",
    "    n_numbers = size // FP32_SIZE\n",
    "    return torch.empty(n_numbers, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379a1d2a-3b15-471e-aca7-31b85534b2ac",
   "metadata": {},
   "source": [
    "**Explain**\n",
    "\n",
    "- `size // FP32_SIZE`: It calculates the number of float32 numbers that will fit in the requested size of memory by dividing the size by `FP32_SIZE`\n",
    "\n",
    "- `torch.empty(n_numbers, dtype=torch.float32)` will create a tensor that takes a continuous block of memory with space for `n_numbers` float32 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23a78a5-d618-4f2a-bff2-bc2b3b90ba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = create_continuous_memory(memory_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33f1961-1937-40f0-97b1-546e8451ca60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576e9d9b-d75b-4e17-b7c1-9c70e7ace79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cache.numel() * cache.element_size()) == memory_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85ba275-c1e2-4fe6-add4-0e7db3f13262",
   "metadata": {},
   "source": [
    "##### Example 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970cf0c4-7b90-4494-90a4-3bb7ed528f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "631e4078-49e8-49a2-a312-0fedb9488a03",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f2950e-1c7d-4d43-8e83-fd072e8d7165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686c2770-1c27-4553-9c15-1fb7b0aca388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class IndexedCachedDataset:\n",
    "#     def __init__(self, path):\n",
    "#         self.data_file = None\n",
    "#         self.cache_index = None\n",
    "#         self.path = path\n",
    "#         self.data_offsets = None\n",
    "    \n",
    "#     def read_data(self, path):\n",
    "#         self.data_file = open(data_file_path(path), \"rb\", buffering=0)\n",
    "        \n",
    "#     def prefetch(self, indicies: List[int]):\n",
    "#         if all(i in self.cache_index for i in indicies):\n",
    "#             return\n",
    "        \n",
    "#         if not self.data_file:\n",
    "#             self.read_data(self.path)\n",
    "        \n",
    "#         indicies = sorted(set(indicies))\n",
    "        \n",
    "#         total_size = 0\n",
    "#         for i in indicies:\n",
    "#             total_size += self.data_offsets[i+1] - self.data_offsets[i]\n",
    "        \n",
    "#         self.cache = np.empty(total_size, dtype=self.dtype)\n",
    "#         self.cache_index.clear()\n",
    "#         ptx = 0\n",
    "        \n",
    "#         for i in indicies:\n",
    "#             self.cache_index[i] = ptx\n",
    "#             size = self.data_offsets[i+1] - self.data_offsets[i]\n",
    "#             array = self.cache[ptx:ptx+size]\n",
    "#             self.data_file.seek()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8c259f-2222-40d9-b9b1-d171b3fe2158",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462e6991-798d-46ba-bfec-c46401126225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_memory_size(x):\n",
    "    return x.numel() * x.element_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8e609a-3429-4a49-8a6c-2a09edb87c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(\"data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30eb9ac-9807-4ef9-b614-5fee4120db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachedDataset(Dataset):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.data = None\n",
    "        self.cache = None\n",
    "        self.cache_index = {}\n",
    "    \n",
    "    def prefetch(self, idxs: List[int]):\n",
    "        if all(i in self.cache_index for i in idxs):\n",
    "            return\n",
    "        \n",
    "        if not self.data:\n",
    "            self.data = torch.load(self.filename)\n",
    "        \n",
    "        total_elements = sum([self.data[i].numel() for i in idxs])\n",
    "        self.total_elements = total_elements\n",
    "        self.cache = torch.zeros(total_elements, dtype=self.data.dtype)\n",
    "        \n",
    "        self.cache_index.clear()\n",
    "        offset = 0\n",
    "        for i in idxs:\n",
    "            n_elements = self.data[i].numel()\n",
    "            self.cache_index[i] = offset\n",
    "            self.cache[offset:offset+n_elements] = self.data[i].view(-1)\n",
    "            offset += n_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7007032b-b0ca-4278-af4a-e1a0498a1790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295fa3c4-5433-40a4-956e-b5d9729663c5",
   "metadata": {},
   "source": [
    "Implement data prefetching for cached data according to the criteria outlined below:\n",
    "\n",
    "- Check if the next training samples (`idxs`) are already cached (`self.cache_index`).\n",
    "If they are, skip the prefetching step.\n",
    "- Verify if the training data is loaded. If it is not, load it before proceeding to load the next training samples into RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e3f1f-ede1-4d27-beeb-b84211f283b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_dataset = CachedDataset(\"data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91867a71-b5b9-4df2-bba7-6beb9c5c4fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[69, 42]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7aa28f8-e220-41b6-961a-de9790ea6853",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_dataset.prefetch(idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b41ea-405e-4eb0-be38-14d021b73059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cached_dataset.cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ee64a-c85c-4837-92c2-38f774ce013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_size = calculate_memory_size(dataset.cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273af04c-41aa-4330-836f-ab81b93e8c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = sum([calculate_memory_size(data[i]) for i in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a9d40-472e-4ed6-980e-2e1a5a0805c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cached_size == sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7f5209-d984-473e-957c-a36909914e1e",
   "metadata": {},
   "source": [
    "##### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b5af6e-57b5-41a6-a777-64df7035d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fe1df6-1126-496c-bd1c-b300eaeb84a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
