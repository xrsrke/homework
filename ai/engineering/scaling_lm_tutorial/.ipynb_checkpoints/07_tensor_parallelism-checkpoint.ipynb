{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3412cd7-a5e6-4be9-8645-44ed20e78064",
   "metadata": {},
   "source": [
    "### Tensor Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e9c1e8-4235-4dbd-9e85-120513aadc2b",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6c9ced8-0648-47a7-a523-ee9f6b7a92c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1823a8f9-f226-48e8-9888-66672b8d5bd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor([\n",
    "    [0, 1, 2, 3],\n",
    "    [4, 5, 6, 7]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f8db7f5-27f4-4a23-8086-382c6a90591b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = torch.tensor([\n",
    "    [10, 14],\n",
    "    [11, 15],\n",
    "    [12, 16],\n",
    "    [13, 17]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdc88cfe-618c-4389-926a-fbb04343c44d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = inputs @ weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179da713-c4c1-4521-82eb-769f6fbd657d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d242b16-7fff-4af9-8fdf-b34ae64454ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = torch.randn(4, 8)\n",
    "weights = torch.randn(8, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "42fb483d-cf49-4ea3-9bf2-40bd78e67abd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2a204de6-0074-47bf-aa53-68a36abedbe6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8]), torch.Size([8, 6]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "724135e4-13da-4037-9d30-18389de12194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "outputs = inputs @ weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fe4b3d-dbd8-491e-91f4-427f8f11a1ef",
   "metadata": {},
   "source": [
    "Compute **the matrix multiplication operation** using tensor parallelism with **a factor of 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c7a0ae33-c8a9-4d0f-809d-79b6e1764adc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def by_column_parallelism(inputs, weights):\n",
    "    n_cols = weights.shape[-1]    \n",
    "    w1, w2 = weights[:, :n_cols//2], weights[:, n_cols//2:]\n",
    "    out1 = inputs @ w1\n",
    "    out2 = inputs @ w2\n",
    "    return torch.cat([out1, out2], dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af33f659-9eec-4b99-b042-0e4ee39281d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "column_output = by_column_parallelism(inputs, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c442f722-e61f-40a1-aaae-52dadfd966b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(outputs, column_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2c998e2b-6e46-40bb-9c5d-b5fd1f116371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def by_row_parallelism(inputs, weights):\n",
    "    x_dim_partrition = inputs.shape[-1] // 2\n",
    "    w_dim_partrition = weights.shape[0] // 2\n",
    "    x1, x2 = inputs[:, :x_dim_partrition], inputs[:, x_dim_partrition:]\n",
    "    w1, w2 = weights[:w_dim_partrition, :], weights[w_dim_partrition:, :]\n",
    "    out1 = x1 @ w1\n",
    "    out2 = x2 @ w2    \n",
    "    return out1 + out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "844b7d85-1aad-426e-a9a1-672edbf77938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "row_output = by_row_parallelism(inputs, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fc0f008d-1c02-461a-9f83-ab29eb573860",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(outputs, row_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcef841d-91bb-444b-8b8c-1fcf4f88af4c",
   "metadata": {},
   "source": [
    "### Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ed0cf7-95f1-41e8-a143-e9db791508e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Example 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829f01a-850f-4082-9fff-eb0ce644a55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efba53d-9852-46be-be1a-81906df36b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1, 2, 3, 4)\n",
    "b = torch.randn(2, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560e3afb-8051-4a16-8ac2-f2a6671cbe12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 2, 3, 4]), torch.Size([2, 12]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de44fbe9-af55-435a-a55a-2bc745eaa5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.numel() == b.numel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da04126-90c8-4dca-a8c0-f96df4399553",
   "metadata": {},
   "source": [
    "Change the shape of `a` same as `b` using PyTorch's built-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314a53bd-9d32-402a-bbd0-724968156fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 12])\n"
     ]
    }
   ],
   "source": [
    "# Use view_as to reshape 'a' to the size of 'b'\n",
    "c = a.view_as(b)\n",
    "\n",
    "print(c.size())  # prints: torch.Size([2, 12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adc3205-c94c-4e95-907c-20d4000cd3f3",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810abbe2-9c4f-4420-bb57-b88559d1485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b81e67e-d1f7-4334-9f87-c1b8cbf359e9",
   "metadata": {},
   "source": [
    "**Hint**\n",
    "- `torch.distributed.ReduceOp.MAX`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9535dc1a-5496-4dea-8af2-06d9b78f3c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_range_for_partition(partition_vocab_size, rank, world_size):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353b71c6-88fa-4ef1-97c5-798447cfd198",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = torch.randint(low=0, high=100, size=(50,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca51e2e-fb63-416e-b54c-88565b3b1071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([26, 35, 89, 40,  3, 96, 26, 60, 65, 99, 51,  5, 81, 24, 29, 74, 82, 53,\n",
       "        16, 66, 31, 75,  2, 60, 43, 58, 45, 97, 99,  9, 16, 58, 36, 49, 81, 35,\n",
       "        12, 96, 69, 11, 67, 93, 79, 50,  7, 11, 67,  0, 72, 26])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7df3f3-c3f9-4429-8a52-c8e638dfbd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "seq_len = 20\n",
    "vocab_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9790f6b1-5ed1-4553-9de2-5c084ea4e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_logits = torch.randn(batch_size, seq_len, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2527183-5d7f-4fd6-8693-32e0f8e1101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cfe8ee-72b9-4d68-8b61-065a88eaacc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f5c31d-ca0f-4021-8c1c-ab4ba23f24e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_size = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13136dbc-e06b-4d49-90e0-b6f9587dca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabParallelEmbedding(torch.autograd.Function):\n",
    "    def forward(self, vocab_parallel_logits, target):\n",
    "        # return values, and indicies\n",
    "        logits_max, _ = torch.max(vocab_parallel_logits, dim=-1)\n",
    "        \n",
    "        torch.distributed.all_reduce(\n",
    "            logits_max,\n",
    "            op=torch.distributed.ReduceOp.MAX\n",
    "        )\n",
    "        \n",
    "        # rank = torch.distributed.get_rank()\n",
    "        # world_size = torch.distributed.get_world_size()\n",
    "        \n",
    "        vocab_start_idx, vocab_end_idx = get_vocab_range_for_partition(\n",
    "            partition_size, rank, world_size\n",
    "        )\n",
    "        \n",
    "        target_mask = (target < vocab_start_idx) | (target >= vocab_end_idx)\n",
    "        masked_target = target.clone() - vocab_start_idx\n",
    "        masked_target[target_mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f324391-be23-4842-8ad3-4a6d35d31090",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.arange(4*6).view(4, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2ec727-007b-4583-82d0-b9dc1dfba1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9, 10, 11],\n",
       "        [12, 13, 14, 15, 16, 17],\n",
       "        [18, 19, 20, 21, 22, 23]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93954ce-8742-403c-8b00-d7776ad65391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5, 11, 17, 23])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(xs, dim=-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01b3a5a-8310-43ec-beaa-408279331a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5, -4, -3, -2, -1,  0],\n",
       "        [-5, -4, -3, -2, -1,  0],\n",
       "        [-5, -4, -3, -2, -1,  0],\n",
       "        [-5, -4, -3, -2, -1,  0]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs - (torch.max(xs, dim=-1)[0]).unsqueeze(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7105adcd-47bd-48a4-b291-fa9a2df12d16",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395d3106-fd05-4eb5-8338-a359e81de3cb",
   "metadata": {},
   "source": [
    "##### Draft 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f21572-a430-4d34-b569-0a9d879cf1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "class CachedDataset:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.cache = None\n",
    "        self.cache_index = {}\n",
    "    \n",
    "    def prefetch(self, indices: List[int]):\n",
    "        if all(i in self.cache_index for i in indices):\n",
    "            return \n",
    "        if not self.cache:\n",
    "            # Load data into memory\n",
    "            self.data = np.load(self.filename)\n",
    "        \n",
    "        # Get the total size of all samples in indices    \n",
    "        total_size = sum([self.data[i].size for i in indices])\n",
    "        \n",
    "        # Allocate memory for cache\n",
    "        self.total_size = total_size\n",
    "        self.cache = np.empty(total_size, dtype=self.data.dtype)\n",
    "        \n",
    "        # Copy data into cache\n",
    "        offset = 0\n",
    "        for i in indices:\n",
    "            size = self.data[i].size \n",
    "            self.cache[offset:offset+size] = self.data[i]\n",
    "            self.cache_index[i] = offset\n",
    "            offset += size\n",
    "            \n",
    "    def __getitem__(self, i):\n",
    "        if i not in self.cache_index:\n",
    "            self.prefetch([i])\n",
    "        \n",
    "        start, stop = self.cache_index[i], self.cache_index[i] + self.data[i].size  \n",
    "        sample = self.cache[start:stop]\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c9aa64-642d-480e-b2ed-0d88a5bd51d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init dataset \n",
    "dataset = CachedDataset(\"data.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcf709c-1fa2-4707-aad5-3f180a30368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices = list(range(10))  \n",
    "indices = [69, 42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116fc25d-c418-429a-bb25-de26997d44d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.prefetch(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d3b75-2f09-4b38-967a-999afc9a44cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fd4561-23ea-4127-8256-70bbbedcb653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{69: 0, 42: 32}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.cache_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d4a99a-4e9d-4394-91bb-42715116a0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdab222-e414-4899-911b-60caff8add3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90727821 0.47052171 0.09785945 0.76302124 0.10989286 0.53942689\n",
      " 0.56296104 0.27903864 0.93956806 0.81588349 0.92999636 0.66565923\n",
      " 0.73933048 0.27453693 0.50694107 0.54195803 0.71630134 0.11058684\n",
      " 0.49252249 0.31574857 0.88411237 0.89961832 0.40477919 0.77834166\n",
      " 0.75873789 0.84388431 0.24626659 0.23231936 0.56750329 0.75355609\n",
      " 0.17288434 0.65904373]\n"
     ]
    }
   ],
   "source": [
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5866b13c-f86f-4645-8e9c-624ab9442ba5",
   "metadata": {},
   "source": [
    "##### Draft 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefd8f50-0036-4213-b040-485ea2262334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "samples = []\n",
    "\n",
    "for i in range(100):\n",
    "    sample = torch.rand(32)  # Random array of 32 floats\n",
    "    samples.append(sample)\n",
    "\n",
    "samples = torch.stack(samples)  # Stack all tensor elements in the list\n",
    "\n",
    "# Save to a file\n",
    "torch.save(samples, \"data.pt\")  # PyTorch typically uses the .pt or .pth file extension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011270d6-32fd-4cf9-acae-bb75e4108345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import List\n",
    "\n",
    "class CachedDataset:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.cache = None\n",
    "        self.cache_index = {}\n",
    "\n",
    "    def prefetch(self, indices: List[int]):\n",
    "        if all(i in self.cache_index for i in indices):\n",
    "            return \n",
    "        if self.cache is None:\n",
    "            # Load data into memory\n",
    "            self.data = torch.load(self.filename)\n",
    "\n",
    "        # Get the total size of all samples in indices\n",
    "        total_size = sum([self.data[i].numel() for i in indices])\n",
    "\n",
    "        # Allocate memory for cache\n",
    "        self.total_size = total_size\n",
    "        self.cache = torch.empty(total_size, dtype=self.data.dtype)\n",
    "\n",
    "        # Copy data into cache\n",
    "        offset = 0\n",
    "        for i in indices:\n",
    "            size = self.data[i].numel()\n",
    "            self.cache[offset:offset+size] = self.data[i].view(-1)\n",
    "            self.cache_index[i] = offset\n",
    "            offset += size\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        if i not in self.cache_index:\n",
    "            self.prefetch([i])\n",
    "\n",
    "        start, stop = self.cache_index[i], self.cache_index[i] + self.data[i].numel()\n",
    "        sample = self.cache[start:stop]\n",
    "        return sample.view_as(self.data[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06afa489-4b3d-4787-b18d-9fe3e5e8f9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init dataset \n",
    "dataset = CachedDataset(\"data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd446b46-b7e8-45f7-a640-a4d6f0a4990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices = list(range(10))  \n",
    "indices = [69, 42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c916c2d9-bf71-4a52-9097-7a3888651281",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.prefetch(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862b8bfc-a536-4418-b59b-90384b044e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2107d5-45ab-40bd-b90b-4fa4c2de83b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{69: 0, 42: 32}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.cache_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ac1e71-b2e6-4263-82ae-dac32fd0280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be315f26-85b2-466b-9e58-2ee74776fcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1744, 0.6199, 0.7196, 0.9808, 0.3005, 0.0986, 0.9263, 0.1980, 0.8668,\n",
      "        0.0573, 0.3137, 0.6258, 0.7518, 0.0397, 0.1570, 0.4208, 0.2324, 0.2188,\n",
      "        0.7201, 0.1034, 0.9380, 0.0234, 0.5270, 0.3557, 0.2978, 0.3853, 0.1590,\n",
      "        0.0405, 0.4142, 0.3107, 0.6874, 0.9507])\n"
     ]
    }
   ],
   "source": [
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d966ebfa-bdcd-4f52-9ef6-47ccac793c04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
