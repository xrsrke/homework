{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c78ae9f-e628-4cc2-9599-f2ee8ed9c70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b04726-331b-4673-a71f-d9db120aca84",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe6638f-483e-4550-b5d8-c4b5636c6adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "SEQ_LEN = 8\n",
    "HIDDEN_SIZE = 16\n",
    "\n",
    "INTERMITTENT_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0be39d-ea69-431b-889c-e0fea6cac012",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(BATCH_SIZE, SEQ_LEN, HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af8014c-f585-49ad-8efd-70f38af9a651",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.randn(HIDDEN_SIZE, INTERMITTENT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3213cfb-226b-4519-8a95-9e1884faf8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2ffea4-23b0-4d7d-beb4-740d6d992ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 8, 16]), torch.Size([16, 16]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb85d75-1239-4a36-b367-267906312421",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = F.relu(torch.matmul(inputs, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b50930d-63bb-4428-afc2-920f0b8bc7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c477ada5-3fd9-4199-958c-18dd5e262997",
   "metadata": {},
   "source": [
    "Suppose that the `weights` parameter is very large and needs to be split across multiple GPUs to enable model parallelism.\n",
    "\n",
    "Implement Megatron's approach to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e30f312-07ef-466c-8880-5506d1492059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_weights(x):\n",
    "    n_cols = x.shape[-1]\n",
    "    assert n_cols // 2 # can be ignored\n",
    "    return x[:, :n_cols//2], x[:, n_cols//2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc1efee-c492-4e15-9037-02a5bbb32505",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight1, weight2 = split_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9131808-1432-43c0-8d4e-801c2de56a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = F.relu(torch.matmul(inputs, weight1)) # on devices 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304f1ee8-5e6d-4810-8509-3ae0d8f27c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = F.relu(torch.matmul(inputs, weight2)) # on devices 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b712ca0-f92d-4205-a7a8-690431fdd501",
   "metadata": {},
   "source": [
    "Concat the output from all devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ba11d3-3a64-466b-87c3-dc23ffe69c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_out = torch.cat([out1, out2], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd94526-c5b6-45ff-bd1f-bddd6b38d16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca361f71-30f4-4ce6-9bdd-1a04c763a5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eq(out, parallel_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc122a6b-0a80-4625-8106-af2a57543683",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60def55-613e-4046-a42b-7b093ad7dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d92044-01a8-46ab-abe8-f2154d4cad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "q, k, v = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
