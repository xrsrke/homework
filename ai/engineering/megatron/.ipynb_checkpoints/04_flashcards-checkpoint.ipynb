{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e261d834-54d3-4258-a283-ef3acfcfacf9",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2c7dd0-ef9a-4656-b672-87cf278dd8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04f738b-7781-4274-9b03-9ce155387ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa6365-8154-4805-8525-ea26315d164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_model_parallel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6544da-d0d9-4585-b32f-2809fbbee6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model_parallel_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0383c3-9947-4287-a187-1c1ccf0e79dc",
   "metadata": {},
   "source": [
    "In context of Megatron-LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b41812-0a28-4364-9d01-76d7098de11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 2, 4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_size, tensor_model_parallel_size, pipeline_model_parallel_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c793a7-7631-499a-ae3a-873233e4751e",
   "metadata": {},
   "source": [
    "Calculate the number of GPUs requires to parallelize a model. Explain the calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a384b7-8406-4aff-9378-18a81edfe1fa",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "In pipeline parallelism, a model is split into `pipeline_model_parallel_size`.\n",
    "\n",
    "Because Megatron-LM incorporates both tensor parallelism and pipeline parallelism, so each stage has `tensor_model_parallel_size` GPUs to parallelize the tensor operations in that stage. So, the total number of GPUs required to parallelize a model would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669f43c-ea70-47ba-b2cd-2aaf83d16ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus_for_each_model = tensor_model_parallel_size * pipeline_model_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2350c27-c294-4b9f-8de4-cc3a98c678bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_gpus_for_each_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818caec9-462a-43e2-90c5-c3e0ceb95c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(num_gpus_for_each_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd614b2-eda1-4fe4-8d67-54fdfc2568b8",
   "metadata": {},
   "source": [
    "Calculate the number of replicates model in data parallelism. Explain the calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae79a281-1ce9-4610-95a3-c232bd994184",
   "metadata": {},
   "source": [
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488626c8-e1fd-4c13-b538-0e8d50ccdbd2",
   "metadata": {},
   "source": [
    "To calculate the number of model replicates in data parallelism, we divide the total number of GPUs (`world_size`) by the number of GPUs used for each model (`num_gpus_for_each_model`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f57416e-c705-4108-9d52-eede46fc2261",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_parallel_size = world_size // num_gpus_for_each_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb9ba79-1dc0-47f0-878c-929145299300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_parallel_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a448df1-ac2a-4544-baac-943457d8794a",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c85d48-2f93-41fd-b8c5-07ff6217e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 16\n",
    "tensor_model_paralell_size = 2\n",
    "num_tensor_model_parallel_groups = world_size // tensor_model_paralell_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed5766a-4142-428b-8421-ad8f814b8030",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ranks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82da7c55-ecdf-44b3-a5f4-d54196988a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_current_tensor_parallel_group(group):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb6601c-1cdc-4fa4-be0b-cfa11e8afefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c274e-9288-4b59-b19b-c9db0225f990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_model_paralell_size, num_tensor_model_parallel_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a469d218-0b89-43dd-a41c-79a262c3a7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a083511-1022-4033-9687-cfa8e8159982",
   "metadata": {},
   "source": [
    "In Megatron-LM, write a script that can be distributed to multiple devices to create tensor model parallel groups.\n",
    "\n",
    "**Hint**: For each GPU, you should specify the group it belongs to by calling the `set_current_tensor_parallel_group(group)` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be4f38e-52bb-4136-bd9e-5a4008345af8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.distributed' has no attribute 'get_rank'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rank \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_rank\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.distributed' has no attribute 'get_rank'"
     ]
    }
   ],
   "source": [
    "rank = torch.distributed.get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2276aa-f257-4558-a018-a9d0f1de76de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rank' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m ranks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\n\u001b[1;32m      3\u001b[0m     i \u001b[38;5;241m*\u001b[39m tensor_model_paralell_size,\n\u001b[1;32m      4\u001b[0m     (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m tensor_model_paralell_size\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m list_ranks\u001b[38;5;241m.\u001b[39mappend(ranks) \u001b[38;5;66;03m# can be ignore\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrank\u001b[49m \u001b[38;5;129;01min\u001b[39;00m ranks:\n\u001b[1;32m     10\u001b[0m     group \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mnew_group(ranks)\n\u001b[1;32m     11\u001b[0m     set_current_tensor_parallel_group(group)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rank' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(num_tensor_model_parallel_groups):\n",
    "    ranks = range(\n",
    "        i * tensor_model_paralell_size,\n",
    "        (i+1) * tensor_model_paralell_size\n",
    "    )\n",
    "    \n",
    "    list_ranks.append(ranks) # can be ignore\n",
    "    \n",
    "    if rank in ranks:\n",
    "        group = torch.distributed.new_group(ranks)\n",
    "        set_current_tensor_parallel_group(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7460cc66-2698-410b-9da7-22625b58e75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0: [0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(f\"Group {i}: {list(x)}\") for i, x in enumerate(list_ranks)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96d22ac-aa53-4ec3-b4e6-99bfddb9dd4b",
   "metadata": {},
   "source": [
    "##### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea5997b-b394-4c6b-b7c9-ff6a02d58741",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c71d7e-ba9f-4f07-98f6-5945d85e7b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model_paralell_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5498bb44-3d1c-42e2-9b41-d3b651b47511",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline_model_parallel_groups = world_size // pipeline_model_paralell_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf2dc3-15db-42ef-9eae-95975d08911f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline_model_parallel_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253a05f-fdd1-4c76-8c29-29f4e2536ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ranks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3150a37-8c34-4073-b611-23ed4a56f582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 8]\n",
      "[1, 9]\n",
      "[2, 10]\n",
      "[3, 11]\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_pipeline_model_parallel_groups):\n",
    "    ranks = range(i, world_size, num_tensor_model_parallel_groups)\n",
    "    \n",
    "    # list_ranks.append(ranks)\n",
    "    # print(list(ranks))\n",
    "    print(list(ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b9e50e-cce3-45e5-b07b-af4feb60b884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[range(0, 16, 8), range(1, 16, 8), range(2, 16, 8), range(3, 16, 8)]\n"
     ]
    }
   ],
   "source": [
    "print(list(list_ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e3c276-1618-44b1-adec-aca6392578a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0: [0, 8]\n",
      "Group 1: [1, 9]\n",
      "Group 2: [2, 10]\n",
      "Group 3: [3, 11]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(f\"Group {i}: {list(x)}\") for i, x in enumerate(list_ranks)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f945331a-e8dd-413c-a979-12619906701b",
   "metadata": {},
   "source": [
    "##### Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb85259-9923-493b-a170-5d88d9718594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3278a1-22ba-493e-aac1-060095e28fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 16\n",
    "tensor_model_parallel_size = 2\n",
    "pipeline_model_parallel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7471a8d7-2d8a-48d8-93e7-9ae1c5140c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpus_for_each_model = tensor_model_parallel_size * pipeline_model_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ef629-cfb2-4788-b319-26256d3e9b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_parallel_size = world_size // n_gpus_for_each_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a6ecf8-5224-4846-a177-dfc599830040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e6bef3-40b2-4f24-8550-01c2c6de053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tensor_model_parallel_groups = world_size // tensor_model_paralell_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67af8d3-4059-4189-abdc-444ea5b013a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline_model_parallel_groups = world_size // pipeline_model_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da75da22-b612-4b35-a5f1-210218d65c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_parallel_groups = world_size // data_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee4dc27-a066-43b6-8cac-7e7ccb6a9ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tensor_model_parallel_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fc767b-da9b-4cfb-872e-b015dd96b498",
   "metadata": {},
   "source": [
    "Build data-parallel groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88dc9b4-847e-46ee-9b58-59c183752a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_parallel_ranks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16f6118-0cf5-44e5-8786-99246c9fdebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ae9d00-b962-489e-a399-481eb5f3bd06",
   "metadata": {},
   "source": [
    "##### Example 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a34f7b7-1eee-4faf-98db-7734bf41ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_group = torch.distributed.ProcessGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f801accc-f856-4953-8d8e-52ce3e684b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a861a44e-76db-4b29-ad88-705dfef33481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.distributed.ProcessGroup"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585b2e4e-ae73-45a9-8c31-c16446aca67f",
   "metadata": {},
   "source": [
    "Write a function in the context of Megatron-LM that broadcasts a tensor to the parallel region `parallel_group` to support both the forward and backward pass.\n",
    "\n",
    "**Hints**:\n",
    "- Support both forward and backward\n",
    "- Check whether the input requires grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552192f4-4cde-4483-8295-b9a8113ecf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_grad_enable(input):\n",
    "    return torch.is_grad_enabled() and input.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfed065-16b3-4ca4-9351-d8ab6389e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _broadcast(inputs):\n",
    "    return inputs.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b1d458-a277-41f8-b96c-de2aac9440b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reduce(inputs):\n",
    "    world_size_of_parallel_group = torch.distributed.get_world_size(group=parallel_group)\n",
    "    \n",
    "    if world_size_of_parallel_group == 1: return inputs\n",
    "    \n",
    "    torch.distributed.all_reduce(inputs, group=parallel_group)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77b8266-10be-488b-b4de-3cac2ec6b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Broadcast(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input): return _broadcast(input)\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output): return _reduce(grad_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02121dbd-2359-42bf-8877-46a2d6a34c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_with_forward_and_backward(inputs):\n",
    "    if is_grad_enable(inputs):\n",
    "        outputs = Broadcast.apply(inputs)\n",
    "    else:\n",
    "        outputs = inputs.clone()\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49085d44-bd13-4636-a573-30bcbe88b789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.broadcast_with_forward_and_backward(inputs)>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcast_with_forward_and_backward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507e535f-ccb5-4c10-a994-cfe648654d08",
   "metadata": {},
   "source": [
    "##### Example 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c97a83a-673b-4da1-99df-19df2d560fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.distributed.ProcessGroup"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b72636f-4d7c-4b4b-9e07-afdd595edabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_local_parallel_size(group):\n",
    "    return torch.distributed.get_world_size(group=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63ff588-2b2e-40cc-b9bc-ae522a6d6471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_local_parallel_rank(group):\n",
    "    return torch.distributed.get_rank(group=group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12926d77-4eed-4c56-bb28-1739584a5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _scatter(inputs):\n",
    "    world_size = _get_local_parallel_size(parallel_group)\n",
    "    rank = _get_local_parallel_rank()\n",
    "    \n",
    "    if world_size == 1:\n",
    "        return inputs\n",
    "    \n",
    "    last_dim_size = inputs.shape[-1]\n",
    "    last_dim_size_per_partition = last_dim_size // world_size\n",
    "    \n",
    "    input_chunks = torch.split(\n",
    "        inputs,\n",
    "        split_size_or_sections=last_dim_size_per_partition,\n",
    "        dim=-1\n",
    "    )\n",
    "    \n",
    "    return input_chunks[rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c67f2-e240-4251-8c7c-b65a3d6ef4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062737fc-a0ca-4105-803d-162a1add623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gather():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c405e662-af98-4492-8a83-24aae029cc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scatter(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, inputs):\n",
    "        return _scatter(inputs)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return _gather(grad_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a60af6f-532e-49f9-aeec-066a20eccdde",
   "metadata": {},
   "source": [
    "### CLIP GRAD NORM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357fa8b5-c3be-4d4a-b25b-8f77593cefc6",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e518ab22-2e96-48f7-9ef7-1c544b9db26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.parameter import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e16548-25ad-4d48-91ba-1283d1de9777",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(69.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f925cc5-e3da-49c2-b6a3-3d4a49ffab34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baaa608-5e91-470c-af45-c62c300cd242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor([2, 3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
