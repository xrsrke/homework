{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e261d834-54d3-4258-a283-ef3acfcfacf9",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2c7dd0-ef9a-4656-b672-87cf278dd8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04f738b-7781-4274-9b03-9ce155387ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa6365-8154-4805-8525-ea26315d164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_model_parallel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6544da-d0d9-4585-b32f-2809fbbee6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model_parallel_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0383c3-9947-4287-a187-1c1ccf0e79dc",
   "metadata": {},
   "source": [
    "In context of Megatron-LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b41812-0a28-4364-9d01-76d7098de11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 2, 4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_size, tensor_model_parallel_size, pipeline_model_parallel_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c793a7-7631-499a-ae3a-873233e4751e",
   "metadata": {},
   "source": [
    "Calculate the number of GPUs requires to parallelize a model. Explain the calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a384b7-8406-4aff-9378-18a81edfe1fa",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "In pipeline parallelism, a model is split into `pipeline_model_parallel_size`.\n",
    "\n",
    "Because Megatron-LM incorporates both tensor parallelism and pipeline parallelism, so each stage has `tensor_model_parallel_size` GPUs to parallelize the tensor operations in that stage. So, the total number of GPUs required to parallelize a model would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669f43c-ea70-47ba-b2cd-2aaf83d16ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus_for_each_model = tensor_model_parallel_size * pipeline_model_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2350c27-c294-4b9f-8de4-cc3a98c678bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_gpus_for_each_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818caec9-462a-43e2-90c5-c3e0ceb95c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(num_gpus_for_each_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd614b2-eda1-4fe4-8d67-54fdfc2568b8",
   "metadata": {},
   "source": [
    "Calculate the number of replicates model in data parallelism. Explain the calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae79a281-1ce9-4610-95a3-c232bd994184",
   "metadata": {},
   "source": [
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488626c8-e1fd-4c13-b538-0e8d50ccdbd2",
   "metadata": {},
   "source": [
    "To calculate the number of model replicates in data parallelism, we divide the total number of GPUs (`world_size`) by the number of GPUs used for each model (`num_gpus_for_each_model`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f57416e-c705-4108-9d52-eede46fc2261",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_parallel_size = world_size // num_gpus_for_each_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb9ba79-1dc0-47f0-878c-929145299300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_parallel_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
