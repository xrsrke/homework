{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e261d834-54d3-4258-a283-ef3acfcfacf9",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2c7dd0-ef9a-4656-b672-87cf278dd8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04f738b-7781-4274-9b03-9ce155387ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa6365-8154-4805-8525-ea26315d164d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_model_parallel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6544da-d0d9-4585-b32f-2809fbbee6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model_parallel_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0383c3-9947-4287-a187-1c1ccf0e79dc",
   "metadata": {},
   "source": [
    "In context of Megatron-LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b41812-0a28-4364-9d01-76d7098de11d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 2, 4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_size, tensor_model_parallel_size, pipeline_model_parallel_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c793a7-7631-499a-ae3a-873233e4751e",
   "metadata": {},
   "source": [
    "Calculate the number of GPUs requires to parallelize a model. Explain the calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a384b7-8406-4aff-9378-18a81edfe1fa",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "In pipeline parallelism, a model is split into `pipeline_model_parallel_size`.\n",
    "\n",
    "Because Megatron-LM incorporates both tensor parallelism and pipeline parallelism, so each stage has `tensor_model_parallel_size` GPUs to parallelize the tensor operations in that stage. So, the total number of GPUs required to parallelize a model would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a669f43c-ea70-47ba-b2cd-2aaf83d16ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus_for_each_model = tensor_model_parallel_size * pipeline_model_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2350c27-c294-4b9f-8de4-cc3a98c678bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_gpus_for_each_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818caec9-462a-43e2-90c5-c3e0ceb95c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(num_gpus_for_each_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd614b2-eda1-4fe4-8d67-54fdfc2568b8",
   "metadata": {},
   "source": [
    "Calculate the number of replicates model in data parallelism. Explain the calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae79a281-1ce9-4610-95a3-c232bd994184",
   "metadata": {},
   "source": [
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488626c8-e1fd-4c13-b538-0e8d50ccdbd2",
   "metadata": {},
   "source": [
    "To calculate the number of model replicates in data parallelism, we divide the total number of GPUs (`world_size`) by the number of GPUs used for each model (`num_gpus_for_each_model`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f57416e-c705-4108-9d52-eede46fc2261",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_parallel_size = world_size // num_gpus_for_each_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb9ba79-1dc0-47f0-878c-929145299300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_parallel_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a448df1-ac2a-4544-baac-943457d8794a",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c85d48-2f93-41fd-b8c5-07ff6217e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 16\n",
    "tensor_model_paralell_size = 2\n",
    "num_tensor_model_parallel_groups = world_size // tensor_model_paralell_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed5766a-4142-428b-8421-ad8f814b8030",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ranks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82da7c55-ecdf-44b3-a5f4-d54196988a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_current_tensor_parallel_group(group):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb6601c-1cdc-4fa4-be0b-cfa11e8afefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c274e-9288-4b59-b19b-c9db0225f990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_model_paralell_size, num_tensor_model_parallel_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a469d218-0b89-43dd-a41c-79a262c3a7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a083511-1022-4033-9687-cfa8e8159982",
   "metadata": {},
   "source": [
    "In Megatron-LM, write a script that can be distributed to multiple devices to create tensor model parallel groups.\n",
    "\n",
    "**Hint**: For each GPU, you should specify the group it belongs to by calling the `set_current_tensor_parallel_group(group)` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be4f38e-52bb-4136-bd9e-5a4008345af8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.distributed' has no attribute 'get_rank'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rank \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_rank\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.distributed' has no attribute 'get_rank'"
     ]
    }
   ],
   "source": [
    "rank = torch.distributed.get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2276aa-f257-4558-a018-a9d0f1de76de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rank' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m ranks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\n\u001b[1;32m      3\u001b[0m     i \u001b[38;5;241m*\u001b[39m tensor_model_paralell_size,\n\u001b[1;32m      4\u001b[0m     (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m tensor_model_paralell_size\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m list_ranks\u001b[38;5;241m.\u001b[39mappend(ranks) \u001b[38;5;66;03m# can be ignore\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrank\u001b[49m \u001b[38;5;129;01min\u001b[39;00m ranks:\n\u001b[1;32m     10\u001b[0m     group \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdistributed\u001b[38;5;241m.\u001b[39mnew_group(ranks)\n\u001b[1;32m     11\u001b[0m     set_current_tensor_parallel_group(group)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rank' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(num_tensor_model_parallel_groups):\n",
    "    ranks = range(\n",
    "        i * tensor_model_paralell_size,\n",
    "        (i+1) * tensor_model_paralell_size\n",
    "    )\n",
    "    \n",
    "    list_ranks.append(ranks) # can be ignore\n",
    "    \n",
    "    if rank in ranks:\n",
    "        group = torch.distributed.new_group(ranks)\n",
    "        set_current_tensor_parallel_group(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7460cc66-2698-410b-9da7-22625b58e75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0: [0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(f\"Group {i}: {list(x)}\") for i, x in enumerate(list_ranks)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96d22ac-aa53-4ec3-b4e6-99bfddb9dd4b",
   "metadata": {},
   "source": [
    "##### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea5997b-b394-4c6b-b7c9-ff6a02d58741",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c71d7e-ba9f-4f07-98f6-5945d85e7b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_model_paralell_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5498bb44-3d1c-42e2-9b41-d3b651b47511",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline_model_parallel_groups = world_size // pipeline_model_paralell_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bf2dc3-15db-42ef-9eae-95975d08911f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pipeline_model_parallel_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b253a05f-fdd1-4c76-8c29-29f4e2536ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ranks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3150a37-8c34-4073-b611-23ed4a56f582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 8]\n",
      "[1, 9]\n",
      "[2, 10]\n",
      "[3, 11]\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_pipeline_model_parallel_groups):\n",
    "    ranks = range(i, world_size, num_tensor_model_parallel_groups)\n",
    "    \n",
    "    # list_ranks.append(ranks)\n",
    "    # print(list(ranks))\n",
    "    print(list(ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b9e50e-cce3-45e5-b07b-af4feb60b884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[range(0, 16, 8), range(1, 16, 8), range(2, 16, 8), range(3, 16, 8)]\n"
     ]
    }
   ],
   "source": [
    "print(list(list_ranks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e3c276-1618-44b1-adec-aca6392578a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0: [0, 8]\n",
      "Group 1: [1, 9]\n",
      "Group 2: [2, 10]\n",
      "Group 3: [3, 11]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[print(f\"Group {i}: {list(x)}\") for i, x in enumerate(list_ranks)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f945331a-e8dd-413c-a979-12619906701b",
   "metadata": {},
   "source": [
    "##### Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb85259-9923-493b-a170-5d88d9718594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3278a1-22ba-493e-aac1-060095e28fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_size = 16\n",
    "tensor_model_parallel_size = 2\n",
    "pipeline_model_parallel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7471a8d7-2d8a-48d8-93e7-9ae1c5140c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpus_for_each_model = tensor_model_parallel_size * pipeline_model_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ef629-cfb2-4788-b319-26256d3e9b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_parallel_size = world_size // n_gpus_for_each_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a6ecf8-5224-4846-a177-dfc599830040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e6bef3-40b2-4f24-8550-01c2c6de053a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tensor_model_parallel_groups = world_size // tensor_model_paralell_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67af8d3-4059-4189-abdc-444ea5b013a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline_model_parallel_groups = world_size // pipeline_model_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da75da22-b612-4b35-a5f1-210218d65c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data_parallel_groups = world_size // data_parallel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee4dc27-a066-43b6-8cac-7e7ccb6a9ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tensor_model_parallel_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fc767b-da9b-4cfb-872e-b015dd96b498",
   "metadata": {},
   "source": [
    "Build data-parallel groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88dc9b4-847e-46ee-9b58-59c183752a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_parallel_ranks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16f6118-0cf5-44e5-8786-99246c9fdebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
