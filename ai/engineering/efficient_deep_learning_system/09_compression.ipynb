{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5039074a-c646-4249-8eee-12a756d349c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.ao.quantization import DeQuantStub, QuantStub\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import trange\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49875016-0d46-4efa-9e32-40aea9842f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class M(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # QuantStub converts tensors from floating point to quantized\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.conv = torch.nn.Conv2d(1, 5, 3)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.linear = torch.nn.Linear(4500, 100)\n",
    "        # DeQuantStub converts tensors from quantized to floating point\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # manually specify where tensors will be converted from floating\n",
    "        # point to quantized in the quantized model\n",
    "        x = self.quant(x)\n",
    "        start = time()\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear(self.flatten(x))\n",
    "        # manually specify where tensors will be converted from quantized\n",
    "        # to floating point in the quantized model\n",
    "        x = self.dequant(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944862a2-6501-4ad8-a6b7-4a7891a611c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M(\n",
       "  (quant): QuantStub()\n",
       "  (conv): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (relu): ReLU()\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear): Linear(in_features=4500, out_features=100, bias=True)\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a model instance\n",
    "model_fp32 = M()\n",
    "\n",
    "# model must be set to eval mode for static quantization logic to work\n",
    "model_fp32.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8be7d1-d6f0-4ccb-abce-63ca8b9bb565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M(\n",
       "  (quant): QuantStub()\n",
       "  (conv): ConvReLU2d(\n",
       "    (0): Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (relu): Identity()\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear): Linear(in_features=4500, out_features=100, bias=True)\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.quantization.fuse_modules(model_fp32, [[\"conv\", \"relu\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a524c523-2b60-4fee-b034-79a9ef29dcb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
