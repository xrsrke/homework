{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fe548df6-630b-42aa-a702-43512b743109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5d4016-3fcc-452c-aa9e-fe2c9f6ea7c2",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aa6c3a35-0ee9-4c77-962d-ca0c8f11cba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b01f7ec7-3c68-4672-9b94-118739d11b95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "seq_len = 100\n",
    "d_model = 16\n",
    "n_experts = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "190b258f-e477-442a-b8ad-09b137aed908",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "switch = nn.Linear(d_model, n_experts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d9d0e3d-1955-408d-9bf6-7d46da6480ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = torch.randn(batch_size, seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad9d8d05-e907-4475-ae7f-fb23e1f56b81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 100, 16])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1e22156-5494-402b-b462-a8c219792890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=16, out_features=5, bias=True)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "switch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0194d28d-77da-4336-9346-3f46f9972ba6",
   "metadata": {},
   "source": [
    "`inputs` has the following shape:\n",
    "\n",
    "- 10 represents the batch size,\n",
    "- 100 represents the sequence length,\n",
    "- 16 represents the hidden size.\n",
    "\n",
    "Calculate which expert each token in the batch goes through using the Top-1 Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24cb3f62-c335-4f86-9a94-1303709337e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flattened_inputs = inputs.view(-1, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba0164fb-82b5-4cd9-b4e1-70c638c2d288",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 16])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc62efca-42ef-42e3-9219-cb45651eaa75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "probs = F.softmax(switch(flattened_inputs), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86bab4d2-7d80-417f-86f4-ad5f498c7a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 5])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c4764a5-c745-43b9-87ec-23e02b24a2b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, idxs = torch.max(probs, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "65f8d9b8-891f-459a-b327-f8a9ba1ab83e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 4, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b94b57fc-07cd-43aa-9a57-beb4030f8d07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d140301b-1ca1-4fda-973f-bf205dfef90e",
   "metadata": {},
   "source": [
    "##### Example 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9ca4bfc4-c25a-4a0f-998b-3a24bdd41d03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indexes_list = [torch.eq(idxs, i).nonzero(as_tuple=True)[0] for i in range(n_experts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ec9697fd-602b-4002-bac8-cb829943938c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([  0,   6,   9,  11,  19,  21,  23,  24,  25,  27,  35,  36,  37,  40,\n",
       "          42,  43,  47,  51,  53,  54,  61,  68,  71,  78,  85,  90,  94,  96,\n",
       "         107, 112, 115, 116, 123, 130, 131, 134, 137, 141, 143, 146, 147, 156,\n",
       "         159, 163, 165, 168, 176, 177, 180, 182, 183, 189, 193, 196, 199, 201,\n",
       "         211, 212, 213, 218, 228, 231, 232, 235, 236, 237, 238, 239, 241, 244,\n",
       "         249, 255, 259, 262, 264, 268, 269, 271, 276, 279, 280, 288, 292, 295,\n",
       "         297, 299, 304, 305, 311, 314, 323, 327, 329, 332, 333, 334, 335, 336,\n",
       "         341, 343, 345, 350, 351, 356, 362, 363, 365, 366, 376, 381, 383, 393,\n",
       "         395, 397, 401, 404, 415, 416, 420, 421, 423, 424, 425, 429, 434, 435,\n",
       "         443, 447, 449, 450, 458, 463, 465, 467, 468, 469, 485, 488, 492, 499,\n",
       "         500, 501, 510, 519, 525, 526, 532, 534, 543, 545, 558, 561, 563, 566,\n",
       "         567, 568, 576, 579, 591, 597, 599, 606, 609, 610, 612, 616, 622, 624,\n",
       "         625, 628, 629, 633, 639, 640, 643, 644, 661, 666, 672, 674, 676, 679,\n",
       "         681, 699, 700, 704, 709, 711, 712, 714, 715, 720, 722, 724, 726, 727,\n",
       "         733, 734, 740, 741, 745, 749, 752, 753, 756, 762, 763, 766, 776, 779,\n",
       "         782, 789, 797, 799, 809, 812, 813, 815, 821, 822, 826, 834, 838, 839,\n",
       "         840, 846, 847, 853, 859, 863, 872, 874, 876, 879, 880, 901, 927, 932,\n",
       "         933, 938, 943, 951, 956, 957, 959, 962, 966, 969, 970, 973, 975, 977,\n",
       "         983, 988, 989, 990, 995, 997]),\n",
       " tensor([  2,  14,  18,  33,  46,  49,  55,  60,  74,  80,  86,  91,  97,  99,\n",
       "         109, 114, 117, 118, 119, 122, 125, 135, 136, 140, 142, 145, 148, 155,\n",
       "         158, 160, 161, 162, 167, 170, 174, 175, 185, 187, 194, 205, 209, 210,\n",
       "         216, 217, 230, 246, 247, 253, 263, 265, 273, 274, 284, 286, 293, 301,\n",
       "         303, 310, 315, 316, 317, 319, 321, 324, 339, 349, 352, 354, 355, 357,\n",
       "         358, 359, 368, 373, 377, 380, 386, 387, 389, 392, 396, 398, 402, 407,\n",
       "         408, 410, 411, 413, 431, 438, 439, 440, 441, 445, 455, 461, 462, 464,\n",
       "         473, 474, 496, 498, 502, 504, 511, 515, 518, 527, 533, 536, 540, 544,\n",
       "         548, 552, 555, 556, 570, 572, 589, 594, 595, 600, 601, 603, 608, 613,\n",
       "         619, 631, 632, 641, 642, 647, 650, 654, 662, 670, 671, 684, 691, 695,\n",
       "         701, 706, 719, 721, 728, 732, 743, 754, 759, 760, 770, 774, 780, 781,\n",
       "         787, 788, 794, 795, 801, 805, 807, 816, 818, 820, 833, 844, 845, 850,\n",
       "         851, 854, 855, 868, 869, 871, 875, 878, 881, 883, 887, 888, 893, 897,\n",
       "         902, 903, 904, 908, 910, 918, 928, 931, 942, 946, 952, 955, 960, 965,\n",
       "         968, 984, 986]),\n",
       " tensor([ 16,  20,  32,  50,  52,  64,  67,  69,  72,  81,  87, 102, 103, 105,\n",
       "         108, 121, 126, 139, 151, 153, 164, 166, 178, 191, 195, 198, 203, 204,\n",
       "         214, 219, 250, 251, 260, 270, 277, 278, 287, 289, 290, 320, 322, 325,\n",
       "         326, 328, 346, 367, 378, 390, 412, 422, 426, 427, 428, 456, 470, 471,\n",
       "         483, 489, 490, 493, 505, 512, 520, 521, 538, 550, 559, 560, 580, 584,\n",
       "         585, 587, 593, 605, 611, 626, 635, 638, 653, 655, 659, 660, 673, 678,\n",
       "         694, 697, 710, 717, 723, 729, 730, 736, 738, 739, 744, 758, 765, 768,\n",
       "         769, 775, 783, 791, 796, 803, 810, 837, 841, 843, 861, 882, 885, 886,\n",
       "         891, 899, 907, 912, 914, 922, 934, 935, 950, 954, 964, 981, 993]),\n",
       " tensor([  3,   5,   7,   8,  10,  12,  13,  15,  22,  26,  28,  29,  30,  31,\n",
       "          34,  39,  44,  56,  58,  59,  63,  65,  66,  70,  75,  76,  77,  79,\n",
       "          82,  88,  92,  93,  95,  98, 106, 111, 113, 120, 127, 128, 129, 132,\n",
       "         133, 138, 144, 149, 150, 152, 154, 157, 169, 171, 173, 179, 181, 186,\n",
       "         188, 190, 192, 197, 200, 202, 206, 207, 208, 215, 220, 221, 222, 223,\n",
       "         224, 226, 229, 233, 234, 245, 252, 254, 256, 257, 258, 261, 266, 267,\n",
       "         272, 275, 283, 291, 294, 296, 298, 300, 302, 307, 308, 309, 312, 313,\n",
       "         318, 330, 340, 342, 360, 361, 369, 370, 371, 372, 375, 379, 382, 385,\n",
       "         388, 394, 399, 400, 403, 405, 406, 409, 414, 418, 419, 430, 433, 436,\n",
       "         437, 442, 444, 451, 453, 457, 460, 466, 472, 475, 476, 478, 480, 481,\n",
       "         482, 486, 487, 491, 494, 495, 497, 503, 506, 508, 509, 513, 514, 516,\n",
       "         517, 522, 523, 524, 528, 529, 530, 535, 539, 541, 542, 546, 547, 549,\n",
       "         551, 554, 557, 562, 564, 565, 571, 573, 575, 577, 578, 581, 582, 588,\n",
       "         590, 592, 596, 598, 602, 604, 607, 615, 617, 618, 620, 621, 623, 627,\n",
       "         630, 634, 636, 645, 646, 648, 649, 651, 656, 657, 658, 664, 665, 668,\n",
       "         669, 675, 677, 680, 682, 683, 685, 686, 688, 690, 692, 693, 696, 698,\n",
       "         703, 705, 713, 716, 725, 731, 735, 737, 742, 746, 747, 748, 750, 751,\n",
       "         755, 757, 761, 764, 771, 773, 778, 785, 786, 790, 792, 798, 800, 802,\n",
       "         804, 806, 808, 811, 814, 817, 823, 824, 825, 827, 828, 829, 830, 831,\n",
       "         832, 835, 836, 842, 849, 852, 856, 857, 858, 860, 862, 864, 867, 870,\n",
       "         873, 877, 890, 894, 895, 896, 898, 900, 906, 909, 911, 915, 917, 919,\n",
       "         920, 924, 925, 926, 930, 936, 937, 940, 941, 947, 948, 949, 961, 963,\n",
       "         967, 971, 972, 974, 978, 979, 980, 982, 985, 987, 991, 992, 994, 999]),\n",
       " tensor([  1,   4,  17,  38,  41,  45,  48,  57,  62,  73,  83,  84,  89, 100,\n",
       "         101, 104, 110, 124, 172, 184, 225, 227, 240, 242, 243, 248, 281, 282,\n",
       "         285, 306, 331, 337, 338, 344, 347, 348, 353, 364, 374, 384, 391, 417,\n",
       "         432, 446, 448, 452, 454, 459, 477, 479, 484, 507, 531, 537, 553, 569,\n",
       "         574, 583, 586, 614, 637, 652, 663, 667, 687, 689, 702, 707, 708, 718,\n",
       "         767, 772, 777, 784, 793, 819, 848, 865, 866, 884, 889, 892, 905, 913,\n",
       "         916, 921, 923, 929, 939, 944, 945, 953, 958, 976, 996, 998])]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2a15ef87-d312-4ed2-8336-93d3f06e91aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(indexes_list) == n_experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ebad5f66-9d84-4f45-aca8-44efbcf714ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 6, 9])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes_list[0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e0cba-838e-4823-84c0-4e14caba8fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_experts):\n",
    "    if indexes_list[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ff7662-7682-4df3-9a0d-1e8dc3defe68",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "64beab51-45ba-4264-bf64-d76a328f4083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "world_size = 16\n",
    "dp_group_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d93c59ef-cbaf-48da-93be-6a6e750c2b50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_parallel_groups = list()\n",
    "for i in range(dp_group_size):\n",
    "    data_parallel_groups.append(\n",
    "        list(range(i, world_size, dp_group_size))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3f043b01-759c-4f8d-9523-0033e607ba06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 2, 4, 6, 8, 10, 12, 14], [1, 3, 5, 7, 9, 11, 13, 15]]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_parallel_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "82024691-a7f4-4317-87a6-2c73ed2644c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dp_world_size = world_size // dp_group_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ab996b85-0111-496e-b99a-88b8f1267c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expert_parallel_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9691c491-1b43-4bc4-911e-6336b7a753e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4, 6]\n",
      "[8, 10, 12, 14]\n",
      "[1, 3, 5, 7]\n",
      "[9, 11, 13, 15]\n"
     ]
    }
   ],
   "source": [
    "expert_parallel_info = None\n",
    "for dp_ranks in data_parallel_groups:\n",
    "    # Construct Expert Parallel Group\n",
    "    for i in range(0, dp_world_size, expert_parallel_size):\n",
    "        ranks = dp_ranks[i : i + expert_parallel_size]\n",
    "        \n",
    "        print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6df75a6-0983-4d78-9d1c-f3dec26772b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.view(-1, experts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318f52ed-33b4-48f4-a8f1-baacc8b81cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = F.softmax(inputs, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17491a59-707b-490a-9f32-febb0738ba70",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, idxs = torch.max(probs, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55c33d9-7f36-485e-8818-b090cc5f989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ready, running, failed, succeeed, cooldown, blacklisted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "947a8f6d-16cb-47bd-9633-cc50a5b5877f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e609e1-7387-4b06-833f-123003535fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms.Compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c042dd-a4da-4045-9fe4-532951e2dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "biocomaptiable, elasticity, reliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de41b662-5507-4872-96f4-2a2978b52d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0afc97-e350-40b7-be36-d6ebdc0457b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6deecca-d50e-42bd-bc3d-bea15250185e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ecd3152d-382d-4aba-ba8a-37dde93b518a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _get_expert_parallel_ranks(world_size, model_parallel_size_, expert_parallel_size_):\n",
    "    \"\"\"Generate expert parallel and expert data parallel group ranks list.\n",
    "\n",
    "        Example - E + M + D parallel\n",
    "        world_size = 16\n",
    "        model_degree = 2\n",
    "        expert_degree = 4 # number of experts in same group\n",
    "        mp_group = [0, 1], [2,3], [4,5] ...\n",
    "        data_parallel_group =[0,2,4,6,8,10, 12,14],                 [1,3,5,7,9,11,13,15]\n",
    "        expert_parallel_group = [0,2,4,6], [8,10,12,14]             [1,3,5,7], [9,11,13,15]\n",
    "        expert_data_parallel_group = [0,8],[2,10],[4,12],[6,14],    [1,9],[3,11],[5,13],[7,15]\n",
    "\n",
    "    Args:\n",
    "        world_size (int): Distributed world size.\n",
    "        model_parallel_size_ (int): Model parallel group size.\n",
    "        expert_parallel_size_ (int): Expert parallel group size.\n",
    "\n",
    "    Returns:\n",
    "        Expert parallel group ranks and Expert data parallel group ranks list.\n",
    "    \"\"\"\n",
    "    _ensure_divisibility(world_size, model_parallel_size_)\n",
    "    dp_world_size = world_size // model_parallel_size_\n",
    "    _ensure_divisibility(dp_world_size, expert_parallel_size_)\n",
    "\n",
    "    # Generate data parallel groups\n",
    "    data_parallel_groups = []\n",
    "    dp_group_size = model_parallel_size_\n",
    "    for i in range(dp_group_size):\n",
    "        data_parallel_groups.append(list(range(i, world_size, dp_group_size)))\n",
    "\n",
    "    expert_parallel_groups = []\n",
    "    expert_data_parallel_groups = []\n",
    "    for dp_ranks in data_parallel_groups:\n",
    "        # partition of expert parallel groups, e.g. [0,2,4,6], [8,10,12,14]\n",
    "        part_ep_groups = []\n",
    "        for i in range(0, dp_world_size, expert_parallel_size_):\n",
    "            part_ep_groups.append(dp_ranks[i:i + expert_parallel_size_])\n",
    "        expert_parallel_groups.extend(part_ep_groups)\n",
    "\n",
    "        # zip part_ep_groups get expert data parallel ranks, e.g [0,8],[2,10],[4,12],[6,14]\n",
    "        for expert_dp_ranks in zip(*part_ep_groups):\n",
    "            expert_data_parallel_groups.append(list(expert_dp_ranks))\n",
    "\n",
    "    return expert_parallel_groups, expert_data_parallel_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "878436bb-fc47-42c8-b5e5-eb1f9932a731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_parallel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5a532c2e-1fea-47a1-a4f5-c267ba1eeaf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "world_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cb609a48-20f7-4542-81c4-7aa5511de634",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rank = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0a052a4a-bc1c-43db-a4c7-bf87d2c24167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_parallel_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3072c4c5-d6f1-482e-8b8d-2b04658e58b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_parallel_rank = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d810e-86ac-4f6f-ba4a-c545cee67bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _create_expert_data_and_model_parallel(expert_parallel_size_, mpu):\n",
    "    \"\"\"\n",
    "        Create expert and data parallel groups based on MPU (model parallel) group.\n",
    "\n",
    "        Note: Caller of this function is responsible to check if the groups already exist.\n",
    "\n",
    "        Example - E + M + D parallel\n",
    "        world_size = 16\n",
    "        model_degree = 2\n",
    "        expert_degree = 4 # number of experts in same group\n",
    "        mp_group = [0, 1], [2,3], [4,5] ...\n",
    "        data_parallel_group =[0,2,4,6,8,10, 12,14],                 [1,3,5,7,9,11,13,15]\n",
    "        expert_parallel_group = [0,2,4,6], [8,10,12,14]             [1,3,5,7], [9,11,13,15]\n",
    "        expert_data_parallel_group = [0,8],[2,10],[4,12],[6,14],    [1,9],[3,11],[5,13],[7,15]\n",
    "    \"\"\"\n",
    "    expert_tensor_parallel_world_size = model_parallel_size\n",
    "\n",
    "\n",
    "    # Get world size and rank. Ensure some consistencies.\n",
    "    _DATA_PARALLEL_GROUP = mpu.get_data_parallel_group()\n",
    "    _MODEL_PARALLEL_GROUP = mpu.get_model_parallel_group()\n",
    "\n",
    "    group_name = f\"ep_size_{expert_parallel_size_}\"\n",
    "\n",
    "    # Only create groups if they don't already exist\n",
    "    # Need to check conditions outside the group creation loop because of the way torch.dist group creation works\n",
    "    if group_name not in _EXPERT_DATA_PARALLEL_GROUP and group_name not in _EXPERT_PARALLEL_GROUP:\n",
    "        \n",
    "        expert_parallel_groups, expert_data_parallel_groups = _get_expert_parallel_ranks(\n",
    "            world_size, model_parallel_size_, expert_parallel_size_)\n",
    "        \n",
    "        for ranks in expert_parallel_groups:\n",
    "            group = dist.new_group(ranks)\n",
    "            if rank in list(ranks):\n",
    "                _EXPERT_PARALLEL_GROUP[group_name] = group\n",
    "\n",
    "        for ranks in expert_data_parallel_groups:\n",
    "            group = dist.new_group(ranks)\n",
    "            if rank in list(ranks):\n",
    "                _EXPERT_DATA_PARALLEL_GROUP[group_name] = group"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
