{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c853eb9d-62db-4763-8a16-aefb48656c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca26b883-0df1-40f9-9f2d-573edcc7efe9",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273c168d-7aee-490c-b11f-9d6e9e96469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'input_ids': [[1, 2, 3], [4, 5, 6], [7, 8, 9]],\n",
    "    'labels': [0, 1, 0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321d19c-8d15-4a07-a3d8-9f04ae437c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[1, 2, 3], [4, 5, 6], [7, 8, 9]], 'labels': [0, 1, 0]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0569a38c-223f-4748-b72d-fdd6e4b0ee4d",
   "metadata": {},
   "source": [
    "Create a dataset from `data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb91f095-7cc1-40ac-bf07-a0f475b39d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d2502d-6c54-41ad-8001-699da3fe727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62eb772-03c4-4cc0-8abe-e885a38109dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'labels'],\n",
       "    num_rows: 3\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89db0846-7339-4db8-8b15-7bd18b2ef225",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e830db97-4366-46d7-91a7-aaa0c4e11bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bb2090-9c64-4929-a9ca-d9b2ac16fa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/Users/education/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"glue\", \"mrpc\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7407d2-00d5-4dc8-abb5-1af6a65c7d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "    num_rows: 3668\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739089d4-0125-4118-904c-bdce1d760a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset = dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bac553-4054-4fb3-b43c-f603242e570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d116c6d8-789e-4ad4-b4cd-8076616dc098",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaf383a-e9d9-4375-a5f4-c1b3e21bb681",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03169345-f86f-486f-81bb-83f99179fd56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d4804-f5e7-4386-a06f-68c929550457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e51ee7-5f0b-4e75-a9d7-be8391a84cd2",
   "metadata": {},
   "source": [
    "Tokenizer the column `sentence1` in the `small_dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a03663b-3130-4192-bdaa-029a0d031882",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_func(x):\n",
    "    return tokenizer(x[\"sentence1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5bd6b3-2fe3-41f4-b14e-1ba83368932e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03d250e25f1485d95e73c193df3d98b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = small_dataset.map(tokenize_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69200ee5-5375-4313-b8a4-f964878a4a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bbfde4-9201-43a1-8072-3f7a3375e8d8",
   "metadata": {},
   "source": [
    "##### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f96cec-bf90-45ab-8316-0e19ac4bb167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf83df03-1564-4d83-add3-49a7d702ba90",
   "metadata": {},
   "source": [
    "Filter all items in the column `sentence1` from `small_dataset` that start with `F`\n",
    "\n",
    "**Hint**: `x.startswith(\"F\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cfb039-e098-4c06-9e7e-edd2401f9f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_func(x):\n",
    "    return x[\"sentence1\"].startswith(\"F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7ab2a5-5d61-489a-98ea-b548f82ddc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/education/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-e4ca0a64df9634ee.arrow\n"
     ]
    }
   ],
   "source": [
    "new_dataset = small_dataset.filter(filter_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3638b650-973f-4cc9-909d-0bea330d4f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2d3a18-efa5-4c4e-874b-214fefcca39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FBI agents arrested a former partner of Big Four accounting firm Ernst & Young ERNY.UL on criminal charges of obstructing federal investigations , U.S. officials said on Thursday .',\n",
       " 'Fewer than a dozen FBI agents were dispatched to secure and analyze evidence .']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset[\"sentence1\"][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f05774-c526-4aa2-8b99-10d4427f0eea",
   "metadata": {},
   "source": [
    "##### Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66f420c-7e18-455b-8d2b-32190fbf1019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(element):\n",
    "    outputs = tokenizer(\n",
    "        element[\"content\"],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "    input_batch = []\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        if length == context_length:\n",
    "            input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b98170a-c3a1-4fe7-911d-7425f750a99d",
   "metadata": {},
   "source": [
    "### Data Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7f2f14-a2cc-44de-8ee7-fc60a9a684f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset onestop_english (/Users/education/.cache/huggingface/datasets/onestop_english/default/1.1.0/6b19eec5680862ad1cf1990e98b06a98d1fa4c85f3585dc4dfab93f52b89d9cf)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c894d9799bea43bf8d31565f8ebc187a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load a dataset from Hugging Face\n",
    "raw_datasets = load_dataset(\"onestop_english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eb00a0-7936-4e3a-aba1-4cd724cb2204",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148cfb63-d1e9-4365-8068-91c15264a552",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a454515-4aa8-4b91-9294-7019210a3de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(element):\n",
    "    outputs = tokenizer(\n",
    "        element[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "    # return outputs\n",
    "    input_batch = []\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        if length == context_length:\n",
    "            input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad92dc4-f5e5-4813-9663-0f6173f616d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a86c009f91444d9fb1b5beee43eee7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize, batched=True, remove_columns=raw_datasets[\"train\"].column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e833a0a6-c965-4128-903e-9f1a604d62f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 3614\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea421bfe-66fe-4c18-baa3-d3649c85ee9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc36fc3-6083-4dcf-99a2-51f17efdd9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a60c5e0-d369-4a3f-858a-850625ac9976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f91870-3dcf-4b6c-8620-62af77e16332",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2d434f-93be-4db7-b708-fa248fd21d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = tokenized_datasets[\"train\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95de268a-8e44-4144-bda9-13c00b696c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='distilgpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a273e66-3250-4c9c-9767-40b6265376a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ed27cf-6ee1-4844-8472-a39e7d7787d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 17673, 2489, 290, 584]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text[\"input_ids\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1f9222-15b5-4b1a-9000-03a4af50b2ff",
   "metadata": {},
   "source": [
    "Generate `attention_mask` and `labels` for training a masked autoregressive language model using Collator\n",
    "\n",
    "**Hints**\n",
    "- `[tokenized_text]`\n",
    "- `mlm=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8c11ce-77b7-4e42-8089-21ed14f6b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a74bff-ce26-4c44-bb1d-853ce4f2eece",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f560fd8d-5000-4a92-85c7-7559630584d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = data_collator([tokenized_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d1a96a-0ec9-47df-a19e-25e423184e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'labels'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee54fa9-6c18-445a-a127-64e9620421f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   11, 17673,  2489,   290,   584])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"labels\"][0][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9a1764-bee4-44ce-af59-029b3e5bf0d4",
   "metadata": {},
   "source": [
    "##### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d956eb-4c3f-4aa6-9550-182cdbe58e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import IterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb703be-a1ee-403f-bcc4-e4b74c9022a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstantLengthDataset(IterableDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        tokenizer, dataset, seq_len,\n",
    "        num_of_sequences, chars_per_token\n",
    "    ):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.eos_token_id = tokenizer.eos_token_id\n",
    "        self.dataset = dataset\n",
    "        self.seq_len = seq_len\n",
    "        self.input_characters = seq_len * chars_per_token * num_of_sequences\n",
    "    \n",
    "    def __iter__(self):\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
