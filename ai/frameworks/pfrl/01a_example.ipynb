{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d12f603-a27b-4938-b1be-f444f3349107",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pfrl\n",
    "import torch\n",
    "import torch.nn\n",
    "import gym\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8161d42-7319-45b2-9b9d-b309dfea82e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation space: Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
      "action space: Discrete(2)\n",
      "initial observation: [-0.00701067  0.00171636 -0.01474044  0.00792075]\n",
      "next observation: [-0.00697635  0.19704658 -0.01458202 -0.2893763 ]\n",
      "reward: 1.0\n",
      "done: False\n",
      "info: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/education/opt/anaconda3/envs/rlexp/lib/python3.8/site-packages/gym/envs/registration.py:505: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1` with the environment ID `CartPole-v1`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "print('observation space:', env.observation_space)\n",
    "print('action space:', env.action_space)\n",
    "\n",
    "obs = env.reset()\n",
    "print('initial observation:', obs)\n",
    "\n",
    "action = env.action_space.sample()\n",
    "obs, r, done, info = env.step(action)\n",
    "print('next observation:', obs)\n",
    "print('reward:', r)\n",
    "print('done:', done)\n",
    "print('info:', info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1284df85-3b1f-46c9-ae7f-0d1fb83b7ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QFunction(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, obs_size, n_actions):\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(obs_size, 50)\n",
    "        self.l2 = torch.nn.Linear(50, 50)\n",
    "        self.l3 = torch.nn.Linear(50, n_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = x\n",
    "        h = torch.nn.functional.relu(self.l1(h))\n",
    "        h = torch.nn.functional.relu(self.l2(h))\n",
    "        h = self.l3(h)\n",
    "        return pfrl.action_value.DiscreteActionValue(h)\n",
    "\n",
    "obs_size = env.observation_space.low.size\n",
    "n_actions = env.action_space.n\n",
    "q_func = QFunction(obs_size, n_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ebd9a73-711b-4963-8ab5-0f7ab4b2b5eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q_func2 = torch.nn.Sequential(\n",
    "    torch.nn.Linear(obs_size, 50),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, 50),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, n_actions),\n",
    "    pfrl.q_functions.DiscreteActionValueHead(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2d66f1a-fbe2-4bef-97e6-1fb6ecff8ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(q_func.parameters(), eps=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a9760d-e2a1-4842-ab8b-2a94fe29b217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the discount factor that discounts future rewards.\n",
    "gamma = 0.9\n",
    "\n",
    "# Use epsilon-greedy for exploration\n",
    "explorer = pfrl.explorers.ConstantEpsilonGreedy(\n",
    "    epsilon=0.3, random_action_func=env.action_space.sample)\n",
    "\n",
    "# DQN uses Experience Replay.\n",
    "# Specify a replay buffer and its capacity.\n",
    "replay_buffer = pfrl.replay_buffers.ReplayBuffer(capacity=10 ** 6)\n",
    "\n",
    "# Since observations from CartPole-v0 is numpy.float64 while\n",
    "# As PyTorch only accepts numpy.float32 by default, specify\n",
    "# a converter as a feature extractor function phi.\n",
    "phi = lambda x: x.astype(numpy.float32, copy=False)\n",
    "\n",
    "# Set the device id to use GPU. To use CPU only, set it to -1.\n",
    "gpu = -1\n",
    "\n",
    "# Now create an agent that will interact with the environment.\n",
    "agent = pfrl.agents.DoubleDQN(\n",
    "    q_func,\n",
    "    optimizer,\n",
    "    replay_buffer,\n",
    "    gamma,\n",
    "    explorer,\n",
    "    replay_start_size=500,\n",
    "    update_interval=1,\n",
    "    target_update_interval=100,\n",
    "    phi=phi,\n",
    "    gpu=gpu,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03cdef8c-1fdd-473a-898d-63993235bc4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 10 R: 15.0\n",
      "episode: 20 R: 13.0\n",
      "episode: 30 R: 23.0\n",
      "episode: 40 R: 10.0\n",
      "episode: 50 R: 9.0\n",
      "statistics: [('average_q', 2.6473818), ('average_loss', 0.1288216543570161), ('cumulative_steps', 778), ('n_updates', 279), ('rlen', 778)]\n",
      "episode: 60 R: 10.0\n",
      "episode: 70 R: 22.0\n",
      "episode: 80 R: 17.0\n",
      "episode: 90 R: 13.0\n",
      "episode: 100 R: 17.0\n",
      "statistics: [('average_q', 6.334226), ('average_loss', 0.3119211425073445), ('cumulative_steps', 1504), ('n_updates', 1005), ('rlen', 1504)]\n",
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "n_episodes = 100\n",
    "max_episode_len = 200\n",
    "for i in range(1, n_episodes + 1):\n",
    "    obs = env.reset()\n",
    "    R = 0  # return (sum of rewards)\n",
    "    t = 0  # time step\n",
    "    while True:\n",
    "        # Uncomment to watch the behavior in a GUI window\n",
    "        # env.render()\n",
    "        action = agent.act(obs)\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        R += reward\n",
    "        t += 1\n",
    "        reset = t == max_episode_len\n",
    "        agent.observe(obs, reward, done, reset)\n",
    "        if done or reset:\n",
    "            break\n",
    "    if i % 10 == 0:\n",
    "        print('episode:', i, 'R:', R)\n",
    "    if i % 50 == 0:\n",
    "        print('statistics:', agent.get_statistics())\n",
    "print('Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "058a6e56-f19c-45d8-9c57-a1ee61470414",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation episode: 0 R: 10.0\n",
      "evaluation episode: 1 R: 10.0\n",
      "evaluation episode: 2 R: 10.0\n",
      "evaluation episode: 3 R: 10.0\n",
      "evaluation episode: 4 R: 9.0\n",
      "evaluation episode: 5 R: 9.0\n",
      "evaluation episode: 6 R: 10.0\n",
      "evaluation episode: 7 R: 8.0\n",
      "evaluation episode: 8 R: 8.0\n",
      "evaluation episode: 9 R: 10.0\n"
     ]
    }
   ],
   "source": [
    "with agent.eval_mode():\n",
    "    for i in range(10):\n",
    "        obs = env.reset()\n",
    "        R = 0\n",
    "        t = 0\n",
    "        while True:\n",
    "            # Uncomment to watch the behavior in a GUI window\n",
    "            # env.render()\n",
    "            action = agent.act(obs)\n",
    "            obs, r, done, _ = env.step(action)\n",
    "            R += r\n",
    "            t += 1\n",
    "            reset = t == 200\n",
    "            agent.observe(obs, r, done, reset)\n",
    "            if done or reset:\n",
    "                break\n",
    "        print('evaluation episode:', i, 'R:', R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ac5af-8aaa-4a8b-8106-05e8ec2001d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
