{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70cc64bd-c7aa-474c-9505-0d04b8b04cb8",
   "metadata": {},
   "source": [
    "### Chapter 3. Building Your First Distributed Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5d44205-934c-4fb3-b4c0-83b3a2a4aecb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class Discrete:\n",
    "    def __init__(self, num_actions: int):\n",
    "        \"\"\" Discrete action space for num_actions.\n",
    "        Discrete(4) can be used as encoding moving in\n",
    "        one of the cardinal directions.\n",
    "        \"\"\"\n",
    "        self.n = num_actions\n",
    "\n",
    "    def sample(self):\n",
    "        return random.randint(0, self.n - 1)\n",
    "\n",
    "\n",
    "space = Discrete(4)\n",
    "print(space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "556cf238-6186-42e7-a028-a8e9df20c003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "class Environment:\n",
    "    def __init__(self,  *args, **kwargs):\n",
    "        self.seeker, self.goal = (0, 0), (4, 4)\n",
    "        self.info = {'seeker': self.seeker, 'goal': self.goal}\n",
    "\n",
    "        self.action_space = Discrete(4)\n",
    "        self.observation_space = Discrete(5*5)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset seeker position and return observations.\"\"\"\n",
    "        self.seeker = (0, 0)\n",
    "\n",
    "        return self.get_observation()\n",
    "\n",
    "    def get_observation(self):\n",
    "        \"\"\"Encode the seeker position as integer\"\"\"\n",
    "        return 5 * self.seeker[0] + self.seeker[1]\n",
    "\n",
    "    def get_reward(self):\n",
    "        \"\"\"Reward finding the goal\"\"\"\n",
    "        return 1 if self.seeker == self.goal else 0\n",
    "\n",
    "    def is_done(self):\n",
    "        \"\"\"We're done if we found the goal\"\"\"\n",
    "        return self.seeker == self.goal\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Take a step in a direction and return all available information.\"\"\"\n",
    "        if action == 0:  # move down\n",
    "            self.seeker = (min(self.seeker[0] + 1, 4), self.seeker[1])\n",
    "        elif action == 1:  # move left\n",
    "            self.seeker = (self.seeker[0], max(self.seeker[1] - 1, 0))\n",
    "        elif action == 2:  # move up\n",
    "            self.seeker = (max(self.seeker[0] - 1, 0), self.seeker[1])\n",
    "        elif action == 3:  # move right\n",
    "            self.seeker = (self.seeker[0], min(self.seeker[1] + 1, 4))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid action\")\n",
    "\n",
    "        obs = self.get_observation()\n",
    "        rew = self.get_reward()\n",
    "        done = self.is_done()\n",
    "        return obs, rew, done, self.info\n",
    "\n",
    "    def render(self, *args, **kwargs):\n",
    "        \"\"\"We override this method here so clear the output in Jupyter notebooks.\n",
    "        The previous implementation works well in the terminal, but does not clear\n",
    "        the screen in interactive environments.\n",
    "        \"\"\"\n",
    "        os.system('cls' if os.name == 'nt' else 'clear')\n",
    "        try:\n",
    "            from IPython.display import clear_output\n",
    "            clear_output(wait=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "        grid = [['| ' for _ in range(5)] + [\"|\\n\"] for _ in range(5)]\n",
    "        grid[self.goal[0]][self.goal[1]] = '|G'\n",
    "        grid[self.seeker[0]][self.seeker[1]] = '|S'\n",
    "        print(''.join([''.join(grid_row) for grid_row in grid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "220df13e-0aad-4e05-9c97-acbcf4808bd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "environment = Environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4430e299-4672-41fe-95b2-51c54180365f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# while not environment.is_done():\n",
    "#     random_action = environment.action_space.sample()\n",
    "#     environment.step(random_action)\n",
    "#     time.sleep(0.1)\n",
    "#     environment.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6fd99c3-7b0e-4076-93ae-af835f8648b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Policy:\n",
    "\n",
    "    def __init__(self, env):\n",
    "        \"\"\"A Policy suggests actions based on the current state.\n",
    "        We do this by tracking the value of each state-action pair.\n",
    "        \"\"\"\n",
    "        self.state_action_table = [\n",
    "            [0 for _ in range(env.action_space.n)]\n",
    "            for _ in range(env.observation_space.n)\n",
    "        ]\n",
    "        self.action_space = env.action_space\n",
    "\n",
    "    def get_action(self, state, explore=True, epsilon=0.1):\n",
    "        \"\"\"Explore randomly or exploit the best value currently available.\"\"\"\n",
    "        if explore and random.uniform(0, 1) < epsilon:\n",
    "            return self.action_space.sample()\n",
    "        return np.argmax(self.state_action_table[state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "133777ce-0c4a-4419-a9e8-100250f00dda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Simulation(object):\n",
    "    def __init__(self, env):\n",
    "        \"\"\"Simulates rollouts of an environment, given a policy to follow.\"\"\"\n",
    "        self.env = env\n",
    "\n",
    "    def rollout(self, policy, render=False, explore=True, epsilon=0.1):\n",
    "        \"\"\"Returns experiences for a policy rollout.\"\"\"\n",
    "        experiences = []\n",
    "        state = self.env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = policy.get_action(state, explore, epsilon)\n",
    "            next_state, reward, done, info = self.env.step(action)\n",
    "            experiences.append([state, action, reward, next_state])\n",
    "            state = next_state\n",
    "            if render:\n",
    "                time.sleep(0.05)\n",
    "                self.env.render()\n",
    "\n",
    "        return experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4efb6d0-6305-42d2-8e4c-91ab8a13f66e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def update_policy(policy, experiences, weight=0.1, discount_factor=0.9):\n",
    "    \"\"\"Updates a given policy with a list of (state, action, reward, state)\n",
    "    experiences.\"\"\"\n",
    "    for state, action, reward, next_state in experiences:\n",
    "        next_max = np.max(policy.state_action_table[next_state])\n",
    "        value = policy.state_action_table[state][action]\n",
    "        new_value = (1 - weight) * value + weight * \\\n",
    "                    (reward + discount_factor * next_max)\n",
    "        policy.state_action_table[state][action] = new_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17800537-49dc-49ff-8f3f-37dc96a87bc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_policy(env, num_episodes=10000, weight=0.1, discount_factor=0.9):\n",
    "    \"\"\"Training a policy by updating it with rollout experiences.\"\"\"\n",
    "    policy = Policy(env)\n",
    "    sim = Simulation(env)\n",
    "    for _ in range(num_episodes):\n",
    "        experiences = sim.rollout(policy)\n",
    "        update_policy(policy, experiences, weight, discount_factor)\n",
    "\n",
    "    return policy\n",
    "\n",
    "\n",
    "trained_policy = train_policy(environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d1687d6-bc31-4864-a73d-d9be649c96f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| | | | | |\n",
      "| | | | | |\n",
      "| | | | | |\n",
      "| | | | | |\n",
      "| | | | |S|\n",
      "\n",
      "8.0 steps on average for a total of 10 episodes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_policy(env, policy, num_episodes=10):\n",
    "    \"\"\"Evaluate a trained policy through rollouts.\"\"\"\n",
    "    simulation = Simulation(env)\n",
    "    steps = 0\n",
    "\n",
    "    for _ in range(num_episodes):\n",
    "        experiences = simulation.rollout(policy, render=True, explore=False)\n",
    "        steps += len(experiences)\n",
    "\n",
    "    print(f\"{steps / num_episodes} steps on average \"\n",
    "          f\"for a total of {num_episodes} episodes.\")\n",
    "\n",
    "    return steps / num_episodes\n",
    "\n",
    "\n",
    "evaluate_policy(environment, trained_policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc080601-17a6-4816-96b5-d6d73e740ac1",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6f04008-95b5-4756-928d-af0ec7bbe98b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "import time\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def slow_function(x):\n",
    "    time.sleep(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3bb16fd2-742e-40ac-9e28-c2221a32f6e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Start 5 tasks that take different times to complete\n",
    "tasks = [slow_function.remote(i) for i in range(5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5e8b41-c024-4465-bbd6-0d4ac76455ba",
   "metadata": {},
   "source": [
    "`tasks` is 5 tasks are currently running in parallel. Retrieve **the first three** tasks that have completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "811f245d-bc29-462d-b247-67a17585d855",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b14b2abb-2660-444a-95e7-af0de2481c43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ObjectRef(359ec6ce30d3ca2dffffffffffffffffffffffff0100000001000000),\n",
       " ObjectRef(1e8ff6d236132784ffffffffffffffffffffffff0100000001000000),\n",
       " ObjectRef(85748392bcd969ccffffffffffffffffffffffff0100000001000000),\n",
       " ObjectRef(d695f922effe6d99ffffffffffffffffffffffff0100000001000000),\n",
       " ObjectRef(2751d69548dba956ffffffffffffffffffffffff0100000001000000)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ecfa6e8b-f762-4a41-a6a0-90bfc3f7aa72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "completed_tasks, pending_tasks = ray.wait(tasks, num_returns=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c6643f0e-94dc-40bf-9dcc-33b6c2803f68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b8ed8039-f203-4f00-b3bd-4ceb359b15d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(completed_tasks), len(pending_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3353cd05-1c1e-47a0-af87-23f2c9817a23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ObjectRef(359ec6ce30d3ca2dffffffffffffffffffffffff0100000001000000),\n",
       " ObjectRef(d695f922effe6d99ffffffffffffffffffffffff0100000001000000),\n",
       " ObjectRef(2751d69548dba956ffffffffffffffffffffffff0100000001000000)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completed_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "837e6d75-bab5-4187-bc8b-f56262833092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the results of the completed tasks\n",
    "completed_results = ray.get(completed_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7e27e35d-0388-4bbc-9f3d-441bffa2ea87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed tasks: [0, 3, 4]\n",
      "Pending tasks: [ObjectRef(1e8ff6d236132784ffffffffffffffffffffffff0100000001000000), ObjectRef(85748392bcd969ccffffffffffffffffffffffff0100000001000000)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Completed tasks:\", completed_results)\n",
    "print(\"Pending tasks:\", pending_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfaf5f29-e4c3-4522-ba92-fc93b7a668e4",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4804e6e3-0a88-4808-a3e2-5363feaf1fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ObjectRef(359ec6ce30d3ca2dffffffffffffffffffffffff0100000001000000),\n",
       " ObjectRef(1e8ff6d236132784ffffffffffffffffffffffff0100000001000000),\n",
       " ObjectRef(85748392bcd969ccffffffffffffffffffffffff0100000001000000)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completed_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75061f3d-54d4-4685-a0f6-0edfb1cab3b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = completed_tasks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cba4f48a-3f3d-4264-9555-ee0e7aa779af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectRef(359ec6ce30d3ca2dffffffffffffffffffffffff0100000001000000)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249afaa6-48c6-49a7-bcbc-22feedc0c810",
   "metadata": {},
   "source": [
    "Obtain the actual value of `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c1c111d7-9c37-4087-939b-5aa74e834aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "850dea01-3304-45f7-be6d-9d14282a916e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "value = ray.get(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a89618a3-9894-4f40-8d56-d7e5534ada2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe36f40-2019-43b1-924e-037f1152c3ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "691bbedc-8486-44fa-a255-6fcca5c9e8de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 14:16:11,366\tINFO worker.py:1553 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "ray.init()\n",
    "\n",
    "@ray.remote\n",
    "class SimulationActor(Simulation):\n",
    "    def __init__(self):\n",
    "        env = Environment()\n",
    "        super().__init__(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c8d583-a76d-49d7-a4f4-f69ad7faf4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_policy_parallel(env, num_episodes=1000, num_simulations=4):\n",
    "    policy = Policy(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826c60f0-074e-4947-8aaa-03be753efb51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
