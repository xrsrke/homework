{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce13481b-b276-4be0-bedc-6a6794eebefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.autograd.profiler as profiler\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3262fd-1faf-4f61-9610-ca0b6e70d092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor of size (6, 3)\n",
    "tensor = torch.randn(6, 3)\n",
    "\n",
    "# Using torch.chunk\n",
    "chunked_tensors = torch.chunk(tensor, chunks=3, dim=0)\n",
    "\n",
    "# Using torch.split with a single integer\n",
    "split_tensors = torch.split(tensor, split_size_or_sections=2, dim=0)\n",
    "\n",
    "# Using torch.split with a list of sizes\n",
    "split_tensors_custom = torch.split(tensor, split_size_or_sections=[1, 2, 3], dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39a3f3-8c71-45eb-a1fe-205be8715061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2207, -0.2316, -1.3084],\n",
       "         [ 0.4861,  1.0719,  0.2642]]),\n",
       " tensor([[ 0.2454, -0.4175,  0.0040],\n",
       "         [ 0.0299, -0.6987, -1.7507]]),\n",
       " tensor([[ 0.2908,  1.7810,  0.2629],\n",
       "         [ 1.9374,  0.3519, -1.6771]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538e6153-0699-419d-ae4b-e0b430a703c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2207, -0.2316, -1.3084],\n",
       "         [ 0.4861,  1.0719,  0.2642]]),\n",
       " tensor([[ 0.2454, -0.4175,  0.0040],\n",
       "         [ 0.0299, -0.6987, -1.7507]]),\n",
       " tensor([[ 0.2908,  1.7810,  0.2629],\n",
       "         [ 1.9374,  0.3519, -1.6771]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b03045-3e54-4979-bd71-42bad3248132",
   "metadata": {},
   "source": [
    "### `Profile`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdb19fd-1e83-4ec1-9d8d-e029d2773894",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c024f92-0114-4d8e-8bb6-12b7410f762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features, bias)\n",
    "\n",
    "    def forward(self, input, mask):\n",
    "        with profiler.record_function(\"LINEAR PASS\"):\n",
    "            out = self.linear(input)\n",
    "\n",
    "        with profiler.record_function(\"MASK INDICES\"):\n",
    "            threshold = out.sum(axis=1).mean().item()\n",
    "            hi_idx = np.argwhere(mask.cpu().numpy() > threshold)\n",
    "            hi_idx = torch.from_numpy(hi_idx)\n",
    "\n",
    "        return out, hi_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02dadb9-7296-449e-b00b-1f588ad1383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModule(500, 10)\n",
    "input = torch.rand(128, 500)\n",
    "mask = torch.rand((500, 500, 500), dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bf6e1a-9550-4932-b246-adf9f6908292",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_params = {\n",
    "    \"with_stack\": True,\n",
    "    \"profile_memory\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1a746c-2a84-4028-bad9-a0cf8d2388c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'with_stack': True, 'profile_memory': True}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35233043-dd5e-4f1c-9e4e-9df5c3d91cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hardcore():\n",
    "    out, idx = model(input, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c4dd4-40b7-4687-ad57-89a8e0778653",
   "metadata": {},
   "source": [
    "Profile the performance of function `hardcore` using `torch.autograd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a12516f-7e10-498f-a479-e9b5550eb223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.autograd.profiler as profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12607be-e8ed-44fd-9dd7-69de05af49da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W collection.cpp:436] Warning: runpy.py(194): _run_module_as_main (function operator())\n",
      "[W collection.cpp:436] Warning: runpy.py(87): _run_code (function operator())\n",
      "[W collection.cpp:436] Warning: ipykernel_launcher.py(17): <module> (function operator())\n",
      "[W collection.cpp:436] Warning: traitlets/config/application.py(992): launch_instance (function operator())\n",
      "[W collection.cpp:436] Warning: ipykernel/kernelapp.py(711): start (function operator())\n",
      "[W collection.cpp:436] Warning: tornado/platform/asyncio.py(215): start (function operator())\n",
      "[W collection.cpp:436] Warning: asyncio/base_events.py(570): run_forever (function operator())\n",
      "[W collection.cpp:436] Warning: asyncio/base_events.py(1859): _run_once (function operator())\n",
      "[W collection.cpp:436] Warning: asyncio/events.py(81): _run (function operator())\n",
      "[W collection.cpp:436] Warning: ipykernel/kernelbase.py(510): dispatch_queue (function operator())\n",
      "[W collection.cpp:436] Warning: ipykernel/kernelbase.py(499): process_one (function operator())\n",
      "[W collection.cpp:436] Warning: ipykernel/kernelbase.py(406): dispatch_shell (function operator())\n",
      "[W collection.cpp:436] Warning: ipykernel/kernelbase.py(729): execute_request (function operator())\n",
      "[W collection.cpp:436] Warning: ipykernel/ipkernel.py(411): do_execute (function operator())\n",
      "[W collection.cpp:436] Warning: ipykernel/zmqshell.py(531): run_cell (function operator())\n",
      "[W collection.cpp:436] Warning: IPython/core/interactiveshell.py(2940): run_cell (function operator())\n",
      "[W collection.cpp:436] Warning: IPython/core/interactiveshell.py(2995): _run_cell (function operator())\n",
      "[W collection.cpp:436] Warning: IPython/core/async_helpers.py(129): _pseudo_sync_runner (function operator())\n",
      "[W collection.cpp:436] Warning: IPython/core/interactiveshell.py(3194): run_cell_async (function operator())\n",
      "[W collection.cpp:436] Warning: IPython/core/interactiveshell.py(3373): run_ast_nodes (function operator())\n",
      "[W collection.cpp:436] Warning: IPython/core/interactiveshell.py(3433): run_code (function operator())\n",
      "[W collection.cpp:436] Warning: /var/folders/pf/g3nr86yn4j71vzzmv6knwdhr0000gp/T/ipykernel_24342/3352848407.py(1): <module> (function operator())\n",
      "[W collection.cpp:436] Warning: torch/autograd/profiler.py(223): __exit__ (function operator())\n",
      "[W collection.cpp:436] Warning: <built-in method _disable_profiler of PyCapsule object> (function operator())\n"
     ]
    }
   ],
   "source": [
    "with profiler.profile(**profile_params) as prof:\n",
    "    hardcore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed39632e-37d0-4a88-9cdf-9e5780575190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prof.key_averages(group_by_stack_n=5).table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee255b03-e04c-4ddf-9d24-2c796aa4a4f7",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a6dde8-d802-4a88-b2e4-76d076e6c9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57552141-01a5-4140-b649-03bd0759a47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d44a64b-941b-4f8d-890e-3cb8f5a1ca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hardcore():\n",
    "    model = models.resnet18()\n",
    "    inputs = torch.randn(5, 3, 224, 224)\n",
    "    return model(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8808f9b9-3299-4f7a-93be-7f867b265846",
   "metadata": {},
   "source": [
    "Profile the function `hardcore` on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4a7281-b0c5-4d42-b77b-73fa729bd7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336fd91b-d89a-45ea-bfb3-114728753bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(activities=[ProfilerActivity.CPU]) as prof:\n",
    "    hardcore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f731d05a-6b37-45b0-b683-964ce43847c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     aten::conv2d         0.01%      56.000us        35.89%     172.144ms       8.607ms            20  \n",
      "                aten::convolution         0.35%       1.686ms        35.88%     172.088ms       8.604ms            20  \n",
      "               aten::_convolution         0.04%     209.000us        35.53%     170.402ms       8.520ms            20  \n",
      "                aten::thnn_conv2d         0.01%      60.000us        35.48%     170.193ms       8.510ms            20  \n",
      "       aten::_slow_conv2d_forward        35.43%     169.932ms        35.47%     170.133ms       8.507ms            20  \n",
      "                    aten::normal_        34.52%     165.558ms        34.52%     165.558ms       7.884ms            21  \n",
      "                   aten::uniform_        14.82%      71.065ms        14.82%      71.065ms       3.230ms            22  \n",
      "                     aten::linear         0.00%       7.000us         5.20%      24.922ms      24.922ms             1  \n",
      "                      aten::addmm         5.19%      24.903ms         5.19%      24.906ms      24.906ms             1  \n",
      "                 aten::batch_norm         0.01%      59.000us         5.08%      24.367ms       1.218ms            20  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 479.640ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c559e-9739-45ea-aed6-4873565dd8ed",
   "metadata": {},
   "source": [
    "##### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e95abd6-c4a6-4d8b-8088-8630289bc786",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedular_params = {\n",
    "    \"wait\": 1,\n",
    "    \"warmup\": 1,\n",
    "    \"active\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546dbddd-8cc6-4353-a1aa-06908758563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hardcore():\n",
    "    for idx in range(8):\n",
    "        model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abf085e-4521-4de4-818c-87803fbdbb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wait': 1, 'warmup': 1, 'active': 2}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedular_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e7a224-ace2-4b4f-a933-4732efe2f35c",
   "metadata": {},
   "source": [
    "Profile the `hardcore` function on CPU using a profiler and set a schedule with the `scheduler_params`\n",
    "\n",
    "**Hint**: Not use the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33baccc6-9d64-4b7a-8a56-a6e208fed7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.profiler import profile, ProfilerActivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d377c8-f2df-4388-b763-b45ee082be67",
   "metadata": {},
   "outputs": [],
   "source": [
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU],\n",
    "    schedule=torch.profiler.schedule(**schedular_params)\n",
    ") as prof:\n",
    "    for idx in range(3):\n",
    "        model(inputs)\n",
    "        prof.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d770d77d-cbc5-4108-98ba-5b0b15fef1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                    ProfilerStep*         4.32%       8.577ms        99.99%     198.590ms      99.295ms             2  \n",
      "                     aten::conv2d         0.03%      53.000us        74.45%     147.871ms       7.394ms            20  \n",
      "                aten::convolution         0.12%     243.000us        74.42%     147.818ms       7.391ms            20  \n",
      "               aten::_convolution         0.09%     171.000us        74.30%     147.575ms       7.379ms            20  \n",
      "                aten::thnn_conv2d         0.03%      64.000us        74.21%     147.404ms       7.370ms            20  \n",
      "       aten::_slow_conv2d_forward        74.11%     147.205ms        74.18%     147.340ms       7.367ms            20  \n",
      "                 aten::batch_norm         0.17%     328.000us         8.61%      17.095ms     854.750us            20  \n",
      "     aten::_batch_norm_impl_index         0.07%     146.000us         8.57%      17.028ms     851.400us            20  \n",
      "          aten::native_batch_norm         8.41%      16.710ms         8.48%      16.848ms     842.400us            20  \n",
      "                     aten::linear         0.00%       5.000us         7.54%      14.969ms      14.969ms             1  \n",
      "---------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 198.618ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8560bb69-cfe1-4cb8-b619-f4ab4073e735",
   "metadata": {},
   "source": [
    "##### Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85278d4f-6799-48b0-8686-f484eb44ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = torch.tensor([69, 69, 69]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4609cabf-465c-4b91-87d5-aebe3e4cceed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = xs.mean(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dd64bd-22ac-44c6-b2d8-ebb821a608ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195a48b2-a6a4-45af-93d4-87b4a43785e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab793026-4b22-441c-b323-89843ae11124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([69., 69., 69.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c31f5b5-835d-4016-a4da-b199636f70d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758cbbc3-52c0-4ff6-bdc4-6d05108dd3c4",
   "metadata": {},
   "source": [
    "Create a new CUDA stream on the `device`, and then calculate the average of xs using that CUDA stream on `device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e592f0-56e4-4dc5-a123-3c1a7e06180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = torch.cuda.Stream(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff85159f-726c-4c26-be6d-59a0badf93d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.device(device):\n",
    "    with torch.cuda.stream(stream):\n",
    "        mean = xs.mean(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0e7ace-d6ae-45f8-9062-83549faf5b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(69.)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd38b85b-81fb-49a8-94a5-fdfeaee38b07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
