{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e017a36-e5fd-408c-9b10-37ea2434f984",
   "metadata": {},
   "source": [
    "##### `torch.autograd.Function`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b31200-874a-4157-aed5-cad7d1f7fd16",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba48fd80-ed25-4113-a072-5d398530d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1., 2., 3.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31098b2e-fcc6-4989-a545-6f1275d20eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d6e854-1283-41cd-9ec3-2fb8b4a464d6",
   "metadata": {},
   "source": [
    "Write a custom autograd function that returns the `input` in the forward pass and returns the gradient as `input + 1` in the backward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc2919d-d73f-4c13-8e2d-956b76974d0b",
   "metadata": {},
   "source": [
    "**Hints**: `ctx` is a context object that can be used to save information needed for the backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5211124-e775-4c74-a99c-5874b2e80ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a237903f-7528-450b-879c-73a6195336b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiplyConstant(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e708816d-7442-4e80-9b6e-23ad9e43c243",
   "metadata": {},
   "source": [
    "To use the custom function, you need to call its `apply` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f57e33-5e0a-431d-8358-697255be7b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = MultiplyConstant.apply(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1206c0-563e-403b-b4d4-797ec5eac819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], grad_fn=<MultiplyConstantBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7be4f99-d24f-4537-97fd-d3b20f6f071e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.backward(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8442dad1-37bf-4b37-9120-6e88fef5a7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3., 4.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df79406-bcf5-4ec5-a45d-f466a6aecbd6",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10646e26-e38d-4d46-854f-48a8cb5996cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiplyConstant(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, constant):\n",
    "        # ctx.save_for_backward(input)\n",
    "        # ctx.constant = constant\n",
    "        return input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # input, = ctx.saved_tensors\n",
    "        # constant = ctx.constant\n",
    "        # grad_input = grad_output * constant\n",
    "        return grad_output, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e9b3a1-befa-4f07-8701-565c648a9106",
   "metadata": {},
   "source": [
    "##### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be2a5d-cbe2-4b51-98f7-ecf7b1254cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef5be6-4b08-48cb-8468-9609b8d59db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Square(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        # Because we are saving one of the inputs use `save_for_backward`\n",
    "        # Save non-tensors and non-inputs/non-outputs directly on ctx\n",
    "        ctx.save_for_backward(x)\n",
    "        return x**2\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_out):\n",
    "        # A function support double backward automatically if autograd\n",
    "        # is able to record the computations performed in backward\n",
    "        x, = ctx.saved_tensors\n",
    "        return grad_out * 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154b1dfd-5b02-4951-bb69-eb6ae3a461ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3, 3, requires_grad=True, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa7d5be-4253-4258-9ab1-b2fefcba8f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.gradcheck(Square.apply, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f307c04d-1f10-42fd-a744-e0bd777a0a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchviz\n",
    "\n",
    "x = torch.tensor(1., requires_grad=True).clone()\n",
    "out = Square.apply(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3a227a-6f64-4ae5-b170-70a9a013f23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_x, = torch.autograd.grad(out, x, create_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348b8a09-8971-47bb-b7da-01d5aaef3aba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
