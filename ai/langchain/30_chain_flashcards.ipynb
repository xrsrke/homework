{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13e47375-d3d5-440c-a96f-893ddc2d6976",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ba06a2-3851-4aca-af23-cc6ee1ce71ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f886d381-d68b-4bfc-bf8d-0939bb2417e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt_1 \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[1;32m      2\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduct\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      3\u001b[0m     template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is a good name for a company that makes \u001b[39m\u001b[38;5;132;01m{product}\u001b[39;00m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 5\u001b[0m chain_1 \u001b[38;5;241m=\u001b[39m LLMChain(llm\u001b[38;5;241m=\u001b[39m\u001b[43mllm\u001b[49m, prompt\u001b[38;5;241m=\u001b[39mprompt_1)\n\u001b[1;32m      7\u001b[0m prompt_2 \u001b[38;5;241m=\u001b[39m PromptTemplate(\n\u001b[1;32m      8\u001b[0m     input_variables\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproduct\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      9\u001b[0m     template\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is a good slogan for a company that makes \u001b[39m\u001b[38;5;132;01m{product}\u001b[39;00m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m chain_2 \u001b[38;5;241m=\u001b[39m LLMChain(llm\u001b[38;5;241m=\u001b[39mllm, prompt\u001b[38;5;241m=\u001b[39mprompt_2)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
     ]
    }
   ],
   "source": [
    "prompt_1 = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "chain_1 = LLMChain(llm=llm, prompt=prompt_1)\n",
    "\n",
    "prompt_2 = PromptTemplate(\n",
    "    input_variables=[\"product\"],\n",
    "    template=\"What is a good slogan for a company that makes {product}?\",\n",
    ")\n",
    "chain_2 = LLMChain(llm=llm, prompt=prompt_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02253983-9564-4bfb-b81e-93e2f86b8c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.base import Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1a9f7e-e8f0-447e-9137-a6299187cfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongChain(Chain):\n",
    "    chain_1: LLMChain\n",
    "    chain_2: LLMChain\n",
    "    \n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        key_1 = set(self.chain_1.input_keys)\n",
    "        key_2 = set(self.chain_2.input_keys)\n",
    "        all_input_variables = key_1.union(key_2)\n",
    "        return list(all_input_variables)\n",
    "    \n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        return [\"concat_output\"]\n",
    "\n",
    "    def _call(self, inputs: Dict[str, str]) -> Dict[str, str]:\n",
    "        output_1 = self.chain_1.run(inputs)\n",
    "        output_2 = self.chain_2.run(inputs)\n",
    "        \n",
    "        return {\"concat_output\": output_1 + output_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50a3b48-ccbf-4933-8126-0f02e5e53a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(langchain.chains.llm.LLMChain, langchain.chains.llm.LLMChain)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain_1), type(chain_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b21fd9-80c7-4bf4-af51-f03ceaf6110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_chain = LongChain(chain_1=chain_1, chain_2=chain_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc711024-e5b2-4afc-b2a5-4fd301f58428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "RocketWorks Technologies.\n",
      "\n",
      "\"Reach for the Stars with Our Rockets!\"\n"
     ]
    }
   ],
   "source": [
    "print(long_chain.run(\"rocket\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00601ef3-5d85-4fb9-9cee-1fc78e4740db",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0c2e46-8117-48f8-b3b4-5f2a1f1ce63d",
   "metadata": {},
   "source": [
    "Load OpenAI's language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91a0a8a-2006-43ce-a614-4a67f4f39aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a53c67-6c40-4b4c-9085-e9055cf7e442",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fac938-d1fa-4cb1-ac82-8f5797a112cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nQ: What did the fish say when it hit the wall?\\nA: Dam!'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28ab7bc-9dbf-4f2d-a2ad-527bb4233b41",
   "metadata": {},
   "source": [
    "##### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dc3a95-9825-4267-b456-13a888dab1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an LLMChain to write a synopsis given a title of a play.\n",
    "llm = OpenAI(temperature=.7)\n",
    "template = \"\"\"This is a conversation between a user and a AI. You're the AI\n",
    "\n",
    "User: {input}\n",
    "AI:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"input\"], template=template)\n",
    "assistant_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba675123-b0dd-492d-9c18-85b85f3e4c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an LLMChain to write a review of a play given a synopsis.\n",
    "llm = OpenAI(temperature=.7)\n",
    "template = \"\"\"This is a conversation between a user and a AI. You're the user\n",
    "\n",
    "AI: {input}\n",
    "User:\"\"\"\n",
    "prompt_template = PromptTemplate(input_variables=[\"input\"], template=template)\n",
    "user_chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e266e7-7a74-4609-bdd9-a6166b141781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(langchain.chains.llm.LLMChain, langchain.chains.llm.LLMChain)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(assistant_chain), type(user_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ef1ec7-301e-4510-92fe-f8805f307a50",
   "metadata": {},
   "source": [
    "Construct a chain in which the output generated by the `assistant_chain` is used as the input for the `user_chain`.\n",
    "\n",
    "**Hint**: Both `assistant_chain` and `user_chain` only have one input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06c2d79-b1e6-4d7e-a2aa-ef6aad06a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20340ab9-a550-4041-a2cd-5f4e410127ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "SimpleSequentialChain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfeade1-351f-4404-87ab-6b7ec30c8888",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = SimpleSequentialChain(\n",
    "    chains=[assistant_chain, user_chain],\n",
    "    verbose=True # can be ignore\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d60733b-d5e5-49bd-aa5f-96c2e232d1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m Hi there! How can I help you?\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m Hi, I'm looking for recommendations for a new laptop.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "review = overall_chain.run(\"Hi there!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee99816-39fe-46bd-b086-5fb5953a0a93",
   "metadata": {},
   "source": [
    "##### Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf6937d-5820-4bfa-8659-2f856f1b8eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.llms.openai.OpenAI"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05830fc-9733-4bcc-a1a3-6ea8f1e50686",
   "metadata": {},
   "source": [
    "Generate a simulated conversation between a user and an AI using `model`. It take the user's questions as `input` and provide the AI with **the current year** as memory (don't put it in the prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cc6c96-a2c4-4731-9410-b25caaea5808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import SimpleMemory\n",
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c9b83d-a747-428c-9946-0415f5ee54e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "This is a conversation between a user and an AI:\n",
    "\n",
    "Here is some context about the current date:\n",
    "Year: {year}\n",
    "\n",
    "User: {input}\n",
    "AI:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631d6878-3d46-4863-8b40-d8269619f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_tempalte = PromptTemplate(\n",
    "    input_variables=[\"input\", \"year\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe023e-3db0-4aaf-9661-71960744d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SimpleMemory(memories={\"year\": \"2023\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacfcee8-1345-453c-8418-ef46ab26d677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleMemory(memories={'year': '2023'})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b5aff2-830c-46ef-9a43-c2d87ae05325",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(\n",
    "    memory=memory,\n",
    "    prompt=prompt_template,\n",
    "    llm=model,\n",
    "    verbose=True # can be ignored\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858d5c49-8f23-46e3-a1f9-23250344690b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThis is a conversation between a user and an AI:\n",
      "\n",
      "Here is some context about the current date:\n",
      "Date and Time: 2023\n",
      "\n",
      "User: Yo! What is the current year?\n",
      "AI:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Yo! What is the current year?',\n",
       " 'year': '2023',\n",
       " 'text': 'The current year is 2023.'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\"Yo! What is the current year?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5aadb1-963e-4188-96b5-c14e171fd596",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9d05ce-7093-4a2b-b08f-a7aa8995f6db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
