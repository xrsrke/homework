{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f55190c-9dc0-487e-9e01-78a1471330d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064439cd-ab25-4adf-a516-be4c5fb2acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OpenAI(\n",
    "    openai_api_key=\"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\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bf1ff3-7d56-48f6-990b-bc11b6b3b331",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02874f5f-6e6a-4342-b7b1-b433a63c0493",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_prompt = \"\"\"\n",
    "Predict the capital of a country.\n",
    "\n",
    "Country:\n",
    "Capital:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156c8bc0-8948-4482-941e-d6124cacad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e16535-be1d-4d12-a3d1-3dbc4fd8a419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predict the capital of a country.\n",
      "\n",
      "Country:\n",
      "Capital:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b453b2c4-3bbd-4ee7-96d7-4f2d3d6f2bc8",
   "metadata": {},
   "source": [
    "Create a prompt template predicts the capital of a country\n",
    "\n",
    "**Hint**: Use the format from `format_prompt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361b3a8-5bbb-4e59-ba0e-8aa1ebe8e663",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Predict the capital of a country.\n",
    "\n",
    "Country: {country}\n",
    "Capital:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc5f822-bcc9-4f02-9ec0-dd1bc0635dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"country\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bd5e6c-2fd2-49c3-b1e4-5804914e4c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.prompts.prompt.PromptTemplate"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103170b2-9c0d-46de-b18e-b0bc1bff7447",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2b287c-f7e1-4b74-8acd-25f1724b3493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a77fb8a-6fb3-4cd4-81a6-57d0b5e9f41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(langchain.prompts.prompt.PromptTemplate, langchain.llms.openai.OpenAI)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompt), type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4228967f-d08f-45a5-8a9a-603ec170d8b8",
   "metadata": {},
   "source": [
    "Given `prompt` and `model`, create a new chain as bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fa5c4c-58c0-42ba-b7d3-2e780bb38595",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(\n",
    "    llm=model,\n",
    "    prompt=prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c19966-f51c-46a6-b41d-d5fde0cdcd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: Mexico City'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(country=\"Mexico\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65adbb2c-9876-477e-9011-cc13fcd1e5e5",
   "metadata": {},
   "source": [
    "##### Example 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00927fa9-2b5c-48a4-861a-0756f8540f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_prompt = \"\"\"\n",
    "This is a conversaton between a user and an AI\n",
    "\n",
    "User:\n",
    "AI:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda3b731-063a-4013-9f0b-406675ffe6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d50bb9-7a12-4d74-8de5-f2f5479f3086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is a conversaton between a user and an AI\n",
      "\n",
      "User:\n",
      "AI:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(format_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b615f9-a5b1-40c8-8c41-1bae68ea6575",
   "metadata": {},
   "source": [
    "Create a template prompt that stores history\n",
    "\n",
    "**Hint**: Use the format from `format_prompt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15624d02-b1f5-4ba7-874d-0fb717cad8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "This is a conversaton between a user and an AI\n",
    "\n",
    "{history}\n",
    "User: {input}\n",
    "AI:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b894fd0a-9337-497b-b01d-7efc2267b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"history\", \"input\"],\n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc993180-ed70-42f7-a821-1edc26f014ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.prompts.prompt.PromptTemplate"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ae3772-2c9f-4a88-8fda-b0b87cc1a04d",
   "metadata": {},
   "source": [
    "##### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe749be1-5f04-4d1c-bfb6-a03517a88c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5aa4a9-a84c-4c2a-85f2-b75b2ae2b3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(langchain.prompts.prompt.PromptTemplate, langchain.llms.openai.OpenAI)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompt), type(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12266d92-df80-451e-96af-12a745f88a2a",
   "metadata": {},
   "source": [
    "Create a chain that remembers all previous inputs/outputs and adds them to the context that is passed as bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e65d45f-de07-4c2b-8e42-d69924995bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(\n",
    "    llm=model,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=ConversationalBufferWindowMemory(k=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcc9104-fc84-44da-8a37-047be6718762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "This is a conversaton between a user and an AI\n",
      "\n",
      "\n",
      "User: Yo\n",
      "AI:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello there! How can I help you?'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input=\"Yo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c17b3a3-6100-41d6-9821-c62c63a794c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "This is a conversaton between a user and an AI\n",
      "\n",
      "Human: Yo\n",
      "AI: Hello there! How can I help you?\n",
      "User: What did i just said?\n",
      "AI:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You said \"Yo\".'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.predict(input=\"What did i just said?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64994c07-2415-4648-8f1f-cf6be1e092da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
