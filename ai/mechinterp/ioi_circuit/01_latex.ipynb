{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f68931-de62-4fdb-b29f-fd890234015c",
   "metadata": {},
   "source": [
    "The path patching technique, as described in the text, is a method that is used in certain machine learning experiments to analyze the effect of changing a specific part of the model's computation, without altering the entire process. It involves modifying activations of certain nodes while keeping others intact.\n",
    "\n",
    "Here's a step by step breakdown:\n",
    "\n",
    "Gather Activations: Run your model on $x_{\\text {orig }}$ and $x_{\\text {new }}$ to collect the activations that each node in the model's computational graph would produce given those inputs.\n",
    "\n",
    "Freeze and Patch Nodes: Set all of your nodes to their activation state on $x_{\\text {orig }}$ except for one node, h, which you set to its activation state on $x_{\\text {new }}$.\n",
    "\n",
    "Run a Forward Pass: Run the model on $x_{\\text {orig }}$ while keeping the nodes frozen and patched. This means that the frozen nodes won't change their state during this forward pass, whereas the rest of the nodes will compute as usual.\n",
    "\n",
    "Save the Receiver Node Activations: In this forward pass, record the activation state of the receiver nodes as if they were recomputed (though in actuality their values are frozen).\n",
    "\n",
    "Run a Last Forward Pass: Finally, you run the model on $x_{\\text {orig }}$ again, but this time you change the receiver nodes to the saved values from the previous forward pass.\n",
    "\n",
    "The activations stored in $A_{\\text {orig }}, A_{\\text {new }}$ and $A_{\\text {patch }}$ are used to track the changes in the model as we perform this process. They represent the output activations of all nodes, with $A_{\\text {patch }}$ holding the activation states of the nodes in R after patching.\n",
    "\n",
    "Here's a simplified example to further illustrate the process:\n",
    "\n",
    "Suppose we have a simple model that computes a mathematical operation on an input, such as a multiplication followed by an addition. So our computational graph M would be something like this:\n",
    "\n",
    "Multiply by 2 (Node 1)\n",
    "Add 3 (Node 2)\n",
    "Now, suppose $x_{\\text {orig }} = 1$ and $x_{\\text {new }} = 2$, and we want to patch Node 1 (h). R includes only Node 2.\n",
    "\n",
    "Gather Activations: Compute $x_{\\text {orig }}$ and $x_{\\text {new }}$ through the model. For $x_{\\text {orig }}$, we'd have (2, 5) for Node 1 and Node 2 respectively. For $x_{\\text {new }}$, we'd have (4, 7).\n",
    "\n",
    "Freeze and Patch Nodes: We set the activation of Node 1 to 4 (from $x_{\\text {new }}$) while Node 2 remains at 5 (from $x_{\\text {orig }}$).\n",
    "\n",
    "Run a Forward Pass: We would bypass Node 1 (as it's frozen) and only compute Node 2, which would be 4 (from Node 1) + 3 = 7.\n",
    "\n",
    "Save the Receiver Node Activations: We'd record the result from Node 2 as 7.\n",
    "\n",
    "Run a Last Forward Pass: We run Node 1 as normal (resulting in 2), but we'd override Node 2's computation with the saved value (7).\n",
    "\n",
    "Through this patching process, we can isolate the effect of changing Node 1's computation without modifying the entire process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9c2801-e48d-443a-81f3-1a7b05b9a975",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611cfba-167a-414a-9f55-05272c32760a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0678f77-8f4c-4c38-9c06-f4968c318ec0",
   "metadata": {},
   "source": [
    "Here are two example prompts, one from $\\text{p}{\\text{IOI}}$ and one from $\\text{p}{\\text{ABC}}$:\n",
    "\n",
    "$\\text{p}_{\\text{IOI}}$ prompt:\n",
    "When Mary and John went to the store, John gave a bottle of milk to Mary.\n",
    "\n",
    "Here \"Mary\" is the indirect object and \"John\" is the subject that is duplicated. The task is to predict \"Mary\" as the final token.\n",
    "\n",
    "$\\text{p}_{\\text{ABC}}$ prompt:\n",
    "When A and B went to the store, B gave a bottle of milk to C.\n",
    "\n",
    "Here the names A, B and C are random and unrelated. The sentence does not have a single plausible indirect object. This distribution is used to mean-ablate nodes by replacing their activations with the average over $\\text{p}_{\\text{ABC}}$.\n",
    "\n",
    "The key differences between the prompts are:\n",
    "\n",
    "In $\\text{p}{\\text{IOI}}$, there is one name (\"Mary\") that is the true indirect object, while in $\\text{p}{\\text{ABC}}$ there are three random names.\n",
    "\n",
    "In $\\text{p}{\\text{IOI}}$, one name (\"John\") is duplicated as both the subject of the dependent clause and the main clause, while in $\\text{p}{\\text{ABC}}$ the names are unrelated.\n",
    "\n",
    "The $\\text{p}{\\text{IOI}}$ prompt has grammatical structures that support identifying the indirect object, while the $\\text{p}{\\text{ABC}}$ prompt does not.\n",
    "\n",
    "Hope this helps! Let me know if you have any other questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446c926e-dee2-4105-972f-ed32a1b4c760",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
