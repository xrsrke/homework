{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abfc87d7-16fe-4ec5-9838-a745a32f65fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f35a1ad6-e4c6-472d-bc18-2d2a25d026a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f938b7a02b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "534d1cf3-bd46-4fd0-971d-16963aac8faf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# subject_names = [\"John\", \" Mary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51f0f207-cfb0-40be-a39c-463a4c807c6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# subject_tokens = [model.to_single_token(x) for x in subject_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "976affe9-1096-43fe-842d-1fdf0eb7b49f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# subject_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9cdaad-fdfe-4610-a6cb-cd3fca79c9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7ae239-cd2c-4169-a96b-0903b0f70963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d1710f3-aaf3-411c-a64b-637ee98db519",
   "metadata": {},
   "source": [
    "##### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d565686-0e86-4132-ad81-8d33ad682445",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformer_lens import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51b2ad46-f3f3-4cb2-accf-25f45a5e3eb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"John told Mary: 'Persistence is all you need.' Mary replied back to \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19d21eec-c67d-4c26-8aae-a4d88bf5bddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "receiver_hook_name = f\"blocks.{12-1}.hook_resid_post\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c39ceeb3-1587-41e3-afc3-38199bf664f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"gpt2-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bd756a8-8c4f-4940-865e-c7628a8b8baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = model.cfg.n_layers\n",
    "n_heads = model.cfg.n_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48e3a5b3-0951-434f-a8f0-1b9d0102cc3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformer_lens.HookedTransformer.HookedTransformer"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58df8fa6-f23a-4b9c-9f80-6f6fb4116db1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12, 'blocks.11.hook_resid_post')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_layers, n_heads, receiver_hook_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d36a30f-5c1e-4a47-b98b-ddfccb82d113",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"John told Mary: 'Persistence is all you need.' Mary replied back to \""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2001cca7-74b5-4559-b20e-91b3da74d65e",
   "metadata": {},
   "source": [
    "Calculate the importance of the computational path **from head 6 at layer 9 to the final layer (`receiver_hook_name`)** in predicting the indirect object token using activation patching and logit difference. Explain your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca81eeee-dc54-4e44-b816-0396a3f6b3c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corrupted_prompt = \"Laura told Katie: 'Persistence is all you need'. Bread replied back to \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47f805c2-7bda-4908-8fc3-ccae35ae9ccf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clean_tokens = model.to_tokens(prompt)\n",
    "corrupted_tokens = model.to_tokens(corrupted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8ba3938-0b29-4ccd-b89e-19126b2e0792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, clean_activations = model.run_with_cache(clean_tokens)\n",
    "_, corrupted_activations = model.run_with_cache(corrupted_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df23cf0-ea70-4d5a-8d2e-c0e643082997",
   "metadata": {},
   "source": [
    "The attention head to be patched is defined here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c3def1d-a328-46a5-974e-05e0288b561f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "head_idx, layer_idx = 6, 9\n",
    "hook_name = utils.get_act_name(\"attn\", layer_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8d4c84-b015-4e30-8842-4fe2a82b2348",
   "metadata": {},
   "source": [
    "We also extract the activations of this head for the corrupted input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1615dbde-ec4e-4004-8ea9-0f526d2cbffd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18, 18])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_head_activations = corrupted_activations[hook_name][0, head_idx, :, :]\n",
    "corrupted_head_activations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5978773-903e-4c88-bc26-4d3026bbefd0",
   "metadata": {},
   "source": [
    "This function replaces the attention head's activations on the clean input with those from the corrupted input. The function is then added as a hook to the model, and the model is run on the clean input with this modification. This simulates the effect of the attention head's outputs on the corrupted input, but within the context of the clean input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40eee15f-ae08-4785-8d79-0bdbd21bba48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_head_activation(activations, hook):\n",
    "    activations[0, head_idx, :, :] = corrupted_head_activations\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb63c871-97c8-492d-98b0-15455cff5e92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.add_hook(hook_name, patch_head_activation)\n",
    "_, patched_activations = model.run_with_cache(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6aebfa65-a8fc-4efa-8a1b-abb391e74007",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_receiver_activations(activations, hook_name):\n",
    "    return activations[hook_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c48a8d8-cddb-4ea8-82fd-5ae89870bfb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "receiver_activations = extract_receiver_activations(patched_activations, receiver_hook_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746904df-fcca-4036-8970-637f8e002b24",
   "metadata": {},
   "source": [
    "This part of the code is patching the receiver nodes (which, in this case, are the final layer activations) to the state they would be in after the patching of the chosen head. This is done to isolate the effect of the chosen head from the downstream computation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f19e07be-f5bb-4262-86e1-29cfc71280be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def patch_receiver_activations(activations, hook):\n",
    "    activations = receiver_activations\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b3a0402-b8cf-443e-9763-a2ed49d0a4e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.reset_hooks()\n",
    "patched_logits = model.run_with_hooks(\n",
    "    clean_tokens,\n",
    "    fwd_hooks=[(receiver_hook_name, patch_receiver_activations)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23d58629-2ad9-4b71-815f-731607384272",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_logit_difference(clean_activations, patched_activations, target_token):\n",
    "    clean_target_logit = clean_activations[:, -1, target_token]\n",
    "    patched_target_logit = patched_activations[:, -1, target_token]\n",
    "    return patched_target_logit - clean_target_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3eee45-4415-48a7-a232-1915a7649e02",
   "metadata": {},
   "source": [
    "Next, we calculate the difference in logits between the `clean_tokens` and the logits of the `clean_tokens` with the patched computational path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "537f8590-215d-4257-885c-475b2d82ca3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.reset_hooks()\n",
    "clean_logits = model(clean_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93fea368-9d3c-4576-b359-032dcac8159f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_token = model.to_single_token(\"John\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "41b4c226-22b7-49e1-b105-f5171dc11a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = compute_logit_difference(clean_logits, patched_logits, target_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef9a0a3d-c7d5-478c-99aa-4de977b4a72f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0321])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0876ec44-fe77-430f-87f5-c5e25463fae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
