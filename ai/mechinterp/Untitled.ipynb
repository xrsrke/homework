{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60325e4d-1ced-4099-987f-03c860ffb53a",
   "metadata": {},
   "source": [
    "$\\langle h, r, t \\rangle$: This is the representation of a relational fact, where $h$ is the head entity, $r$ is the relation, and $t$ is the tail entity. For example, in the fact \"Paris is the capital of France\", Paris is the head entity, \"is the capital of\" is the relation, and France is the tail entity.\n",
    "\n",
    "$x$: This is the input prompt or the fill-in-the-blank query given to the model. For example, \"The capital of France is _____.\"\n",
    "\n",
    "$\\mathrm{P}_x\\left(\\hat{w}_i^{(l)}\\right)$: This represents the probability of the correct answer given the input prompt $x$ and the activation value of the $i$-th neuron in the $l$-th FFN being set to a given constant $\\hat{w}_i^{(l)}$.\n",
    "\n",
    "$y^*$: This denotes the correct answer to the fill-in-the-blank query.\n",
    "\n",
    "$w_i^{(l)}$: This denotes the $i$-th neuron in the $l$-th FFN in the Transformer model.\n",
    "\n",
    "$\\hat{w}_i^{(l)}$: This is a given constant that the $i$-th neuron in the $l$-th FFN is assigned to during the calculation of the attribution score.\n",
    "\n",
    "$\\operatorname{Attr}\\left(w_i^{(l)}\\right)$: This is the attribution score of the $i$-th neuron in the $l$-th FFN. It quantifies how much this neuron contributes to the prediction of the correct answer.\n",
    "\n",
    "$\\alpha$: This is a variable that ranges from 0 to 1, used to gradually change the activation value of a neuron from 0 to its original value $\\bar{w}_i^{(l)}$ during the calculation of the attribution score.\n",
    "\n",
    "$m$: This is the number of steps used to approximate the continuous integration process when calculating the attribution score. In this study, they chose $m=20$.\n",
    "\n",
    "$t$: This is a threshold for deciding whether a neuron is a \"knowledge neuron\". If a neuron's attribution score is higher than $t$, it's considered a knowledge neuron.\n",
    "\n",
    "$n$: This is the number of diverse prompts or fill-in-the-blank queries produced for a given relational fact.\n",
    "\n",
    "$p%$: This represents a certain percentage of the prompts. In the refining step, a neuron is retained as a knowledge neuron if it is shared by more than $p%$ of the prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6860b7-e875-4049-9448-baa1461f314a",
   "metadata": {},
   "source": [
    "The expression $\\frac{\\partial \\mathrm{P}_x\\left(\\frac{k}{m} \\bar{w}_i^{(l)}\\right)}{\\partial w_i^{(l)}}$ is a derivative which measures how the output of the model changes as we incrementally adjust the value of the $i$-th neuron in the $l$-th FFN layer.\n",
    "\n",
    "To make it more intuitive, let's break it down:\n",
    "\n",
    "$\\mathrm{P}_x\\left(\\frac{k}{m} \\bar{w}_i^{(l)}\\right)$ represents the output probability of the model given the prompt $x$ and a scaled value of the neuron $w_i^{(l)}$. The neuron's value is scaled by $\\frac{k}{m}$, where $k$ is the current step in the approximation and $m$ is the total number of steps.\n",
    "\n",
    "The partial derivative operator $\\frac{\\partial}{\\partial w_i^{(l)}}$ signifies that we are taking the derivative with respect to $w_i^{(l)}$ only, keeping the values of all other neurons constant.\n",
    "\n",
    "So, $\\frac{\\partial \\mathrm{P}_x\\left(\\frac{k}{m} \\bar{w}_i^{(l)}\\right)}{\\partial w_i^{(l)}}$ measures how sensitive the model's output probability is to small changes in the value of $w_i^{(l)}$.\n",
    "\n",
    "If the derivative is large, that means a small change in $w_i^{(l)}$ will result in a large change in the model's output. Therefore, $w_i^{(l)}$ is considered to be an important neuron for that particular output. Conversely, if the derivative is small, that means changing $w_i^{(l)}$ doesn't have much effect on the output, and so it's considered less important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7e4255-ea47-48c5-8427-8e4dbf30ac2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
