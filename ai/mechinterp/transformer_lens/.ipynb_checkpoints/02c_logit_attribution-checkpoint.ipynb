{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5981114a-ea4d-4aea-a779-6e3fd1cfcfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pf/g3nr86yn4j71vzzmv6knwdhr0000gp/T/ipykernel_6396/3994847249.py:5: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"load_ext autoreload\")\n",
      "/var/folders/pf/g3nr86yn4j71vzzmv6knwdhr0000gp/T/ipykernel_6396/3994847249.py:6: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"autoreload 2\")\n"
     ]
    }
   ],
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "ipython = get_ipython()\n",
    "# Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
    "ipython.magic(\"load_ext autoreload\")\n",
    "ipython.magic(\"autoreload 2\")\n",
    "\n",
    "# Import stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.notebook as tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from jaxtyping import Float, Int\n",
    "from typing import List, Union, Optional\n",
    "from functools import partial\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f070e6-0140-473b-a638-76a22c646dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysvelte\n",
    "\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6973a765-afa2-433c-b977-f4f506380208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(tensor, renderer=None, **kwargs):\n",
    "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", **kwargs).show(renderer)\n",
    "\n",
    "def line(tensor, renderer=None, **kwargs):\n",
    "    px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295e1b55-8f29-4948-b806-4aba4edf71e9",
   "metadata": {},
   "source": [
    "### Indirect Object Identification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272d7c41-0a0c-41c6-929d-0ce46a855525",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73bc4b8-567d-4f4b-9a2c-c62945d4bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = \"After John and Mary went to the store, John gave a bottle of milk to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e273ab19-bfd7-4618-b388-3473e1c0aa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_answer = \" Mary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ada276a-b649-4c8d-9ba3-b804f3f31a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'After', ' John', ' and', ' Mary', ' went', ' to', ' the', ' store', ',', ' John', ' gave', ' a', ' bottle', ' of', ' milk', ' to']\n",
      "Tokenized answer: [' John']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.35</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.54</span><span style=\"font-weight: bold\">% Token: | John|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m15.35\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m4.54\u001b[0m\u001b[1m% Token: | John|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 18.09 Prob: 70.07% Token: | Mary|\n",
      "Top 1th token. Logit: 15.38 Prob:  4.67% Token: | the|\n",
      "Top 2th token. Logit: 15.35 Prob:  4.54% Token: | John|\n",
      "Top 3th token. Logit: 15.25 Prob:  4.11% Token: | them|\n",
      "Top 4th token. Logit: 14.84 Prob:  2.73% Token: | his|\n",
      "Top 5th token. Logit: 14.06 Prob:  1.24% Token: | her|\n",
      "Top 6th token. Logit: 13.54 Prob:  0.74% Token: | a|\n",
      "Top 7th token. Logit: 13.52 Prob:  0.73% Token: | their|\n",
      "Top 8th token. Logit: 13.13 Prob:  0.49% Token: | Jesus|\n",
      "Top 9th token. Logit: 12.97 Prob:  0.42% Token: | him|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' John'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' John'\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.test_prompt(example_prompt, \" John\", model, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0af260f-ec3d-425b-8de6-e2d13b5b7d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When John and Mary went to the shops, John gave the bag to', 'When John and Mary went to the shops, Mary gave the bag to', 'When Tom and James went to the park, James gave the ball to', 'When Tom and James went to the park, Tom gave the ball to', 'When Dan and Sid went to the shops, Sid gave an apple to', 'When Dan and Sid went to the shops, Dan gave an apple to', 'After Martin and Amy went to the park, Amy gave a drink to', 'After Martin and Amy went to the park, Martin gave a drink to']\n",
      "[(' Mary', ' John'), (' John', ' Mary'), (' Tom', ' James'), (' James', ' Tom'), (' Dan', ' Sid'), (' Sid', ' Dan'), (' Martin', ' Amy'), (' Amy', ' Martin')]\n"
     ]
    }
   ],
   "source": [
    "prompt_format = [\n",
    "    \"When John and Mary went to the shops,{} gave the bag to\",\n",
    "    \"When Tom and James went to the park,{} gave the ball to\",\n",
    "    \"When Dan and Sid went to the shops,{} gave an apple to\",\n",
    "    \"After Martin and Amy went to the park,{} gave a drink to\",\n",
    "]\n",
    "names = [\n",
    "    (\" Mary\", \" John\"),\n",
    "    (\" Tom\", \" James\"),\n",
    "    (\" Dan\", \" Sid\"),\n",
    "    (\" Martin\", \" Amy\"),\n",
    "]\n",
    "# List of prompts\n",
    "prompts = []\n",
    "# List of answers, in the format (correct, incorrect)\n",
    "answers = []\n",
    "# List of the token (ie an integer) corresponding to each answer, in the format (correct_token, incorrect_token)\n",
    "answer_tokens = []\n",
    "for i in range(len(prompt_format)):\n",
    "    for j in range(2):\n",
    "        answers.append((names[i][j], names[i][1 - j]))\n",
    "        answer_tokens.append(\n",
    "            (\n",
    "                model.to_single_token(answers[-1][0]),\n",
    "                model.to_single_token(answers[-1][1]),\n",
    "            )\n",
    "        )\n",
    "        # Insert the *incorrect* answer to the prompt, making the correct answer the indirect object.\n",
    "        prompts.append(prompt_format[i].format(answers[-1][1]))\n",
    "answer_tokens = torch.tensor(answer_tokens)\n",
    "print(prompts)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4f1863-8f20-486f-b701-b2414b9b1a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(prompts, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70539d58-627c-4dd7-83d6-66308888a9a3",
   "metadata": {},
   "source": [
    "### Direct Logit Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585f60cc-63cd-456b-a8c6-d8bf71dca21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_logits, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0307fa2-f679-4587-8c08-db17ba3363e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa28e953-7efb-4586-b39a-7d899084b2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5335,  1757],\n",
       "        [ 1757,  5335],\n",
       "        [ 4186,  3700],\n",
       "        [ 3700,  4186],\n",
       "        [ 6035, 15686],\n",
       "        [15686,  6035],\n",
       "        [ 5780, 14235],\n",
       "        [14235,  5780]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4429df42-10e8-4d7e-8916-3d16786f3e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_residual_directions = model.tokens_to_residual_directions(answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575e5aa1-34fa-41ee-a430-403ea21f6c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_residual_directions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c8e592-5a40-4982-a01d-535640db6d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_diff_directions = answer_residual_directions[:, 0] - answer_residual_directions[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e9cfec-9cc7-45f5-bd6b-e23a3dd5878f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_diff_directions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229e0563-92a8-4dc2-8a04-eea743422ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5335,  1757],\n",
       "        [ 1757,  5335],\n",
       "        [ 4186,  3700],\n",
       "        [ 3700,  4186],\n",
       "        [ 6035, 15686],\n",
       "        [15686,  6035],\n",
       "        [ 5780, 14235],\n",
       "        [14235,  5780]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474ac5fb-f270-4506-950b-77a51cbecf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3024adb-0e3b-4c28-8aca-a515eaa4a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_residual_stream = cache[\"resid_post\", -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed77589-4e84-477c-ae05-d2e69fa2dad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 15, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_residual_stream.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ad1436-ea5f-45aa-b239-7d3f1928326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_token_residual_stream = final_residual_stream[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08268d70-743b-42c9-9216-143d1a6c4a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_token_residual_stream.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4885a8e-fbea-409f-b84f-d859f95c106a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaled_final_token_residual_stream = cache.apply_ln_to_stack(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2d4ff3-8679-4e11-9d3a-e2b3b46673cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-7.3107e-01,  5.6513e-01, -1.9252e+00,  ...,  5.5697e-01,\n",
       "           1.0524e+00, -4.5406e-01],\n",
       "         [ 1.0534e+00, -4.7922e+00,  8.2390e+00,  ...,  4.0869e-01,\n",
       "          -1.5729e+00, -9.4340e+00],\n",
       "         [ 2.2844e-01,  7.0241e+00,  3.8416e+00,  ...,  2.3653e+00,\n",
       "          -3.0928e+00,  4.4728e-01],\n",
       "         ...,\n",
       "         [ 8.3668e+00, -4.1369e+00,  5.3449e+00,  ...,  1.7024e+00,\n",
       "          -2.4825e+00, -1.7049e+01],\n",
       "         [ 5.7748e+00, -4.0720e-01, -1.0594e+01,  ...,  2.9123e-01,\n",
       "          -3.0663e+00, -2.6462e+00],\n",
       "         [ 9.2831e+00, -5.0196e+00,  8.3061e-01,  ..., -1.3695e+01,\n",
       "           2.4261e+00, -1.2054e+00]],\n",
       "\n",
       "        [[-7.3107e-01,  5.6513e-01, -1.9252e+00,  ...,  5.5697e-01,\n",
       "           1.0524e+00, -4.5406e-01],\n",
       "         [ 1.0534e+00, -4.7922e+00,  8.2390e+00,  ...,  4.0869e-01,\n",
       "          -1.5729e+00, -9.4340e+00],\n",
       "         [ 2.2844e-01,  7.0241e+00,  3.8416e+00,  ...,  2.3653e+00,\n",
       "          -3.0928e+00,  4.4728e-01],\n",
       "         ...,\n",
       "         [ 7.6015e+00, -2.8418e+00,  4.7024e+00,  ...,  1.2065e+00,\n",
       "          -1.8449e+00, -1.8194e+01],\n",
       "         [ 6.0357e+00, -2.8163e-01, -1.0190e+01,  ...,  2.9161e-01,\n",
       "          -2.7763e+00, -3.7952e+00],\n",
       "         [ 4.5560e+00, -1.0375e+00, -9.3817e-01,  ..., -9.0005e+00,\n",
       "           6.6947e+00, -5.5245e+00]],\n",
       "\n",
       "        [[-7.3107e-01,  5.6513e-01, -1.9252e+00,  ...,  5.5697e-01,\n",
       "           1.0524e+00, -4.5406e-01],\n",
       "         [ 1.0534e+00, -4.7922e+00,  8.2390e+00,  ...,  4.0869e-01,\n",
       "          -1.5729e+00, -9.4340e+00],\n",
       "         [ 3.9064e+00, -6.7573e+00,  1.1168e-02,  ..., -5.1852e-01,\n",
       "          -2.7914e+00, -3.7613e+00],\n",
       "         ...,\n",
       "         [ 8.2779e+00, -1.6514e+00,  6.0000e+00,  ...,  1.4845e+00,\n",
       "           2.1246e+00, -1.0360e+01],\n",
       "         [ 4.1014e+00, -5.9506e+00, -2.7241e+00,  ...,  2.5212e+00,\n",
       "           9.7402e-01, -9.0817e+00],\n",
       "         [ 7.9352e+00,  2.8179e+00,  1.7050e+00,  ..., -5.1515e+00,\n",
       "           1.0848e+01,  1.0681e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-7.3107e-01,  5.6513e-01, -1.9252e+00,  ...,  5.5697e-01,\n",
       "           1.0524e+00, -4.5406e-01],\n",
       "         [ 1.0534e+00, -4.7922e+00,  8.2390e+00,  ...,  4.0869e-01,\n",
       "          -1.5729e+00, -9.4340e+00],\n",
       "         [ 1.5950e-01,  2.5955e+00,  3.6687e+00,  ...,  2.5441e+00,\n",
       "          -1.8913e+00,  1.7720e+00],\n",
       "         ...,\n",
       "         [ 1.2196e+01, -6.0147e+00, -1.0844e+01,  ...,  4.1349e+00,\n",
       "          -1.8907e+00, -8.4262e+00],\n",
       "         [ 5.0762e+00,  1.8402e+00, -5.7917e+00,  ...,  9.7049e-01,\n",
       "          -3.0339e+00, -2.9439e+00],\n",
       "         [ 1.0250e+01,  1.9688e+00,  2.8635e+00,  ..., -5.3836e+00,\n",
       "           4.3428e+00, -8.6272e+00]],\n",
       "\n",
       "        [[-7.3107e-01,  5.6513e-01, -1.9252e+00,  ...,  5.5697e-01,\n",
       "           1.0524e+00, -4.5406e-01],\n",
       "         [ 2.3599e+00,  3.9583e+00,  5.6511e-01,  ..., -3.4969e+00,\n",
       "           6.1848e+00, -7.3915e-02],\n",
       "         [-1.1934e+00,  6.7890e+00,  1.7274e+00,  ...,  3.5954e+00,\n",
       "          -3.1539e+00,  5.7652e+00],\n",
       "         ...,\n",
       "         [ 2.9079e+00,  6.1570e-02, -9.8789e-01,  ..., -4.9854e+00,\n",
       "          -5.3014e+00, -5.5623e+00],\n",
       "         [ 3.2953e+00, -1.0462e+00, -1.1876e+01,  ..., -8.8275e-02,\n",
       "          -2.3667e+00, -2.5282e+00],\n",
       "         [ 4.4744e+00,  6.2316e+00,  1.5445e+00,  ..., -7.5424e+00,\n",
       "           1.1315e+01, -8.9223e+00]],\n",
       "\n",
       "        [[-7.3107e-01,  5.6513e-01, -1.9252e+00,  ...,  5.5697e-01,\n",
       "           1.0524e+00, -4.5406e-01],\n",
       "         [ 2.3599e+00,  3.9583e+00,  5.6511e-01,  ..., -3.4969e+00,\n",
       "           6.1848e+00, -7.3915e-02],\n",
       "         [-1.1934e+00,  6.7890e+00,  1.7274e+00,  ...,  3.5954e+00,\n",
       "          -3.1539e+00,  5.7652e+00],\n",
       "         ...,\n",
       "         [ 3.3312e+00, -1.2682e+00, -1.0163e+00,  ..., -3.8607e+00,\n",
       "          -4.8896e+00, -6.5390e+00],\n",
       "         [ 3.3197e+00, -2.5018e+00, -1.1746e+01,  ...,  5.3561e-02,\n",
       "          -3.0484e+00, -2.7336e+00],\n",
       "         [ 6.5328e+00,  5.6787e+00, -4.1082e+00,  ..., -6.2494e+00,\n",
       "           1.0614e+01, -7.4712e+00]]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_residual_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6745fe9-0e03-4c1d-acf9-6f5561ff394f",
   "metadata": {},
   "source": [
    "##### Draft 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6fd63f-f5f8-4760-87aa-0357db40c3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 15])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2d9f96-4ed4-4266-9bf9-a15905257dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_residual_stream = cache[\"resid_post\", -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784c8b4e-9ca5-47cc-b2a4-eb8306adb606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 15, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_residual_stream.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddc844b-0e9a-4067-bc38-98584d665227",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_token_residual_stream = final_residual_stream[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c718125-23d8-4321-807b-d05ba57a5187",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_final_token_residual_stream = cache.apply_ln_to_stack(final_token_residual_stream, layer = -1, pos_slice=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff0bfa-7d08-4afb-b66e-004da77230ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 15, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_residual_stream.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ec6536-10d3-47e3-a20d-56ba8f6e8456",
   "metadata": {},
   "source": [
    "`scaled_final_token_residual_stream` represent the residual stream of the final token in `tokens`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e51ad5-ad31-4d57-86eb-87729586b746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_final_token_residual_stream.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed668a48-6d1d-4161-894f-ce7c24c2524c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 15])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e76b00-2453-446e-b3ea-d646a5edfa38",
   "metadata": {},
   "source": [
    "`logit_diff_directions` is the difference in residual stream of `answer_tokens`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33243706-9757-4175-a8f5-010fed983fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db093b-3bc9-41ce-bbb7-c851612649f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_diff_directions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b89ff-87a2-4cb9-9718-0a6ef9819ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ed82b5-9487-4fc3-a0a3-79e07bbedf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_diff = einsum(\n",
    "    scaled_final_token_residual_stream,\n",
    "    logit_diff_directions,\n",
    "    \"batch d_model, batch d_model ->\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8300a40-d3f8-411e-b9ef-1c6ddeb35943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28.4150, grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b21cf4-dbee-450c-bc48-733089b5312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_logit_diff = logit_diff / len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497dcd7b-1eba-45e5-9561-df0ef9bcb07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5519, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_logit_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f40f04a-8b7e-499c-b168-3d0bfd13fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_stack_to_logit_diff(residual_stack: Float[torch.Tensor, \"components batch d_model\"], cache: ActivationCache) -> float:\n",
    "    scaled_residual_stack = cache.apply_ln_to_stack(residual_stack, layer = -1, pos_slice=-1)\n",
    "    return einsum(\"... batch d_model, batch d_model -> ...\", scaled_residual_stack, logit_diff_directions)/len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5de803-bbf4-49f3-a5dd-c9ae6d2567b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168b3054-7413-46b3-8b54-e28f521475cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a29daac1-7671-4a68-abae-3707d980dc75",
   "metadata": {},
   "source": [
    "`logits_to_ave_logit_diff`\n",
    "- obtain `cache` using `tokens`\n",
    "- extract the logit of the final token from `cache`\n",
    "- extract the logits of the `answer_tokens`\n",
    "- minus the logit difference of two tokens in `answer_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1710fc5-e6b6-4a1b-ae43-431567e84217",
   "metadata": {},
   "source": [
    "`other`\n",
    "- obtain `cache` using `tokens`\n",
    "- extract the `answer_residual_directions` from `cache`\n",
    "- `logit_diff_directions` from the residual directions`, just like minius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2dffce-79d3-4dfc-9593-fc3ac3bfb227",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caba38f-21af-4c08-85a6-d5f3b5ad14cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6597b88-75e8-40f5-b826-f17bf9c41c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 15, 50257])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eccf1a-1990-48f6-a403-9644728a9932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logits_to_ave_logit_diff(logits, answer_tokens, per_prompt=False):\n",
    "    # Only the final logits are relevant for the answer\n",
    "    final_logits = logits[:, -1, :]\n",
    "    answer_logits = final_logits.gather(dim=-1, index=answer_tokens)\n",
    "    answer_logit_diff = answer_logits[:, 0] - answer_logits[:, 1]\n",
    "    return answer_logit_diff.mean()\n",
    "\n",
    "original_average_logit_diff = logits_to_ave_logit_diff(original_logits, answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b530da73-6720-4e1d-a9f2-5da23e63149d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5519, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_average_logit_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a506a-35f9-45b5-84a7-1403f267efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_residual_directions = model.tokens_to_residual_directions(answer_tokens)\n",
    "logit_diff_directions = answer_residual_directions[:, 0] - answer_residual_directions[:, 1]\n",
    "\n",
    "\n",
    "final_residual_stream = cache[\"resid_post\", -1]\n",
    "\n",
    "final_token_residual_stream = final_residual_stream[:, -1, :]\n",
    "\n",
    "scaled_final_token_residual_stream = cache.apply_ln_to_stack(\n",
    "    final_token_residual_stream,\n",
    "    layer = -1,\n",
    "    pos_slice=-1\n",
    ")\n",
    "\n",
    "average_logit_diff = einsum(\n",
    "    scaled_final_token_residual_stream,\n",
    "    logit_diff_directions,\n",
    "    \"batch d_model, batch d_model -> \"\n",
    ")/len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0513805-6357-4381-9bd0-243dcabb4776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5519, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_logit_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580b3a64-6134-4f1c-9c32-e9f528587fed",
   "metadata": {},
   "source": [
    "##### Tokens -> logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d166b9-609a-4eca-a2dd-cea03c55e6b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embed()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e48792-d667-4491-8d68-fe0680fe44fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosEmbed()"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pos_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f544f-5dd2-403f-a927-18ac02f5529f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aed88e2-f46d-4994-b71a-3b081cc41daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = self.hook_embed(self.embed(tokens)\n",
    "\n",
    "if self.cfg.positional_embedding_type == \"standard\":\n",
    "    pos_embed = self.hook_pos_embed(\n",
    "        self.pos_embed(tokens, pos_offset)\n",
    "    )  # [batch, pos, d_model]\n",
    "    residual = embed + pos_embed\n",
    "\n",
    "transformer_block_list = self.blocks\n",
    "\n",
    "\n",
    "residual = block(\n",
    "    residual,\n",
    "    past_kv_cache_entry=None\n",
    "    shortformer_pos_embed=None,\n",
    ")  # [batch, pos, d_model]\n",
    "\n",
    "\n",
    "residual = self.ln_final(residual)# [batch, pos, d_model] \n",
    "logits = self.unembed(residual) # [batch, pos, d_vocab]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
