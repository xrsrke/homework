{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e917c25-9152-4db6-bc03-58f48b5e2231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pf/g3nr86yn4j71vzzmv6knwdhr0000gp/T/ipykernel_8835/4115428919.py:5: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"load_ext autoreload\")\n",
      "/var/folders/pf/g3nr86yn4j71vzzmv6knwdhr0000gp/T/ipykernel_8835/4115428919.py:6: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"autoreload 2\")\n"
     ]
    }
   ],
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "ipython = get_ipython()\n",
    "# Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
    "ipython.magic(\"load_ext autoreload\")\n",
    "ipython.magic(\"autoreload 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7b7bab-2298-4b9e-a9c0-7ded1c2d50d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.notebook as tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from jaxtyping import Float, Int\n",
    "from typing import List, Union, Optional\n",
    "from functools import partial\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffa49fe-10be-4ae9-a931-6d4d5016ff9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysvelte\n",
    "\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8647ddb5-2abd-4a3e-a0bc-0aea867b2e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(tensor, renderer=None, **kwargs):\n",
    "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", **kwargs).show(renderer)\n",
    "\n",
    "def line(tensor, renderer=None, **kwargs):\n",
    "    px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952555e5-76b8-47f6-be24-ecd91b4cd7ab",
   "metadata": {},
   "source": [
    "### Indirect Object Identification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afdb798-34e8-4e9b-9f49-87e369e98b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18acfe7d-aa1d-4785-ab64-e7a046958da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = \"After John and Mary went to the store, John gave a bottle of milk to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b972a6f0-6204-41ac-aea5-e91c37133f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_answer = \" Mary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d0ef61-70fd-447c-89b5-ae51ac1f872e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When John and Mary went to the shops, John gave the bag to', 'When John and Mary went to the shops, Mary gave the bag to', 'When Tom and James went to the park, James gave the ball to', 'When Tom and James went to the park, Tom gave the ball to', 'When Dan and Sid went to the shops, Sid gave an apple to', 'When Dan and Sid went to the shops, Dan gave an apple to', 'After Martin and Amy went to the park, Amy gave a drink to', 'After Martin and Amy went to the park, Martin gave a drink to']\n",
      "[(' Mary', ' John'), (' John', ' Mary'), (' Tom', ' James'), (' James', ' Tom'), (' Dan', ' Sid'), (' Sid', ' Dan'), (' Martin', ' Amy'), (' Amy', ' Martin')]\n"
     ]
    }
   ],
   "source": [
    "prompt_format = [\n",
    "    \"When John and Mary went to the shops,{} gave the bag to\",\n",
    "    \"When Tom and James went to the park,{} gave the ball to\",\n",
    "    \"When Dan and Sid went to the shops,{} gave an apple to\",\n",
    "    \"After Martin and Amy went to the park,{} gave a drink to\",\n",
    "]\n",
    "names = [\n",
    "    (\" Mary\", \" John\"),\n",
    "    (\" Tom\", \" James\"),\n",
    "    (\" Dan\", \" Sid\"),\n",
    "    (\" Martin\", \" Amy\"),\n",
    "]\n",
    "# List of prompts\n",
    "prompts = []\n",
    "# List of answers, in the format (correct, incorrect)\n",
    "answers = []\n",
    "# List of the token (ie an integer) corresponding to each answer, in the format (correct_token, incorrect_token)\n",
    "answer_tokens = []\n",
    "for i in range(len(prompt_format)):\n",
    "    for j in range(2):\n",
    "        answers.append((names[i][j], names[i][1 - j]))\n",
    "        answer_tokens.append(\n",
    "            (\n",
    "                model.to_single_token(answers[-1][0]),\n",
    "                model.to_single_token(answers[-1][1]),\n",
    "            )\n",
    "        )\n",
    "        # Insert the *incorrect* answer to the prompt, making the correct answer the indirect object.\n",
    "        prompts.append(prompt_format[i].format(answers[-1][1]))\n",
    "answer_tokens = torch.tensor(answer_tokens)\n",
    "print(prompts)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdadd63-ec45-4e02-b21f-965282b8fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(prompts, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3dbdf1-fb69-400b-bd5c-9d0d4839e890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50256,  2215,  1757,   290,  5335,  1816,   284,   262, 12437,    11,\n",
       "          1757,  2921,   262,  6131,   284],\n",
       "        [50256,  2215,  1757,   290,  5335,  1816,   284,   262, 12437,    11,\n",
       "          5335,  2921,   262,  6131,   284],\n",
       "        [50256,  2215,  4186,   290,  3700,  1816,   284,   262,  3952,    11,\n",
       "          3700,  2921,   262,  2613,   284],\n",
       "        [50256,  2215,  4186,   290,  3700,  1816,   284,   262,  3952,    11,\n",
       "          4186,  2921,   262,  2613,   284],\n",
       "        [50256,  2215,  6035,   290, 15686,  1816,   284,   262, 12437,    11,\n",
       "         15686,  2921,   281, 17180,   284],\n",
       "        [50256,  2215,  6035,   290, 15686,  1816,   284,   262, 12437,    11,\n",
       "          6035,  2921,   281, 17180,   284],\n",
       "        [50256,  3260,  5780,   290, 14235,  1816,   284,   262,  3952,    11,\n",
       "         14235,  2921,   257,  4144,   284],\n",
       "        [50256,  3260,  5780,   290, 14235,  1816,   284,   262,  3952,    11,\n",
       "          5780,  2921,   257,  4144,   284]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d1a598-f6ae-414c-bc95-8339363c405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_logits, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c934329-bc93-46da-a398-f5290276f7fc",
   "metadata": {},
   "source": [
    "### Direct Logit Attribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2960b3dd-023e-4d2e-8ad6-1ba606137105",
   "metadata": {},
   "source": [
    "##### Flashcard 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7460f1-241c-41cf-b45c-eefd73ac507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_U = model.W_U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef82e90f-b4f0-4c83-82f4-d3c07592badb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.tensor([69, 420])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6127f63a-dd70-461d-b772-0861891b6270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 69, 420])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6281cab5-8a24-4430-892f-a1c8cfe24415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 50257])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_U.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e3bb1f-86aa-48a0-a272-f748acf0144f",
   "metadata": {},
   "source": [
    "Give `W_U` is the unembedding matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380de5c6-a751-432a-a379-f804453d9b40",
   "metadata": {},
   "source": [
    "Extract the residual directions of `tokens`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f3cf28-4c31-4ec4-927f-f7fea8c29466",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_directions = W_U[:, tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5bdf73-0479-4ce4-b3b2-01f6ed3263f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 2])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_directions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc799ea-b324-4e5a-9301-57a8e70d4da9",
   "metadata": {},
   "source": [
    "##### Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb01fbe-bcaa-451d-b1a6-f20fcf72020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_token = torch.tensor(5335)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d239dd52-ba2f-4888-8dc4-934c9a4c5d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_token = torch.tensor(1757)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdbcb7d-fa24-4f63-92a9-593beeb9c9a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformer_lens.HookedTransformer.HookedTransformer"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee4a146-b346-4750-9ecb-5e002d43607f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5335), tensor(1757))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_token, incorrect_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe24564d-35ea-47b3-b98c-3d647688b7dd",
   "metadata": {},
   "source": [
    "Compute the logit difference of the residual directions of two tokens above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddafb34-1690-4ddc-80fc-331e3e81388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_residual_direction = model.tokens_to_residual_directions(correct_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efcaf5b-20da-42cc-957d-77e9291a6639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_residual_direction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4f0bcc-82f9-474a-a048-0fa7118183fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_residual_direction = model.tokens_to_residual_directions(incorrect_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4567e6-067c-43dd-8862-fdf850bc4203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_residual_direction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7eda48-1596-4e41-992c-076330f94d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_diff_direction = correct_residual_direction - incorrect_residual_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2d2282-43ac-4a89-b9cb-fbb5d6f1f7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_diff_direction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c576f9-7d0f-4f73-9ae1-f7d78108dd38",
   "metadata": {},
   "source": [
    "##### Example 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b4d6a7-849c-4030-965b-ff875c3b2fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unembedding = model.W_U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3bd8e4-60c5-44b6-b2ca-2dc019a95aa6",
   "metadata": {},
   "source": [
    "`768` is the dimension of an embedding vector, `50257` is the number of vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7717f8-7fcb-4092-9626-eb2ec70cdc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 50257])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unembedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7743874a-ecc9-4c16-9356-a290602d262e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5335), tensor(1757))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_token, incorrect_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64c3fed-5d9b-4bf0-901a-47843c7e8045",
   "metadata": {},
   "source": [
    "Compute the logit difference of the residual directions of two tokens above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd7fb1c-e06a-4fbb-9592-fb4aebfe3db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_residual_direction = unembedding[:, correct_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11171d5b-31ef-429a-a50c-4bfacc0edb3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_residual_direction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71489709-2e84-4dc3-ad9b-6363fe85b7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_residual_direction = unembedding[:, incorrect_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f827ae-3661-4c35-9b15-0012229a078a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_residual_direction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03137856-6e98-4856-91a0-4771402dfac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_diff_direction = correct_residual_direction - incorrect_residual_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9956aa-3bf2-4413-a6f2-ef42888c3c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_diff_direction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e061e811-2d80-4581-9f79-19bc3d8dcf44",
   "metadata": {},
   "source": [
    "##### Example 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df83b05-ff5e-45b7-bd2a-1dfe06ff0885",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(prompts, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f9474c-1ffa-4485-a931-92bb0d1106f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_logits, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f0cd91-3823-47fc-806c-831e7216e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache.compute_head_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415445ef-289c-4ee1-92da-9bdcd0397e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from einops import rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d234c7c-2fe8-4b7f-b221-1d118108fc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformer_lens.ActivationCache.ActivationCache"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a66561-6db7-4a9c-85ad-3b8462fdafb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blocks.0.attn.hook_q',\n",
       " 'blocks.0.attn.hook_k',\n",
       " 'blocks.0.attn.hook_v',\n",
       " 'blocks.0.attn.hook_attn_scores',\n",
       " 'blocks.0.attn.hook_pattern',\n",
       " 'blocks.0.attn.hook_z',\n",
       " 'blocks.0.attn.hook_result']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[key for key in cache.keys() if key.startswith(\"blocks.0.attn\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27fd4aa-24cd-4455-88ff-2ab623621129",
   "metadata": {},
   "source": [
    "Stack the output of all attention layer from layer `0` to layer `2` as bellow. Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b076ac39-2509-4694-9135-8f5a66bf0dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5e5fac-bcd1-474f-840d-8e51c9be4fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(3):\n",
    "    outputs.append(cache[f\"blocks.{layer}.attn.hook_result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f04f6-8437-45a5-9bac-c8ded7ddb292",
   "metadata": {},
   "source": [
    "The `outputs` list contains the attention outputs from three layers. The output shape for the first layer is `[8, 15, 12, 768]`, which corresponds to a batch size of 8, a sequence length of 15, 12 attention heads, and an embedding of 768."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871e2e29-2c93-4215-be1b-50bad4665e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4250d641-504b-49e2-a52d-842e2891ff99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 15, 12, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8d76fa-07fe-44eb-ae14-ffaf3b0b133b",
   "metadata": {},
   "source": [
    "The goal is to combine all the attention heads from the different layers, which are located along dimension 2 (or the last two dimensions). To do this, the `outputs` are concatenated along dimension 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec0b941-e503-478a-8b79-522f87189032",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.cat(outputs, dim=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929ddf42-306a-4bfe-abd7-a4850f37e877",
   "metadata": {},
   "source": [
    "After concatenation, the resulting output shape is `[8, 15, 36, 768]`, which corresponds to a batch size of 8, a sequence length of 15, 36 attention heads (combined from all layers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7096acf5-0fd4-4b00-8347-5b2ea9c54599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 15, 36, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0aa17f-c2c5-485f-bffc-e63984e5a1e6",
   "metadata": {},
   "source": [
    "##### Example 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7173991-64a6-445a-a1dc-ad131bc141a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = rearrange(outputs, \"... concat_head_index d_model -> concat_head_index ... d_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e29b1e5-c326-46b6-aac1-8913527a3376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([36, 8, 15, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cae29ff-4f52-4514-8de2-aa29d89b0366",
   "metadata": {},
   "source": [
    "##### Example 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44db2609-7f4f-40ba-b27a-2bca9f0aa354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformer_lens.ActivationCache.ActivationCache"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aa51c2-70f7-49c7-a9c6-83c801d309d9",
   "metadata": {},
   "source": [
    "Extract the residual direction of all heads from layer `0` to layer `2` using `transformer_lens`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec62021b-be0b-4e19-a4fe-5712670e035e",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_head_residual = cache.stack_head_results(layer=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0355330c-4a0a-4843-aab4-0c08934d793a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([24, 8, 15, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_head_residual.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c804e833-e332-4710-9bc4-fcee278d11fa",
   "metadata": {},
   "source": [
    "##### Example 6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96e785-93aa-4592-b5dd-5b6e1be4b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(0, 8).view(2, 4)\n",
    "y = torch.arange(0, 8).view(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0726e7-8c70-445a-a07c-43da74e80d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4]), torch.Size([2, 4]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181ced0d-933c-4e2d-b3fb-7388cfed3f69",
   "metadata": {},
   "source": [
    "`x` and `y` have batch size `2`, and dimension `4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e9d9b-0b19-4c2d-b720-a5a410c2d0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3],\n",
       "        [4, 5, 6, 7]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac70354-4f0c-4850-9fc9-8a6f5ae31f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3],\n",
       "        [4, 5, 6, 7]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23288378-7423-4197-875c-9fececf73268",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = (x * y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2600c7-fb89-415d-80fb-5b5a3fe47308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(140)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590a4510-e496-4f49-adb7-551f6065888f",
   "metadata": {},
   "source": [
    "Perform a single operation on x and y using `einops` to do element-wise multiplication between them, and then sum up the resulting value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814f0cb9-9eb7-4b54-8d96-675de653dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13023149-9f16-4eaa-a2cc-e5fd94928d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "einops_output = einsum(x, y, \"batch dim, batch dim ->\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f98f1-e81f-415b-9eac-6d4545ae86d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(140)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "einops_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a4787e-774c-406f-a1f6-97e2e06b76ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output == einops_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6100754-d6c6-4c54-9b12-b087238ff113",
   "metadata": {},
   "source": [
    "##### Example 6.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eb7b04-1b73-4c9a-a6e9-2ec57772ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_logits, _cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4ea3a1-1d3f-464c-adca-d8bb863950ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformer_lens.HookedTransformer.HookedTransformer"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74dd31b6-ed4a-4a1b-aaa3-efbec526f05f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 15, 50257])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d86bc1-bb94-4f37-9e11-0e275d579957",
   "metadata": {},
   "source": [
    "Manually calculate the logits of `tokens` by going through each component of `model` individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e550797-04a5-4dea-90b6-68726b898973",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.pos_embed(tokens) + model.embed(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e73d22-620e-4edc-a993-8660cf0a71af",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f690d8ff-aea9-4c29-8156-0f8cafb7fd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for block in model.blocks:\n",
    "    residual = block(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d7843-f757-4171-a09c-9c1ae8dac67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = model.ln_final(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dca643-4aed-4a7d-9cf7-74bf0d86b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_logits = model.unembed(residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d17bba-e72e-4c1d-836b-c476697c56d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(manual_logits, _logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8c21e1-78ea-4c22-8951-f712e07b96fe",
   "metadata": {},
   "source": [
    "##### Example 6.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40239eb8-dfee-4cd6-a874-5ddd7ece1a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformer_lens.HookedTransformer.HookedTransformer"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec46c0-5dfa-40fb-ade6-fab7deea1395",
   "metadata": {},
   "outputs": [],
   "source": [
    "_embeddings = model.embed(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4006904b-88a5-459a-93a4-6a5a411ab232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformer_lens.HookedTransformer.HookedTransformer"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b969b6-5b96-471f-8c44-ffd60ed97619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 15, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f240c3-0b58-495e-a792-0b114408db65",
   "metadata": {},
   "source": [
    "Retrieve the text embedding matrix of the `model` and compute the text embedding of `tokens` using it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb852ebd-313c-4b84-be90-d416e3f824c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_E = model.W_E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42033ca8-5f10-4948-b076-f18b01b79da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50257, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f88b577-3790-4d57-a865-ebbd73069481",
   "metadata": {},
   "outputs": [],
   "source": [
    "_manual_embeddings = model.W_E[tokens, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84f76fe-bee3-4498-bb4e-e448e06e7706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(_embeddings, _manual_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268ed84b-e95f-461e-bace-ddc276cfcaf8",
   "metadata": {},
   "source": [
    "##### Example 6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfcb7d4-285b-403e-9615-5431add13f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1167cc-63fa-436a-8f71-e1e946642c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 model.W_pos[tokens, :]                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">IndexError: </span>index <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50256</span> is out of bounds for dimension <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> with size <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1024</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 model.W_pos[tokens, :]                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mIndexError: \u001b[0mindex \u001b[1;36m50256\u001b[0m is out of bounds for dimension \u001b[1;36m0\u001b[0m with size \u001b[1;36m1024\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.W_pos[0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27f2908-f01c-4ce3-a580-887b25ff8c2c",
   "metadata": {},
   "source": [
    "##### Example 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9594b0a-3815-4c4b-b92e-26c064611d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_head_residual, labels = cache.stack_head_results(layer=-1, pos_slice=-1, return_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5318e3-5bf4-443e-b5c0-6cac9b59d6e5",
   "metadata": {},
   "source": [
    "`per_head_residual` is ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17555f8-e238-4a13-ac44-8ffedf6f7557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([144, 8, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_head_residual.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdbd82b-8fb1-413c-bb9a-07428ec0bfcd",
   "metadata": {},
   "source": [
    "Calculate the logit difference. Explaindef residual_stack_to_logit_diff(residual_stack: Float[torch.Tensor, \"components batch d_model\"], cache: ActivationCache) -> float:\n",
    "    scaled_residual_stack = cache.apply_ln_to_stack(residual_stack, layer = -1, pos_slice=-1)\n",
    "    return einsum(\"... batch d_model, batch d_model -> ...\", scaled_residual_stack, logit_diff_directions)/len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd03f5a-3474-4406-8310-30939f885d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_residual_directions = model.tokens_to_residual_directions(answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d244d590-3329-410f-a181-5b209cb114c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_diff_directions = answer_residual_directions[:, 0] - answer_residual_directions[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7554760-6ed3-46a0-ad64-c2b536eafc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_head_residual, labels = cache.stack_head_results(layer=-1, pos_slice=-1, return_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fd84ad-98fb-4cf3-9d8a-4effd888a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_stack_to_logit_diff(residual_stack: Float[torch.Tensor, \"components batch d_model\"], cache: ActivationCache) -> float:\n",
    "    scaled_residual_stack = cache.apply_ln_to_stack(residual_stack, layer = -1, pos_slice=-1)\n",
    "    return einsum(\"... batch d_model, batch d_model -> ...\", scaled_residual_stack, logit_diff_directions)/len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9c671f-a34b-4f10-a230-3b8753ecf38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 per_head_logit_diffs = residual_stack_to_logit_diff(per_head_residual, cache)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>per_head_logit_diffs = einops.rearrange(per_head_logit_diffs, <span style=\"color: #808000; text-decoration-color: #808000\">\"(layer head_index) -&gt; lay</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">residual_stack_to_logit_diff</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">residual_stack_to_logit_diff</span>(residual_stack: Float[torch.Tensor, <span style=\"color: #808000; text-decoration-color: #808000\">\"components batch d</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 │   </span>scaled_residual_stack = cache.apply_ln_to_stack(residual_stack, layer = -<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>, pos_slic     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> einsum(<span style=\"color: #808000; text-decoration-color: #808000\">\"... batch d_model, batch d_model -&gt; ...\"</span>, scaled_residual_stack, logi     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/education/miniforge3/envs/gym/lib/python3.8/site-packages/einops/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">einops.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">787</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">einsum</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">784 │   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">785 │   </span>pattern = tensors_and_pattern[-<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>]                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">786 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(pattern, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>):                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>787 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">788 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"The last argument passed to `einops.einsum` must be a string,\"</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">789 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" representing the einsum pattern.\"</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">790 │   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>The last argument passed to `einops.einsum` must be a string, representing the einsum pattern.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 per_head_logit_diffs = residual_stack_to_logit_diff(per_head_residual, cache)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0mper_head_logit_diffs = einops.rearrange(per_head_logit_diffs, \u001b[33m\"\u001b[0m\u001b[33m(layer head_index) -> lay\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92mresidual_stack_to_logit_diff\u001b[0m:\u001b[94m3\u001b[0m                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mresidual_stack_to_logit_diff\u001b[0m(residual_stack: Float[torch.Tensor, \u001b[33m\"\u001b[0m\u001b[33mcomponents batch d\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m\u001b[2m│   \u001b[0mscaled_residual_stack = cache.apply_ln_to_stack(residual_stack, layer = -\u001b[94m1\u001b[0m, pos_slic     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m einsum(\u001b[33m\"\u001b[0m\u001b[33m... batch d_model, batch d_model -> ...\u001b[0m\u001b[33m\"\u001b[0m, scaled_residual_stack, logi     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m4 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/education/miniforge3/envs/gym/lib/python3.8/site-packages/einops/\u001b[0m\u001b[1;33meinops.py\u001b[0m:\u001b[94m787\u001b[0m in \u001b[92meinsum\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m784 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m785 \u001b[0m\u001b[2m│   \u001b[0mpattern = tensors_and_pattern[-\u001b[94m1\u001b[0m]                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m786 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96misinstance\u001b[0m(pattern, \u001b[96mstr\u001b[0m):                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m787 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m788 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mThe last argument passed to `einops.einsum` must be a string,\u001b[0m\u001b[33m\"\u001b[0m                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m789 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m representing the einsum pattern.\u001b[0m\u001b[33m\"\u001b[0m                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m790 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mThe last argument passed to `einops.einsum` must be a string, representing the einsum pattern.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "per_head_logit_diffs = residual_stack_to_logit_diff(per_head_residual, cache)\n",
    "per_head_logit_diffs = einops.rearrange(per_head_logit_diffs, \"(layer head_index) -> layer head_index\", layer=model.cfg.n_layers, head_index=model.cfg.n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e9b27-80b5-434c-a53b-5a3df1454642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
