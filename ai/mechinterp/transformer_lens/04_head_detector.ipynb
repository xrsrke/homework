{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c34e00fb-bf3c-4647-908b-42656b88fe20",
   "metadata": {},
   "source": [
    "# TransformerLens Head Detector Demo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65b2e3d-f230-4d90-b82a-84685b3946d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff109fa6-e227-4044-9104-6ba93fd671c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import einops\n",
    "import pysvelte\n",
    "from tqdm import tqdm\n",
    "\n",
    "import transformer_lens\n",
    "from transformer_lens import HookedTransformer, ActivationCache\n",
    "from neel_plotly import line, imshow, scatter\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde57db5-0d81-4931-9930-04cd2569152e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = 'cpu'\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"{device = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dd5fa9-e4a4-4b53-bbe4-d23065f12e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_head_detection_scores(\n",
    "    scores: torch.Tensor,\n",
    "    zmin: float = -1,\n",
    "    zmax: float = 1,\n",
    "    xaxis: str = \"Head\",\n",
    "    yaxis: str = \"Layer\",\n",
    "    title: str = \"Head Matches\"\n",
    ") -> None:\n",
    "    imshow(scores, zmin=zmin, zmax=zmax, xaxis=xaxis, yaxis=yaxis, title=title)\n",
    "\n",
    "def plot_attn_pattern_from_cache(cache: ActivationCache, layer_i: int):\n",
    "    attention_pattern = cache[\"pattern\", layer_i, \"attn\"].squeeze(0)\n",
    "    attention_pattern = einops.rearrange(attention_pattern, \"heads seq1 seq2 -> seq1 seq2 heads\")\n",
    "    print(f\"Layer {layer_i} Attention Heads:\")\n",
    "    return pysvelte.AttentionMulti(tokens=model.to_str_tokens(prompt), attention=attention_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48272120-bb5f-45d8-a961-1089187b59a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\"gpt2-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159ac0b0-4bb2-4f30-881a-551ef44e94e1",
   "metadata": {},
   "source": [
    "### Head Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6723c198-0b3a-4445-a3a4-bf7c43aa8e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_square(x):\n",
    "    return x.ndim == 2 and x.shape[0] == x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fece36-9460-460c-a951-0a6863307649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_lower_triangular(x):\n",
    "    if not is_square(x):\n",
    "        return False\n",
    "    return x.equal(x.tril())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94feb1e-8bf3-4756-9ec2-5248ad99b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_head(\n",
    "    model,\n",
    "    seq,\n",
    "    detection_pattern,\n",
    "    heads,\n",
    "    cache\n",
    "):\n",
    "    matches = tor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad46fa0-0b83-49b1-9cad-1e1f75287a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = model.cfg.n_layers\n",
    "n_heads = model.cfg.n_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae1028c-26e5-46c5-997e-689b460fd3fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebe04a1-6ef1-4ac4-849b-781714494847",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.zeros(n_layers, n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e212d21-6ec8-4bb3-b07f-8688df89c489",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer2heads = {\n",
    "    layer_idx: list(range(n_heads)) for layer_idx in range(n_layers)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717b5bf5-77bb-4a19-87c3-0ec2abf6cde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       " 1: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       " 2: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       " 3: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       " 4: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       " 5: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       " 6: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       " 7: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       " 8: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       " 9: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       " 10: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
       " 11: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer2heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43620f5-a174-4f41-9d7e-a4fdf4510c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a778bc-40cc-4692-b4e1-0e442c57a8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blocks.1.attn.hook_pattern'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.get_act_name(\"pattern\", 1, \"attn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cf6bfb-e991-4245-a8c6-6fa4834a2e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Persistence is all you need.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec183947-555d-4c86-ac66-4b692c3e47ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7382499-2582-40d5-8b62-0ba9c7834d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b2363a-13a1-4da9-b40f-1c75e055f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_head_attention_similarity_score(attention_pattern, target_pattern):\n",
    "    score = attention_pattern * target_pattern\n",
    "    return score.sum() / attention_pattern.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f950247-d45a-495d-981a-2454a5be3595",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_pattern(tokens):\n",
    "    seq_len = tokens.shape[-1]\n",
    "    pattern = torch.zeros(seq_len, seq_len)\n",
    "    pattern[torch.arange(seq_len), torch.arange(seq_len)] = 1\n",
    "    return pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221fa358-9d81-4a7b-8c49-85e3fa29f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pattern = get_target_pattern(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09acd70d-6232-4137-bb7b-0380c570e478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262cc0aa-ffa4-4ccb-ada8-809b99b5f461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ebbc2-c2dd-49c0-922d-277fd6dcea96",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96764149-ebe4-4c67-86b7-12d467a13a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer_idx=0, head_idxs=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "layer_idx=1, head_idxs=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "layer_idx=2, head_idxs=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "layer_idx=3, head_idxs=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "layer_idx=4, head_idxs=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "layer_idx=5, head_idxs=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "layer_idx=6, head_idxs=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "layer_idx=7, head_idxs=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "layer_idx=8, head_idxs=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "layer_idx=9, head_idxs=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "layer_idx=10, head_idxs=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "layer_idx=11, head_idxs=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n"
     ]
    }
   ],
   "source": [
    "for layer_idx, head_idxs in layer2heads.items():\n",
    "    print(f\"layer_idx={layer_idx}, head_idxs={head_idxs}\")\n",
    "    \n",
    "    hook_name = f\"blocks.{layer_idx}.attn.hook_pattern\"\n",
    "    layer_attn_patterns = cache[hook_name]\n",
    "    \n",
    "    for head_idx in head_idxs:\n",
    "        # set_trace()\n",
    "        head_attn_patterns = layer_attn_patterns[batch_idx, head_idx, :, :]\n",
    "        head_score = compute_head_attention_similarity_score(\n",
    "            attention_pattern=head_attn_patterns,\n",
    "            target_pattern=target_pattern\n",
    "        )\n",
    "        data[layer_idx, head_idx] = head_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e6c27-8563-484f-b49c-621688a6d996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1878, 0.9888, 0.1791, 0.7570, 0.5007, 0.8425, 0.2004, 0.2856, 0.3645,\n",
       "         0.2010, 0.3534, 0.2259],\n",
       "        [0.2204, 0.2185, 0.2602, 0.2743, 0.2132, 0.2384, 0.1680, 0.1819, 0.2130,\n",
       "         0.1605, 0.4746, 0.7680],\n",
       "        [0.2174, 0.1606, 0.2036, 0.1936, 0.1981, 0.2440, 0.2492, 0.3668, 0.2184,\n",
       "         0.1947, 0.2794, 0.1931],\n",
       "        [0.1489, 0.1969, 0.1992, 0.1892, 0.1327, 0.1666, 0.2243, 0.2040, 0.2486,\n",
       "         0.2181, 0.2232, 0.2539],\n",
       "        [0.1834, 0.1760, 0.1549, 0.1920, 0.1501, 0.2024, 0.1614, 0.5871, 0.1408,\n",
       "         0.1688, 0.1483, 0.1250],\n",
       "        [0.1339, 0.1263, 0.1409, 0.1597, 0.1684, 0.1339, 0.1594, 0.1627, 0.1487,\n",
       "         0.1294, 0.1449, 0.2265],\n",
       "        [0.1676, 0.1611, 0.1386, 0.1384, 0.1767, 0.1743, 0.1750, 0.1594, 0.1490,\n",
       "         0.1307, 0.1423, 0.1855],\n",
       "        [0.1532, 0.1368, 0.1259, 0.1558, 0.1426, 0.1501, 0.1388, 0.1310, 0.1659,\n",
       "         0.1522, 0.1273, 0.1286],\n",
       "        [0.1678, 0.1349, 0.1677, 0.1465, 0.1869, 0.1771, 0.1612, 0.1673, 0.1716,\n",
       "         0.1802, 0.1641, 0.1350],\n",
       "        [0.1601, 0.1337, 0.1929, 0.1683, 0.1558, 0.1469, 0.1291, 0.1451, 0.1426,\n",
       "         0.1288, 0.1604, 0.1294],\n",
       "        [0.1327, 0.1363, 0.1367, 0.1455, 0.1674, 0.1789, 0.1385, 0.1432, 0.1335,\n",
       "         0.1737, 0.1337, 0.1548],\n",
       "        [0.2698, 0.1382, 0.1364, 0.2008, 0.1662, 0.1709, 0.1351, 0.1535, 0.5185,\n",
       "         0.1431, 0.2181, 0.2052]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1563acab-708b-4e14-85d1-f0ac1e913f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_previous_token_head_detection_pattern(tokens):\n",
    "    seq_len = tokens.shape[-1]\n",
    "    detection_pattern = torch.zeros(seq_len, seq_len)\n",
    "    detec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076f4861-4c58-4fc6-af10-58c23a8f20b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Persistence is all you need.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e865e88-49b2-4d69-b87e-da96f5abfb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349f9916-3f7d-44c1-b42b-1c7e43378255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50256, 30946, 13274,   318,   477,   345,   761,    13]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a3ef25-f176-48fa-8465-fb52c634487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = tokens.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db94b118-65ef-4608-8654-47eabcae4b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2e7b69-ce0a-4e00-a906-881b232cb617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
