{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2712bae3-5c91-407e-9e90-54830c072db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pf/g3nr86yn4j71vzzmv6knwdhr0000gp/T/ipykernel_2100/4115428919.py:5: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"load_ext autoreload\")\n",
      "/var/folders/pf/g3nr86yn4j71vzzmv6knwdhr0000gp/T/ipykernel_2100/4115428919.py:6: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic(\"autoreload 2\")\n"
     ]
    }
   ],
   "source": [
    "from IPython import get_ipython\n",
    "\n",
    "ipython = get_ipython()\n",
    "# Code to automatically update the HookedTransformer code as its edited without restarting the kernel\n",
    "ipython.magic(\"load_ext autoreload\")\n",
    "ipython.magic(\"autoreload 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2861fdf5-d0ef-4a20-b333-12c633cfc84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.notebook as tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from jaxtyping import Float, Int\n",
    "from typing import List, Union, Optional\n",
    "from functools import partial\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e67e4-42ac-43a0-92e6-42ca9adf0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysvelte\n",
    "\n",
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1d40ed-c2b2-4748-9ac8-c5540e0580dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(tensor, renderer=None, **kwargs):\n",
    "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", **kwargs).show(renderer)\n",
    "\n",
    "def line(tensor, renderer=None, **kwargs):\n",
    "    px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91931c12-7e26-4a81-929f-ac9253bce5d7",
   "metadata": {},
   "source": [
    "### Indirect Object Identification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb68e3-72b9-449f-9b80-61739d7ba3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "    center_unembed=True,\n",
    "    center_writing_weights=True,\n",
    "    fold_ln=True,\n",
    "    refactor_factored_attn_matrices=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63201e94-2428-408b-9b83-bd202218ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = \"After John and Mary went to the store, John gave a bottle of milk to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cd471b-1dd9-4993-b637-f307f8c7bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_answer = \" Mary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d882d8-ef58-4861-92bc-5ab753922afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'After', ' John', ' and', ' Mary', ' went', ' to', ' the', ' store', ',', ' John', ' gave', ' a', ' bottle', ' of', ' milk', ' to']\n",
      "Tokenized answer: [' John']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.35</span><span style=\"font-weight: bold\"> Prob:  </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4.54</span><span style=\"font-weight: bold\">% Token: | John|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m15.35\u001b[0m\u001b[1m Prob:  \u001b[0m\u001b[1;36m4.54\u001b[0m\u001b[1m% Token: | John|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 18.09 Prob: 70.07% Token: | Mary|\n",
      "Top 1th token. Logit: 15.38 Prob:  4.67% Token: | the|\n",
      "Top 2th token. Logit: 15.35 Prob:  4.54% Token: | John|\n",
      "Top 3th token. Logit: 15.25 Prob:  4.11% Token: | them|\n",
      "Top 4th token. Logit: 14.84 Prob:  2.73% Token: | his|\n",
      "Top 5th token. Logit: 14.06 Prob:  1.24% Token: | her|\n",
      "Top 6th token. Logit: 13.54 Prob:  0.74% Token: | a|\n",
      "Top 7th token. Logit: 13.52 Prob:  0.73% Token: | their|\n",
      "Top 8th token. Logit: 13.13 Prob:  0.49% Token: | Jesus|\n",
      "Top 9th token. Logit: 12.97 Prob:  0.42% Token: | him|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' John'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' John'\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.test_prompt(example_prompt, \" John\", model, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a2839d-43f7-4c26-a814-0dde6caac133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['When John and Mary went to the shops, John gave the bag to', 'When John and Mary went to the shops, Mary gave the bag to', 'When Tom and James went to the park, James gave the ball to', 'When Tom and James went to the park, Tom gave the ball to', 'When Dan and Sid went to the shops, Sid gave an apple to', 'When Dan and Sid went to the shops, Dan gave an apple to', 'After Martin and Amy went to the park, Amy gave a drink to', 'After Martin and Amy went to the park, Martin gave a drink to']\n",
      "[(' Mary', ' John'), (' John', ' Mary'), (' Tom', ' James'), (' James', ' Tom'), (' Dan', ' Sid'), (' Sid', ' Dan'), (' Martin', ' Amy'), (' Amy', ' Martin')]\n"
     ]
    }
   ],
   "source": [
    "prompt_format = [\n",
    "    \"When John and Mary went to the shops,{} gave the bag to\",\n",
    "    \"When Tom and James went to the park,{} gave the ball to\",\n",
    "    \"When Dan and Sid went to the shops,{} gave an apple to\",\n",
    "    \"After Martin and Amy went to the park,{} gave a drink to\",\n",
    "]\n",
    "names = [\n",
    "    (\" Mary\", \" John\"),\n",
    "    (\" Tom\", \" James\"),\n",
    "    (\" Dan\", \" Sid\"),\n",
    "    (\" Martin\", \" Amy\"),\n",
    "]\n",
    "# List of prompts\n",
    "prompts = []\n",
    "# List of answers, in the format (correct, incorrect)\n",
    "answers = []\n",
    "# List of the token (ie an integer) corresponding to each answer, in the format (correct_token, incorrect_token)\n",
    "answer_tokens = []\n",
    "for i in range(len(prompt_format)):\n",
    "    for j in range(2):\n",
    "        answers.append((names[i][j], names[i][1 - j]))\n",
    "        answer_tokens.append(\n",
    "            (\n",
    "                model.to_single_token(answers[-1][0]),\n",
    "                model.to_single_token(answers[-1][1]),\n",
    "            )\n",
    "        )\n",
    "        # Insert the *incorrect* answer to the prompt, making the correct answer the indirect object.\n",
    "        prompts.append(prompt_format[i].format(answers[-1][1]))\n",
    "answer_tokens = torch.tensor(answer_tokens)\n",
    "print(prompts)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0994205c-4c68-41c7-ab85-2d09221c9ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = model.to_tokens(prompts, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8610abc1-321d-4e27-b470-f6bf599dcb03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd81c88-0b61-4af3-bfed-faddac6782c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_logits, cache = model.run_with_cache(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837660d5-0a6d-40e7-b864-02e5ea170e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_residual_directions = model.tokens_to_residual_directions(answer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d28a3e-f7ef-4068-8028-4d3b1879ab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_diff_directions = answer_residual_directions[:, 0] - answer_residual_directions[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8610f682-5d27-482d-ac63-310e273434d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tried to stack head results when they weren't cached. Computing head results now\n"
     ]
    }
   ],
   "source": [
    "per_head_residual, labels = cache.stack_head_results(layer=-1, pos_slice=-1, return_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3392b156-78f1-4f88-8450-75ab7abfba91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([144, 8, 768])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_head_residual.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947ff649-6885-44e9-b91f-feecc69f76f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5335, 1757])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e595333-71f1-4eac-916c-862f9da59a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Mary John'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to_string(answer_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc49d5d-7b40-4739-9e03-f670271d2304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_stack_to_logit_diff(\n",
    "    residual_stack, cache\n",
    "):\n",
    "    scaled_residual_stack = cache.apply_ln_to_stack(residual_stack, layer=-1, pos_slice=-1)\n",
    "    return einsum(\"... batch d_model, batch d_model -> ...\", scaled_residual_stack, logit_diff_directions)/len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c144cc40-4b49-41a9-8685-62f2b7d4682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_head_logit_diffs = residual_stack_to_logit_diff(per_head_residual, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9abe8a9-a796-4623-a138-eab5a76814dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([144])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_head_logit_diffs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e493422d-1c14-4def-8a3f-bf5a45e7744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attention_patterns(\n",
    "    heads,\n",
    "    local_cache=None,\n",
    "    local_tokens=None,\n",
    "    title=\"\"\n",
    "):\n",
    "    if isinstance(heads, int):\n",
    "        heads = [heads]\n",
    "    elif isinstance(heads, list) or isinstance(heads, torch.Tensor):\n",
    "        heads = utils.to_numpy(heads)\n",
    "    \n",
    "    if local_cache is None:\n",
    "        local_cache = cache\n",
    "    \n",
    "    if local_tokens is None:\n",
    "        local_tokens = tokens[0]\n",
    "    \n",
    "    labels = []\n",
    "    patterns = []\n",
    "    batch_index = 0\n",
    "    \n",
    "    for head in heads:\n",
    "        layer = head // model.cfg.n_heads\n",
    "        head_index = head % model.cfg.n_heads\n",
    "        patterns.append(local_cache[\"attn\", layer][batch_index, head_index])\n",
    "        labels.append(f\"L{layer}H{head_index}\")\n",
    "    \n",
    "    str_tokens = model.to_str_tokens(local_tokens)\n",
    "    patterns = torch.stack(patterns, dim=-1)\n",
    "    \n",
    "    attention_vis = pysvelte.AttentionMulti(attention=patterns, tokens=str_tokens, head_labels=labels)\n",
    "    display(HTML(f\"<h3>{title}</h3>\"))\n",
    "    attention_vis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89f0417-1ed2-4dfa-8ff1-7e30c7a6684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce8ece3-eba0-401f-873b-aef8ca2cc819",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_positive_logit_attr_heads = torch.topk(per_head_logit_diffs.flatten(), k=top_k).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc9a64b-8c2f-47aa-b573-c567a1a2770b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([117, 114, 120])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_positive_logit_attr_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f503bb6-958e-40f7-b026-148e393075f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_attention_patterns(top_positive_logit_attr_heads, title=f\"Top {top_k} Positive Logit Attribution Heads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf553eef-d77a-43b1-854b-6fab0f4eff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_head_residual, labels = cache.stack_head_results(layer=-1, pos_slice=-1, return_labels=True)\n",
    "per_head_logit_diffs = residual_stack_to_logit_diff(per_head_residual, cache)\n",
    "top_positive_logit_attr_heads = torch.topk(per_head_logit_diffs.flatten(), k=top_k).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ec3fe-f14a-4803-959e-efc104725d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens.utils import get_act_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266456d8-bfdb-4b88-a5e4-0c26b44bc545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blocks.1.attn.hook_result'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_act_name(\"result\", 1, \"attn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefaaac7-2a02-4a5a-b578-76f45235e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_starting_with_attn = [key for key in cache.keys() if key.startswith(\"blocks.1.\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2e1945-0ba5-4822-ab7f-5f4b1c0c243d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blocks.1.hook_resid_pre',\n",
       " 'blocks.1.ln1.hook_scale',\n",
       " 'blocks.1.ln1.hook_normalized',\n",
       " 'blocks.1.attn.hook_q',\n",
       " 'blocks.1.attn.hook_k',\n",
       " 'blocks.1.attn.hook_v',\n",
       " 'blocks.1.attn.hook_attn_scores',\n",
       " 'blocks.1.attn.hook_pattern',\n",
       " 'blocks.1.attn.hook_z',\n",
       " 'blocks.1.hook_attn_out',\n",
       " 'blocks.1.hook_resid_mid',\n",
       " 'blocks.1.ln2.hook_scale',\n",
       " 'blocks.1.ln2.hook_normalized',\n",
       " 'blocks.1.mlp.hook_pre',\n",
       " 'blocks.1.mlp.hook_post',\n",
       " 'blocks.1.hook_mlp_out',\n",
       " 'blocks.1.hook_resid_post',\n",
       " 'blocks.1.attn.hook_result']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keys_starting_with_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a6052d-312b-443d-b0fb-561b935aafa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hook_embed', 'hook_pos_embed', 'blocks.0.hook_resid_pre', 'blocks.0.ln1.hook_scale', 'blocks.0.ln1.hook_normalized', 'blocks.0.attn.hook_q', 'blocks.0.attn.hook_k', 'blocks.0.attn.hook_v', 'blocks.0.attn.hook_attn_scores', 'blocks.0.attn.hook_pattern', 'blocks.0.attn.hook_z', 'blocks.0.hook_attn_out', 'blocks.0.hook_resid_mid', 'blocks.0.ln2.hook_scale', 'blocks.0.ln2.hook_normalized', 'blocks.0.mlp.hook_pre', 'blocks.0.mlp.hook_post', 'blocks.0.hook_mlp_out', 'blocks.0.hook_resid_post', 'blocks.1.hook_resid_pre', 'blocks.1.ln1.hook_scale', 'blocks.1.ln1.hook_normalized', 'blocks.1.attn.hook_q', 'blocks.1.attn.hook_k', 'blocks.1.attn.hook_v', 'blocks.1.attn.hook_attn_scores', 'blocks.1.attn.hook_pattern', 'blocks.1.attn.hook_z', 'blocks.1.hook_attn_out', 'blocks.1.hook_resid_mid', 'blocks.1.ln2.hook_scale', 'blocks.1.ln2.hook_normalized', 'blocks.1.mlp.hook_pre', 'blocks.1.mlp.hook_post', 'blocks.1.hook_mlp_out', 'blocks.1.hook_resid_post', 'blocks.2.hook_resid_pre', 'blocks.2.ln1.hook_scale', 'blocks.2.ln1.hook_normalized', 'blocks.2.attn.hook_q', 'blocks.2.attn.hook_k', 'blocks.2.attn.hook_v', 'blocks.2.attn.hook_attn_scores', 'blocks.2.attn.hook_pattern', 'blocks.2.attn.hook_z', 'blocks.2.hook_attn_out', 'blocks.2.hook_resid_mid', 'blocks.2.ln2.hook_scale', 'blocks.2.ln2.hook_normalized', 'blocks.2.mlp.hook_pre', 'blocks.2.mlp.hook_post', 'blocks.2.hook_mlp_out', 'blocks.2.hook_resid_post', 'blocks.3.hook_resid_pre', 'blocks.3.ln1.hook_scale', 'blocks.3.ln1.hook_normalized', 'blocks.3.attn.hook_q', 'blocks.3.attn.hook_k', 'blocks.3.attn.hook_v', 'blocks.3.attn.hook_attn_scores', 'blocks.3.attn.hook_pattern', 'blocks.3.attn.hook_z', 'blocks.3.hook_attn_out', 'blocks.3.hook_resid_mid', 'blocks.3.ln2.hook_scale', 'blocks.3.ln2.hook_normalized', 'blocks.3.mlp.hook_pre', 'blocks.3.mlp.hook_post', 'blocks.3.hook_mlp_out', 'blocks.3.hook_resid_post', 'blocks.4.hook_resid_pre', 'blocks.4.ln1.hook_scale', 'blocks.4.ln1.hook_normalized', 'blocks.4.attn.hook_q', 'blocks.4.attn.hook_k', 'blocks.4.attn.hook_v', 'blocks.4.attn.hook_attn_scores', 'blocks.4.attn.hook_pattern', 'blocks.4.attn.hook_z', 'blocks.4.hook_attn_out', 'blocks.4.hook_resid_mid', 'blocks.4.ln2.hook_scale', 'blocks.4.ln2.hook_normalized', 'blocks.4.mlp.hook_pre', 'blocks.4.mlp.hook_post', 'blocks.4.hook_mlp_out', 'blocks.4.hook_resid_post', 'blocks.5.hook_resid_pre', 'blocks.5.ln1.hook_scale', 'blocks.5.ln1.hook_normalized', 'blocks.5.attn.hook_q', 'blocks.5.attn.hook_k', 'blocks.5.attn.hook_v', 'blocks.5.attn.hook_attn_scores', 'blocks.5.attn.hook_pattern', 'blocks.5.attn.hook_z', 'blocks.5.hook_attn_out', 'blocks.5.hook_resid_mid', 'blocks.5.ln2.hook_scale', 'blocks.5.ln2.hook_normalized', 'blocks.5.mlp.hook_pre', 'blocks.5.mlp.hook_post', 'blocks.5.hook_mlp_out', 'blocks.5.hook_resid_post', 'blocks.6.hook_resid_pre', 'blocks.6.ln1.hook_scale', 'blocks.6.ln1.hook_normalized', 'blocks.6.attn.hook_q', 'blocks.6.attn.hook_k', 'blocks.6.attn.hook_v', 'blocks.6.attn.hook_attn_scores', 'blocks.6.attn.hook_pattern', 'blocks.6.attn.hook_z', 'blocks.6.hook_attn_out', 'blocks.6.hook_resid_mid', 'blocks.6.ln2.hook_scale', 'blocks.6.ln2.hook_normalized', 'blocks.6.mlp.hook_pre', 'blocks.6.mlp.hook_post', 'blocks.6.hook_mlp_out', 'blocks.6.hook_resid_post', 'blocks.7.hook_resid_pre', 'blocks.7.ln1.hook_scale', 'blocks.7.ln1.hook_normalized', 'blocks.7.attn.hook_q', 'blocks.7.attn.hook_k', 'blocks.7.attn.hook_v', 'blocks.7.attn.hook_attn_scores', 'blocks.7.attn.hook_pattern', 'blocks.7.attn.hook_z', 'blocks.7.hook_attn_out', 'blocks.7.hook_resid_mid', 'blocks.7.ln2.hook_scale', 'blocks.7.ln2.hook_normalized', 'blocks.7.mlp.hook_pre', 'blocks.7.mlp.hook_post', 'blocks.7.hook_mlp_out', 'blocks.7.hook_resid_post', 'blocks.8.hook_resid_pre', 'blocks.8.ln1.hook_scale', 'blocks.8.ln1.hook_normalized', 'blocks.8.attn.hook_q', 'blocks.8.attn.hook_k', 'blocks.8.attn.hook_v', 'blocks.8.attn.hook_attn_scores', 'blocks.8.attn.hook_pattern', 'blocks.8.attn.hook_z', 'blocks.8.hook_attn_out', 'blocks.8.hook_resid_mid', 'blocks.8.ln2.hook_scale', 'blocks.8.ln2.hook_normalized', 'blocks.8.mlp.hook_pre', 'blocks.8.mlp.hook_post', 'blocks.8.hook_mlp_out', 'blocks.8.hook_resid_post', 'blocks.9.hook_resid_pre', 'blocks.9.ln1.hook_scale', 'blocks.9.ln1.hook_normalized', 'blocks.9.attn.hook_q', 'blocks.9.attn.hook_k', 'blocks.9.attn.hook_v', 'blocks.9.attn.hook_attn_scores', 'blocks.9.attn.hook_pattern', 'blocks.9.attn.hook_z', 'blocks.9.hook_attn_out', 'blocks.9.hook_resid_mid', 'blocks.9.ln2.hook_scale', 'blocks.9.ln2.hook_normalized', 'blocks.9.mlp.hook_pre', 'blocks.9.mlp.hook_post', 'blocks.9.hook_mlp_out', 'blocks.9.hook_resid_post', 'blocks.10.hook_resid_pre', 'blocks.10.ln1.hook_scale', 'blocks.10.ln1.hook_normalized', 'blocks.10.attn.hook_q', 'blocks.10.attn.hook_k', 'blocks.10.attn.hook_v', 'blocks.10.attn.hook_attn_scores', 'blocks.10.attn.hook_pattern', 'blocks.10.attn.hook_z', 'blocks.10.hook_attn_out', 'blocks.10.hook_resid_mid', 'blocks.10.ln2.hook_scale', 'blocks.10.ln2.hook_normalized', 'blocks.10.mlp.hook_pre', 'blocks.10.mlp.hook_post', 'blocks.10.hook_mlp_out', 'blocks.10.hook_resid_post', 'blocks.11.hook_resid_pre', 'blocks.11.ln1.hook_scale', 'blocks.11.ln1.hook_normalized', 'blocks.11.attn.hook_q', 'blocks.11.attn.hook_k', 'blocks.11.attn.hook_v', 'blocks.11.attn.hook_attn_scores', 'blocks.11.attn.hook_pattern', 'blocks.11.attn.hook_z', 'blocks.11.hook_attn_out', 'blocks.11.hook_resid_mid', 'blocks.11.ln2.hook_scale', 'blocks.11.ln2.hook_normalized', 'blocks.11.mlp.hook_pre', 'blocks.11.mlp.hook_post', 'blocks.11.hook_mlp_out', 'blocks.11.hook_resid_post', 'ln_final.hook_scale', 'ln_final.hook_normalized', 'blocks.0.attn.hook_result', 'blocks.1.attn.hook_result', 'blocks.2.attn.hook_result', 'blocks.3.attn.hook_result', 'blocks.4.attn.hook_result', 'blocks.5.attn.hook_result', 'blocks.6.attn.hook_result', 'blocks.7.attn.hook_result', 'blocks.8.attn.hook_result', 'blocks.9.attn.hook_result', 'blocks.10.attn.hook_result', 'blocks.11.attn.hook_result'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405c8bc9-6310-4c92-badd-f48f85d28308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 cache[<span style=\"color: #808000; text-decoration-color: #808000\">\"blocks.1.attn\"</span>]                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/Users/education/miniforge3/envs/gym/lib/python3.8/site-packages/transformer_lens/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">ActivationCach</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">e.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">72</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getitem__</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 69 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> key <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.cache_dict:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 70 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.cache_dict[key]                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 71 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">elif</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>(key) == <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 72 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.cache_dict[utils.get_act_name(key)]                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 73 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 74 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(key) &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> key[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>] <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 75 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> key[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>] &lt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'blocks.1.attn'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 cache[\u001b[33m\"\u001b[0m\u001b[33mblocks.1.attn\u001b[0m\u001b[33m\"\u001b[0m]                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/Users/education/miniforge3/envs/gym/lib/python3.8/site-packages/transformer_lens/\u001b[0m\u001b[1;33mActivationCach\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33me.py\u001b[0m:\u001b[94m72\u001b[0m in \u001b[92m__getitem__\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 69 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m key \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.cache_dict:                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 70 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.cache_dict[key]                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 71 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mtype\u001b[0m(key) == \u001b[96mstr\u001b[0m:                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 72 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.cache_dict[utils.get_act_name(key)]                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 73 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 74 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(key) > \u001b[94m1\u001b[0m \u001b[95mand\u001b[0m key[\u001b[94m1\u001b[0m] \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 75 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m key[\u001b[94m1\u001b[0m] < \u001b[94m0\u001b[0m:                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'blocks.1.attn'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cache[\"blocks.1.attn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de57d01d-a722-4786-a486-47c4d1e4312f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
