{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c435421-14c0-4496-84fa-8e18d867099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_imdb(text, label):\n",
    "    return \"The following movie review expresses a \" + [\"negative\", \"positive\"][label] + \" sentiment: \\n\" + text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddab016f-28af-4c1d-a832-9f967d512ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForMaskedLM, AutoModelForCausalLM\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7058a8b-f898-4546-98d3-cede8201df14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_imdb(text, label):\n",
    "    \"\"\"\n",
    "    Given an imdb example (\"text\") and corresponding label (0 for negative, or 1 for positive), \n",
    "    returns a zero-shot prompt for that example (which includes that label as the answer).\n",
    "    \n",
    "    (This is just one example of a simple, manually created prompt.)\n",
    "    \"\"\"\n",
    "    return \"The following movie review expresses a \" + [\"negative\", \"positive\"][label] + \" sentiment:\\n\" + text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c9a32d-133f-4527-898c-9bdbfe39e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hidden_states_many_examples(\n",
    "    model, tokenizer, data, model_type, n=100\n",
    "):\n",
    "    model.eval()\n",
    "    all_negative_hidden_states = []\n",
    "    all_positive_hidden_states = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for _ in range(n):\n",
    "        while True:\n",
    "            idx = np.random.randint(len(data))\n",
    "            text, true_label = data[idx][\"content\"], data[idx][\"label\"]\n",
    "            \n",
    "            if len(tokenizer(text)) < 400:\n",
    "                break\n",
    "        \n",
    "        negative_prompt = format_imdb(text, 0)\n",
    "        positive_prompt = format_imdb(text, 1)\n",
    "        \n",
    "        negative_hidden_state = get_hidden_states(\n",
    "            model,\n",
    "            tokenizer,\n",
    "            positive_prompt,\n",
    "            model_type=model_type\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe4412f-1550-495b-b710-c4d29ef822bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a04de6d-d8d6-4572-975a-83e4bef2d10a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"negative\", \"positive\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f87a9ee-27ec-4a50-b97d-57770e7eb54b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
